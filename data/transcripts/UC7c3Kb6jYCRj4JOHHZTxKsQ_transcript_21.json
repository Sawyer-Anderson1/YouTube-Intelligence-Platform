[
    {
        "text": " It seems like GPT 5.2 is imminent. And of course it is because Gemini 3 just came out. They're sucking up all the oxygen in the room from a media perspective. So of course Open AI has to make a splash before years end. But here's the crazy part. It seems like insiders are trading on prediction markets knowing when 5.2 is going to come out. Here's an example. At sometime late on December 7th, early December 8th, we see a drop from about a 90% chance of GPT 5.2 coming out on December 9th to absolutely nothing to basically like 2 3% essentially not going to happen. And it's becoming clear that these prediction markets are being moved by insiders. And if we actually check out the market on Poly Market, we can see right here, what day will OpenAI next release a new frontier model? They're talking about 5.2 too. And at right about 4:00 a.m. today, the markets are saying it's going to come out on December 11th. A very large increase all the way up to now at 87%. So, it's kind of wild to see that these prediction markets, especially for release dates of models, seem to be moving very suddenly and most likely by insiders who know what's going on. So, this is kind of a combination story. 5.2 to coming very soon, maybe this week, but also insiders seem to be moving the markets. All right, next. Mistral AI has released Devstrol 2 and yes, it is a coding model and it seems to be really good. Of course, Mistral known for putting out open-source openweights models. So, Devstrol 2 comes in two sizes, both opensource, which is phenomenal. And also, they're releasing Mistral Vibe, a native CLI enabling end-to-end automation. So, Devstrol 2 comes in two sizes, 123 billion parameters, and that's under an MIT license, and Devstrol Small, 24 billion under Apache 2.0. It's interesting that they chose two different licenses for two models in the same model family. Both state-of-the-art, open source, free to use, and available now via the API. Here are the benchmarks. So, this is Swebench verified, and we see yes, Devstrol 2 is very much in line with the other Frontier models. It's not quite at the level of Gemini, ChachiBT, and Claude, but it's close enough and it is open source. And also, as I mentioned, they're releasing their command line coding assistant, very similar to Claude Code and other command line coding assistants. And this is a really interesting chart right here. What we see is it is a very small model, but also performs incredibly well. Now, the only models that they're showing on this chart are open source because obviously if it's closed source, we don't know the size. Now, I actually really appreciate that they compared it to Sonnet 4.5 right here. Here's the model performance comparison. Devstrol 2 versus Sonnet 4.5, 21.4% win rate versus 53.1 for",
        "start": 0.16,
        "duration": 348.87800000000004
    },
    {
        "text": "that they're showing on this chart are open source because obviously if it's closed source, we don't know the size. Now, I actually really appreciate that they compared it to Sonnet 4.5 right here. Here's the model performance comparison. Devstrol 2 versus Sonnet 4.5, 21.4% win rate versus 53.1 for finally gone mainstream. Sam Alman, CEO of OpenAI, went on the Jimmy Fallon show. This is the broadest of broad audiences you could possibly get. And now they're talking about ChachiBT. Obviously, most people know at this point what ChachiBT is, but what I found interesting is one of the questions Jimmy Fallon asked at the very beginning. It is still a question that he thought was worthwhile asking to tell his very general audience. Now, imagine they had the Google CEO on there. Do you think he would have asked, \"Okay, tell me what Google search is.\" No, they definitely wouldn't. So, that again is just very telling as to where we are in this journey of artificial intelligence. We are still incredibly early. People are still learning about chat GPT for the first time. And of course, for a very broad audience, he asked very broad questions like, \"Is AI good? What do you use it for?\" And Sam Albin brought out all the hits. All right. Next, Anthropic and OpenAI are working together to start the Agentic AI Foundation. This is an open-source nonprofit where they're donating things that they've built to be put into this nonprofit for the benefit of society. Two things, Anthropic is donating the model context protocol, which really solidified the framework in which agents can call tools. And by the way, the adoption of MCP has been kind of insane. Listen to this. So MCP was introduced a year ago. There are now more than 10,000 active public MCP servers covering everything from developer tools to Fortune 500 deployments. MCP as a protocol has been adopted by Chad GPT, Cursor, Gemini, Microsoft Copilot, Visual Studio Code, and other popular AI products. And MCP is joining the Linux Foundation. That is the foundation tasked with managing the Agentic AI Foundation. This newly created entity. And on the Open AI side, they are donating agents. MD. This is what they describe a simple open format for providing agents with project specific instructions and context. This is the file that you use in your code in whatever coding or project you're using to tell the agents your best practices and your standards for that codebase. And again, agents.md was widely adopted by the industry very quickly. So glad to see both of these protocols have been donated to this open source foundation. And next, OpenAI is launching a certification for their AI course. So basically, you learn all about artificial intelligence through chat GPT and then they give you a badge that you can show off that you are certified and knowledgeable about how to implement artificial intelligence. All right,",
        "start": 174.959,
        "duration": 672.3989999999999
    },
    {
        "text": "source foundation. And next, OpenAI is launching a certification for their AI course. So basically, you learn all about artificial intelligence through chat GPT and then they give you a badge that you can show off that you are certified and knowledgeable about how to implement artificial intelligence. All right, something incredible. This is called super power. It is a 42 megawatt natural gas turbine and it is optimized for AI data centers. Basically, you plop this next to your data center and then all of a sudden you have an enormous amount of energy ready to go. It's basically a jet engine and the company that produced it is Boom Supersonic, which they were working on high-speed commercial jets. I just think this looks really cool. And the CEO of Boom Power, Boom Supersonic, posted a few follow-up items to this announcement. This is one of them. This is the electricity generation over time, the United States compared to China. Now as you can see the United States growing very very slowly and then all of a sudden right around 2000 China absolutely exploded in power generation. They are building so many nuclear facilities and electricity is an absolute requirement to have AI supremacy. So we as the United States and the West need to get our electricity generation game up and this is a fantastic first step forward. what he is proposing. Large arrays of midsize turbines are the blade servers of the energy world. Imagine these enormous servers, these enormous data centers. Blade servers mean you can easily just take out one piece of it. The whole server still works and you can replace it easily. It's just really a modular way to put together big machines. And listen to this. I texted Sam Alman who had been a boom investor for more than a decade. Would 42 megawws nat gas turbine be helpful? The answer was a resounding yes. 90 days later, we had a launch order for 1.21 gawatt and well over 1 and a4 billion backlog. And let me take a moment to tell you about the sponsor of today's video, Dell. And a quick thank you to Dell Technologies for sponsoring this part of the video. Dell Technologies has a family of laptops and desktop PCs featuring Nvidia RTX Pro Blackwell chips, which are absolute beasts for AI workloads. Check out the family of products link down below. And last, speaking of power and data centers, Gavin Baker did a podcast in which he outlined the most important thing that we'll see in the next 3 to four years for data center tech in general, and that is data centers in space. That seems to be what everybody's talking about. Jensen Wong talked about it. Sundar Pachai, the CEO of Google, talked about it. It seems all of these tech leaders are thinking, how do we put data centers in space? And here is why they are thinking that in space you can",
        "start": 340.72,
        "duration": 977.279
    },
    {
        "text": "seems to be what everybody's talking about. Jensen Wong talked about it. Sundar Pachai, the CEO of Google, talked about it. It seems all of these tech leaders are thinking, how do we put data centers in space? And here is why they are thinking that in space you can day. The sun is 30% more intense which results in six times more irradiance than on Earth. So you don't need a battery. The cooling in these data centers is incredibly complicated. Space cooling is free. Now last time I said this, a lot of you talked about thermodynamics and how it's not just well you put it in space and it cools automatically. There's actually a lot more complication than that. But that is what he's saying. You just put a radiator on the dark side of the satellite. The only thing faster than a laser going through a fiber optic cable is a laser going through absolute vacuum. So that is the third piece of this puzzle. Link satellites with lasers and you have a faster and more coherent network than any data center on Earth. Google research published information on project starcatcher which they basically proposed having tons of these satellites flying in close proximity to each other basically powering the next generation of data centers while beaming information between them. It's like the coolest most science fiction thing ever. I love it. So a lot of thought into how to build out the next generation of data center, how to power it, and I can't wait to see how this plays out. Being able to deploy the data center is one thing. Being able to power it in a sustainable way is basically the only thing left that we really need to figure out. So that's it for today. If you enjoyed this video, please consider giving a like and subscribe.",
        "start": 495.28,
        "duration": 1143.1189999999995
    }
]