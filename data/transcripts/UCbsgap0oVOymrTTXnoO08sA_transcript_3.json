[
    {
        "text": " OpenAI just launched GPT 5.3 codec Spark running on Cerebra's hardware for real-time coding. Google upgraded Gemini 3 Deepthink with serious reasoning power and sketch to 3D creation. And Miniax just dropped M2.5 with agent performance so cheap it can run all day. Fast coding, deep thinking, and always on AI agents all landed at once. And this feels like a real shift in how software is about to get built. So, let's talk about it. All right. Open AI first. Codeex has been drifting toward two very different kinds of work. One kind is the long mission where an agent can plan, run tools, grind through a multi-file task, and keep going for a while. The other kind is the tight realtime loop where you're sitting there writing code, tweaking logic, polishing an interface, and you want the assistant to keep up with your pace. Codeex Spark is built for that second mode. OpenAI describes it as a smaller version of GPT 5.3 codeex tuned for fast inference. So it feels near instant. In normal human terms, that means the model is meant to respond quickly enough that you stay in flow. You toss it a function, it edits it. You ask for a refactor, it reshapes the logic. You adjust a UI component, it gives you a clean patch. The point is momentum. And the most important part is how they're powering that momentum. Spark runs on Cerebra's wafer scale engine 3. The WE3. If GPUs are the standard engine most AI inference lives on, Cerebras is like a specialized drag car built for straight line speed. WSE3 is a wafer scale chip, meaning it's built around a huge piece of silicon instead of the typical smaller chip approach, and it's packed with 4 trillion transistors. OpenAI is calling Spark the first milestone in its partnership with Cerebras, which was announced as a multi-year deal worth over $10 billion. That's not a casual side quest. It's a serious bet on a mixed compute future where different hardware exists for different experiences. GPUs stay the foundation for broad usage because they're still the most coste effective way to serve tons of tokens to tons of people. Cerebras becomes the latency first tier where the goal is making the interaction feel immediate. And here's a detail that matters more than most people think. Speed is never just the model. If you've used AI tools that feel fast sometimes and sluggish other times, a lot of that comes from everything around the model. Network overhead, session setup time, time to first token, streaming behavior, all of it adds friction. OpenAI says Spark pushed them to tighten the whole request response pipeline. They mentioned streamlining how responses move from client to server and back, rewriting pieces of the inference stack, improving session initialization so the first token appears sooner, and using a persistent websocket connection so the interaction stays responsive while you iterate. The end result is supposed to",
        "start": 2.639,
        "duration": 332.4819999999999
    },
    {
        "text": "request response pipeline. They mentioned streamlining how responses move from client to server and back, rewriting pieces of the inference stack, improving session initialization so the first token appears sooner, and using a persistent websocket connection so the interaction stays responsive while you iterate. The end result is supposed to faster brain. Now, capability-wise, Spark is meant to be small and fast, not largest and strongest. It ships with a 128k context window and it's text only right now. During the research preview, it has its own rate limits and usage doesn't count against standard rate limits, which is basically a way of saying go play with it, stress it, and teach us how people use real-time coding. It's rolling out for chat GPT pro users inside the codeex app, plus the CLI and the VS Code extension, which is perfect because that covers the three main places devs actually work. OpenAI also backs up the trade-off with benchmark context. On Terminal Bench 2.0, Spark sits at 58.4% while full GPT 5.3 Codeex is higher at 77.3% and GPT 5.1 Codeex Mini sits at 46.1%. That gap is the point. Spark gives up some raw power to get speed and responsiveness. And when you're doing quick edits and rapid iteration, that trade often feels like a win because you aren't asking the model to solve a massive engineering marathon. You're asking it to help you move quickly through dozens of small steps. So the real story with Codex Spark is this. OpenAI is carving out a real-time coding lane where latency matters almost as much as intelligence. And it's pairing that with specialized hardware and pipeline optimizations to make the loop feel snappy. Now, that same momentum is reshaping how AI video actually gets made. Higsfield is sponsoring today's video, and they've built one of the fastest growing creator focused AI production platforms out there, designed to feel more like a real studio workflow than just a prompt box. When you land on Higsfield, everything is structured around how videos actually get made. You start with an idea, shape your shots, and generate and refine inside one connected pipeline. Instead of bouncing between different AI tools for scripts, visuals, and edits, your whole project stays in one place from concept to export. That creator first setup is what really makes the platform stand out, especially if you're trying to produce more than just quick test clips. They already host many of the newest and strongest AI video models, and the latest edition is Clling 3.0, which is honestly one of the most impressive video models out right now. Inside Higsfield's workflow, your script, references, and audio direction all feed into one structure generation process, so scenes flow naturally, camera movement makes sense, and characters and objects stay consistent from shot to shot. In practice, you open a project, drop in a short script or idea, map out the scene, generate your video, tweak timing or visuals, and export something",
        "start": 169.76,
        "duration": 653.8409999999998
    },
    {
        "text": "into one structure generation process, so scenes flow naturally, camera movement makes sense, and characters and objects stay consistent from shot to shot. In practice, you open a project, drop in a short script or idea, map out the scene, generate your video, tweak timing or visuals, and export something Definitely worth checking out if you're serious about AI film making. link is in the description. All right, now back to the video. Now, slide over to Google because Gemini 3 Deepthink is basically the other extreme. Google calls Deepthink a specialized reasoning mode and this upgrade is framed around practical use in science, research, and engineering. So, the vibe is solve modern challenges, not chat better. They talk about collaborating with scientists and researchers and the key idea is handling problems where the data looks incomplete, constraints feel fuzzy, and the path to a solution has a lot of uncertainty. That's exactly the kind of work where normal models can drift, get overly confident, or lose track of details. And Google comes in with a scoreboard. Deepthink is highlighted with 48.4% on humanity's last exam without tools, 84.6% 6% on ARC AGI 2 verified by the Ark Prize Foundation, a 3,455 ELO on Code Forces, and gold medal level performance on the International Math Olympiad 2025. Those are four different flexes aimed at four different audiences. Broad frontier reasoning people with HLE, generalization fans with ARC AGI2, hardcore coding folks with code forces, and math purists with IMO. Now, benchmark numbers can feel abstract. So, here's the grounded translation. Code forces ELO is a competitive programming signal. High ELO means strong algorithmic thinking, building correct solutions under constraints, handling tricky edge cases, and optimizing runtime in a way that's closer to elite programmers. ARK AGI 2 is a different flavor, more like learn a rule from examples and apply it to a new puzzle. People care because it hints at adaptable reasoning rather than just pattern replay. Google also leans into test time compute which is basically giving the model more thinking budget during inference so it can internally verify steps and prune bad paths before it answers. That's a big deal because as models get stronger reliability becomes the real product feature. You want fewer confident wrong answers especially when the domain is science engineering or anything where small mistakes become expensive. And then there's the demo that makes this click for mainstream brains sketch to 3D printing. The claim is that you can draw something. Deep Think analyzes the drawing, models the shape, generates the file, and you can print it. That's a clean bridge between reasoning and real world output. And it also shows why Google is using the phrase practical applications. It's not just solving puzzles. It's taking a fuzzy human input and turning it into a concrete artifact through code. Availabilitywise, this upgraded Deepthink shows up in the Gemini app for Google AI Ultra subscribers, and it's also coming through the Gemini API with",
        "start": 332.479,
        "duration": 979.8399999999998
    },
    {
        "text": "is using the phrase practical applications. It's not just solving puzzles. It's taking a fuzzy human input and turning it into a concrete artifact through code. Availabilitywise, this upgraded Deepthink shows up in the Gemini app for Google AI Ultra subscribers, and it's also coming through the Gemini API with it's positioned as a premium high capability reasoning mode aimed at power users and serious workflows. Now, Miniax comes in with a third angle that's honestly the most disruptive, economics. The story with M2.5 is not fast like Spark or deep like Deep Think. Its agents become practical when you can afford to run them constantly. Miniax introduces M2.5 as a model trained heavily with reinforcement learning across hundreds of thousands of real world environments and it's pitched as soda in coding agentic tool use search office work and other high value tasks. They site 80.2% 2% on SWE bench verified, 51.3% on multiSWE bench, and 76.3% on browse comp with context management. And they also push speed. SWE bench verified finishing 37% faster than M2.1 with endtoend runtime around the same ballpark as Claude Opus 4.6. But the thing they hammer hardest is cost. They basically say worrying about cost should disappear. The headline is run the model continuously for an hour at 100 tokens per second for about $1. And at 50 tokens per second, it drops to around 30. That's a pricing narrative built for agent builders because agents need retries, exploration, tool calls, and do it again, but better loops. And those loops get painful fast when every run feels expensive. Miniax also releases two versions, M2.5 and M2.5 Lightning. same capability, different speed, and both support caching. Lightning sits at 100 tokens per second throughput and has published token pricing of 0.3 per million input tokens and $2.4 per million output tokens, while the slower one costs half. In plain language, they're trying to dominate the cheap, fast, always on lane. And there's a behavioral claim in there that's actually important. M2.5 supposedly plans like an architect before coding. Meaning it tends to break down features, structure, and UI design first, then writes code. That sounds small, but it's a massive difference when you're building anything bigger than a toy demo. Most bad AI generated code comes from skipping structure and rushing to output. Planning first leads to fewer rewrites and less spaghetti. They also flex language breadth and real system coverage. trained across more than 10 programming languages and more than 200,000 environments and designed to handle the full life cycle from setup and system design through feature iteration, review and testing. They even emphasize full stack work, multiple platforms, APIs, databases and business logic, which is the kind of claim aimed at people who are tired of look it built a tiny webpage demos. Now their search and tool section is where agent stuff becomes real. Minia says, \"Good tool calling and search are prerequisites for autonomous work,\" which is basically the",
        "start": 497.599,
        "duration": 1325.7589999999996
    },
    {
        "text": "business logic, which is the kind of claim aimed at people who are tired of look it built a tiny webpage demos. Now their search and tool section is where agent stuff becomes real. Minia says, \"Good tool calling and search are prerequisites for autonomous work,\" which is basically the dense web pages, pulling facts, calling tools, editing documents, and maintaining context under pressure. They highlight evaluations like browse comp and wide search. Then add a benchmark called rise meant to test realistic interactive search on professional tasks where most of the work is deep exploration rather than a quick query. They also talk about efficiency. Fewer rounds, better token efficiency. Around 20% fewer rounds compared to M2.1 across multiple agent tasks. That's meaningful because agent loops can waste time by searching too much, looping too long, or second-guessing without progress. Better decision-making often matters more than raw smartness in a real workflow. And then office work, which sounds boring until you remember most jobs are office work. Miniax claims it trained on deliverable output quality for Word, PowerPoint, and Excel scenarios shaped by collaboration with senior professionals in finance, law, and social sciences. They even describe an internal evaluation framework judging both the final deliverable and the professionalism of the agents process while tracking token costs to estimate productivity gains. Then comes the most dramatic internal claim. M2.5 is deployed inside MiniAX agent and it supposedly completes around 30% of the company's overall tasks autonomously across functions like R and D, product, sales, HR, and finance. They also claim M2.5 generated code accounts for around 80% of newly committed code. If that's even directionally true for their environment, it signals a workflow where the model isn't a helper. It's integrated into the operating system of the company. There's also a stronger push on reinforcement learning. An in-house framework called Forge separates training from inference so agents can plug into different tools more easily. The focus is speed, long context, and rewarding real outcomes like finishing tasks efficiently. In simple terms, the goal moves beyond learning language toward learning how to operate inside real workflows and get jobs done properly. So, I guess the real question now is this. Does faster feedback matter more than deeper reasoning? Let me know what you think in the comments. Hit like, subscribe for more updates like this. Thanks for watching and I'll catch you in the next one.",
        "start": 672.72,
        "duration": 1596.5599999999995
    }
]