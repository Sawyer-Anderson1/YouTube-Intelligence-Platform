[
    {
        "text": " All right, so Google has been on a wild streak lately and the past couple of days dropped update after update across completely different parts of the AI ecosystem. They introduced a new long-term memory system for huge context windows, prepared a cheaper nano banana 2 flash model that performs close to the pro version, quietly tested AI generated headlines on people's phones, and push Gemini's growth so hard that its monthly active users are rising far faster than chat GPTs. And while all that was happening, the Open AGI Foundation dropped Lux, a computer use model that suddenly reshaped the agent conversation entirely. All right, the first big story comes from Google research where they finally opened up about Titans and Myraz. If you remember Titans from last year's paper, that was the moment Google basically hinted they were done accepting the limitations of standard transformers. The problem is pretty simple. Transformers fall apart on super long inputs. Even with all the fancy optimization tricks, the compute cost shoots up like crazy as the context gets longer. And once you push past a few hundred,000 tokens, things stop working the way they should. But if you swing to the other extreme and use something like a modern RNN or a state space model, you gain speed but lose detail because the whole history gets squeezed into one tiny state. It's efficient, but it forgets too much. Titans is Google trying to blend both worlds. It keeps short-term memory through window detention, which is sharp and precise, and then adds a separate long-term memory module that actually updates while the model is running. And that's a big deal because most models today don't genuinely learn during use. Titans chooses what to store based on surprise. The more unexpected something is, the more likely it gets saved. And it forgets in a smart way instead of just wiping old info. Google built three types of this long-term memory. Memory as context, memory as gate, and memory as layer. And the Mac version in particular destroys long sequence tests. We're talking context windows over 2 million tokens and a 760 million parameter model punching way above its weight. It handled the needle in a haststack test with more than 95% accuracy at 16,000 tokens and it dominated the Babylon benchmark where models have to connect facts scattered across huge documents. Titans beat GPT4 recurrent Gemma 9b Llama 3.170B and even Llama 3 paired with retrieval tools. The only real question now is whether these results hold up once people start using Titans in the wild. Because if they do, this could mark the beginning of a shift away from frozen one-time pre-trained models. That's where Mias comes in. Google introduced it as almost a unifying theory for sequence models. When you really zoom out, transformers, Mamba, Retnet, RWKV, Deltanet, they're all versions of the same idea. An internal memory system that stores and retrieves information with different",
        "start": 2.56,
        "duration": 347.1210000000001
    },
    {
        "text": "away from frozen one-time pre-trained models. That's where Mias comes in. Google introduced it as almost a unifying theory for sequence models. When you really zoom out, transformers, Mamba, Retnet, RWKV, Deltanet, they're all versions of the same idea. An internal memory system that stores and retrieves information with different core questions. What shape is the memory? How does the model decide what's worth storing? How quickly does new info push out old entries? And how does memory get updated over time? With that mindset, Google created a new set of attention-free models, Moneta, Yad, and Mamora, each exploring different memory behaviors. And in ultraong context tests, some of them actually outperform Mamba 2 and even classic Transformers. So Miris isn't a single model. It's more like a roadmap for where next generation architectures can go. And you can feel the shift happening already, especially when people like Ilia Sutzkever say they want models that learn the way a talented teenager learns, continuously, actively, and not by chewing through another mountain of static training data. All right, quick pause. You see how we stay on top of AI news every single day and break everything down in a clear, structured way? A big part of that consistency comes from having the right workflow. So, I put together a free guide with 10 of the best prompts to help you with becoming more productive at your job, your business, and you everyday life. You can grab it using the link in the description or by scanning the QR code on the screen. These are the same prompts I use to plan my day, cut through noise, and turn ideas into something usable fast. The AI Power Prompt starter pack is free, it's practical, and it's waiting for you in the description. All right, now back to the video. So, that's the memory side of the story. Now, let's jump to something completely different, but equally important. Lux, the new computer use model from the Open AGI Foundation. And this one is honestly interesting because it feels less like a research toy and more like infrastructure. Lux isn't a chat model with some browser plugin slapped onto it. It actually looks at the screen, reads the UI, and outputs clicks, scrolls, key presses, everything. It's meant to operate full desktops, browsers, spreadsheets, editors, even email clients. And the team says the whole point is to make AI handle real user interfaces instead of depending on APIs for everything. And the crazy part is how well it performs. On the online Mind 2 web benchmark, over 300 real tasks pulled from actual websites. Lux scores 83.6. Gemini CUA sits at 69.0, Open AI operator at 61.3, and Claude Sonnet 4 at 61.0. The gap speaks for itself. Mine 2 Web is brutally unforgiving because every task depends on visual context, shifting layouts, random UI behaviors, and inconsistent design choices. Lux keeps its footing through all of it. Its control system",
        "start": 175.92,
        "duration": 655.2790000000002
    },
    {
        "text": "69.0, Open AI operator at 61.3, and Claude Sonnet 4 at 61.0. The gap speaks for itself. Mine 2 Web is brutally unforgiving because every task depends on visual context, shifting layouts, random UI behaviors, and inconsistent design choices. Lux keeps its footing through all of it. Its control system three levels of autonomy, not for marketing, but because real workflows demand different styles of execution. Actor mode covers the straightforward cases, quick steps like filling forms, pulling reports, or extracting small fields. And it runs at about 1 second per step, which is impressively fast for a model processing full screens. Thinker mode handles broad fuzzy goals and breaks them into steps on its own. Tasker mode delivers full determinism. You supply a Python list of steps and Lux executes them with retries and clean failure handling. Each mode aligns with a different category of real work people actually need to automate and the training method is the real turning point. Open AGI built Lux through agentic active pre-training a process where the model learns by acting inside digital environments instead of only absorbing text or static logs. The system behind this OS gym is open- sourced under MIT and can spin up over 1,000 OS replicas at once generating around 1,400 multi-turn trajectories per minute. This gives Lux experience that comes from direct interaction, not secondhand data. It learns patterns, adapts to unfamiliar layouts, and builds intuition for how real interfaces behave under pressure. The team also reports that Lux ends up around 10 times cheaper per token than OpenAI operator, which completely changes the economics of long multi-step automation. Whether Lux becomes the core engine others build around or triggers a wave of competing systems from Google, OpenAI or Anthropic, it's clear that this entire category of agents just accelerated faster than anyone expected. Now, let's shift to something lighter but still meaningful for the overall AI race. Google appears to be preparing a new model called Nano Banana 2 Flash. Yes, they're sticking with the food names. The pro version of Nano Banana 2 was internally known as ketchup and now references to Mayo started popping up in code. Early access signals that Nano Banana 2 flash performs almost identically to the Pro model but at a much lower operational cost. And this is exactly how Google likes to play this game. They use the Pro models for premium performance and then deploy flash versions for high volume scenarios where cost efficiency is the priority. Based on current signals, the public announcement is probably coming sometime in December. And if it really delivers prolevel quality with flash level cost, Google will immediately widen the distribution of the nano banana line, especially for users who rely on highfrequency image generation or large batch workloads. Flash models are perfect for that because you can run them endlessly without your bill exploding. And since Nano Banana is a major driver of Gemini's engagement numbers right now, dropping a cheaper",
        "start": 332.479,
        "duration": 980.7210000000003
    },
    {
        "text": "the nano banana line, especially for users who rely on highfrequency image generation or large batch workloads. Flash models are perfect for that because you can run them endlessly without your bill exploding. And since Nano Banana is a major driver of Gemini's engagement numbers right now, dropping a cheaper very strategic move. It's basically Google saying, \"We want more people using this model every day at scale.\" But while all of this is happening on the model and infrastructure side, Google quietly rolled out a much stranger experiment inside Google Discover. And this one actually upset a lot of newsrooms. Android users started noticing that Google was rewriting their headlines. Not the articles, the headlines. And not small rewrites, but ones that sometimes completely change the meaning. Journalists from several outlets started reporting examples. PC Gamer wrote a story about a glitch in Balders's Gate 3 that lets players clone in-game child characters. Google Discover turned that into BG3 players exploit children, which is an entirely different implication. RS Technica wrote a piece explaining that Valve had not announced pricing for the Steam Machine and Google's AI rewrote it to Steam Machine price revealed. Other headlines were cut down so aggressively that they lost all context. Stuff like Microsoft developers using AI, which doesn't tell you anything, or weird fragments like schedule one farming backup and AI tag debate heats, which look like generic clickbait slapped next to a publisher's name. Some users saw fourword titles that didn't resemble anything the article said. And the real problem is that the AI label only appears after you tap into the interface. So on the feed, it looks like the publisher wrote it. Editors told reporters they're worried this will erode trust because readers might think the publication intentionally published a misframed or misleading headline. Google said the whole thing is a small UI experiment for a limited set of discover users meant to make topics easier to scan. But they did not address why so many rewritten titles diverge so far from the actual meaning of the articles. And because of everything else happening right now, AI overviews, image glitches, weird political results, misaligned summaries, newsrooms are already skeptical. Watching Google silently rewrite their headlines only adds more tension. And now we get to the final part of this whole wave of updates. The new user data showing Gemini surging ahead in growth. This came just after Sam Alman called a code red in telling his team they need to accelerate development across all product lines and focus on personalization, reliability, image generation, and core features. According to the information, the internal memo connected this to the rise of Gemini 3 and Google's growing momentum. And then Sensor Tower dropped the actual numbers and they explain exactly why Google is feeling confident. Chat GPT still holds the biggest slice of global downloads at around 50%. And it has about 55% of global monthly active users. In raw",
        "start": 497.12,
        "duration": 1291.361
    },
    {
        "text": "rise of Gemini 3 and Google's growing momentum. And then Sensor Tower dropped the actual numbers and they explain exactly why Google is feeling confident. Chat GPT still holds the biggest slice of global downloads at around 50%. And it has about 55% of global monthly active users. In raw monthly active users from August to November, which is massive, but growth slowed. It only climbed around 6% over that period. Gemini, meanwhile, grew around 30% in the same time frame. And the stronger trend is year-over-year. ChatGpt's global MAUs rose about 180%. But Gemini rose 170% and the share gained over the past 6 months shifted in Google's favor. Gemini's MAU share climbed by 3 percentage points from May to November, while Chat GPT lost 3 percentage points from August to November. Downloads tell a similar story. Gemini up 190% year-over-year, Chat GPT up 85%, Perplexity up 215%, and Claude up 190%. Engagement also paints a clear picture. Gemini users now spend around 11 minutes per day inside the app, which is up 120% since March. Chat GPT's inapp time grew only around 6%. And all of this is being driven by the nano banana image generator which exploded in popularity, especially among younger users who treat it like a creativity engine built directly into Google's ecosystem. The distribution advantage is massive, too. In the United States, twice as many Gemini users access it through Android as through the standalone app. And in markets like India, where Android dominates, that advantage scales even harder. It basically turns Gemini into the default AI for millions of people before they ever search for alternatives. Open AAI's response, prioritize upgrades and put advertising experiments on hold. The team is now fully focused on developing a new model cenamed Garlic, which insiders say is meant to outperform Gemini 3 in coding and reasoning tasks. The timing shows how seriously they're taking Google's acceleration. When your competitor grows five times faster in active users, you react immediately. And that's exactly what the code red represents. And with open AI preparing garlic, anthropic scaling sonnet 4, perplexity climbing hard in search, and lux entering the agent arena with numbers that outclass everyone else, the space is about to shift again, probably sooner than anyone expects. Thanks for watching, and I'll catch you in the next one.",
        "start": 654.72,
        "duration": 1556.9610000000007
    }
]