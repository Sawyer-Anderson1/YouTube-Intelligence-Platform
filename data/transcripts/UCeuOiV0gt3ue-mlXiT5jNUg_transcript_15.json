[
    {
        "text": " From model to movement, we have only one step, but it is the most difficult step to make. Embodied AI, where sensors, maps, and decisions converge into a trajectory about the practices and errors of the real world is going to be discussed by our next speaker. the head of the mobile robotics lab at Scholtech, Gonzalo Ferrer Mingus with the report embodied AI. Okay. thanks everyone for having me and I will try to present slides. So the question is what is robotics doing in the AI era? Okay. So today there have been very good speakers talking about different variants of AI right so autonomous driving natural language processing. So I will discuss from the perspective of my lab right and we work on robotics. So first of all as introduction the lab is a mobile robotics lab. Okay. So we have PhD students master students researchers. This is a picture of us, right? We have several robots and this is a university group research group. Okay, so well basically we have limited resources. What are the topics that we are interested in studying? So slam planning sensor calibration today I'm going to talk mostly about planning. Okay, what can we do for navigating robots? And there's also some courses that are related to these topics that are perception in robotics explaining all these problems about slam and the second one is planning algorithms right which is happening right now. Okay. So this is the summary in one slide of what are our research projects going on. Okay. So the main goal is to make robots navigate in the real world. Okay. So we want to go outside the lab because the real world is very rich. There's very unique structures objects that are not commonly find and a lot of corner cases that are required for having true autonomy. Okay, we have some robot manipulation like this one in in the in the image. Okay, this is also like mounted in a in a wheel platform and we also have we also are interested in studying wheel robotic platforms. Okay. so let's do a little comparison with other other AI fields. Okay. So for instance natural language processing on computer vision they had tremendous success. Okay. We have all seen like some of these models being developed and really advancing very quickly. Okay. So I'm going to compare later with robotics. So all of them have in common like this approach. There was like pre 2010 okay before the deep learning era and after this there was like rapid succession of network architectures and there was more and more data available. Okay. And we see how the path actually bring great success to both of of these topics. So just to have an idea of what the magnitude of this data we are talking about. So for instance for images in 201 11 I think appear image net it was revolution for computer vision there",
        "start": 0.0,
        "duration": 457.08
    },
    {
        "text": "how the path actually bring great success to both of of these topics. So just to have an idea of what the magnitude of this data we are talking about. So for instance for images in 201 11 I think appear image net it was revolution for computer vision there the amount of data we are talking went from millions now to trillions right so trillions of data that for instance lamatu is using or other NLP models out there so well this data is available it's obtained in the internet. either text either like images you need to mine them but basically the effort was on obtaining them. After you get this then with enough computational resources and a team of people working on getting all these models trained properly. we see like these tremendous success cases like image generation segmentation like this is seen understanding. We also have like many families now of chats like really really being capable of providing solid answers and well this is kind of summary that I think has got to most to to many people already right to most of the population this is outside research now it's kind of being deployed so I think almost majority of people have access one way or another one of these large models So the question is how is this road of success looks for robotics? So there's great cases of success okay but still it's not really taking off as as quickly as maybe the other disciplines right are doing. So let's analyze this a little bit. We also start with classical methods and I'm going to discuss what these classical methods mean. Okay, because we start with these representations already. So everything has inertia, right? It comes from story and then there's the same u network architectures that are available for everyone. Okay, all fields could be using them. And then there's this question about massive data. Okay, so what this massive data means? robots can generate a lot of data but this is not useful always, right? or not exactly like that. And then what we see is that although there's cases of success, this growth is not has not been as spectacular as in other fields. Okay. So, this is just like criticism. It's not really like a pessimist. Okay. I'm really optimist on on success and wrote ahead in robotics. But I'm just bringing here a little bit of discussion right on on current estate and comparing with with other fields. So the classical methods for robotics start with parading that is very strict. Okay. So let me explain about this. most of these applications rely on a representation that is an accurate map. Okay. So after you have this accurate map, it could be like equivalent to the blueprints of a building. Okay, you have walls, you have all these spaces. from this you can start you can start like defining robotic task like go to places",
        "start": 241.599,
        "duration": 850.3610000000001
    },
    {
        "text": "representation that is an accurate map. Okay. So after you have this accurate map, it could be like equivalent to the blueprints of a building. Okay, you have walls, you have all these spaces. from this you can start you can start like defining robotic task like go to places approach requires high precision sensors like lighters and a little bit more expensive sensors. Okay. So with this you create high quality map then you are able to kind of also update it and and localize in this map. And the problem is when this map representation fails all this approach is not so useful. Okay. So that's why I'm here I'm discussing that maybe this representation is very strict is not as flexible and this is the initial point. Okay. So from here there's many problems that come because now the new paradigm that we are discussing is datadriven. Okay. So somehow we cannot really take away all these classical algorithms but but we need to build on the more powerful algorithms that are all the machine learning and the AI are giving us. Okay. So on the network architectures I think there's not much to discuss. They have proven to be very effective. So it's just a problem of how to train them properly and for this well you have like ways of training but also the most important part is the data okay and this is this question that we are raising now what is this equivalent to massive data so internet scale right like all images in internet all text available all these kind of things what is the equivalent of this for robotics okay So the problem is there are several ways of obtaining data. Okay. we have seen examples but it's not exactly the same kind of data and this is what's makes what is making this problem more complicated for the field. So if you imagine a task that requires manipulation holding an object in your hand is very complex. Okay. So this is structure over time. Okay. There is physical interaction. There is cause effect. If you think about it in text, okay, in text there will be a sentence saying that a person is holding an object. Okay, so there all these kind of complexities are disappearing. This is just a representation, right? Language is representation. so the data is simply more complex and we need to deal with this. We need to find ways of dealing with this. It's also more expensive to acquire. So imagine someone here like providing examples on how the robot is should be manipulating how it we should be moving around. acquiring these examples in real world is expensive. So this is another problem and basically also the complexity is very high. Environments have a lot of elements. You don't you cannot know for sure if all elements are important or only some of them. You cannot discard any of these. Right? So this basically",
        "start": 439.84,
        "duration": 1233.9610000000002
    },
    {
        "text": "real world is expensive. So this is another problem and basically also the complexity is very high. Environments have a lot of elements. You don't you cannot know for sure if all elements are important or only some of them. You cannot discard any of these. Right? So this basically important. Remember what we had before for the classical approach is maps highquality maps and from here we build stuff. So in these maps we have like static objects walls and these kind of other objects that are represented there. So if we go away from this paradigm and we just have like data and from this data we train algorithms then understanding these scenes becomes very comp complicated. Okay. So it's also a problem of representation. So well we can discuss on this but too simple which is what we had before what you have is limited results too complicated then there is no interpretability and you can even fail on understanding and executing task. Okay. So there must be some balance here. Okay. And then the question and this is the discussion I want to bring to you right. so what can we do? What can robotics do? I mean we hope to get like great success on our research developing new models but we see that there are some limitations right. So one of the things that one of the main things o of the success was the amount of data okay collected and for this we can do several things okay so we could produce these examples from robots and then just generate enough data to train algorithms similar as it was done before. This is realistic but very expensive. Okay. So this is always something that people try to avoid. if not done properly. Okay. second is we should be using augmentations properly and by augmentations means like maybe changing objects, maybe changing little things on the scene that are enough to provide v variability on the data that we are going to be used for training. there's the whole different approach which is simulation. Okay, let's simulate environments. And here there has been massive progress also every time models are more realistic, images generated are undistinguishable from real images, right? So it it's getting really great but still there is a gap. Okay, so simulation is not the only thing. and then there's also very interesting approach which is you could be mining videos from the internet and solve the domain gap let's say from seeing some people doing manipulation or some task transferring this problem to robots. Okay. So there are some differences. This is what we call like this gap. Okay. but if you can solve this you can use like a tremendous amount of data that has been recorded in films in videos etc etc. Okay. So then a proposal this is just a view is that just to make this path robust and solid to continue",
        "start": 637.12,
        "duration": 1633.5619999999994
    },
    {
        "text": "this gap. Okay. but if you can solve this you can use like a tremendous amount of data that has been recorded in films in videos etc etc. Okay. So then a proposal this is just a view is that just to make this path robust and solid to continue bit. So we need to create like ways to generate more data and not just more data but also data that are quality data. Okay. So we also need better representations and this means that we might have to develop new algorithms that might be fundamental algorithms. we will be using all the network architectures that are there and with this kind of new data well progress should be I mean progress in in what capabilities are for robots should should improve okay so let's look a little bit on some of the things we are doing in the lab now so this was more like general discussion I think it's important right because this is the time we are living many of the speakers today were discussing about data That's one of very important things not just for robotics but in general. So some of the things we could be doing is let's record data but it must be high quality. What does it mean high quality? It should have annotations maybe trajectories maybe semantics traversability if you're a robot that wants to understand how to move in the world and these things. So for instance this was an effort that we did recently. So this is the ego data set. We were providing a lot of examples of walking walking examples in the region of Moscow and we were using this for training our model. Okay, we were including all these other extra annotations because imagine you just have a video of someone walking. Okay, fine. You understand that things are going on but maybe you require more data than that. Okay, maybe you need the context. Maybe you need like annotations of what is going on. Maybe you want to annotate when you have a collisions. All these things is what I'm discussing about high quality data. Okay. So in the ego data set we were comparing with others. Of course this is an approach that people are taking in other places. At the end some of these models are trained in jointly. So they take data sets from everywhere. They put this together and this ensures more variability. So our data set was composed of scenes, indoor, outdoor, annotations, everything. this is examples of where we were recording here. So we have parks, indoors, museums, night, day, different times of the the year. This actually matters when we are recording when we want to gather as much diverse data as possible. Okay. And well you see the kind of environments that were considered here and this is distribution of of the times of the year and maybe the kind of",
        "start": 839.12,
        "duration": 1974.6019999999987
    },
    {
        "text": "the the year. This actually matters when we are recording when we want to gather as much diverse data as possible. Okay. And well you see the kind of environments that were considered here and this is distribution of of the times of the year and maybe the kind of quality data also means that it needs to be diverse. If I collect like 100 hours in the same environment is not going to help us at all. Okay. So this was the acquisition platform here. Well we also did development. So this is other part of things we need to do in the lab. This is system integration. Okay, in this case working with sensors and with a recording platform and well this is like some of the other augmentations in this case traversability just looking at more lightweight algorithms that later can navigate in environments. Okay. also like thinking about this idea about efficiency there is like this whole question about knowledge graphs. Okay, this is very important topic in retrieval. Okay, just for text but it can also be used for us in robots. and this is a way to represent the scenes. Okay, so we are going to have now a bunch of objects in the scene and we are going to have places represented only as images. So this is a substitution of this highquality map that I was talking before. There is relation between objects. Okay. So chairs are on on the floor. maybe chair is standing next to a table or a door is open or closed. Okay, there's relations there that need need to be considered when we do navigation. So, in this case we were proposing how to create like this scene representation. Okay, we were collecting videos breaking it into chunks creating graphs and this graph is actually holding all the import all the important information in the scene all objects that are se segmented and we also look for consistency of objects. Okay. And you need to think about it as open vocabulary graph representation where maybe an object is detected here as a chair and then a little bit later is detected as blue chair. Okay, but they are the same object. So we need to unify this and after creating a graph we are capable of doing simple task. Okay. So the task could be like find me a printer or navigate me to the exit. Okay. well basically this is the idea also how we are constructing the graph. Okay. And at the end yes this is important thing. We want to preserve identity of object objects. So it's not just the objects but it's also the places and the objects. Right. So all these nodes live in the same graph. Okay. So, a navigation query will look like this. , we just find like a task and the most relevant things are just search over over it. Okay. Let me",
        "start": 1011.839,
        "duration": 2334.040999999999
    },
    {
        "text": "the objects but it's also the places and the objects. Right. So all these nodes live in the same graph. Okay. So, a navigation query will look like this. , we just find like a task and the most relevant things are just search over over it. Okay. Let me better. so we are asking here how to get to where to put our code. Okay. So in this case we look at the graph and it's telling us in which frame frame here is like what picture is that the most relevant that gives you the information. So in this case it's successfully giving you this information looking for a printer asking questions about the scenes and these kind of things. Okay. So after we have this we can have actually robot living in this kind of environment and having like very rich set of task that are just every time check with the with this scene representation. Okay. Well, I think I'm running a little bit out of time. So, , let me go fast on this. We definitely think this is good representation for us. , this is on top of the data that we were collecting. Another project that is going on is I didn't talk about this until now but manipulation. So, it's very similar kind of robots. Okay, they have more degrees of freedom. But this problem is also like how we are giving data. So there is a manipulator volunteer that moves the robot and the robot then takes what the arm is doing on the volunteer it's exactly replicated on the robot. Okay. So that's how we are manipulating these robots and with this we can collect data and then the question is what kind of augmentations we could be doing. Okay. So these two images are from the same scene but if you see they are a little bit different right? So the chair is different, the robot below is is different, the table is different. This is just like augmentations we do with computer vision. Okay, so this is just to have a little bit more variability. Okay, so well that was like very fast but just to say look there's different robots but at the end all of them have the same problems. So in this case this data is more complex okay either for manipulation or for walking around it's more complex we need to deal with this at the same time this is a opportunity right because we still need to understand what is a data okay for other disciplines data might be a label it's a cat it's a dog or maybe a sentence right you can remove parts of this and it's fine maybe for a robot data sample removing parts is not an option because then you are missing crucial information. So this quality data okay we need more augmentations more modalities the more we can get because still the data",
        "start": 1194.16,
        "duration": 2648.6019999999985
    },
    {
        "text": "sentence right you can remove parts of this and it's fine maybe for a robot data sample removing parts is not an option because then you are missing crucial information. So this quality data okay we need more augmentations more modalities the more we can get because still the data still like better ways of presenting it. Okay. and we also think that a representation of the environments is important. So this is a problem that cannot be solved with brute force. Okay. So better representations will give us like algorithms that are a little bit more I think capable just by less using less resources. Okay. So this is something that we should not lose. okay so that's that's the presentation. Thank you so much. yes, thank you professor. Okay, goodbye. We thank all of the keynote speakers, all of the participants today. Science is showing what it's capable of. Fewer dogmas, more testable hypothesis. Over these three days, we now have gained a clearer understanding finances, regulations take the speed from AI and science gives it depth and sustainability. Thank you for the frank conversation and the readiness to ride the wave with AI. We are going to learn about the authors of the best papers for AI journey scientific journal, the winners of AIG contest and the more effective participants of AI challenge. Very short break just 5 minutes and we resume here for the ceremonies for the continuation.",
        "start": 1354.0,
        "duration": 2844.441999999998
    }
]