[
    {
        "text": " One of the simplest ways of making your AI agents more powerful is by simply giving them access to Bash. But that can be a little complex. You need a real shell. You need a file system, servers, and containers, and overall just a lot of infrastructure. Or at least you did. But what if I told you there's a simpler way? You can actually just use a TypeScript implementation of Bash. Now, I know that might sound a little bit crazy, but trust me, this is super cool and it could even save you money. Let me show you how. This is a new package called Just Bash. And you can see on that readme, it says it's a simulated bash environment with an in-memory virtual file system written in TypeScript. This is designed for AI agents that need a secure sandboxed bash environment. But before I show you how you can actually link this up to your AI agents to give them more capabilities. I just want to show you some really simple code so you have some context for how this works. Here I'm starting a new bash environment from the just bash package. And inside of that, we can run our bash command. So we're doing env.exec. And here I'm simply running the bash command of echohhello and saying I want to save that to a file called greeting.txt. Then on the next line I'm running an exec again in the same environment saying I now want to read that greeting.txt file. And you can see we can actually log out the standard output of the result that we get back there. The exit code and also the environment variables. And when I run this you can see it has successfully written that file and also read it. We get an exit code of zero and then the environment variables in our simulated bash shell. But the important thing to remember here is as I said this is just a simulated bash shell. This is literally a version of those bash commands written in Typescript. So it's not actually attached to any real shell. It's simply converting the command that we give it here into TypeScript and running that. So this file as well called greeting.txt that doesn't exist on any file system. That's actually an in-memory virtual file system. Although there are options if you do want to attach a real one. So a simple way of thinking about what it's doing is it's simply taking the bash command that we write inside of the exec function and converting that into a JavaScript function which it then runs which means that it doesn't need a real shell. And we can actually see that in that codebase here. When I put echo inside of exec it's actually running this JavaScript function. And we see this simply has logic for passing the flags that the echo command has in bash and turning them into JavaScript and",
        "start": 0.08,
        "duration": 250.557
    },
    {
        "text": "a real shell. And we can actually see that in that codebase here. When I put echo inside of exec it's actually running this JavaScript function. And we see this simply has logic for passing the flags that the echo command has in bash and turning them into JavaScript and whatever we put after echo. And you can see down here, it simply returns an object that has the standard output with the output in JavaScript, standard error, and also an exit code. And if you're thinking that it can't possibly handle all of the basics of bash, you can actually see a list here of all of the supported commands. And it really has loads of them. It has things like cat, copy, orc, base 64. It has advanced ones for data processing like jq, python 3, and sqlite. And you can even run network requests as well using curl. You actually set up a white list, so it's actually secure. And there's also shell features down here. So, it has pipes, redirections, command chaining. It really just gives you everything that a basic bash shell would. So, you can see the package is really cool and it's got a lot of functionality, but you're also probably still wondering why you'd actually want a bash implementation in Typescript and how this can help your agents and save you money. Well, to answer that, let me show you one of its use cases with a very simple chat app. Now, say in this chat app, I wanted to talk about this JSON file. So, this is a JSON file that contains loads of records. And let's say I wanted to ask the AI to retrieve certain information within this or maybe do some analysis on some of these fields. You can see it's an absolutely massive file. One of the simplest but definitely wrong ways of doing that is you could get the contents of the entire file and put it inside of the prompt. You can see here I'm using the AI SDK and also using GPT 5.2. If we actually run this agent and ask it to fetch us a specific record, you can see the assistant is going to reply and I can confirm this is correct. as these larger models are pretty good at retrieving values from that large context. But the trouble is this used 133,000 tokens and it's also going to start to fall apart if you ask it some more advanced questions. Maybe you want to do some data manipulation or ask it about data within certain ranges. As I said though, that is obviously the wrong way to do things. So the next way that you may have attempted before is maybe some rag method or even giving the agent a sandbox so it can run bash commands and manipulate the data that way. But the trouble with those approaches is you start to need a lot of infrastructure.",
        "start": 128.399,
        "duration": 471.99599999999964
    },
    {
        "text": "things. So the next way that you may have attempted before is maybe some rag method or even giving the agent a sandbox so it can run bash commands and manipulate the data that way. But the trouble with those approaches is you start to need a lot of infrastructure. with just bash. To do this with the AI SDK, you can actually use the bash tool package which is built on top of just bash. And what this allows us to do is in our API endpoint for the chat, we can create a new bash tool, pass this any files that we want to be in our simulated bash environment. So in my case, I'm passing through that JSON file that we had earlier, the really large one. Then I'm also setting up the destination for where these files are going to go. So it's going to go into a simulated /workspace directory. After that, all we need to do in the stream that we have from our AI SDK is pass it through the bash tool that we have. So that's just bash tool.bash. And I've also passed it some agent instructions which you can find in the node modules folder. These are simply just instructions that the package has provided that can help your AI agent understand how to use the bash tool. Now, with that very simple setup, if we ask the assistant the exact same question to fetch us a piece of information from that JSON file, instead of using its own context, needing to do some needle in the haststack finding, you can see it actually goes off and runs some bash commands, but again, this is in our simulated TypeScript environment. In this case, it tried to run a jQ command, but it looks like it ran into an error. So, next it ran a head bash command so it could see what this file actually looked like. And that way, it got the correct format of the JQ command and gave us our answer. So yes, while we did get the exact same answer out of this, and maybe it did take a little bit longer, the key here is you can actually see it took 6,000 input tokens, whereas the other method took 133,000. This is just a way better method for handling long context. And that's not even its only advantage. It becomes a lot more powerful when you start to ask more deep questions about your data. For example, if I ask it how many records between a,000 and 2,500 have metadata.active active true. You can see you can just simply go off and run a bash command and guess the answer straight away. If you actually tried this in the other version, A, it would take up a lot of context and B, it'd probably just give you a wrong answer based on guessing. This is going to be far more accurate as you're essentially",
        "start": 240.959,
        "duration": 685.9159999999997
    },
    {
        "text": "bash command and guess the answer straight away. If you actually tried this in the other version, A, it would take up a lot of context and B, it'd probably just give you a wrong answer based on guessing. This is going to be far more accurate as you're essentially complete access to a bash shell, even though it technically doesn't. It's honestly just such a simple free value ad that you can provide to your agents to make them more powerful with no additional infrastructure needed. And that's what I really love about it. Hopefully I've showcased just one of its use cases, but trust me, there is so many more. As we actually saw earlier, you can get basic Python, SQL, and curl commands working in here. And if you wanted to, you can actually attach this to a real file system. Let me know what you think of Just Bash in the comments below. While you're there, subscribe. And as always, see you in the next one.",
        "start": 349.6,
        "duration": 746.9539999999997
    }
]