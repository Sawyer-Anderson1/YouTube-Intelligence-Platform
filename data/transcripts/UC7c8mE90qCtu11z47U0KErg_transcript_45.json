[
    {
        "text": " Okay, so remember a few months ago when everyone was turning their photos into those Giblly style anime pictures. That was chat GPT. Open AAI dropped that the internet went crazy. They got like a million new users in an hour. It was insane. That's when the AI image war really started. And now OpenAI is back. GPT 5.2 last week, GPT image 1.5 last night. Four times faster, better text, better faces. They're going allin. Google's Nano Banana Pro also everywhere. People are obsessed with it. So, everyone's asking which one's actually better. I ran 10 tests to find out. But here's the thing. Test number 10. I wasn't even sure the AI could do it. I asked both of them to put Jethalal and Michael Scott in the same movie poster. Two different countries, two different shows, one poster. And what came out? Honestly, I didn't expect it. You'll see. And the other tests, I went a little crazy. Avatar poster. The movie is not even out yet. An Indian government ID for Elon Musk. Oh, and I found the benchmark OpenAI used to show off the new model. So, obviously I had to test if they can even pass their own test. 10 tests, same prompts. Let's see who wins. Okay, before we get into the battle, let me show you what's new. Chat GPT now has this dedicated images tab right here in the left sidebar. Click it and you get this whole new interface. At the top, you've got your standard prompt area. Just describe what you want. Same as before. But here's where it gets interesting. There's this try a style on an image section with a ton of predefined styles. We're talking Bollywood poster, festival vibes, Navat 3, Jaipur, textile pattern, landscape sketch, DY outfit, doodle. But wait, there's more. There's a discover something new tab. And this is where Chad GPT just absolutely destroys Nano Banana Pro. Now compare that to Nano Banana Pro. You get this, a blank prompt box. That's it. No templates, no predefined styles, no guided workflows. You're completely on your own. If you're a prompt engineering pro, then it's fine. But if you're a normal person who just wants to make a birthday card or fix a product photo, chat GPT just made it 10 times easier. Test one. Movie poster avatar fire and ash drops December 19th. That's 2 days from now. I'm going to make both AIs create a cinematic poster with the title, tagline, release date, even some Na'vi text. Let's see who can make something that actually looks like it belongs in a theater. My prediction, GPT image 1.5 takes this one. Movie posters are pure aesthetics. Composition, dramatic lighting. That's OpenAI strength. Let's see if I'm right. All right, I'm using Higsfield to run both models side by side. First up, GPT image 1.5. The prompt asks for a cinematic avatar poster. Title at the top, fire and ash",
        "start": 0.16,
        "duration": 324.0
    },
    {
        "text": "this one. Movie posters are pure aesthetics. Composition, dramatic lighting. That's OpenAI strength. Let's see if I'm right. All right, I'm using Higsfield to run both models side by side. First up, GPT image 1.5. The prompt asks for a cinematic avatar poster. Title at the top, fire and ash Release date, the works generating. Same prompt now with Nano Banana Pro. Let's see what we get. Okay, GPT is done. First impression, this looks cinematic. The colors are dramatic. Fire elements are there. Let me check the text. Titles spelled correctly. Avatar, fire, and dash. That's good. Na'vi text is there. Release date is there. Prompt adherence solid. Now, Nano Banana Pro. Hm. This has a different vibe. More animated like a stylized poster rather than photorealistic. Let me look at the characters in the GPT version. These Na'vi characters, I don't recognize them. Like, these aren't characters from Avatar. GPT just made them up. But in Nano's version, these actually look like characters from the Avatar universe. The design language matches. The facial structures match. Nano understood the franchise. GPT just made Pretty Aliens. So, here's the situation. GPT followed the prompt better, text, layout, all that. But Nano understood the context better. what Avatar actually looks like. So, who wins test one? For a movie poster, I need something that could actually be a movie poster. And if you put invented characters on an avatar poster, that's a problem. Nano Banana Pro takes round one. And yeah, I was wrong. I thought aesthetics would carry GPT. But Nano's understanding of the Avatar universe, that Gemini 3 brain, that's what made the difference. It's not just generating pixels. It knows what avatar looks like. score GPT0 nano1. My prediction accuracy 0%. Great start. But that's one test. 14 to go. Let's see if the pattern holds. Test two, brain anatomy. This one's important. Students are already using AI to make study materials, diagrams, flashcards, infographics. But what if the labels are wrong? You study a diagram that mislabels the phalamus. You fail your exam. Or worse, you're a doctor someday, and that mistake actually matters. So this isn't just make a pretty picture. This is can AI be trusted for educational content. The prompt detailed brain diagram, sagittal and coronal views, color-coded loes, labeled structures, corpus colossum, thealamus, hypothalamus, brain stem, the works. GPT gives us this textbook style, clean layout. I like the facial profile helps with orientation. Now the real question, are the labels correct? Corpus colossum, thalalamus, hypothalamus, pituitary, brain stem, all pointing to the right places. Nano goes for a different style. Clean 3D render, more modern aesthetic. Labels frontal, parietal, corpuscalosum, thalamus, hypothalamus, brain stem also correct. Good news, both are anatomically accurate. No mislabeled structures. A student could use either without learning something wrong. The difference is presentation. GPT went textbook facial profile, clear hierarchy. Nano went 3D aesthetic looks modern, but no anatomical context. For an educational diagram, that context",
        "start": 168.879,
        "duration": 680.1599999999999
    },
    {
        "text": "hypothalamus, brain stem also correct. Good news, both are anatomically accurate. No mislabeled structures. A student could use either without learning something wrong. The difference is presentation. GPT went textbook facial profile, clear hierarchy. Nano went 3D aesthetic looks modern, but no anatomical context. For an educational diagram, that context version is more functional as a study tool. GPT image 1.5 takes round two. We're tied 1-1. Quick thing, everything I tested today, all of it was done on Higsfield. And right now, they're doing their Cyber Weekend thing. 67% off. They're calling it the biggest price drop in Genai history. You get unlimited Nano Banana Pro, unlimited Cling 2.6, plus Veo 3.1, Sora 2, basically every top tier image and video model in one place. Pro starts at like 17 bucks, ends December 19th. Links in the description. All right, next test. Open AAI says this is where they improve the most. Let's test it. This has always been AI's biggest weakness. Spelling errors, gibberish, weird letter spacing. OpenAI claims GPT image 1.5 handles dense text better than ever. Let's test that. You can see the full prompt on screen. But basically, a 1920s newspaper front page with specific headlines, multiple columns of text, and a political cartoon. That's a lot of text to get right. GPT finishes first. Again, the Daily Gazette headline correct sub headline there. Cartoon with caption. All present. Design is balanced. Not too textheavy. Nano gives us the daily chronicle. Different vibe. More aged. Darker texture. Feels like an actual old newspaper. Headline correct. Sub headline there. Cartoon present. But this one went textheavy. More dense. Both nailed the text. Headlines spelled right. No gibberish. No artifacts. The difference is just style. GPT went clean and balanced. Nano went authentic and dense. Who wins? I can't pick. Both followed the prompt. Both got the text right. Only difference is artistic style. That's subjective. This is a tie. GPT 1 and a half. Nano 1 and a half. Still neck and neck. Next test four. Multilingual. English is one thing, but can these models handle Dagri script? Hindi text with complex conjunctions? Non-English text has always been a struggle for image models. Let's see if that's changed. A 1960s to7s retro Coca-Cola poster with Hindi text and a Japanese vintage aesthetic. We're judging on Hindi accuracy, cultural authenticity and bilingual balance. GPT gives us this. The Hindi text Coca-Cola is correct. Dave Nagri is rendered properly. Red and white branding is present along with taglines. Japanese elements are there as well. Mount Fuji in the background, a rising sun, vending machines. But the model in the image looks Indian, not Japanese. Now Nano's version the Hindi text is also correct. Dave Nagri looks good and the taglines are present. Now look at the cultural elements. Mount Fuji cherry blossoms a classic Coke bottle. A full Japanese vintage aesthetic. Both models got Hindi right. Bilingual balance is solid in both cases but we specifically",
        "start": 349.84,
        "duration": 1025.922
    },
    {
        "text": "version the Hindi text is also correct. Dave Nagri looks good and the taglines are present. Now look at the cultural elements. Mount Fuji cherry blossoms a classic Coke bottle. A full Japanese vintage aesthetic. Both models got Hindi right. Bilingual balance is solid in both cases but we specifically Nano understood that. GPT included the background elements but placed an Indian-looking model in a Japanese style ad. That's a cultural mismatch. Hinty text both nailed it. That's impressive. But cultural authenticity is where GPT lost this round. Nano Banana Pro takes round four. GPT 1 and a half. Nano 2 and a half. Next test five progressive edits. When Sam Altman announced GPT image 1.5, he specifically called out facial consistency as a key improvement. So let's stress test that. Five consecutive edits on a single image. Usually by edit five, most AI models completely lose the original identity. Let's see who survives. I'm uploading a reference image, then asking both models to make five edits in sequence. Edit one, change background to sunset beach. Edit two, add aviator sunglasses. Edit three, change outfit to Hawaiian shirt. Edit four, slick back hair. Edit five, age the person by 20 years. Judging on identity preservation edit precision and no collateral changes. GPT's result. Let's check the edits. Background. Sunset beach done. Sunglasses aviators done. Outfit Hawaiian shirt done. Even kept the body posture. Hair sllicked back done. Age 20 years older done. All five edits completed. Impressive. But here's the problem. The face. Compare it to the original. That's not the same person. Nano's version. Edits. Background. Sunglasses, Hawaiian shirt, sllicked hair, aged. All five done. But two problems. One, it zoomed in, lost the original framing. Two, facial consistency is also gone. Compared to original, different person. So here's the situation. Both completed all five edits. That's good. But both lost facial consistency. The whole point of this test was identity preservation and both failed. Who wins? Edit precision. Both nailed it. All right, this one's going to be insane. I drew stick figures and scribbles on a photo. Rectangle here, circle there, crude guitar sketch. Can the AI understand what I want and where I want it and make it look real? Prompts on screen. I've annotated this photo with sketches. Rectangle on the left. That's where I want a wooden bookshelf. Circle around his hands. Put an acoustic guitar there. Sketch on the right. Potted plant. Judging on annotation understanding, placement accuracy, lighting match and realism, GPT's output. It added the guitar there, potted plant there, bookshelf there. It understood the annotations, placed everything where I drew them. But look at the face morphed. You can clearly see the facial consistency is not there. Now Nano's version, this output is really good. First thing, Nano's generating in 4K. GPT doesn't have a specific output resolution. We've seen this pattern across the last few tests. Look at the details. Perfect plant, shadows underneath. Looks like it was actually",
        "start": 528.64,
        "duration": 1381.6019999999996
    },
    {
        "text": "see the facial consistency is not there. Now Nano's version, this output is really good. First thing, Nano's generating in 4K. GPT doesn't have a specific output resolution. We've seen this pattern across the last few tests. Look at the details. Perfect plant, shadows underneath. Looks like it was actually guitar there, and the face. Facial consistency is good. You can tell it's the same person. Clear conclusion. GPT followed the prompt, but messed up the face. Nano followed the prompt, kept the face, and gave us studio quality output in 4K. Nano Banana Pro wins this one. So, I've got a WhatsApp community where I drop everything I discover. tools, workflows, updates, all in one place before they go mainstream. If you want access, links in the description. This one's interesting. When Google launched Nano Banana Pro, OpenAI went into Code Red. And when they announced GPT image 1.5 last night, they showed off this test as their own benchmark. The 6x6 grid. 36 specific objects in a perfect grid. Let's see if their own model can pass their own test. Prompts on screen. A 6x6 grid with 36 specific objects. Greek letter, beta, beach ball, lemon, robot, and so on. Judging on grid structure, object accuracy, and text rendering. GPT's output, let me count. We got 38 images, but I asked for 36. That's not a 6x6 grid. Text and spelling, those look correct, but the grid structure wrong. Nano's version. Counting, we got around 42 images. That's even further off. I asked for 36, got 42. Neither followed the prompt. I asked for a 6x6 grid. That's 36 objects. GPT gave me 38. Nano gave me 42. Both failed. the grid structure. Here's the funny part. This is OpenAI's own benchmark. They use this test to show off GPT image 1.5 and they failed their own test. To be fair, Nano failed, too. Neither model could count to 36. This is a tie. Both failed. No points for anyone. Test eight. Website UI. Can AI generate a full website mockup? Not code, just the visual design. I'm asking for a secret Santa gift box service. Dark mode. Glass morphism UI. Christmas vibes. Let's see who understands modern web design. Prompts on screen. A secret Santa gift box website with specific design requirements. Glass morphism UI. Deep red and pine green accents. Frosted snow glass cards. Minimalist layout. Judging on design accuracy, visual hierarchy and overall polish. GPT's output. It followed the glass morphism UI. I can see that color theme is there. Deep red is present. But look at this. Less pine green, more gray accents. That's not what I asked for. And the layout, it's cluttered. A lot going on. Not minimalist at all. It's good, but it's not great. Oh, wow. Nano nailed the prompt. Glass morphism UI, check. Deep red and pine green accents, check. Frosted snow glass cards, check. It even added pricing tiers for the gift boxes.",
        "start": 708.72,
        "duration": 1683.2019999999993
    },
    {
        "text": "And the layout, it's cluttered. A lot going on. Not minimalist at all. It's good, but it's not great. Oh, wow. Nano nailed the prompt. Glass morphism UI, check. Deep red and pine green accents, check. Frosted snow glass cards, check. It even added pricing tiers for the gift boxes. background. This looks minimalist yet premium. Exactly what I asked for. Side by side. It's obvious. GPT's version is cluttered. Nano's version is sleek. Nano gives you more information in a less cluttered way. That's good design clear winner. GPT followed some of the prompt but missed the minimalist brief and the color balance. Nano followed all of the prompt. Glasmorphism, colors, cards, snowfall, everything. Nano Banana Pro takes it. Test nine. We're going to make Elon Musk Indian. Okay, I'm kidding. But we are going to generate an Aadhaar card for him. That's India's national ID. This is a good test because it needs both English and Hindi text. proper government design, the whole thing. Let's see who gets it right. So, the prompt is asking for a realistic ATR card. Elon's photo, his name and ADA number, blue and white background, proper fonts, you know, the whole official look. Okay, GPD is done. Let's see what we got. All right, so the English is good. names there, date of birth, gender, that's all correct. But look at the Hindi. It's kind of a mess. Like some characters are right, but most of it is just garbled. Dave Nagri is still tripping it up. and it literally put verified by AI on the card. I mean, points for honesty, I guess. But hey, it got the email format and toll-free number, right? So, that's something. Okay, now let's see what Nano gave us. Okay, the Hindi is actually clean. Like, no weird characters, no gibberish. It actually looks right. Names there, photos there, ADAR number, all good. And it actually follows the real design. Wait, look at this. It even got the STMF Jayati emblem. That's the national emblem. That's actually impressive. QR codes in the right spot. Fonts look official. This actually looks like a real AR card. Okay, so side by side this was actually close. GPT did well on the English stuff, but the Hindi not great. Nano got both languages right and even nailed that government emblem. That's the difference. Look, GPT 1.5 put up a good fight here. But here's the thing, for something like an ID card, if your Hindi looks like gibberish, the whole thing falls apart. You know, it just looks fake. Nano Banana got the Hindi right, got the emblem right, got the layout right, it just looks more real. Winner badge. Nano Banana Pro. Nano Banana Pro takes this one. Okay, final test. And for this one, we're doing something you did not expect. This one's for my Indian audience and my international audience. You know, Jatal from Tarak Metaka, Ulta Chashma and Michael Scott",
        "start": 861.76,
        "duration": 1957.041999999999
    },
    {
        "text": "just looks more real. Winner badge. Nano Banana Pro. Nano Banana Pro takes this one. Okay, final test. And for this one, we're doing something you did not expect. This one's for my Indian audience and my international audience. You know, Jatal from Tarak Metaka, Ulta Chashma and Michael Scott salesmen, both chaotically lovable, but they have never been in the same universe until now. I want a cinematic movie poster. Jetal and Michael Scott standing back to back in an office. World's best boss mug. The whole vibe. This tests face preservation, cultural costume blending, typography, and honestly, meme potential. Okay, GPT is done. Let's see. Oh, okay. So, the poster would look good if there wasn't this random imaginary hand just sitting on Michael's shoulder. Like, whose hand is that? Where did it come from? Chad GPT, you did it bad. I mean, we can't even defend Chad GPT at this point anymore. Now, let's see Nano Banana. Oh, this is way better. Look at how it handled the face blending, the cultural costume mashup, Jethal's look, Michael's suit, it works. The typography, two legendary salesmen, clean, readable poster quality. There's a tiny glitch with one hand here, too. But compared to GPTs, this is miles better. It followed everything I told it in the prompt. So, for the final test, GPT gave us a poster with a mystery ghost hand. Nano gave us a poster that actually looks like a movie poster. Clear winner, Nano Banana Pro takes the final test. And that brings us to the final score. GPT image 1.5, two and a half points. Nano Banana Pro 7 and 1/2 points. Nano Banana Pro wins. So after 10 tests, it's not even close. Nano16, GPT1, three ties, and ties don't count. GPT image 1.5 is not bad. It's fast. English text is solid. But Hindi text, cultural stuff, complex prompts, Nano just gets it right more. Now, this was image AI, but if you want to know which overall AI you should actually be using in 2025, Chad GPT, Claude, Gemini, Grock, Kimmy, I tested all of them, 10 brutal challenges. That video is right here. Drop a comment which test surprised you the most. Higfield link in the description if you want to try these yourself. I'll see you in the next",
        "start": 1000.959,
        "duration": 2196.402
    }
]