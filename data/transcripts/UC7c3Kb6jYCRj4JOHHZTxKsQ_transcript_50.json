[
    {
        "text": " Nano Banana is here. It is Gemini 2.5 flash image generation and it is truly incredible. It really is the best image generation and editing model I have ever used. Its understanding of physics, style transfer, and character consistency is unlike anything I've ever seen. All right, let me show you this first example. So, here's a thumbnail from MKBHD. In it, he is holding two phones, an iPhone and an Android. Now, watch how crazy this is. I simply said, \"Flip the phones over.\" And look at this. It knew what the other side of the iPhone looks like. It knew what all of the icons of the iPhone looks like, the entire operating system. It knew that the Android had a smaller notch at the top. And it is also very much an Android operating system. Now, there's a couple little issues with the icons and some of the letters in here, but overall, I found this to be absolutely incredible. So, let's test this thoroughly. The first thing I'm going to show you is all about 3D multiv- view and composition. Check this out. Here's the original image. A bunch of cause characters. And I simply say spin the right two cause characters around 180\u00b0. So, as you can see, it spun three of them around instead of two. And since two of these guys have their internal organs exposed, these that got flipped around do not. Plus, it switched the position of one of these guys. So, it's okay. The thing that it does really well is actually predicting what the other side is going to look like. Here's another example. So, I said, \"No, just the two right guys.\" And it did it much better. Here's the next test. We have a can of Coke and I said, \"Show this can of Coke from three different angles.\" And this is flawless. Three different angles. The logo is perfect. All of the little droplets of condensation are perfect. I think this looks phenomenal. Then I uploaded a picture of myself and said, \"Now give this person a can of Coke to hold.\" And so the can of Coke is a little bit small, but the thing that really sets Nano Banana apart is character consistency. This is the exact image that I uploaded and then I was able to add a can of Coke. Then I uploaded a pair of these glasses and I said, \"Put them on me.\" So now I'm holding the can of Coke and wearing these reflective glasses. Look at the reflection in the glasses. This is absolutely crazy. You can actually see all of the yellow flowers in the reflection. So, it had to understand that most likely the field of yellow flowers also continues in front of me. And it also had to understand that the glasses are reflective and would reflect those yellow flowers back. This is completely generated. Then I said, \"Show",
        "start": 0.16,
        "duration": 318.48
    },
    {
        "text": "yellow flowers in the reflection. So, it had to understand that most likely the field of yellow flowers also continues in front of me. And it also had to understand that the glasses are reflective and would reflect those yellow flowers back. This is completely generated. Then I said, \"Show it is. So, I think this is actually quite good. That is kind of what the back of my head looks like. All right. Now, let me show you some more 3D rotation, more character consistency. We have two cause characters. And keep an eye on this because later I'm going to show you how these characters were actually generated. And it is wild. But for now, here they are. Two cause characters. Then I said, \"Give me three poses. Here's another one. Thumbs up.\" Everything looks really good still. And interestingly enough, it actually was able to generate two images in a row just from my prompt saying, \"Give me three.\" Although, of course, it should have given me three, but that's okay. Here's another pose. Looks good. A little bit of clipping right there. Then I said one more time, give me three different angles all in the same photo. So there we go. So slightly different angles between these two. And then this one is a completely different one from the back. And I think this looks great. All right. Next, let's test some composition. Here we have a famous photo of a moon landing. But was it faked? Let's find out. Turns out it was. Here it is on the set. We have some cameramen in the background. And what's super impressive is the style consistency. So you can see the original image was very grainy and then the people in the background look like they're from the same time in the same photo. All of the lighting looks kind of old school. All of the equipment in the background looks old school and it just looks phenomenal. But that's not convincing enough. Let's really see if this image was faked. Now zoom out and show me all of this on a sound stage. And there it is. There are the characters still there. We have some folks walking around and we can see this is on a sound stage in Hollywood. I knew it. But this is one of the most impressive image editors I've ever seen. The character consistency is just insane. The astronaut in the middle was real and through multiple generations changing everything around it looks the same. It really does. AI models are exploding in scale. And if you're building anything from millions to trillions of parameters, you already know you need serious infrastructure. That's where Nebius comes in. The new Nvidia Blackwell GPU clusters are already available in Nebus AI cloud and they're built for the next gen of AI. We are talking 30x faster inference and 4x faster training than the previous generation H100's. You get fully managed",
        "start": 160.48,
        "duration": 604.6399999999996
    },
    {
        "text": "you need serious infrastructure. That's where Nebius comes in. The new Nvidia Blackwell GPU clusters are already available in Nebus AI cloud and they're built for the next gen of AI. We are talking 30x faster inference and 4x faster training than the previous generation H100's. You get fully managed orchestration and DevOps support built in so you can focus on building not backend. These are fully turnkey data centers, new cooling systems and GPU utilization tuned to the limit. If you need storage, that's covered as well. You can get costefficient object storage or ultra high performance shared storage. So reasoning models along context inference, training massive, Blackwell on Nebus is purposebuilt for that. They already launched a massive data center in Kansas City and they have a new one coming in New Jersey so you can scale across the US where you need it. So, thank you again to Nebus for sponsoring this video. And now, let's get back to it. So, here's the announcement post from Sundar Pichai, the CEO of Google. Our image editing model is now rolling out and yes, it is bananas. Okay, top of LM Arena's image edit leaderboard. Here's a couple examples that he provided. Dog on a surfboard looks very good. Dog wearing a cowboy hat. Dog jumping over with a superhero costume. And dog chef. And yes, it is number one on the LM Arena leaderboard. Look at this. Gemini 2.5 Flash image preview right there. A massive jump from Flux One Context Max. Massive. Look at that. A nearly 200 point jump in ELO score. So, this is really just a phenomenal model and plenty of votes to work with. All right. And again, I uploaded an image of myself. Put this guy in a fighter jet pilot outfit in front of an SR71 Blackbird. And there it is. This is absolutely flawless. All the little details of the fighter jet suit, all the little clips and latches and rings, everything. Plus, we have the helmet with reflection. And if we look closely at the reflection, we can actually see somebody taking a photo of me. And yes, that is the SR71 Blackbird in the background, but I couldn't see it enough. So, I asked it to zoom out. And here it is. Now, you can see more of the SR71 Blackbird. You can see all of the detail remains consistent. Really, the only thing from the original image is kind of the bottom half of my face, which is exactly consistent with the original image. And here's another example of image editing. So, we have a photo of the original founders of OpenAI. Remove the man on the right. Boom. Gone. flawless. Like you would not have known that anybody was removed from this image. Then I said, \"Remove the woman on the left.\" Boom. Gone again. And just the remaining two founders. But that's not good enough. I uploaded a",
        "start": 305.68,
        "duration": 906.4799999999996
    },
    {
        "text": "of OpenAI. Remove the man on the right. Boom. Gone. flawless. Like you would not have known that anybody was removed from this image. Then I said, \"Remove the woman on the left.\" Boom. Gone again. And just the remaining two founders. But that's not good enough. I uploaded a in.\" This looks phenomenal. It changed the expression of my face. It changed my hands. And it put me in the photo. The shadows look phenomenal. My kind of expression matches the rest of the expressions. And this is the photo that I uploaded. So, it's very different from what actually ended up happening. And I just think this looks great. Again, let me show you an image of myself. I said add a giant zezy top beard. And there it is. I think that looks really cool. And of course, not good enough. Here is me with a giant afro. This is probably what I would look like if my hair grew out. And now, let's edit Alex's photo a little bit since he did me so dirty in the thumbnail. So, make it raining bananas again. Just phenomenal. Look at the physics. Look how happy this guy is having bananas rained on his head. But look at the liquid coming down, splashing off his shoulders. All of the bananas. But why would he be happy about that? I think he would be very sad. So there he is crying. Now the facial expression looks good. The tears look very bad. It looks very fake. So I just said remove the tears and there they are. And of course, let's add some bananas sticking out of his ears. And now let's continue on character consistency. So, I said, \"A four panel comic strip showing the same character eating breakfast, going to work, attending a meeting, and coming home.\" So, we have the woman eating breakfast, unhappy. The second panel did not include that woman, surprisingly enough. But the next two did. Meeting marathon. There's the same woman. And home happiness. Finally, there's the same woman. And look at this. The cat in the background sitting on the window sill is now sitting on her lap as she watches TV. Very cool. And removing the background on images could not be easier. Now, look at this. Here's a picture of Sam Alman and remove the background. Flawlessly done. There's literally not a single mistake in all of removing the background. Then I said make him buff. So yeah, there it is. A little bit of inconsistency with the hand here. You can see a sleeve on the hand, but he's wearing a sleeveless shirt to show off the guns. , so yeah. And again, we can do multiple different techniques on a single image. We can do style transfer. We can see its character consistency. We can do 3D rotations. Let me show you that. So, here's a picture of Sam Alman. And I said, make this into",
        "start": 458.4,
        "duration": 1171.7599999999995
    },
    {
        "text": "guns. , so yeah. And again, we can do multiple different techniques on a single image. We can do style transfer. We can see its character consistency. We can do 3D rotations. Let me show you that. So, here's a picture of Sam Alman. And I said, make this into looks really good. Then I said, \"Now make it 3D.\" And as you can see, this is 3D. And it looks anime, but also 3D. Then I said, \"Now show me the whole body.\" And there it is. Again, just super impressive. Then I said, \"Now give me a character sheet with different poses and angles.\" Here he is. Look at that. So, if you're into making 3D models, if you're into product placement, all of this is now easily possible with this new image model. And it's not just editing that it's good at, it's also good at raw generation from nothing. So, here a random realworld moment captured mid happening. The scene, subjects, actions, perspective, lighting, and composition are unpredictable and arbitrary, as if reality itself was paused at an instant. No curation, no intention, just a frozen slice of everyday life with whatever people, objects, and environments happen to be there. And here it is. So, a little bit of I don't know what this is. Lens flare on the bus, but we can see the shadows are fantastic. It's highly stylized, but I still think it's quite good. Same prompt, another generation. Just wanted to see what happened. This guy looks like he's happy to have dropped his coffee. We have the little dog on a leash that's floating nowhere. So, a little bit of inconsistency there. We have a kite getting caught up in the power lines. A massive pigeon looking like it's about to steal that hot dog. And a lot of other little minor details in the background. I really like this image. And look at this. At the very front of the image, we have a water bottle on the ground that is completely blurred because of the bokeh effect. And so just really cool how it's crisp in the area that we're trying to focus on and blurred out otherwise. Generate an image of a banana wearing a costume. Here it is. Very nice. And here's another one. A cat with fur that looks exactly like moss. So again, generation works really well as well. Generation from scratch, that is. And a quick thank you to Dell Technologies for sponsoring this part of the video. Dell Technologies has a family of laptops and desktop PCs featuring Nvidia RTX Pro Blackwell chips which are absolute beasts for AI workloads. Check out the family of products linked down below. And again, it is really good at physics. Listen to this. A car photograph from the front, headlights identical with reflections perfectly showing the person photographing. And there it is. You can see the person just perfectly reflected",
        "start": 593.92,
        "duration": 1472.5599999999993
    },
    {
        "text": "for AI workloads. Check out the family of products linked down below. And again, it is really good at physics. Listen to this. A car photograph from the front, headlights identical with reflections perfectly showing the person photographing. And there it is. You can see the person just perfectly reflected looks really good. the reflection of the tires on the liquid on the ground. The reflection of the guy taking the photo just really good. And now let's test thumbnail creation. So here I have a photo that I usually use for my thumbnails. Then I just said make a YouTube thumbnail. I didn't give it any specifics other than that, but here it is. Gives me some text on top of it. That's okay. And I said good, but remove the background and put a solid color. This looks much better. Then I said, now make my mouth open. And I also think that looks really good. And then I said a much more surprised look. I'm pretty sure I took this photo at one point and you've all seen it a million times. So now I don't have to take photos anymore, it seems. Then I said, now make it in the style of a Mr. Beast thumbnail challenge style. I unlock my brain 24-hour focus challenge. That's decent. What I do like is all of the light in the background is being put on my face really well. It looks very accurate. But again, the thing that it can't do is replacing faces. So, I have a Mr. Beast thumbnail right here, and I say, \"Now, put my face into this thumbnail and replace the guy in it.\" But that is definitely far from what I was talking about. So, here is an actual thumbnail. So, big news. And I said, \"Change the text to say huge news.\" And look at that. It kept the exact font and style of the text, but replaced it to say huge instead of big. And photo restoration and colorization is basically a solved problem. Now, look at this. Here's an old photo. Lots of damage, black and white. First, I said repair all damage. And there it is. There's a little bit of damage here and there, but overall, compared to the original, it looks so much better. Then I said, colorize the photo. And I'd say this is extremely accurate. Then I said remove any remaining damage. And it continued. And yeah, it really did remove all damage that I can find on it. Here's a photo of Einstein, black and white. Let's colorize it. Look at that. Maybe the eyes look the wrong color, but everything else looks really good. And then I said, \"Now zoom out.\" And there he is. Still consistent, a little different, interestingly enough. And it does look actually a little bit more stylized than I was hoping, but still very good. And here's a photo of Nixon and Elvis Presley. Let's colorize it.",
        "start": 746.56,
        "duration": 1745.440999999999
    },
    {
        "text": "really good. And then I said, \"Now zoom out.\" And there he is. Still consistent, a little different, interestingly enough. And it does look actually a little bit more stylized than I was hoping, but still very good. And here's a photo of Nixon and Elvis Presley. Let's colorize it. want to use it, let me show you the two most easy ways to use it. So we are in a studio.google.com. You come over here. You select under featured Gemini 2.5 flash image preview. It is free. I believe it's rate limited, but you can get started with it. You can play around with it just like normal. You can adjust the temperature, which adjusts the creativeness of the photo generation. You have your safety settings, which of course I always turn off. And then we have top P. Those are the main settings that you're going to be playing around with. The other way to test this new image generation model is in Gemini. So if you select choose your model fast all-around help 2.5 flash then down here you click these three little dots and under that is image generation there it is this is nano banana. So those are the two ways to give it a try right now. Next let me show you continuity. It can actually understand what a progression of a series of images or even different frames in the same image would look like. Listen to this image sequence. a candle unlit on the left, burning in the middle, and melted on the right. And there it is, perfectly. So, the candle in the middle is slightly higher than the one on the left. And I think it shouldn't be obviously, but otherwise, it's really good. Look at the reflection on the little candle holder in the background of the light. And then the melted candle on the left. Phenomenal. We were actually able to trigger thinking mode for the image. Check this out. a photoreal image sequence of a burger left alone on a coffee table where the sequence starts from the moment the burger is placed piping hot to years later when the burger has decayed. Think of the best moments to capture in this timeline and create a series chronologically. So, here's the original burger. It looks pretty good. It definitely doesn't look 100% real, but okay. Here's the second one where it starts to decay. We see some mold right here. Another image where yeah, it's really starting to get moldy and gross. And then finally, fully molded, fully decayed burger. So, it seems triggering thinking mode is possible with image generation. And what if you want to do material change? Here's what that looks like. A teapot made of transparent ice steaming with hot tea inside. Here it is. That looks really good. Then we said, now change the teapot to be made of metal instead, but everything else",
        "start": 884.8,
        "duration": 2018.3999999999987
    },
    {
        "text": "image generation. And what if you want to do material change? Here's what that looks like. A teapot made of transparent ice steaming with hot tea inside. Here it is. That looks really good. Then we said, now change the teapot to be made of metal instead, but everything else identical. That's the part that's always super impressive that I've mentioned a couple times is it only really changes the thing that you're telling it to change. And it did change the teapot to be metal. And of course, it's good at meme generation. So, here's a meme. Blank slate on the whiteboard. And I just said, \"Put a banana on the whiteboard with the text. Photoshop, but really easy.\" And there it is. And how about its ability to handle counting? I said, \"Seven identical apples in a straight line on a white table.\" Here it is. Now, as you can see, surprisingly enough, they're not identical. These two in the middle do not include this leaf off of its stem. I don't know why it didn't have that. It's so weird that it makes these tiny mistakes, but still. Otherwise, these apples are absolutely consistent. And how about human anatomy? We all know the AI images with six fingers. Let's see if we can get that to work here. Two hands interlocking fingers in a handshake. Ultra realistic high detail. We click in. It's flawless. Five fingers. Everything looks perfect. Now, the only tiny little thing I see right here is kind of a little drop of water coming off of one of the fingers, but I'm going to give that a pass because otherwise it's perfect. Look at the texture on the skin. The little hairs on the arm. Everything is good. I even see the nails are a little dirty right here. Just perfect. If you enjoyed this video, please consider giving a like and subscribe.",
        "start": 1023.279,
        "duration": 2186.0009999999993
    }
]