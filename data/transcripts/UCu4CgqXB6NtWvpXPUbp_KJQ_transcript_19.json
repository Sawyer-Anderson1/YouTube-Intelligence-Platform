[
    {
        "text": " Hello. Hello. Thank you for joining me today. Thanks, Kari. I am Kari Briski, Vice President of Generative AI software at Nvidia. And I am joined with a man who needs no introduction. But we will. A man who has, the coolest name and an even cooler job. So, Konstantine Buhler, thank you for joining me today. You are an AI engineer turned venture capitalist and a partner at Sequoia. Tell me a little bit about what you do. Well, thank you, Kari, for that very kind introduction. And I did bring my mandatory leather jacket. We get to wear here. Yeah. So I'm an engineer by training. I learned about it when I went to school. I went here out west and studied at Stanford. Got pretty deep into the deep learning revolution in the early 20 tens. Fell in love with this concept of massively parallelized and sequential compute. Being able to predict almost anything and worked at a couple companies in that area. Past six years have been at Sequoia. So you are working with founders who are you're building the future of AI. You were sort of known for being able to predict big technologies over the next decade. I think that's kind of interesting because, when you're in the AI space, it tends to move so fast. And sometimes even having a roadmap that is one year out, let alone a decade out. What is your protocol or a way of thinking to come up with, like these big visions? So for me, it was it was very simple. I knew I would be a really big, important trend just from the technology. When I was in undergrad and grad school. It felt like this is something that's going to change the world. I wasn't sure exactly how. You know, a lot of the smartest, academics at the time thought that it might be more elegant models they'd talk about than a raw, unbridled neural network. And it turns out that wasn't exactly true. But I did know that this idea of prediction was incredibly powerful because at its core, I felt like intelligence itself is prediction. There was a previous AI hype cycle. This was 2017/18, where every company, or many, many companies claimed to be doing some AI and it wasn't really core to what they were doing. So I felt like my role for my friends would be for the technical friends. Hey, is this a real business? And for the non-technical friends. For my friends from business. Hey, is this real technology? And that's kind of how I created my little niche in, the AI venture world was companies that are real technology and real businesses. Wow. So today we're here to talk about open source. We're here to talk about specialization. We're here to talk about the challenges for both of those with adopting, agenetic AI. And then we're also here to talk about innovation and investments.",
        "start": 7.5,
        "duration": 161.69800000000004
    },
    {
        "text": "companies that are real technology and real businesses. Wow. So today we're here to talk about open source. We're here to talk about specialization. We're here to talk about the challenges for both of those with adopting, agenetic AI. And then we're also here to talk about innovation and investments. Or let's talk about just open models. Right. People really weren't adopting them. And then I go to the era of 2024 was about RAG AI retrieval, augmented generated systems. You start to see the pickup of open models and frameworks, and then you go into 2025 with reasoning and just agents. And so you see the adoption of open technologies. Do you think that open technology is driving a lot of the transparency and adoption of of agents today? Yeah. So I, I do generally agree with that timeline. You know, I think that there's always in the future is already here. It's not evenly distributed. It's old you know, old freight saying. I feel like there are companies that are now getting there and then the companies that are already on the next thing. And so I do think that the timeline you outlined is what core enterprises are now thinking about. I think that the startups are already thinking about what's next. Next. So most of the startups that I work with are thinking about swarms of agents. So agents working together, agents actually making decisions with each other or running background agents or having that kind of communication. Yes, definitely. Open source played a key role in that, because it's a lot easier to be able to take an AI into your enterprise when you actually control the weights. And we're really excited about the prospect of open source, because it gives more power to the enterprise and ultimately to the consumer. We actually have a shared investment ReflectionAI where we just raised $2 billion and Nvidia was a participant and a wonderful partner in this. And, they're building, trying to really carry the banner of, you know, the US open source, development ecosystem. Like, that's a really good thing for everyone because enterprises can then build it into their solution, and enterprises can now compete and win, with their own workflows, not just the startups that use closed source APIs. Two things that you mentioned. One was about the communication of agents to agents. And I think that, you know, you and I actually have used this analogy. I don't even know that we've known that. We've done this, independently. But let's talk about it together. Is it the stage of genetic adoption? And I always explain it as, comparing it to the internet, because you had Arpanet and then internet and then internet. And so that's sort of the stages of adoption, standards that needed to be put in place. Do you do you kind of see that evolution like 2025 isn't the year of agents. We're going to have agents to come",
        "start": 174.166,
        "duration": 305.46399999999994
    },
    {
        "text": "because you had Arpanet and then internet and then internet. And so that's sort of the stages of adoption, standards that needed to be put in place. Do you do you kind of see that evolution like 2025 isn't the year of agents. We're going to have agents to come Yeah. Could you talk a little bit about that? Totally. So I think there's at least three things that are in the way of us having really great agents. You know, the first is agent memory. So that is an unsolved problem. Some of the great researchers right now are trying to figure out agent memory. If you think about interacting with a person like Kerry, you and I have had great interactions. If every time you met me, I was a different personality. It would be pretty weird. Yeah, right. With agents, how do you actually carry that memory along? Because if you're going to be working with an entity, an agent, you want it to have a persistent memory of you and of itself. See, I think most people are talking about agents having memory of me, not of itself, because I think people are working a lot about, memory in the moment or memory possession or, you know, or working across, key value pairs of KB cache, across similar, queries, across different people, but not necessarily the agent is aware of itself. And keeping that memory. And so I think that's really important. Totally, totally. Because it's like, of course you want someone to understand you like when you when you interface with someone, remember their name and their family and all those good things, that feels really good. But consistency of the individual themselves is also really important, right? You know, you think about someone you work with, and they're really good partner. And if all of a sudden they were dramatically different every day, you probably would want to work with them very long. It would be pretty weird. Same thing with AI agents. So this this memory problem is open. But the good news is some of the greatest researchers are now focused on that. Do you think that enterprises are going to have to fine tune or build their own AI to stay competitive? Because I think of agents having memory about themselves as being fine tuned or, have gone through reinforcement learning about themselves. So then they become who they are rather than having maybe the same memory is and has been trained in. Is that where you're talking about a different type of memory? I think it's both. You know, we both are computer enthusiasts. So I think like some of it's going to be like having, the, the code that's been loaded into the processor itself. Some of it's going to be like Ram, some of it's going to be like large storage and you access that in different ways. So in this case, yes,",
        "start": 325.933,
        "duration": 435.19900000000007
    },
    {
        "text": "I think like some of it's going to be like having, the, the code that's been loaded into the processor itself. Some of it's going to be like Ram, some of it's going to be like large storage and you access that in different ways. So in this case, yes, That's one of the values of open source, where you can take those models and basically decide which neural pathways to change in which direction based on what type of new information. That's a technique some people are using. And it's it's really smart. At the same time, RAG and vector databases and all these other techniques. They're not going to be forgotten. They're just going to be used in different ways. Right. And there will be other ways of us thinking about memory that haven't even been brought mainstream yet. That's going to be one of the three most important things, at least in the next year, for getting AI agents to work. The second is communication protocols. You know, we've talked a lot about MCP and this idea that in order to have agents work together, they have to be able to talk together. You know, we both speak the same language, not only the same technical language of English, but a similar business language and a similar, you know, technical jargon that helps us communicate really fluently. AI agents are going to have to have something similar. And that actually reminds me a lot like the internet, where in the early days you had TCP IP that wasn't the finish line, that was the starting gun. And then the third is AI security. So now that you have agents that have memories and are communicating with each other, we're going to have to figure out ways that they communicate very securely. And it's actually Jensen who said this in a previous conversation. I thought it was pretty awesome. He said, think about agents as not needing to have the same requirements of the physical world. So in the physical world, you might have one person, as a security guard and a thousand people that they're protecting. And that's because of physical space and also because of cost. But in the future, he pointed out, maybe you're going to have 1000 security agents around one cognitive, intelligence agent. And so we have so much to solve in the security side of things. Those three areas memory, communication, security are all being solved real time and are going to yield the agent economy. You said the agent economy. I love that term. We call it digital workers. But there's going to be some sort of niche market that's built up around new frameworks, new, training types just to support this economy. Raise it like just like we have an economy for humans. We're gonna have an economy for agents. You also. So you talked about this three problems. Another problem that I see. Not necessarily for agents,",
        "start": 462.933,
        "duration": 572.9330000000001
    },
    {
        "text": "that's built up around new frameworks, new, training types just to support this economy. Raise it like just like we have an economy for humans. We're gonna have an economy for agents. You also. So you talked about this three problems. Another problem that I see. Not necessarily for agents, So you and I were talking about stochastic mindset and determinism. Talk to me a little bit about because I see when, when, you know, we've all heard the study about, you know, 95% of pilots don't make it to production. I actually kind of disagree with that because I see where the pilots are focusing on, targeted use cases or specialization. They're actually succeeding in getting into production. And, and, you know, the definition of AI, of what's done or what we're used to and what goes into production people tend to forget about. So we can we can talk a little bit about that, but talk about this stochastic mindset and evaluations. Sure. So I'll answer a little on the stochastic mindset. And then I'll share how I'm seeing evals evolve over time. So in stochastic mindset, the idea is that we're changing how computes happening. And frankly, you guys have been at the forefront of changing how compute is happening for decades now. And this type of compute is no longer fully deterministic. It is stochastic. So there's some randomness in the system. And for those out there I know nothing is fully deterministic, right? Even even, historical types of compute, but pretty close to deterministic. If you and I put the number 37 in a spreadsheet and we check that spreadsheet tomorrow, it would almost certainly be the number 37. But the way I works is a lot more like humans. So if I said, hey, Kari, you know, can you remember the number 37 for me? And I checked back in in six months or a week? You're really, really smart. So you remember 37, but maybe the average person might also remember 73 or 30 8 or 36. The point is, there's a distribution of how that memory is okay. And over time probably gets worse and worse. And that kind of change is a difference in how you interface with the computer. So it's going to be a lot more like interfacing with people, which is mostly a good thing. I love people, I think you do too. Like we're people, people, but there's challenges where people, you know, forget things in certain ways, or there's randomness in certain ways that aren't true of computers. And so therefore, when we expect or evaluate or retrain to keep agents up to date, we have to think about this. Definitely. Absolutely. And and I'll, I'll share one way we're seeing this happen in the industry. But I want I'd love to hear how you are seeing it because you talk to the biggest enterprises that are doing this.",
        "start": 607.833,
        "duration": 704.2020000000002
    },
    {
        "text": "keep agents up to date, we have to think about this. Definitely. Absolutely. And and I'll, I'll share one way we're seeing this happen in the industry. But I want I'd love to hear how you are seeing it because you talk to the biggest enterprises that are doing this. from academic evals to real world evals. So we work with a company called XPO. They set out to build the most the most effective AI hacker in the world, basically penetration testing. Can you find vulnerabilities in in a software platform? And they said, hey, how do we show that I can be so good at finding vulnerabilities? So they said instead of academic benchmarks, which they did and they succeeded in, we're going to go out into the real world. And they registered on HackerOne, which is the leaderboard for all things hacking globally. And they started competing to find vulnerabilities. And within a few months, they ranked number one in the world. So the number one hacker on HackerOne in the world is an AI, which is simultaneously scary and exciting. I mean, all technology for the for all of history is people have used technology for good or bad. And so if you're using AI to do bad things, you need to combat bad things with AI. It's the only way. Exactly. Yeah, exactly. Which is why with this company, I get to work with them. It feels national security level important because without question, you're right. The bad guys have also seen this, and they're taking action on it for sure. And so the response isn't to put our head in the sand is to say, hey, we have to be even better. We have to find these vulnerabilities before the bad guys do. We have to patch them. Our job is even harder. So for a company like that, I think it's amazing what they've done, not just because of the impact, but because they said, we're going to evaluate this not just on an academic benchmark, but in the real world. For specialized AI. I foresee, especially for agents, is this reinforcement learning and the amount of gems. And so when you talk about this evaluation benchmark, you're going off and letting the AI train in an environment or learn through an environment, or learn through doing and then taking all that and reinforcing it back in. And so the more Jim's just like, the more we work out, the more we exercise or the more, variations on scenarios that we're put into, the the better we are at engaging a new, a new, new scenarios, new systems, new input. Totally. And so I foresee like, new new studios, new gyms, new RL environments, specifically for specialized, niche domains. And why do I say that? So I think, when we look at what has been successful has been coding agents right now. Right. I think that's because the verifiers",
        "start": 749.566,
        "duration": 848.9700000000005
    },
    {
        "text": "input. Totally. And so I foresee like, new new studios, new gyms, new RL environments, specifically for specialized, niche domains. And why do I say that? So I think, when we look at what has been successful has been coding agents right now. Right. I think that's because the verifiers and you're able to reinforce that learn. Right? You have a lot of people who code and they can say, yes, that was right. That's code does not. Now when you get into I'm calling it like sort of this last mile of expertise when you get into an enterprise or a specific domain like you were just talking about, if you have experts in expert knowledge, the verifiers become very hard because they're either expensive or those people that can verify and need to be doing their job rather than verifying an AI. And so I think that, synthetic data generations can become really important there because you have high quality seed data to create specialized AI. You also need again, to be able to create the, the verifier. And again, code is yes or no or math. The answer is right or wrong. It doesn't. It's not so easy when the verifier is like it depends or it's close but not that right? So you obviously work with all these startups. Is there a field where you see the people are getting more into kind of moving up the stack, moving away from model building models, more around the agents and these verifiers or gems or environments, or which models can train better for specialized AI. I think what you said was really, really a great point. And I've actually been wrestling with this concept for a while. You know, how what what is the gatekeeper for progress in AI? And I think what you said, which is being able to verify quickly, is, is a brilliant point. And it's so true of code. It's it's so true of code because you can see it compiles, but then you can just build it and look at it and then run unit tests, and you can iterate fast enough that the stochastic nature of AI doesn't prevent you from making progress. In fact, it's fine. You know, you can just go quickly enough. It's harder in other areas. So I'll give an example. You know, my my wife is a surgeon. So she does, you know, it's a high consequence field. And, you know, she, she does a specific kind of surgery that, like, you got to get, right. So the importance of verification is extremely high there. There are other parts in the process that the verification is much quicker. So she might use AI for scribing, when she's talking to a patient, taking all the notes, allowing her to speak to the patient, learning to focus on that. She might use, you know, a company like Abridge for that. She might use a company like OpenEvidence",
        "start": 903.0,
        "duration": 987.2340000000008
    },
    {
        "text": "is much quicker. So she might use AI for scribing, when she's talking to a patient, taking all the notes, allowing her to speak to the patient, learning to focus on that. She might use, you know, a company like Abridge for that. She might use a company like OpenEvidence That's an area of where it's going into, an application that is actually really hard to verify. But she has so much expertise, she can then read it, accept the notes, accept the conclusion, and then move on and by the way, that makes the models better too. That's right. And so we might think of scribing as, not as, as needing expertise, but you actually do because it's a language. It's the jargon. It's the technical expertise of the words that you're saying or accurate about a patient or what might be happening. Right. And so. Definitely. Yeah. What do you see enterprises mostly wanting like when Nate, when they come to you and they say we need generative AI, which they definitely do, you know, to not fall behind. How do they think about the use cases that are reasonable and verifiable? And how do you guide them through that? I think for whatever use case they're coming to, they want the most accurate model on the tiniest cost of ownership. And it's a really tough trade off. Right. They want high accuracy. But they want it, on a small footprint, but they want it on their own data. They want it private. And they don't want to send their IP or intellectual property and private information out of their, their data. I said this input to my partnership a couple of years ago when we had these big, big models. I said at some point, you know, it's going to become about distillation, which is this concept of taking those big models and then making them much more efficient, so usually much smaller, and then focus on a domain. And I feel like we're still in the bigger, bigger, bigger model. You know, part of the cycle. But I do think the smart enterprises say, well, I need this to be cost effective. I need this to be efficient. I need to be fast. And the best way to do that is that kind of distillation. There's distillation. There's looking at model architecture. There's all kinds of ways of of making models more efficient. I think. Honestly, if you if you look at models development, just like any regular software development platform, you kind of demystify it for a second. You're always you're writing code, you're compiling it, you're putting it out to run. And so when you're building models, you're getting the data, you're retraining, you're putting it out there. So no software application is just ever out there and done. You have bugs. You have feature requests. You have to, you know, you have to improve it and then write the code, recompile, rereleased.",
        "start": 1052.6,
        "duration": 1122.4020000000005
    },
    {
        "text": "when you're building models, you're getting the data, you're retraining, you're putting it out there. So no software application is just ever out there and done. You have bugs. You have feature requests. You have to, you know, you have to improve it and then write the code, recompile, rereleased. not just about the features, it's also about optimization. You know, the best performance that you're getting out of, the software at runtime. And so if you think about model development, this is a new software development platform. It kind of takes the scariness out of it and understands that, hey, you want to get your MVP. You want to get your MVP right. And then you can optimize over time. And that's. Well said. I couldn't agree more. That makes a lot of sense. Okay. So we talked about challenges. You talked about persistent identity seamless communication security. How can open source contribute or accelerate solving those challenges. So I think something like communication protocols have to be open source because Definitionally, you know, many applications have to participate. I could see a world where memory and security are closed source, memory. There are benefits to open source. But you we store memory differently in different context. Software memory and security is also pretty proprietary, but I think the area that open source would be most critical to is having these base models to go build on, of course, which we get to work on together, which is amazing. And then separately, communication protocols. How are models going to talk to each other. Okay. So when you talk about working together someone talk about investment in innovation. And we talked a lot about agency model training. And so I think a lot of the capital investments are moving from this model space to like up the stack to more of the agent space. So the agent layer, what is driving that shift. What do you see. Why do you think that's happening? I think it's because at the end of the day, it's all about people, no matter what. It's always all about people. And you, as an enterprise leader here, probably know that better than anyone. It's it's always a people problem. It's always a people opportunity. And that's why we're shifting from the model layer more and more to the application layer. So I'll give a concrete example. And this is an example of going from, you know, model layer to automated model to human in the loop model. I work with a company in our portfolio called ROX, and they are building an agent operating system. I think Nvidia uses them. And they have basically built a technology that helps instead of a base layer, you know, right out of undergrad automation of some salesperson. They want to have the best sellers sell even more effectively. And so they connect with models. And they might do a lot of research ahead of a meeting",
        "start": 1199.6,
        "duration": 1267.4690000000003
    },
    {
        "text": "basically built a technology that helps instead of a base layer, you know, right out of undergrad automation of some salesperson. They want to have the best sellers sell even more effectively. And so they connect with models. And they might do a lot of research ahead of a meeting They introduce a feature that allows for emailing. So if you're an executive, you had a meeting, you're sending a follow up email. And like a lot of teams, they started by offering that as an auto send. So we've created the model and we're able to to send it. But they realized that they actually could get much higher conversion if they brought the seller back in the loop. So the seller now is able to edit every email before it gets sent. Kind of like that idea of, you know, the human supervising or verifying and return emails went up three x so materially higher here. And that story gives the essence of what's going on. You know, the essence of going what's going on is at the end of the day, this is all about people. And especially in something like selling it's about people. And so the idea of cutting a humans out of the loop is just naive. And the idea of if you really want to help the best people do better, integrate them in quickly, have I help them build into their workflow and you'll have the best possible product. And I think that that's building and trust, right? A trust layer and I've heard you talk about before like the definition of AI because, you know, at one point, you know, computer vision, I'll that's not AI anymore because it's already happened. I trust it, you know, I get that you're pointing out whether it's a Chihuahua or a blueberry muffin. Like, I. I love that era. I love when you're talking about computer vision. I was like, people still underestimate how awesome computer vision is. It is. But putting it all together, it's still really hard, right? So the visual understanding and the language and speech and audio and using it all together. And so maybe that we always keep moving the bar for what is AI and. Right. And so. Totally. But it's always about people. Always, always. I feel like you and I were talking about this beforehand, where AI is such a tortured name for the industry, where it's it's you're naming it intelligence. And by definition, people will consider intelligence whatever the machine can't do. So as soon as the machine does it, they'll start to forget it as being intelligence. And I already see this in tasks. I mean, when you and I were getting into AI, you know, ten plus years ago, the idea that a computer could understand the difference between a two hour and a blueberry muffin was awesome going. It was awesome. It was a huge deal. Yeah.",
        "start": 1355.9,
        "duration": 1405.936
    },
    {
        "text": "already see this in tasks. I mean, when you and I were getting into AI, you know, ten plus years ago, the idea that a computer could understand the difference between a two hour and a blueberry muffin was awesome going. It was awesome. It was a huge deal. Yeah. computer vision. Yeah. You know, even self-driving cars, I'm now seeing, you know, self-driving cars are on the streets of San Francisco, and I don't really hear a lot of people talking about it as mind blowing AI. They're just calling it autonomy or autonomous vehicles. So with every era of AI, it eventually gets pushed back. And that's my job to to be hey, what can be that next form of AI that's going to make the world feel like it's magic? You just had the best lead into. My next question was, well, where will we see the next big wave of innovation? I feel like you guys are all over this, which is, I think world models are going to be extremely exciting. And, you know, I'll give a very base layer kind of like you were talking about, of the progression over time. I generally moves from less data intensive to more data tons of over time. And, you know, we had eras of AI that were numbers in and numbers out, and the generative AI text in, text out era. And then we've gotten pretty good at images, and we're getting pretty darn good at videos. And in between those two, we got really good at voice. So basically richer and more intensive data types. Logically, what comes next? Well, of course we're going to have voice get really good in the next year or two and video and all of that. But then what starts to ramp is world models. These are extremely data intensive. You know, it's the whole space around us and. Streaming in. And streaming. And the data streaming into us at all times, whether totally we accept it or not. 100%. Absolutely. And then it gets really philosophical, like, how do you perceive the world and do you perceive it as we all have mental models that we're testing against, or do you perceive it as, you know, our eyes and senses are constantly streaming in new data. I'm probably the former, actually. I think we perceive the world. Yeah. In any case, it becomes about that. And then from there, once we have those good world models, we can do amazing things. I think that's actually going to be the base layer for all this robotic opportunity. That will be truly massive. That's amazing. We always try and work on the hardest problem, the biggest workload. Right. We always say that if you want to go to the moon, Nvidia will take you there. If you want to walk across the street, you're on your own. That's awesome. That's funny. Okay, so companies who, are moving fast",
        "start": 1502.866,
        "duration": 1537.2359999999999
    },
    {
        "text": "and work on the hardest problem, the biggest workload. Right. We always say that if you want to go to the moon, Nvidia will take you there. If you want to walk across the street, you're on your own. That's awesome. That's funny. Okay, so companies who, are moving fast they seem to iterate often and it sort of, reminds me of the design thinking approach where you want to fail fast or iterate off and pivot if you need to. And if you were to talk to, a leader today or a new founder that you're just talking to you and you're going to give them advice, how would you tell them to adopt that mindset or would you tell them to adopt that mindset at all? Okay, so I feel like this is a very safe place for a very nerdy technical analogy here. Absolutely. Okay. Excellent. Which is I do believe that you should iterate incredibly quickly, and I get inspiration from gradient descent algorithms, or just invert it and call it gradient ascent algorithms. And, you know, whether it's a truly stochastic gradient descent algorithm or batches where you get a bunch of information and then update it, I think that's the best way to build a company. So, you know, you don't know all the information, nobody knows all the information in the market because the beauty is the vast majority of that information lives in other people's brains. You know, they they know what their preferences are. And the whole point of the market is to serve other people. So we'll never know all the information. Even if we have a perfect world model, we'll still only have some estimates. So it's the job of the founder to gather as much information as possible, a batch of new information, and then run a stochastic gradient descent and try to find something new. So then that begs the question in this super hyperdimensional universe, with all of these, you know, hills and convex, hills in this dimension, in this space, how do you find the highest one to climb? And Nvidia did like that. I think that ultimately happened. You guys said, we're going to think about all of compute in a new way of computing and acceleration. At lightspeed. That is a huge mountain to climb. So you picked a great starting place, and it took many, many, many years to climb that and encourage founders to pick a starting place that's worthy of them. I pick something that is sufficiently exciting, big, challenging that if you do succeed, it was worth it. Big reward. Yeah. What do you see from startup founders selling in enterprises? Do you feel like they're iterating too fast, breaking things, or going the right speed? I think enterprises are a completely different world. Not that they're second movers per se, but I definitely think that they have more risk. They have legacy systems.",
        "start": 1643.4,
        "duration": 1673.9339999999988
    },
    {
        "text": "see from startup founders selling in enterprises? Do you feel like they're iterating too fast, breaking things, or going the right speed? I think enterprises are a completely different world. Not that they're second movers per se, but I definitely think that they have more risk. They have legacy systems. So that curve of adoption is taken slower for enterprises because they were figuring out how to integrate something as fast moving as AI. Right? I think that enterprises aren't moving as fast as, say, the startup world, but they definitely get their influence from the community, from open source, from the startup world. They look to that to see where, again, what is everybody working on and what do I need to adopt? That's why I think enterprise, hasn't adopted generative AI like the way that we wanted them to within the last year. But I think now that it's become easier to to fine tune and specialize, easier to, generate data through synthetic data generation and easier to evaluate or put through these reinforcement learning environments that they're going to be able to start to really specialize per domain. I think some enterprises started thinking like this one model is going to solve the world, and there's not one model to rule them all. There's many smaller models or different sizes of models. It's systems of models to actually achieve a use case. I feel like we speak the same language here. I think a lot of it comes just from being from having been in other areas of AI where you've noticed. Yes, it seems at some point that one model will be able to do everything and always it turns out that a specialized model ends up doing the thing better. There might be one, like you said, to start and to get things going, to start training, to kick things off. But it turns out specialization is a superpower, and I feel like that's going to continue to happen in the AI realm each year. Well, that's all the questions I had today. All right. Thank you for coming. And thank you very much. Headquarters. And having this glass of water with me. Amazing. Yes, it was strong glass of water. Cheers.",
        "start": 1786.233,
        "duration": 1778.2329999999988
    }
]