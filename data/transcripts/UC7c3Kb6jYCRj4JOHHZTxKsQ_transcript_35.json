[
    {
        "text": " This video is brought to you by Stack AI. More on them later. GPT6 might be coming by the end of the year. This guy on CNBC said he just got done talking to Brad Gersonner, a prominent figure in Silicon Valley, and he just said GPT6 is coming by the end of this year. That's 2 and 1/2 months from now. Now, that comes right on the heels of GPT5. And honestly, I don't think it's going to be happening. It would be very weird to have this massive launch GPT5 really a fundamental shift in the way users interact with chat GPT rather than choosing from a bunch of different models. They have one primary model and a router and it was just this very unifying moment, this unifying model that I would find very surprising to have replaced not more than just a few months later. But who knows? We'll see. Next, Nvidia has started selling the smallest supercomput on Earth. This is the DGX Spark, and Jensen himself is delivering it to the top AI companies in the world. Check out this video of him delivering the original DGX to Elon Musk in 2016. And now, fast forward less than 10 years later, he's delivering the DGX Spark. Watch this. How's it going? Good. How's it going? Is this your office? , this is this is the rocket factory. The SpaceX rocket factory at Star, Texas. I just want everybody in the world to hear that you said I build bigger things than you do. you do. The data centers are very enormous. It all started in 2016. I announced the world's first AI supercomput. The DGX1, the most advanced computer that anyone has ever built. It was just crickets. Crickets except for one person. And it was you. It was like a great idea. So, I built another DGX. Great. And this thing is mighty. This is the new DGX Spark. So, that's the whole thing. Wow. Five times the computational power of DJX1. 40 watts, not four. Wow. DJX1 to DJX Spark. I cannot wait to get my hands on one of these. I've already asked the team and I'm just on a waiting list now. And of course, the OpenAI team got one as well. Here it is. Here's Greg Brockman. Here's Sam Alman. And there is Jensen. I see Mark Chen up in the corner. And the rest of the OpenAI team with the beautiful DGX Spark. Next, Anthropic launched something very unique and it kind of went under the radar, but I think it might actually be a bigger deal than most people think it is. This is Claude Skills. Check this out. Today, we're introducing skills in Claude.ai, Claude Code, and the API. skills let you package specialized knowledge into reusable capabilities that claude loads on demand as agents tackle more complex tasks. A lot of people are saying this is a replacement for MCP, although it",
        "start": 0.08,
        "duration": 356.8
    },
    {
        "text": "Claude Skills. Check this out. Today, we're introducing skills in Claude.ai, Claude Code, and the API. skills let you package specialized knowledge into reusable capabilities that claude loads on demand as agents tackle more complex tasks. A lot of people are saying this is a replacement for MCP, although it this graph right here. So, Alex says it's kind of like in the Matrix where Neo learns new skills by literally just piping in the knowledge into his brain. It's kind of like that. So, you load a folder with skill.md in it. The file starts with a name and description, then contains instructions, code, and resources. This simplicity means anyone can now specialize Claude without building custom agents. Skills can contain effectively unlimited context without bloating the context window. So, it loads only what it knows it needs. These bundled files can contain everything from additional markdown instructions to image assets to code snippets that Claude can execute. All right, so check it out. Here's an example of how it works. So, let's say you run a company and you have brand guidelines. You put your brand guidelines in there. You have a skill.md folder and resources. You put it all together in this little zip file. Then you upload it as a skill and now Claude has access to your brand guidelines anytime you talk about branding. So, of course, my company is working on an exciting new game. Help us with the creative pitch deck and checking for the brand guideline skill. It found it and now it can load in the assets. It can load in the instructions and anything else it needs to help it create brand guidelines. And again, you don't have to load this into every single context window. It just knows to go look for it. So, I think this is really cool. I haven't had a chance to check it out yet. If you want me to create a full tutorial on it, just let me know in the comments. And if you like building with agents, check out the sponsor of today's video, Stack AI. AI agents are the future of work, but most teams don't actually know how to build them. That's where Stack AI comes in. It's the enterprise toolkit for building secure, powerful AI agents quickly. You can start from a pre-built template, plug in your knowledge base, run rag, and OCR. Pick your favorite LLM, and you can choose from over 100 natively integrated tools. You can even export with your own UI, passwords, SSO, source URLs, the works. And it's SOCK 2, GDPR, HIPPA compliant with built-in PII protections, no training on your data, and guard rails. The best part, you just type in what you want and let the platform do the rest. It'll build you exactly what you need. So if you need agents for IT, legal, finance, research, all backed by a secure infrastructure build with stack",
        "start": 177.599,
        "duration": 631.7600000000001
    },
    {
        "text": "training on your data, and guard rails. The best part, you just type in what you want and let the platform do the rest. It'll build you exactly what you need. So if you need agents for IT, legal, finance, research, all backed by a secure infrastructure build with stack I'll drop a link down below. Let them know that I sent you. It helps us build the channel. And now back to the video. All right. Next, in something that we probably all saw coming, Poly Market says, \"US Army general admits he used ChachiPT to make key command decisions.\" And this went absolutely viral. 7.5 million views. All right. Now, there's a lot to unpack with this. Now, if the general is simply asking, \"Who do I attack?\" That's not good. But if it's using chat GPT to help him understand all of the different options, to gather information, to think through different permutations of what could possibly happen in certain situations, I actually think this is a good thing. This is what I use it for. Now, of course, my use cases aren't life or death, but to use Chat GPT to get a better sense of the battlefield, to get a better sense of all of the potential options, I do think this is good. And somebody asked rock, what do you think? AI tools like chatbt can brainstorm ideas or summarize data quickly which might aid decision-making. However, for critical military commands relying on unverified outputs from general purpose models invites risks like hallucinations, biases or security leaks. Human judgment backed by specialized truth focused AI remains essential. XAI prioritizes that reliability over hype. So Grock essentially echoes what I said which is use it to gather information use it to synthesize information verify the outputs and then for key decisions for the actual verification and decision-m that needs to stay with humans use AI to gather information to synthesize information and then ultimately the decision and the verification needs to be in human hands human in the loop. All right. Next, OpenAI is going around pitching companies on using a signin with chat GPT button. Very similar to what we already have with signin with Google, signin with Apple, but now sign in with chat GPT. Obviously, this has a lot of benefit to OpenAI. They get their pixel, their button on a lot of different websites. They get all of this additional telemetry data. But an interesting part of the pitch according to the information is that companies that agree can transfer the cost of using open AAI models to their customers. Very interesting. So as Chad GPT continues to infiltrate all of the kind of traditional websites, traditional apps, all of that compute, all of that inference cost is being paid for by the publisher, by the app developer. And now let's say I have a ChachiBT Pro account. I can log into a website and use my own Chachi BT Pro",
        "start": 318.0,
        "duration": 941.5200000000001
    },
    {
        "text": "the kind of traditional websites, traditional apps, all of that compute, all of that inference cost is being paid for by the publisher, by the app developer. And now let's say I have a ChachiBT Pro account. I can log into a website and use my own Chachi BT Pro or app developer not have to pay for me, but I might actually get a higher quality model because that's what I'm paying for with Chat GBT Pro. So I actually think this is super smart on OpenAI's part. And of course, I've been talking about platform risk a ton lately. And anytime you're building some part of your infrastructure on top of another company, and especially OpenAI lately, there's always this inherent platform risk. If OpenAI decides to change their rules and all of a sudden your website does not comply with their rules and they disable that sign-in button, maybe a large fraction of your user base can no longer log in easily and they have to switch. So again, there's just so much to think about, but from OpenAI's perspective, it just makes a ton of sense. All right, next. This was hilarious. So 50 people in San Francisco went to a dead-end street during dusk and ordered Whimos, and they all ordered it to the end of this deadend street. And of course, the consequence, all of them got stuck. Here's a couple images of it. You can see all the Whimos just waiting in line. They can't really do anything. I've actually found that Whimos on deadend streets really struggle and they take a lot of time. I was staying in an Airbnb in San Francisco a few months ago. I ordered an Airbnb to this dead-end street and it would take like 30 seconds or 60 seconds for it to figure out how to just turn around and it wouldn't move. It would just wait there as it figured it out and then moved. So imagine that times 50. Here's another image of it. Look at all these poor Whimos just stuck in the corner here. But I think this is hilarious and Riley called it the first Whimo DOS attack. All right, next. Vo 3.1 is out. This is a minor version bump, but a lot of cool updates. So with VO3.1, we're bringing audio to existing capabilities to help you craft the perfect scene. With ingredients to video, you can use multiple reference images to control the character objects and style. Flow uses your ingredients to create a final scene that looks just as you envisioned. Then you can also control the shot from start to finish. So provide a starting and ending image with frames to video. And this will allow you to tie multiple videos together and really just get unlimited video length. Now you can create videos lasting a minute or more. Each video is generated based on the final second of your previous clip,",
        "start": 474.72,
        "duration": 1226.3190000000002
    },
    {
        "text": "provide a starting and ending image with frames to video. And this will allow you to tie multiple videos together and really just get unlimited video length. Now you can create videos lasting a minute or more. Each video is generated based on the final second of your previous clip, longer established shots. You can also insert elements into an existing scene. Something I saw for the first time with Genie 3. You can also remove unwanted objects and characters from a scene as well. Very cool. We've been testing it out lightly, not extensively yet. I think some people are having a lot of success with it being better than V3, and some people say it's not that much better, if not at all. Let me know what you think in the comments. All right, speaking of video models, Sora got a few updates itself. First, storyboards are now available on the web to pro users. You can kind of think of that like Google's flow to VO is storyboards to Sora. All users can now generate videos up to 15 seconds on app and web. Pro users up to 25 seconds. So just a couple quick updates on Sora. Next, we are in the era of AI models discovering novel science. This is the most exciting part of AI to me today. Sundar, the CEO of Google, an exciting milestone for AI and science. Our C2S scale 27B foundation model built with Yale and based on Gemma, so open source open weights generated a novel hypothesis about cancer cellular behavior which scientists experimentally validated in living cells. And the most exciting part is these models are just limited by how much compute we can throw at them. And so if it's a function of how much compute can we throw at it to solve cancer, we should just be throwing as much as possible at it. So, with more preclinical and clinical tests, this discovery may reveal a promising new pathway for developing therapies to fight cancer. Very cool, Google. All right. Next, Androll seems to be bringing our military into the future. They just released Eagle Eye, which is kind of a full futuristic helmet that the military will be wearing. So, Eagle-Eye offers the ultimate bird's eyee view through a collaborative 3D sand table. This is just one example of what it can do. I'll show you a couple more. Execute remote mission rehearsals, integrate location aware video feeds, coordinate moves, win the fight. So, here's another demo video. And again, it looks like a video game, but it's not. This is actually augmented reality for our military. And as you can see, it has a little mini map in the bottom left corner. In the top right, we have all of these status updates. We also have like what you get in Assassin's Creed. So, if you have a a mission goal, you can see it in red over here and green. It's just",
        "start": 620.399,
        "duration": 1510.0800000000004
    },
    {
        "text": "a little mini map in the bottom left corner. In the top right, we have all of these status updates. We also have like what you get in Assassin's Creed. So, if you have a a mission goal, you can see it in red over here and green. It's just right you get video. They are just really taking video game aesthetics and functionality and making it reality. It is so awesome. Here's another example. Even the menu system how it looks. I swear it's straight out of Call of Duty. But there we go. You can see it is tracking enemies. You get friendlies over here. It tracks it behind the car. So cool. All right. Next. Jeff Bezos says data centers might be moving to orbit and there are a number of benefits. One being constant solar energy, another being it's quite cold up there and you might not need as much power to cool these systems. Listen to this clip. One of the things that's going to happen in the ne it's hard to know exactly when it's 10 plus years, but I bet it's not more than 20 years. We're going to start building these giant gigawatt data centers in space. So these giant training clusters, those will be better built in space because we have solar power there 247. We will be able to beat the cost of terrestrial data centers in space in the next couple of decades. And so space will end up being one of the places that keeps making Earth better. It already has happened with weather satellites. It's already happened with communication satellites. the next step is going to be data centers and then other kinds of manufacturing. That's so cool to think about and it does make sense. There's only one potential downside. It is going to be incredibly expensive to build a data center in space. And that cost might outweigh the cost of just building it here and powering it on Earth. All right. In a visualization I thought was really cool and I wanted to share with you all. This is what cloud code looks like when it's navigating through your codebase. Check this out. The blue node that you're about to see is Cloud Code navigating and exploring your codebase. There it is. This guy right there going through all of your code, exploring all the different files, all the different directories, and just learning as it goes. I just found this visualization to be really fun to look at. And last, a new paper attempts to define what AGI actually is because it has been a moving target. There's been a number of different definitions. Even from a single company, the definitions have been changing. So this is Dan Hendris. The term AGI is currently a vague moving goalpost. To ground the discussion, we propose a comprehensive testable definition of AGI. Using it, we can quantify progress. GPT4 was 27% of the",
        "start": 764.8,
        "duration": 1800.3200000000006
    },
    {
        "text": "of different definitions. Even from a single company, the definitions have been changing. So this is Dan Hendris. The term AGI is currently a vague moving goalpost. To ground the discussion, we propose a comprehensive testable definition of AGI. Using it, we can quantify progress. GPT4 was 27% of the we're quite close. So our definition of AGI is an AI that can match or exceed the cognitive versatility and proficiency of a well-educated adult. To measure this, we assess multiple dimensions of intelligence derived from the most empirically validated model of human intelligence, CHC theory. So here are some of the categories that go into that. General knowledge, reading and writing, mathematical, on the spot reasoning, working memory, long-term memory storage and retrieval, visual, auditory, and speed. So for example, if a model doesn't have persistent memory, it's going to score a 0% on memory storage and retrieval. relying on massive context windows is a capability contortion, a workaround that mass this fundamental limitation. So, by the way, if you want me to do a full breakdown of this paper, let me know in the comments. So, that's it for today. Thank you to Stack Aai. Check them out. They're a great partner to us. Link in the description below. Click it. Let them know I sent you. If you enjoyed this video, please consider giving a like and subscribe. and I'll see you in the next",
        "start": 910.72,
        "duration": 1917.5980000000009
    }
]