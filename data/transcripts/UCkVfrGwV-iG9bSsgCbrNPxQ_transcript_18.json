[
    {
        "text": " Meta is speedr runninging the AI race fumble. Now, let's talk about this. So, of course, we need to talk about the Yan Lan situation because this is important. So, now if you don't know who Yan Lan is, well, he's basically AI royalty. This guy won the Turing Award, which is basically the Nobel Prize for Computer Science. He's one of the fathers of deep learning and the technology that makes modern AI actually work. Now, he's been at Meta for over a decade, remember decade, as their chief AI scientist. And this is the guy that you would want leading your AGI push, right? Well, here's the problem. Yanlen has a very specific vision for how to build AGI. And it's actually completely different from what everyone else is doing. While the entire industry is going in on LLMs, you know, the chat GBT approach, Yanlick has been saying for years that this is the wrong path. He believes we need something fundamentally different, something more inspired by how human brains actually work. He's been pushing this idea of world bottles and energy based learning systems. Now, you might think, okay, well, he's right. Maybe the guy who helped invent the entire space knows exactly what he's talking about. But now, the problem is that Meta doesn't agree. They just don't want to hear this out because [music] other companies are making money now. They're getting users now. So, what has Meta done? Well, they've sidelined their chief AI scientist. [music] They're not technically pushing him out, but they're not allowing him to fulfill his vision either. They're just doing what everyone else is doing, building bigger and bigger large language models, hoping that if they just make them large enough, AGI will magically emerge. It's like hiring Gordon Ramsay to run your restaurant, then ignoring all his advice and making bigger and bigger burgers. Surely, there might be a bigger burger, but you're missing the point entirely. The point is is that Yanukan could actually be right. The current approach to AI just making models bigger and feeding them more data has already started to hit walls. are seeing those diminishing returns. But Meta's too committed to the hype train to pivot. So you got the situation where you've got the most qualified person who's basically being ignored because his ideas don't fit the current trend. That's not how you win a technology race. That's how you become blockbuster when Netflix shows up. And here's the kicker that most people are forgetting is that other companies are starting to notice what Yanickin has been saying. World models, the idea that AI needs to build an internal understanding of how the world actually works rather than just predicting the next word is gaining serious traction. Companies like Tesla are betting big on world models for their self-driving technologies. Researchers at DeepMind are exploring how world models could be the key to true reasoning and planning. Even some",
        "start": 0.16,
        "duration": 288.39999999999986
    },
    {
        "text": "understanding of how the world actually works rather than just predicting the next word is gaining serious traction. Companies like Tesla are betting big on world models for their self-driving technologies. Researchers at DeepMind are exploring how world models could be the key to true reasoning and planning. Even some around this approach, believing that world models are just how we'll get to AGI, not just bigger large language models. And these companies are actually taking Len's ideas [music] seriously and putting real resource behind them. Meanwhile, Meta has the guy who pioneered these concepts and they're just letting him sit there while they chase the same approach that everyone else is doing. Now, it's important to note that Yanlun isn't just 100% right about everything. Nobody ever is. Oftentimes, I see critics of Lun saying that Yanlukan has been wrong in the past. And yes, he has. This article here shows that Yan Lakun was initially wrong about LM when they first came out. He said that I don't think we can train a machine to be purely intelligent from text because the amount of information that the world is contained is tiny compared to what we need to know. And he had this example of where he said that if I take an object, I put it on a table, I push the table, it's completely obvious to you and me that the object would be pushed with the table. But with a textbased model, you could train it as much as you want. This would never occur. Essentially, what he was saying is that these models don't really understand how the real physical world works. And so no matter how much text you train them on, it's pretty pointless to, you know, pursue that path. Now, I think there was some element to truth at this at the start because these models weren't that smart. But of course now with the way models reason they do start to get the answers a lot more. Now we definitely need to talk about this because most people seem to have forgotten what the Llama 4 benchmark scandal was. So this probably should have been a bigger scandal than it actually was. And the Financial Times recently actually broke you know a story about Meta's Llama 4 model. Now so Llama 4 at the time was essentially the comparison to GPT4 or GBT 5 at the time and that was of course the big flagship model from Meta. Now when you're building AI models you have to test them. You need to do benchmarks and there are standardized tests that measure how smart your AI is. Can it answer questions correctly? Can it reason through problems? Can it write code? All of that stuff. Now, companies live and die by the benchmark scores because it's kind of like how everyone decides whose AI is best. People don't have the time to test the models themselves. They just look at the",
        "start": 144.56,
        "duration": 511.19999999999965
    },
    {
        "text": "correctly? Can it reason through problems? Can it write code? All of that stuff. Now, companies live and die by the benchmark scores because it's kind of like how everyone decides whose AI is best. People don't have the time to test the models themselves. They just look at the have actually improved. Now, the thing is is that when Meta released Llama 4, the benchmark scores looked pretty good. They weren't like worldbeating, but they were respectable. They were, you know, telling everyone, \"Look at how great our AI is. We're actually competitive up there with some of the big organizations.\" But then the Financial Times recently dug into the details and they actually found something pretty shady. Meta had been cherry-picking their results and they'd run the benchmarks multiple times instead of reporting the average score like you're supposed to. They just reported the best run. Now, sometimes they'd run it a dozen times and just pick the highest number. And that's not how benchmarks work. They basically cheated. Now, the whole point of benchmarks is to actually set a realistic, honest assessment of how good your AI is. When you start gaming a system like this, you're not just lying to the public, you're lying to yourself. You're making business decisions based on fake data. And this is why this is damaging to Meta's AGI strategy. If your leadership can't get honest benchmark scores, how are they supposed to make good decisions about where people invest billions of dollars in research? if Llama 4 isn't actually as good as they think it is, but they're making strategic decisions around those fake scores. They're building the entire AI strategy on quicksand. Plus, think about it like this. If Meta releases another AI model, are you even going to trust their benchmarks anymore? I know certainly there's no way in hell I'm trusting Meta's future benchmark scores. That has just completely destroyed the trust. Llama 5. Unless it goes vigorous, and I mean vigorous testing, and other people say it's good, and I've first tested it myself, there's no way I'm even going to think about using that model because they're probably going to cherrypick the results again. Now, we actually need to talk about something that most people seemingly forgot because at the time, this was hilarious. I remember looking at all the Twitter replies, which we'll get into in a moment, but this is something where you actually see the strategy falling apart. Meta Vibes. Have you even heard of this app? Probably not, because it's terrible and nobody uses it. So meta vibes was supposed to be this cool AI powered social experience where you could create and share AI generated content. I mean it sounds okay in theory, right? AI is hot, social is what meta does. Let's blend those two things together. But of course in practice it is just slop, complete AI slop. And for those of you",
        "start": 257.6,
        "duration": 758.7210000000001
    },
    {
        "text": "social experience where you could create and share AI generated content. I mean it sounds okay in theory, right? AI is hot, social is what meta does. Let's blend those two things together. But of course in practice it is just slop, complete AI slop. And for those of you people use for lowquality obviously generated AI content that floods the internet. You know the stuff weird with AI generated images, soulless content that just doesn't serve any purpose. Now, Meta Vibes is basically a slot factory. It encourages people to massproduce this garbage and share it. You know, the thing that drives me crazy about this kind of content is that Meta has access to some of the smartest AI researchers in the world. This is a company that has billions of dollars. They have the infrastructure that most companies can only dream of. And this is what they build, an app that generates forgettable, lowquality content that nobody asks for. You could have built absolutely anything. And this is what you spend your time and money on. I mean, this just shows a fundamental misunderstanding of what people actually want from AI. People don't want tools to create more mediocre content. The internet already is filled with AI slop. People want something from AI that is genuinely useful that saves them time or something that's genuinely creative that surprises and delights them. And Meta AI vibes just does neither. It's just a way to share slot, which people simply don't value. And the worst part of this is that the app probably consumes, you know, hours of engineering time, millions of dollars, resources that are probably better spent building actual AGI and research that could have actually went into AGI research instead. Instead, they wasted, you know, time on a product that was dead on arrival. Nobody asked for this. And this is the problem with meta. This is what happens when you don't have a coherent strategy. You ship random products because AI is hot and you feel like, oh, I need to do something, anything, just to stay relevant. But you're not building towards AI. You're just thrashing. I mean, take a look at these meta AI vibes public reactions. You can see someone said, \"Horrible, meaningless nonsense that literally no one on Earth asked for. Should have called it trough, the kind of pigs eat their slop out of. We ain't watching this slop feed Lau.\" And then someone says, \"Slop as a service.\" Genuinely, that tweet where they announced Meta AI vibes was ratioed completely. All of the tweets underneath had way more likes and way more retweets [music] than Meta did themselves. I mean, I don't understand what kind of, you know, research and development they did because this is genuinely not good at all. Now, you might have thought, all right, that the Meta AI vibes app was bad, but trust me, guys, it gets even",
        "start": 383.28,
        "duration": 1010.4809999999999
    },
    {
        "text": "[music] than Meta did themselves. I mean, I don't understand what kind of, you know, research and development they did because this is genuinely not good at all. Now, you might have thought, all right, that the Meta AI vibes app was bad, but trust me, guys, it gets even there are literally, you know, chat bots that nobody asked for. Okay, now look at these chat bots because this is just I mean, insane. Meta decided to launch a bunch of AI characters which were celebrity chat bots personalities you could chat with on Instagram and Facebook and some of them were super super weird and this was one of the characters that you know of course gained a lot of attraction because someone at Meta thought you know what the world needs a parasocial relationship with fake AI stepmoms. Now I'm not here to judge anyone's interest but think about this as a product strategy for a company trying to build AGI. What are we doing here? I mean these chatbots are the definition of AI slop. They're generic, boring, serve no real purpose. They're not even tools. They're not entertaining. They're just there taking up space in Meta's apps, confusing users who accidentally kick on them. The celebrity ones were even weirder. I mean, they had actual celebrities lend their likeness to AI chatbots, but the chatbots were so bland and restricted, they don't actually capture anything about the actual celebrities. It's like talking to a corporate press release that happens to have a famous person's face. I mean, this is a problem with Mess's approach to AI. They're just focused on engagement metrics and keeping users on their platform that they're building things nobody wants. I mean, think about real AGI research. That's understanding true intelligence. That's about building systems that can think, reason, learn, and adapt. It's deep, hard, fundamental research. Meta's chatbots are none of that. They're just existing large language models with, you know, boring system prompts. You're a stepmom. You're a celebrity. That's no innovation, no progress towards AGI. Slop, more slop. Meta just simply looked at the, you know, air revolution and said, \"How can we use this to increase engagement on social platforms?\" Instead of asking, \"How can we use this to actually advance towards AGI?\" And this is why Meta is losing. While they're building AI stepmoms, other companies are doing actual research, making breakthroughs, and pushing towards actual AGI. I mean, look at the public reactions from this tweet. We are truly only investing more and more into Meta Super Intelligence Labs as a company. And in reporting to the contrary of that is clearly mistaken. That tweet is from Alexander Wang, currently the CEO of Meta Super Intelligence Labs. And this tweet, the response tweet, which is hilarious to me, is from Steven Hyel, who says, \"Who's your favorite Meta AI character, Russian girl or stepmom?\" He's clearly taking a jab at the fact that these",
        "start": 510.96,
        "duration": 1254.8019999999997
    },
    {
        "text": "tweet is from Alexander Wang, currently the CEO of Meta Super Intelligence Labs. And this tweet, the response tweet, which is hilarious to me, is from Steven Hyel, who says, \"Who's your favorite Meta AI character, Russian girl or stepmom?\" He's clearly taking a jab at the fact that these towards AI, but all the products they seem to be working on are just AI slot products. Now, I got to be honest, guys. We need to talk about something that is called the management disaster. Okay? And honestly, it sounds like a joke, but it is real. And this captures why at the fundamental level, Meta's air strategy is just broken. Okay? There are reports, credible reports, that Meta has a 28-year-old managers supervising people like Yanak. Remember the guy who we talked about in the, you know, beginning? Okay, think about that for a second. Think about that for a second. A 28-year-old is managing a touring award winner. A guy who's been doing AI research since before the manager was born. Now, I'm not saying that 20-year-olds cannot be smart or capable. Some of them are brilliant. But managing legendary AI researchers that requires a very specific set of skills, experience, and credibility that you just don't have at 28. This is a symptom of a much bigger problem at Meta. [music] They've completely bought into Silicon Valley's youth worship culture and think that young equals innovative. They think that disruption means putting inexperienced people in charge. But think about it guys. Building AGI is not like building a social media app. You cannot just move fast and break things. You need deep rooted expertise. You need people who understand the science, the math, the philosophy of what you're trying to build. And when you have managers who don't understand all of the technical work, several bad things can happen. First, you get terrible prioritization. The manager doesn't know which research directions are promising and which are dead ends. So, they just go with whatever sounds cool or whatever leadership is hyping up that week. And second, you lose your best people. Imagine being Yan Leon. You spent decades at the cutting edge of AI research. You've trained thousands of students. You've published hundreds of research papers. And now some kid who graduated college 6 years ago is telling you what to work on and when you have it done. Would you, if you were him, stick around or would you start looking for the exit? And then of course you're going to get political dysfunction where managers don't have technical credibility. So they can't win arguments on merit. So everything becomes about office politics. Who can sell their ideas better? Who's better at corporate maneuvering? the actual quality of the research becomes secondary. And this is organizational suicide for a company trying to build AGI. Remember guys, AI is hard. Think about what you're trying to do. You're trying to recreate the",
        "start": 635.68,
        "duration": 1498.0820000000003
    },
    {
        "text": "office politics. Who can sell their ideas better? Who's better at corporate maneuvering? the actual quality of the research becomes secondary. And this is organizational suicide for a company trying to build AGI. Remember guys, AI is hard. Think about what you're trying to do. You're trying to recreate the technical problem that humanity is probably ever going to attempt. You need your best people and you need them empowered and listened to. Instead, Meta has created a structure where their best people being managed by folks who might not even understand the entire game. I mean, look at this. From the article in the Financial Times, it's very clear that Yan Lakun was upset at this structure. You can see he says that Alexander Wang isn't telling me what to do either. You don't tell a researcher what to do. You certainly don't tell a researcher like me what to do. And I mean look at the public opinions on Wang when people realized that this was the guy leading Meta's labs. You can see here that someone said the Wang dude just made a data labeling startup and he acted like he was an AI genius. Never understood the hype around him. And someone else says that I had the same thought. I listened to an interview with him around a year ago and he didn't seem to offer new anything to the convo apart from we need to scale. And then someone else says no A 28-year-old dude is not enough experience to lead a huge organization like Meta. Wow. And now here's where we get into even more of Meta issues because yes, there are more. So, let's talk about Meta's favorite strategy, which is buying your way to success. Well, since Meta doesn't have the researchers, the organizational structure, or even the vision. I mean, what do they do? Well, if you can't build it yourself, well, you can just buy it. Can't hire good people, just acquire entire companies. A meta recently bought Manis, which is of course the EI agent startup, which is a very good startup. But you have to think about this, okay? I mean, sometimes buying talent and technology is faster than building the tech yourself. But here's the problem that Meta may not understand. Meta is using acquisitions as a substitute for having a coherent strategy. They're not buying those companies because those companies fit into a master plan. There's buying those companies because they're just panicking. Opening eyes ahead. Google's ahead. Anthropic's ahead. So Meta's like, \"Okay, let's just throw money at the problem and let's see if something sticks.\" They're trying to win at basketball by buying the most expensive shoes, the fanciest gears, hiring random coaches, hoping that somehow makes you good. But if you don't have a game plan, if you don't have coherent trading strategy, none of those things are going to work. Now, the same thing is happening with their research hiring.",
        "start": 758.639,
        "duration": 1723.6819999999998
    },
    {
        "text": "buying the most expensive shoes, the fanciest gears, hiring random coaches, hoping that somehow makes you good. But if you don't have a game plan, if you don't have coherent trading strategy, none of those things are going to work. Now, the same thing is happening with their research hiring. top AI research from other companies. These articles showcase exactly what Meta is doing. We're talking millions of dollars in compensation. Again, nothing wrong with paying people well. AI researchers are some of the most sought after talent at the moment. But you need something to do with those people once you hire them. You need to give them clear direction, good management, and the resources to do the breakthrough research. Instead, Meta is hiring all of these brilliant people and then they're making them build chat bots for Instagram, making them work on engagement optimization and sticking them in a dysfunctional organizational structure where 28-year-olds are making all the technical decisions. It's just a waste. These researchers came to Meta because they want to work on AGI, on cuttingedge problems, and instead they're working on incremental improvements to ad targeting algorithms. This is what happens when you have unlimited money but no strategy. You throw money at everything hoping something works, but money alone cannot create AGI. Focus, vision, and excellent execution create AGI. Meta has the money. They don't have the rest. And the worst thing about this and the thing that annoys me so much is because Meta could be great. They have the best resources in the world. They got the best infrastructure. They have the best data. They've literally got everything you need, but without the strategy tying it together, it's just a pile of expensive resources going nowhere. I mean, it's very clear that individuals are starting to realize that Facebook seems erectionist, steps behind, and they're trying to throw money at every problem. And the worst thing about this is that Yanukan has actually said that some people who are still in Meta, who haven't left yet, will actually leave because there's, you know, a loss of confidence in major divisions. Now, I'm not saying I'm some kind of genius that can develop a strategy for a large tech company such as Meta, but I think I understand where Meta's gone wrong clearly, and there's some clear steps that Meta need to take. So, if I was leading Meta, this is what I would do. Okay, so first I would actually listen to Yanlakan. Maybe he's wrong about how to build AGI. Maybe he's right. Nobody knows. But think about this. He's earned the right to actually try out his approach. Give him a division. Give him the resources and let him pursue his division. You guys have billions of dollars anyways. So if it doesn't work, fine. You'll learn something. But dismissing him without trying his ideas are insane. Secondly, stop faking the benchmarks. That doesn't make any sense.",
        "start": 872.399,
        "duration": 1969.4429999999998
    },
    {
        "text": "approach. Give him a division. Give him the resources and let him pursue his division. You guys have billions of dollars anyways. So if it doesn't work, fine. You'll learn something. But dismissing him without trying his ideas are insane. Secondly, stop faking the benchmarks. That doesn't make any sense. decisions based on the reality, not wishful thinking. If your models aren't good enough, they aren't good enough. Fix them. Third, fix your management structure. You need leaders who can understand the technology, who can actually make good technical decisions, who have the credibility to lead worldclass researchers. Don't put inexperienced people in charge of critical research divisions. That's just a big mistake. Fourth, when it comes to products matter for the love of God, don't make the same mistakes that other AI companies are making. Stop shipping AI slop. Not every product needs to be userfacing. Maybe just spend a few years doing research before you try to monetize it. OpenAI spent years on research before releasing Chat TV and their patience paid off. You need to make products that people actually want. Don't just make sloppy products that nobody asked for. Do some actual user feedback. See what's working in the real world and develop something that people can actually use. And last of all, please for the love of God, develop an actual strategy. What is your vision? What are you trying to do? How are you going to get there? What are your milestones? What research directions are you pursuing? Do it and commit to it. Stop throwing money at the problem. Use your acquisitions properly. Don't just buy AI companies and let them sit there. Integrate them into the entire actual strategy and give them more resources and autonomy to do what they're already good at. But it would require them to admit that they've been wrong. And it would require major organizational shakeup. And it would require patience and long-term thinking, which doesn't play well on those quarterly earnings calls. They're probably going to keep doing what they're doing, throwing money at their problem, shipping random AI products, and claiming they're making progress while falling even further behind. And in five years, when opening a Google or Anthropic or some startup we've never heard of achieves AGI, Meta will be left holding the bag with expensive chat bots and fake benchmark scores, wondering where it all went",
        "start": 998.32,
        "duration": 2166.8029999999994
    }
]