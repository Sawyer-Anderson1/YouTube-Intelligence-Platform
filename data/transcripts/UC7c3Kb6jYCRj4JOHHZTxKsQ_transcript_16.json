[
    {
        "text": " I have a lot to talk about in this video and it all starts with this article from the information. How open AI's organizational problems hurt Chad GPT? And I'm going to be answering a broader question. Does model improvement matter all that much anymore? What I mean is when we continue to see these incredible gains on the common benchmarks, the science benchmarks, the math benchmarks, do these gains actually matter? I'm going to make the case that no, they don't for the vast majority of use cases. And if you've watched this channel at all over the last year, you know I've been saying this for a while. The common sentiment is if model intelligence froze today, there would still be so much work on the scaffolding and implementation and deployment side to just get the most value out of these models the way they are today. And maybe that's the friction that the information's article is describing within OpenAI. Let me read a little bit of it. In prior years, every time OpenAI made a big upgrade to the artificial intelligence that powers the chatbot, usage surged as people easily found ways to get useful responses out of it, one employee said. So, what it's saying is in previous years, they would improve the model quality. And we felt it, right? Prior to this year, every model release was some huge unlock, but at a certain point, the models got really, really good and it felt like the improvements were iterative versus big step changes. And so what would happen is they would release a new model. It would be incredibly more capable and thus more people would hear about it, more people would figure out how to use it in their day-to-day lives. And that leads us to where we are today in which a ton of people, billions of people are using AI every single day. But here's the thing. If I already have PhD level intelligence in my pocket wherever I go, is there really that much benefit to be gained from having the best PhD versus a SOS so PhD? For me personally, most use cases, not really. And to be frank, and a lot of you might react strongly to this, I don't even use deep research or max level thinking all that much. There are certainly times where I need it, but for the vast majority of use cases, for me, I'm using the regular model. I'm just saying give me the best response as quickly as you possibly can and keep speed. I'm gonna come back to that. And here's the key sentence. But even as ChiaBT attracted more users this year, improvements to the underlying AI models intelligence and the in-depth research or calculations it could suddenly handle didn't seem to matter to most people using the chatbot. And so I think that is really what they're seeing. And so there's this common sentiment that",
        "start": 0.0,
        "duration": 345.43800000000016
    },
    {
        "text": "ChiaBT attracted more users this year, improvements to the underlying AI models intelligence and the in-depth research or calculations it could suddenly handle didn't seem to matter to most people using the chatbot. And so I think that is really what they're seeing. And so there's this common sentiment that users and chat GPT and OpenAI is more known for consumers. And so that's another thing I want you to keep in mind as we go through this. Whether that's true or not, that's the perception today. And that perception is certainly emphasized by the fact that Anthropic is really only known for their API and their models are incredibly good at coding and mostly used for coding. Whereas Chat GPT is more well known through its interface rather than through its API. And maybe that's just my perception of it. But then you have things like OpenAI acquiring Johnny Ives company and designing the next generation of consumer hardware devices. You have them talking about ads in chatbt. You have them talking about shopping. All of these things are consumerf facing. Whereas philanthropic the only thing you hear from them is model performance API and alignment. And so back to the article and back to the theme of this video, continued model improvements to the core intelligence don't really move the needle for Chad GPT's customers, which are perceived to be majority consumers. And another thing that you probably know if you've watched this channel at all, I am a speed maxi. I've been saying this for a while. Speed matters more than getting the absolute best response. As long as the response is right for 99% of my personal use cases, I want the fastest response possible. That includes vibe coding. And yes, I want AI to write the best code possible for me. But being able to iterate quickly through different ideas and different builds is more important than having the best possible code. And so, listen to this. Reasoning models don't do much for Chad GPT, whose users generally want answers fast. according to a person who worked on them. Now, if you think about Chat GPT as going head-to-head with Google search, which is one of the biggest markets on earth, and Google search is the best business of all time, then yeah, of course, they want to go directly at that. But being really good at search doesn't require deep thinking. It doesn't require spending more tokens on testime compute. It doesn't require PhD level intelligence. It's all about integrations. Making sure you have access to the right data. Making sure you can crawl websites correctly. Making sure you have access to my calendar and my email and everything else that I use every single day. That's where the real value comes from. And I think a lesser problem that they're facing that's highlighted in this article is as follows. Chat GPT faces an even bigger problem than the issue with reasoning",
        "start": 172.239,
        "duration": 676.6389999999999
    },
    {
        "text": "my calendar and my email and everything else that I use every single day. That's where the real value comes from. And I think a lesser problem that they're facing that's highlighted in this article is as follows. Chat GPT faces an even bigger problem than the issue with reasoning understand the full range of topics the chatbot can answer questions about even when it's using non-reasoning models that give faster answers. So that's just an education problem. I think that's actually quite solvable and solvable in the short run as AI continues to infiltrate every single area of culture and society then it's just going to become part of what we do every day all day. But I think this problem is actually more acute when you think about what models can actually do for you. That's really where even I struggle. I generally know what types of answers chat GBPT and other AI are going to be really good at and really good at getting me good answers, but I'm less good at identifying certain problems that can be automated well with AI, certain tasks that can be completed with AI. That's something that I personally struggle with. So, I have to assume their broader customer base also struggles with that. But again, that's a very solvable problem. Now that's where the crux of this article comes in, which is the tension between the research division and the product division of OpenAI. This is Fiji Simo, new CEO of applications at OpenAI, one of the most senior leaders at OpenAI currently, basically responsible for all applications at OpenAI. And the counterpart is Mark Chen and Yakob Pachaki who run the research side. And again, according to the article, there is this perceived tension between the research and the product side of the business. So on Fiji's own blog, she said, \"At its core, OpenAI remains a research focused company, and products aren't the goal themselves.\" And that might be the case, but I don't actually think so. I think product is incredibly important, but at the same time, they need the best models. They need to be seen as a researchbased company. They need to be doing that cutting edge research to retain the top research talent because otherwise they're going to lose talent to other research focused organizations. That's just what researchers want to do. They want to research. And so if research is deemphasized in open AI, researchers are going to go elsewhere and that will manifest in them falling behind on the total capabilities of these models, the intelligence of the models, maybe the next breakthrough that allows the models to be so much more useful. And you're probably asking yourself, \"Hey, Matt, didn't you just say that model capabilities are sufficient as they are today? You don't need anymore. Why do you care if you have all these researchers?\" Well, the flip side of the argument is an absolute race towards self-improving artificial intelligence.",
        "start": 341.36,
        "duration": 975.8380000000004
    },
    {
        "text": "useful. And you're probably asking yourself, \"Hey, Matt, didn't you just say that model capabilities are sufficient as they are today? You don't need anymore. Why do you care if you have all these researchers?\" Well, the flip side of the argument is an absolute race towards self-improving artificial intelligence. first company to really achieve self-improving artificial intelligence is going to be the ultimate winner. They are forever going to be in the lead. And so no company wants to fall behind if that ends up being the case. I'm not saying that's what's going to happen, but if we're doing the thought experiment and trying to game it out, these companies certainly don't want to fall behind. And a quick thank you to Dell Technologies for sponsoring this portion of the video. Check out the new Dell Promax workstation with Nvidia RTX Pro Blackwells built in. This thing is an absolute beast for AI workloads. With NVIDIA RTX Pro, you now have a supercomput sitting on your desk, and it can do more with local AI than ever before. So, learn more about Dell Pro Max. Click the link in the description below to let them know I sent you. And I actually want to show you a counter example to the notion that this is ultimately a research company because Greg Brockman through OpenAI's own video said they've had to make very difficult decisions about their compute allocation. Specifically, they've moved some compute away from research and towards product towards the demand side of the business. We did not have enough compute to keep that going and so we made some very painful decisions to take a bunch of compute from research and move it to our deployment to try to be able to meet the demand and that was really sacrificing the future for the present. And so there you see Greg Brockman talking about in this moment in which their image generation became insanely viral, insanely popular, they had to take compute away from research and put it towards the demand side of their business. And so that's just one little example, but I'm sure he has to make difficult decisions like that every single day. In fact, I interviewed him and he said something along the same lines. Watch this. What is the conversation internally at OpenAI like when you're trying to decide where that compute investment belongs? Pain and suffering. It's the only it's the it's the real truth. It's like it's so hard because you see all these amazing things and someone comes and pitches another amazing thing and you're like, \"Yes, that is amazing.\" Now, I want to go back to the perception that Open AI is seen as a consumer AI company and Anthropic is seen as an enterprise AI company. I don't actually think that's the case. I think a lot of that is perception just because anthropic is entirely focused on enterprise and open AI is focused on",
        "start": 491.68,
        "duration": 1262.9590000000007
    },
    {
        "text": "the perception that Open AI is seen as a consumer AI company and Anthropic is seen as an enterprise AI company. I don't actually think that's the case. I think a lot of that is perception just because anthropic is entirely focused on enterprise and open AI is focused on be a focus maxi and of course if you're not marshalling and focusing all of your resources on a single thing you will never be as good as your competitor who is doing that. But that doesn't mean they can't be incredibly good at enterprise as well. And in fact, there's something about having the brand name in consumer and that translating to enterprise demand. Chat GPT is the verb for AI. It is very similar to how you say, \"Okay, go Google it for search.\" People say, \"Okay, just chat GPT it for AI answers.\" And so when you have that aura, when you have that brand name, of course, when enterprise decision makers are thinking about which products to go with and they have this rich history with Chacht in their personal lives, they are more likely to want to go with ChachiPT in the enterprise as well. In fact, here's Sam Olman in an interview that he just did saying exactly that. I think people really want to use one AI platform. People use their phone at their personal life and they want to use the same kind of phone at work. Most of the time we're seeing the same thing with AI. the strength of chat GPT consumer is really helping us win the enterprise. of course enterprises need different offerings but people think about okay I know this company open and I know how to use this chat GPT interface. So where these companies really need to focus and where I actually think Google has an incredibly big moat is in the integrations in the distribution. the fact that at least me, I use Gmail, I use Google Calendar, I use Drive, I use so many different Google products and they can simply have the star, the Gemini logo appear everywhere. And they did that with Gemini 3. That is so incredibly powerful. And I think that's probably the biggest uphill battle that Open AI has. It's not being number one on LM Arena. It's not this enterprise verse consumer play. It is strictly how do we get chat GPT to be everywhere that our users already are. If you enjoyed this video, please consider giving a like and subscribe.",
        "start": 638.24,
        "duration": 1517.4390000000012
    }
]