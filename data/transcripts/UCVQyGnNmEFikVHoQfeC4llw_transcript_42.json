[
    {
        "text": " Good evening. The whale is back and this time it brought an IMO gold medal. an open-source model from China just did something only Google DeepMind and OpenAI could do and then publish the weights on hugging face for free. Deepseek, the same lab that rattled Nvidia and wiped billions of big tech valuations with its ultra cheap R1 model has gone quiet for months. But tonight, the whale is back. They've dropped Deep Seek Math V2, a specialized reasoning model that hit gold medal performance at IMO 2025, which is five out of six problems, scored 118 out of 120 on the Putinham, beating the best human and in Deep Seek's own test, Outreason GPD5 thinking and Gemini 2.5 Pro on hard Olympiad style math, even on its first try. Oh, and one more thing. This is the world's first openweight IMO gold medal model. So, is GPD5 in danger? Google's Gemini Deep Think no longer alone at the top and is self-verification now the real arms race in AI, not just bigger GPUs? This front page by A IM network. Let's break down what Deep Seek just did. Why every serious AI lab is now watching China and what this means for the future of reasoning research and your next AI product. But before we do that, please make sure to like, share, and subscribe. Now that you've done it, let's go ahead. Deepseek has released Deepseek Math Vi 2, a math specialist model built on top of their experimental Deepseek VI3.2 EXP base. On paper, the numbers are insane. IMO 2025 solves five out of six problems, which is gold medal tier. China Mathematical Olympiad 2024, again gold medal level. Putnham 2024, Undergrad Math 118 out of 120, higher than the best human score of 90. This puts Deep Seek in the same elite club as Google Deep Mind's Gemini Deep Think, OpenAI's internal reasoning model that also hit IMO gold. The difference, Google and OpenAI are still closed. API only, internal only. Deepseek just threw an IMO gold brain on hugging face and said here download it. That's basically a shotfired at the entire closed model business model altogether. Most AI benchmarks today are well wibes. You throw a bunch of multiple choice questions or short answers at a model and if it gets the final number right, you declare victory. That works for AIM, HMMT, school level math. It doesn't work for IMO level problems where there is no simple final answer. You have to produce a rigorous proof. Every step can be right, almost right or completely made up. Traditional RL methods reward final answer correctness models. Quickly learn a bad habit. Bluff your way through the proof. Pray the last number matches. Deepseek math v2 flips this. It doesn't just ask did you get the right answer. It asks did you prove it properly and did you check yourself. The core idea reward self reflection not confident nonsense. Deep Seek basically put three",
        "start": 10.4,
        "duration": 501.35999999999996
    },
    {
        "text": "way through the proof. Pray the last number matches. Deepseek math v2 flips this. It doesn't just ask did you get the right answer. It asks did you prove it properly and did you check yourself. The core idea reward self reflection not confident nonsense. Deep Seek basically put three problem solver which is the generator writes the proof also writes a mini self-critique. This step might be wrong. I'm unsure here. The reward function is wired so that admitting doubt plus fixing it later is greater than bluffing confidently and being wrong. So the best strategy is equal to find and correct your own mistakes before submitting. The ironfisted judge which is the verifier a separate model trained just to grade proofs step by step doesn't care about final answer scores like an Olympiad jury. One is fully rigorous.5 is idea correct details missing and zero is logically broken. The auditor of the judge, the metaverifier, checks whether the judge itself is being lazy or hallucinating errors. If the judge flags a mistake that doesn't exist, then the judge gets punished. Wow, how interesting. Anyway, this forces the verifier to be both strict and honest over time. This creates a closed loop. The generator keeps discovering new weird proofs which leads to exposing blind spots. The verifier gets retrained on these tricky proofs. Resultantly it becomes sharper. The metaverifier keeps the whole system from gaming its own rules. So in the last training stages deepseek says human labeling almost disappears. The system is autoleabeling its own hard proofs with a quality that matches expert judges. And this is the real story. Not just AI solves IMO, but AI builds, tests, and upgrades its own reasoning engine. Here's the brutal part. Even if you strip away all of this multi-step thinking and selfcorrection, even if you say, let's say, no chain of thought, no retries, just answer once, Deepc claims math v2 still beats GPD5 thinking high from open AAI, Gemini 2.5 Pro from Google on a tough internal benchmark spanning algebra, geometry, number theory. Combinities comparable to China's high school math league. So especially in geometry, Deepseek Math V2 reportedly scores almost three times of Gemini. So two things are now true at the same time. It's raw intuition. One short answer is already elite. So when you allow it to think multiple times plus self-verify its proof quality jumps even higher and this is exactly how humans work. The first draft usually is intuition. Second draft self-critique not always but yes final draft carefully checked solution. Deepseek just showed that self-verification plus test time compute is a more powerful lever than just make the model bigger and hope that's a direct strategic challenge to the GPD5 style of more parameters, more data, more GPUs. So why opensourcing this is a big deal? Here's why. Deepseek just released the weights, shared the training recipe, detailed the verifier plus metaverifier loop. In other words, they handed the entire ecosystem. Here's",
        "start": 261.919,
        "duration": 964.7990000000002
    },
    {
        "text": "that's a direct strategic challenge to the GPD5 style of more parameters, more data, more GPUs. So why opensourcing this is a big deal? Here's why. Deepseek just released the weights, shared the training recipe, detailed the verifier plus metaverifier loop. In other words, they handed the entire ecosystem. Here's answer, it checks itself. The implications here they are academia and research. You can now fine-tune or extend an IMO gold model for theorem proving, cryptography, physics, formal methods, longstanding open problems might get AI co-ressearchers instead of just AI calculators. As far as the enterprise is concerned, this same pattern which is generator plus verifier plus metaverifier is not limited to math. So let's think contracts, code, compliance, safety checks, medical guidelines, any domain where process matters more than the final answer can use this architecture. As for geopolitics and the AI race, Chinese open models already account for a growing slice of global downloads. Now they also have the first open IMO gold model. It's a soft power move. You want top tier reasoning, you'll be running Chinese open weights. For closed labs like OpenAI and Google, the risk isn't just competition on leaderboards. It's actually commoditization of core reasoning tricks they hoped would stay proprietary. And now what this means for builders and more importantly India. If you're building AI products, here's the quiet but important shift. Until now, open versus closed was mostly about cost, cost, sorry, and access. Closed models is equal to best brains. Open models is equal to cheaper, but good enough. Deepseek is trying to break that assumption. They're saying you can have state-of-the-art reasoning and open weights and low cost. So for India this matters because our research labs, IITs and deep tech startups can now experiment with an IMO tier reasoning engine without waiting for API access, export approvals or pricing changes. So as we think about sovereign AI, national research clouds and India a compute mission models like this are exactly what you want to host locally and extend. The next decade will be one by models that can prove they are right or admit when they're wrong. Deepseek math v2 is one of the first serious proofs of that future. And finally, it is time for the front page take. Here it is. Deepseek just turned mathematical humility into a competitive advantage. Instead of training an AI to be the loudest kid in the class, they trained it to be the one who shows it works, checks its steps, corrects itself, and only then raises its hand. Oh, sorry. In a world where GPD5, Gemini, and others are racing to impress with bigger context windows and flashy demos, Deepc quietly asked a very different question. Can your model mark its own paper and still pass? If the answer to that becomes yes at scale across math, code, law, and science, the real disruption won't just be to GPD5. it'll be to how we trust AI in the first",
        "start": 496.479,
        "duration": 1383.5979999999997
    },
    {
        "text": "Deepc quietly asked a very different question. Can your model mark its own paper and still pass? If the answer to that becomes yes at scale across math, code, law, and science, the real disruption won't just be to GPD5. it'll be to how we trust AI in the first Network. Like, share, and subscribe if you want to stay ahead of stories like this. And not just which model is smartest this week, but which ones are quietly rewriting the rules of intelligence itself.",
        "start": 707.839,
        "duration": 1417.5989999999997
    }
]