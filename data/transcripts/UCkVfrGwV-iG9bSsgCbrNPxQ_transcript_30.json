[
    {
        "text": " So AI CEOs have quietly disappeared and we need to talk about it. So I'm going to show you guys a clip from Iman Mustak, the British entrepreneur and tech leader, better known as the former founder and CEO of Stability AI, the company behind stable diffusion, which is one of the most influential open source AI image generation models. And he made a comment on a podcast which I think we need to pay attention to that just kind of glossed over most people's head as not something that was really crazy, but I think this is super super important. So, take a listen to this and then I'm going to dive into all of those claims and show you guys why this statement is very, very big for 2026. Avoid a crisis. He estimates this could push unemployment to 20% within 1 to 5 years. I'd be interested to see if you think that that's conservative or on point. , is this kind of looming disruption why the billionaires are building bunkers? , yes, actually it's one of the reasons generally it's what they do. But I know a lot of AI CEOs now who've canled all public appearances, especially in the wake of Charlie Kirk and things like that. They think that that's going to be the next wave of anti-AI sentiment next year cuz next year is the year that AI models go from not being good enough, the dumb member of your team, and again the people listening to this will be like, \"Yeah, the AI is not good enough.\" Then overnight it becomes good enough. So, one of the key things he mentioned was the fact that these AI CEOs have somewhat quote unquote disappeared because they're afraid of the backlash. And one of the things that I want to talk about is, you know, firstly, I guess you could talk about is the doomsday scenario. Now, I know it might seem completely completely speculative on how we would even get there. And of course, there are many issues facing individuals in today's day and age that we should probably focus on. But I think it's something that we do need to take attention to because all of his statements, I think they're probably going to come truer the more you start to realize where AI is headed. Now, I'm showing you guys this, which is what you can see, Ilia's bunker. And of course, if you aren't familiar with who I savvy is, he's a super super smart scientist that worked on, you know, the early chat models. and he you know has his own company now Super Intelligence Safe Super Intelligence Inc. And of course they're valued at you know billions of dollars. And now what's interesting is that he said that they are planning for the sense that they need some kind of protection when AGI actually happens. And it does sound like some crazy crazy",
        "start": 0.08,
        "duration": 284.47999999999985
    },
    {
        "text": "Intelligence Safe Super Intelligence Inc. And of course they're valued at you know billions of dollars. And now what's interesting is that he said that they are planning for the sense that they need some kind of protection when AGI actually happens. And it does sound like some crazy crazy works at OpenAI say that we need a doomsday bunker for when the machines become smarter than man. But this is a real scenario that happens. And trust me this is probably the lightest issue that I'm going to be discussing in the video. And so what he actually said, which is pretty crazy if you ask me, he said, \"We're definitely going to build a bunker before we release AGI.\" And this is what Satka said in 2023, months before he would leave the company. And he said, you know, of course it's going to be optional whether or not you want to get into the bunker. And what's crazy about this is that, you know, he actually left the company OpenAI for a variety of different reasons, but they were basically talking about the fact that, you know, OpenAI are probably going to build AGI and it's going to be unsafe and the world is going to, you know, potentially collapse and, you know, some crazy kind of scenario. And then at the bottom here, you can see it says there is a large group of people, Ilia, believe in one of them, who believe that building AGI will bring about a rapture, said one researcher that how quotes. And you know that's why Ilia Saskatka is building a bunker because it's probably going to be some kind of raptured style event when AGI does happen. Now it does sound like crazy and I know this video is going to come across as crazy but as you dive into the video you'll understand that it's not as crazy as it seems and these claims for 2026 and 2027 are probably going to get more realistic as time goes on. Now I did some digging and I found this book which there was something that Douglas Rushkov were noting in his book the artificial intelligence and he you know this book is called survival of the fittish escape the fantasies of tech billionaires and one of the key things that's driving these guys to build bunkers is AI artificial intelligence is one of the central themes from this book survival of the fittest and basically he talks about you know the common belief system is that you know societal catastrophe is basically inevitable and can be escaped through sufficient money and technology by externalizing the damage of their enterprises onto others. And one of those things is that, you know, they're going to, of course, build bunkers to escape the inevitable collapse when it happens. Now, I'm not fear-mongering when I'm saying this. In an interview, Sam Alman, you know, he was speaking with Theon and they're",
        "start": 142.239,
        "duration": 513.92
    },
    {
        "text": "their enterprises onto others. And one of those things is that, you know, they're going to, of course, build bunkers to escape the inevitable collapse when it happens. Now, I'm not fear-mongering when I'm saying this. In an interview, Sam Alman, you know, he was speaking with Theon and they're you know, you know, like society could eventually collapse and they were talking about, you know, bunkers and stuff like that. And Sam Alman, if you aren't familiar, he's actually been a doomsday pre for quite some time. and he talks about the fact that I have underground concrete, heavy reinforcement basements, but I don't have something that I would call a bunker. And you know, of course, Avon said that is basically a bunker, dude. So, you know, they were just talking about this and kind of joking about it, but I think it, you know, should be noted that all of these billionaire CEOs are building safe havens away from the eventual release of AGI. Mark Zuckerberg is also building, you know, you know, work on his Kula Ranch, his sprawling 1,400 acre compound in the Hawaiian state of Kauaii as far back as 2014. And once again, this is some bunker. Now, I think it's important to know that this bunker kind of thing is, you know, something that's way way down the line. But what I should, you know, talk about in this video, and I think, you know, why AI CEOs probably won't be as public as they were in the past, is that AI backlash is getting to a critical point. And I don't think people understand just how bad it has gotten. And I do not think the AICOs will continue to be as public as they are in probably 2027, 2028, maybe even towards the tail end of 2026. And and this is why Imad Mosak is basically saying that AI is reaching that tipping point and this is why AI CEOs are disappearing. So I think what this shows as well and you know we don't even have to talk about you know just Charlie Kirk. There's of course other individuals who have been killed, other billionaires and CEOs who have been killed by individuals from the public. I'm not going to dive into it too much. I don't want the video to get demonetized, but I started to notice a trend. So, I went on Twitter and I kind of looked around because I wanted to see exactly what was going on. And it was worse than I thought. Like, AI backlash is getting so bad that I don't want to say that, you know, someone's going to try and harm an, you know, public CEO. But I wouldn't be surprised if it's happened. And I'm not calling for this. Of course, violence is never the answer in my genuine opinion. I think things can be solved through discourse. But look at how bad it has gotten and how",
        "start": 259.44,
        "duration": 744.3999999999997
    },
    {
        "text": "and harm an, you know, public CEO. But I wouldn't be surprised if it's happened. And I'm not calling for this. Of course, violence is never the answer in my genuine opinion. I think things can be solved through discourse. But look at how bad it has gotten and how something AI generated comes upon the feed. I've never seen anything like this. And at first it was, you know, maybe one or two tweets here and there. But now there is a common consensus and this is among normal people outside of the AI bubble. So if you're watching this channel, you're not likely to be exposed to the AI hate as much because you're in the AI bubble. You talk to people who use AI on a daily basis. I talk to people who use AI on a daily basis. But people outside of it genuinely hate AI. And this is a wakeup call when speaking to people who aren't as deep in AI as I am. So you can see tweets here. If you just type in F AI, you can see someone saying F AI. Someone said F AI. And I can't state this enough. AI in any creative field. Go f yourself. F Google for pushing this too. F Meta. F this. Enough is enough. And you know this just goes on and on. And then of course you can see you know individuals, humans are piggybacking on this. Of course AI hate wave. You can see that Culture Crave said that this film was willfully made for humans by humans. Screw AI. And of course, people are going to now embrace that. Of course, you can see here is that why is everything AI? Why adverts now AI? Why do people find AI videos funny? F off. It looks horrible. Someone else said, you know what, f AI? It's greatly raising your cost of electricity. It's tripling the RAM prices, which will now only go higher. Is blowing through the freshwater supply for cooling. The temporary power plants for some of these data centers are built insane amounts of pollution and destroy the local air quality. It is being forced everywhere costing people jobs even when it doesn't work. It is straight up trash or makes any sense. We people are always getting screwed over so the rich can get richer. Like this is something that just goes on and on and on and on. These things have tons and tons and tons and tons of likes and retweets. I mean, there was even, you know, an AI campaign where someone was trying to promote the AI pendant and then someone said pure un unadulterated evil. Screw this guy, you know. And then, of course, you have here, you know, AI backlash. What I I'm one of the, you know, people that worked on this ad. And this is sarcasm, by the way. So, McDonald's a few days ago, they",
        "start": 375.84,
        "duration": 980.5599999999996
    },
    {
        "text": "someone said pure un unadulterated evil. Screw this guy, you know. And then, of course, you have here, you know, AI backlash. What I I'm one of the, you know, people that worked on this ad. And this is sarcasm, by the way. So, McDonald's a few days ago, they Christmas ad. And the studio behind it was saying that they hardly slept and they used AI to refine the prompts and shots. And people were saying, you know, the prompts that my team actually used were make it funny, make it epic, and make it funnier. And they're basically taking in Mickey that basically just taking extreme sarcasm to the point that you know AI doesn't you know nearly take as much time and effort as it would to do a human production. And I mean I found so many different tweets of people saying I just want it to go away. I saying I hate it. I hate it. And there are you know a lot that I can't find that have millions and millions of tweets but I think it's getting to a point now where what happens when people hate AI so much that you know there is just a public outrage and discourse. What is going to happen to society at that point where society fractures? I do think that billionaires will probably leave the public eye. And I do think that they're probably going to have to change their relationship with AI because it's simply going too far. And I do think that the next phase is going to get worse. And this is the point of the video where I'm showing you guys this is why things are going to get worse. And this is the AI job section. So we got a tweet from Unusual Wales that says AI and automation could eliminate nearly 100 million jobs in the US over the next decade per the Senate report. Now I did some research again. I was looking at a Goldman Sachs report and it talks about how employment is contracting in some sectors where anecdote suggests the AI is substituting for labor. So what we have here is we have you know I guess you could some some of this is white collar work some of this is you know entry- level jobs depending on what you call it. But a lot of these, you know, jobs and I think a lot of these careers and opportunities were good opportunities for individuals to bootstrap themselves and, you know, push themselves up, social mobility, all that kind of stuff, which is of course good for the morale and individuals of the economy. But we can see that many of these, you know, careers ever since the release of Chhat, you know, it's been declining pretty steadily. Now, of course, you could make some macro macroeconomic statements about the fact that the economy has been declining in this area or that area. Certain",
        "start": 496.4,
        "duration": 1205.039999999999
    },
    {
        "text": "But we can see that many of these, you know, careers ever since the release of Chhat, you know, it's been declining pretty steadily. Now, of course, you could make some macro macroeconomic statements about the fact that the economy has been declining in this area or that area. Certain overhiring in 2020 thanks to the pandemic. Of course, those are factors, but I think it would be, you know, very foolish to ignore the fact that AI hasn't played a part in how companies are thinking about their expenses moving forward. And these are just some of the areas where employment may be contracting and that's only going to further fuel the resentment and anger towards AI which isn't helpful for anyone. And the report basically talks about despite the the you know widespread job losses concern AI adoption is expected to have only a modest and relatively temporary impact on employment levels. I'm not sure I agree with this. I think people have always underestimated AI. And one mistake I'm no longer making is I'm no longer underestimating AI. I think it's better to overestimate AI and that way you'll be safer because AI has always exceeded our expectations in recent history. Now, Iman mustach, he he dives into this a little bit more and he talks about the fact that it's probably going to get worse before it gets better. Every single company in the world that's a knowledge company is going to be asking the same question in a year from now. Do I need that human and all the liabilities that come with them when I can hire an AI at pennies that never complains, that gets the work done at a better level than the human, and I can't tell it's not a human on the other side of the screen. And maybe that's a recipe for massive unrest like we've never seen before because how do you ban that as a government? Should you be banning that as a government? Governments are in a race where they're trying to embrace this technology right now. But the new jobs of the future, if there are new jobs, aren't going to come at that time. Capital itself will disappear. Like what's the value of a media franchise? It's its network effects and other things like that when you can create brand new franchises almost on the fly in a year or two. What's the value of a New York taxi medallion when you have Teslas auto driving for a few dollars, you know, and this is why quite bullish blockchain, but at the same time, like you got this cognitive surplus coming, and I can't see how that's not going to be massively disruptive. And here we have the anthropic CEO who's actually been pretty open and honest about the coming changes in society. Take a listen. We have a choice here. I'm not saying we're faded for the bad outcomes, but if",
        "start": 610.399,
        "duration": 1460.7199999999984
    },
    {
        "text": "I can't see how that's not going to be massively disruptive. And here we have the anthropic CEO who's actually been pretty open and honest about the coming changes in society. Take a listen. We have a choice here. I'm not saying we're faded for the bad outcomes, but if that that fast growth could be coupled with job displacement for a lot of people that you could get a much bigger pie, but also that pie could be concentrated more in in a smaller number of people and there could be some people who don't get any. That is my concern. And specifically if we look at jobs like as you [music] said entrylevel white collar work you know I think of people who work at law firms like firstear associates there's a lot of document review it's very repetitive but every example is different that's something that AI is quite good at if you think of you know first year at you know entrylevel work at a consulting company you know these the typical you typical entry level white collar work, right? If you think of a lot of kind of entrylevel administrative work, right? People who coordinate things, who, you know, who schedule things, who organize things, who take notes. If you think of entry-level work at a finance company, right? Doing routine analysis of financial documents, right? These these are kind of the workh horses of entry-level white collar labor. And yet there are things that AI is already pretty good at and AI is rapidly getting better at. And so when you realize that you've got AI job loss, which is probably going to happen within the next 3 to 5 years on a scale that most people haven't seen yet, we have the fact that people already hate AI because it is, you know, doing a lot of stuff that humans are meant to be doing already. It's, you know, ruining the internet in certain areas and just a variety of different things that I won't need to get into. and you have this societal unrest and you've got a lot of people who are clearly angry. I think I wouldn't be surprised if many of these AICOs start to disappear out of the public eye because that hate and that sentiment is going to flow somewhere. And honestly, I'm pretty concerned about where societyy's heading if we don't manage this transition very effectively. I think AI can be a tool for good. I think it can be something that, you know, truly uplifts society. But right now, we're in this fractured state where it's not really being managed well. it's not being, you know, looked into in terms of all the potential unknown unknowns, the effects. I think we do need organizations that can sort of ensure the transition becomes super smooth. And governments are usually pretty slow. So, I'm hoping that someone out there decides to, okay, AI is good,",
        "start": 739.6,
        "duration": 1741.0389999999986
    },
    {
        "text": "being, you know, looked into in terms of all the potential unknown unknowns, the effects. I think we do need organizations that can sort of ensure the transition becomes super smooth. And governments are usually pretty slow. So, I'm hoping that someone out there decides to, okay, AI is good, just have the effects just propagate throughout the economy and society without rein it in. I mean, you've already seen what social media has done to people's mental health and other unintended consequences. AI is going to be far bigger and we need to just, you know, catch it early. So, let me know what you guys think. I just thought that this was something that was interesting and something that I was seeing. and I love to see no",
        "start": 883.199,
        "duration": 1781.5999999999988
    }
]