[
    {
        "text": "I think this might be a good place to",
        "start": 2.96,
        "duration": 4.16
    },
    {
        "text": "define pre-training, mid-training and",
        "start": 4.24,
        "duration": 5.12
    },
    {
        "text": "post-training. So restraining is the",
        "start": 7.12,
        "duration": 4.16
    },
    {
        "text": "classic training one next token",
        "start": 9.36,
        "duration": 3.12
    },
    {
        "text": "prediction at a time You have a big",
        "start": 11.28,
        "duration": 3.92
    },
    {
        "text": "corpus of data and Nathan probably also",
        "start": 12.48,
        "duration": 4.24
    },
    {
        "text": "has a very interesting insights there",
        "start": 15.2,
        "duration": 3.52
    },
    {
        "text": "because of three It's a big portion of",
        "start": 16.72,
        "duration": 4.479
    },
    {
        "text": "the paper focuses on the right data mix",
        "start": 18.72,
        "duration": 4.639
    },
    {
        "text": "So restraining is essentially just you",
        "start": 21.199,
        "duration": 4.16
    },
    {
        "text": "know train across entropy loss training",
        "start": 23.359,
        "duration": 4.641
    },
    {
        "text": "on next token prediction on a a vast",
        "start": 25.359,
        "duration": 5.201
    },
    {
        "text": "corpus of internet data books papers and",
        "start": 28.0,
        "duration": 4.8
    },
    {
        "text": "so forth It has changed a little bit",
        "start": 30.56,
        "duration": 4.48
    },
    {
        "text": "over the years in the sense people used",
        "start": 32.8,
        "duration": 4.8
    },
    {
        "text": "to throw in everything they can Now",
        "start": 35.04,
        "duration": 4.96
    },
    {
        "text": "it's not just raw data it's also",
        "start": 37.6,
        "duration": 5.279
    },
    {
        "text": "synthetic data where people re um let's",
        "start": 40.0,
        "duration": 5.2
    },
    {
        "text": "say rephrase certain things Uh so",
        "start": 42.879,
        "duration": 3.84
    },
    {
        "text": "synthetic data doesn't necessarily mean",
        "start": 45.2,
        "duration": 5.359
    },
    {
        "text": "purely AI makeup data It's also taking",
        "start": 46.719,
        "duration": 5.601
    },
    {
        "text": "something from an article Wikipedia",
        "start": 50.559,
        "duration": 4.721
    },
    {
        "text": "article and then rephrasing it as a Q&A",
        "start": 52.32,
        "duration": 7.039
    },
    {
        "text": "question or um summarizing it rewarding",
        "start": 55.28,
        "duration": 6.72
    },
    {
        "text": "it and and making uh better data that",
        "start": 59.359,
        "duration": 4.88
    },
    {
        "text": "way Cuz I think of it also like with",
        "start": 62.0,
        "duration": 5.119
    },
    {
        "text": "humans if someone let's say reads a",
        "start": 64.239,
        "duration": 4.801
    },
    {
        "text": "book compared to a messy I don't know",
        "start": 67.119,
        "duration": 3.36
    },
    {
        "text": "no offense but like Reddit post or",
        "start": 69.04,
        "duration": 2.8
    },
    {
        "text": "something like that I do think you",
        "start": 70.479,
        "duration": 2.481
    },
    {
        "text": "learn laughter",
        "start": 71.84,
        "duration": 3.52
    },
    {
        "text": "you no offense but I think",
        "start": 72.96,
        "duration": 4.33
    },
    {
        "text": "i there's going to be a post about this",
        "start": 75.36,
        "duration": 2.72
    },
    {
        "text": "laughter",
        "start": 77.29,
        "duration": 2.71
    },
    {
        "text": "i Well, some Reddit data is very coveted",
        "start": 78.08,
        "duration": 3.359
    },
    {
        "text": "and excellent for training You just",
        "start": 80.0,
        "duration": 2.64
    },
    {
        "text": "have to filter it laughter",
        "start": 81.439,
        "duration": 1.761
    },
    {
        "text": "i Yeah.",
        "start": 82.64,
        "duration": 2.799
    },
    {
        "text": "i I think that's the idea Uh I I think",
        "start": 83.2,
        "duration": 5.36
    },
    {
        "text": "it's like if someone took that and",
        "start": 85.439,
        "duration": 5.841
    },
    {
        "text": "rephrases that in a let's say more",
        "start": 88.56,
        "duration": 4.96
    },
    {
        "text": "concise and structured way Yeah, I",
        "start": 91.28,
        "duration": 3.92
    },
    {
        "text": "think it's higher quality data that gets",
        "start": 93.52,
        "duration": 4.639
    },
    {
        "text": "the LLM maybe the same You get the same",
        "start": 95.2,
        "duration": 4.879
    },
    {
        "text": "LLM out of it at the end but it gets",
        "start": 98.159,
        "duration": 3.681
    },
    {
        "text": "there faster It trains faster because",
        "start": 100.079,
        "duration": 3.841
    },
    {
        "text": "the let's say if the grammar and the",
        "start": 101.84,
        "duration": 4.239
    },
    {
        "text": "punctuation is correct it already",
        "start": 103.92,
        "duration": 4.72
    },
    {
        "text": "learns the correct way versus getting",
        "start": 106.079,
        "duration": 4.241
    },
    {
        "text": "information from a messy way and then",
        "start": 108.64,
        "duration": 3.439
    },
    {
        "text": "learning later how to correct that and",
        "start": 110.32,
        "duration": 3.759
    },
    {
        "text": "stuff like that So I think that is how",
        "start": 112.079,
        "duration": 5.121
    },
    {
        "text": "restraining evolved and how um how",
        "start": 114.079,
        "duration": 6.64
    },
    {
        "text": "still while why scaling still works is",
        "start": 117.2,
        "duration": 5.519
    },
    {
        "text": "that it's not about just the amount of",
        "start": 120.719,
        "duration": 4.481
    },
    {
        "text": "data It's also the tricks to make that",
        "start": 122.719,
        "duration": 5.76
    },
    {
        "text": "data better for you in a sense And then",
        "start": 125.2,
        "duration": 5.36
    },
    {
        "text": "mid-training is I mean it used to be",
        "start": 128.479,
        "duration": 3.84
    },
    {
        "text": "called pre-training. It's I think it's",
        "start": 130.56,
        "duration": 2.96
    },
    {
        "text": "called mid training because it was",
        "start": 132.319,
        "duration": 2.801
    },
    {
        "text": "awkward to have restraining and post",
        "start": 133.52,
        "duration": 2.719
    },
    {
        "text": "training but nothing in the middle",
        "start": 135.12,
        "duration": 2.24
    },
    {
        "text": "right it sounds a bit weird You have",
        "start": 136.239,
        "duration": 2.241
    },
    {
        "text": "restraining and post training but",
        "start": 137.36,
        "duration": 2.56
    },
    {
        "text": "what's the actual training So the",
        "start": 138.48,
        "duration": 4.56
    },
    {
        "text": "mid-training is usually similar to uh",
        "start": 139.92,
        "duration": 5.039
    },
    {
        "text": "restraining but you know it's a bit",
        "start": 143.04,
        "duration": 3.36
    },
    {
        "text": "more I would say specialized in",
        "start": 144.959,
        "duration": 3.28
    },
    {
        "text": "pre-training. It's the same algorithm",
        "start": 146.4,
        "duration": 4.08
    },
    {
        "text": "but what you do is you focus for example",
        "start": 148.239,
        "duration": 4.481
    },
    {
        "text": "on long context like one example you",
        "start": 150.48,
        "duration": 4.24
    },
    {
        "text": "have long context documents The reason",
        "start": 152.72,
        "duration": 3.84
    },
    {
        "text": "you don't do that during just pure",
        "start": 154.72,
        "duration": 3.12
    },
    {
        "text": "restraining is because you don't have",
        "start": 156.56,
        "duration": 2.959
    },
    {
        "text": "that many long context documents You",
        "start": 157.84,
        "duration": 4.24
    },
    {
        "text": "have a specific phase and one problem of",
        "start": 159.519,
        "duration": 4.08
    },
    {
        "text": "LMS is also still it's a neurons",
        "start": 162.08,
        "duration": 3.28
    },
    {
        "text": "network It has the problem of",
        "start": 163.599,
        "duration": 3.841
    },
    {
        "text": "catastrophic forgetting So you teach it",
        "start": 165.36,
        "duration": 4.0
    },
    {
        "text": "something it forgets other things And",
        "start": 167.44,
        "duration": 4.56
    },
    {
        "text": "you want to it's not 100% forgetting",
        "start": 169.36,
        "duration": 4.159
    },
    {
        "text": "but you know it's like no free lunch",
        "start": 172.0,
        "duration": 2.72
    },
    {
        "text": "You can't It's also the same with",
        "start": 173.519,
        "duration": 3.281
    },
    {
        "text": "humans If you ask me some math I",
        "start": 174.72,
        "duration": 3.68
    },
    {
        "text": "learned 10 years ago I don't know I",
        "start": 176.8,
        "duration": 2.56
    },
    {
        "text": "would have to look at it again",
        "start": 178.4,
        "duration": 2.64
    },
    {
        "text": "i Oh, Nathan was actually saying that he's",
        "start": 179.36,
        "duration": 3.519
    },
    {
        "text": "consuming so much content that there's a",
        "start": 181.04,
        "duration": 3.279
    },
    {
        "text": "catastrophic forgetting issue",
        "start": 182.879,
        "duration": 3.121
    },
    {
        "text": "i Yeah, I'm like trying to learn so much",
        "start": 184.319,
        "duration": 3.28
    },
    {
        "text": "about AI. I was like I was learning",
        "start": 186.0,
        "duration": 3.76
    },
    {
        "text": "about restraining parallelisms I'm",
        "start": 187.599,
        "duration": 3.521
    },
    {
        "text": "like I lost something and I don't know",
        "start": 189.76,
        "duration": 2.88
    },
    {
        "text": "what laughter it was I don't want to",
        "start": 191.12,
        "duration": 4.08
    },
    {
        "text": "uncomorphize LLMs but it's I think the",
        "start": 192.64,
        "duration": 4.319
    },
    {
        "text": "same kind of in that sense how humans",
        "start": 195.2,
        "duration": 4.319
    },
    {
        "text": "learned I mean the quantity is not",
        "start": 196.959,
        "duration": 4.64
    },
    {
        "text": "always better because yeah it's like",
        "start": 199.519,
        "duration": 3.521
    },
    {
        "text": "being selective and I in the mid",
        "start": 201.599,
        "duration": 3.441
    },
    {
        "text": "training is being selective in terms of",
        "start": 203.04,
        "duration": 4.16
    },
    {
        "text": "quality content at the end So the last",
        "start": 205.04,
        "duration": 3.839
    },
    {
        "text": "thing the LM has seen is the quality",
        "start": 207.2,
        "duration": 4.64
    },
    {
        "text": "stuff and then post training is all the",
        "start": 208.879,
        "duration": 5.92
    },
    {
        "text": "uh fine-tuning supervised finetuning uh",
        "start": 211.84,
        "duration": 5.759
    },
    {
        "text": "DPO um reinforcement learning with",
        "start": 214.799,
        "duration": 5.921
    },
    {
        "text": "verifiable rewards with human feedback",
        "start": 217.599,
        "duration": 5.36
    },
    {
        "text": "and so forth So the refinement stages",
        "start": 220.72,
        "duration": 3.76
    },
    {
        "text": "and it's also interesting it's like the",
        "start": 222.959,
        "duration": 2.56
    },
    {
        "text": "cost thing right I mean it's like",
        "start": 224.48,
        "duration": 2.88
    },
    {
        "text": "restraining you spend a lot of money on",
        "start": 225.519,
        "duration": 4.881
    },
    {
        "text": "that right now RL a bit less RL you",
        "start": 227.36,
        "duration": 4.4
    },
    {
        "text": "don't really I would say teach it",
        "start": 230.4,
        "duration": 3.119
    },
    {
        "text": "knowledge it's more like unlocking the",
        "start": 231.76,
        "duration": 3.52
    },
    {
        "text": "knowledge it's more like a skill",
        "start": 233.519,
        "duration": 3.28
    },
    {
        "text": "learning like how to solve problems with",
        "start": 235.28,
        "duration": 2.72
    },
    {
        "text": "the knowledge that it has from",
        "start": 236.799,
        "duration": 3.36
    },
    {
        "text": "restraining there are paper actually",
        "start": 238.0,
        "duration": 5.519
    },
    {
        "text": "three papers this year last year 2025 on",
        "start": 240.159,
        "duration": 6.0
    },
    {
        "text": "RL for restraining but I I mean I don't",
        "start": 243.519,
        "duration": 4.0
    },
    {
        "text": "think anyone does that in production",
        "start": 246.159,
        "duration": 2.72
    },
    {
        "text": "i toy examples for now",
        "start": 247.519,
        "duration": 3.44
    },
    {
        "text": "i toy examples right but to generalize RL",
        "start": 248.879,
        "duration": 4.0
    },
    {
        "text": "Well, post training is more like the",
        "start": 250.959,
        "duration": 4.321
    },
    {
        "text": "skill unlock where restraining is like",
        "start": 252.879,
        "duration": 3.841
    },
    {
        "text": "soaking up the knowledge essentially",
        "start": 255.28,
        "duration": 1.84
    },
    {
        "text": "Yeah.",
        "start": 256.72,
        "duration": 2.56
    },
    {
        "text": "i A few things that could be helpful for",
        "start": 257.12,
        "duration": 5.2
    },
    {
        "text": "people A lot of people get like think",
        "start": 259.28,
        "duration": 4.88
    },
    {
        "text": "of synthetic data as being bad for",
        "start": 262.32,
        "duration": 3.28
    },
    {
        "text": "training the models You mentioned like",
        "start": 264.16,
        "duration": 4.72
    },
    {
        "text": "the deep sea got OCR which is optical",
        "start": 265.6,
        "duration": 5.68
    },
    {
        "text": "character recognition paper A lot of",
        "start": 268.88,
        "duration": 6.24
    },
    {
        "text": "labs did AI2 had one like had multiple",
        "start": 271.28,
        "duration": 6.16
    },
    {
        "text": "And the reason that each of these labs",
        "start": 275.12,
        "duration": 3.84
    },
    {
        "text": "has these is because there's vast",
        "start": 277.44,
        "duration": 3.28
    },
    {
        "text": "amounts of PDFs and other digital",
        "start": 278.96,
        "duration": 3.92
    },
    {
        "text": "documents on the web that are in formats",
        "start": 280.72,
        "duration": 3.919
    },
    {
        "text": "that aren't encoded with text easily So",
        "start": 282.88,
        "duration": 4.96
    },
    {
        "text": "you use these almost CR these or deeper",
        "start": 284.639,
        "duration": 5.441
    },
    {
        "text": "and we called ours CR to extract what",
        "start": 287.84,
        "duration": 4.639
    },
    {
        "text": "can be trillions of tokens of um",
        "start": 290.08,
        "duration": 5.839
    },
    {
        "text": "candidate data for restraining and",
        "start": 292.479,
        "duration": 5.521
    },
    {
        "text": "restraining data sets is on the order",
        "start": 295.919,
        "duration": 4.161
    },
    {
        "text": "of trillions is measured in trillions of",
        "start": 298.0,
        "duration": 4.56
    },
    {
        "text": "tokens smaller models from researchers",
        "start": 300.08,
        "duration": 5.28
    },
    {
        "text": "can be something like 5 to 10 trillion",
        "start": 302.56,
        "duration": 5.04
    },
    {
        "text": "Um Quen has documented going up to like",
        "start": 305.36,
        "duration": 3.76
    },
    {
        "text": "50 trillion and there's rumors that",
        "start": 307.6,
        "duration": 3.039
    },
    {
        "text": "these closed labs can go to like 100",
        "start": 309.12,
        "duration": 3.2
    },
    {
        "text": "trillion tokens And just getting this",
        "start": 310.639,
        "duration": 3.521
    },
    {
        "text": "potential data to put in I think they",
        "start": 312.32,
        "duration": 3.68
    },
    {
        "text": "they have a very big funnel and then the",
        "start": 314.16,
        "duration": 3.28
    },
    {
        "text": "data you actually train the model on is",
        "start": 316.0,
        "duration": 4.24
    },
    {
        "text": "a small percentage of this like the this",
        "start": 317.44,
        "duration": 4.319
    },
    {
        "text": "character recognition data would be",
        "start": 320.24,
        "duration": 2.959
    },
    {
        "text": "described as synthetic data for",
        "start": 321.759,
        "duration": 3.681
    },
    {
        "text": "restraining in a lab And then there's",
        "start": 323.199,
        "duration": 4.961
    },
    {
        "text": "also the things like chat GPT now gives",
        "start": 325.44,
        "duration": 4.56
    },
    {
        "text": "wonderful answers and you could train on",
        "start": 328.16,
        "duration": 3.36
    },
    {
        "text": "those best answers and that's synthetic",
        "start": 330.0,
        "duration": 3.68
    },
    {
        "text": "data It's very different than like",
        "start": 331.52,
        "duration": 4.959
    },
    {
        "text": "early chat GPT lots of hallucinations",
        "start": 333.68,
        "duration": 4.4
    },
    {
        "text": "data when people became grounded in",
        "start": 336.479,
        "duration": 3.121
    },
    {
        "text": "synthetic data One interesting question",
        "start": 338.08,
        "duration": 4.24
    },
    {
        "text": "is if I recall correctly 3 was trained",
        "start": 339.6,
        "duration": 5.28
    },
    {
        "text": "with less data than specifically some",
        "start": 342.32,
        "duration": 4.64
    },
    {
        "text": "other overweight models maybe even two",
        "start": 344.88,
        "duration": 3.52
    },
    {
        "text": "but you still got better performance and",
        "start": 346.96,
        "duration": 3.44
    },
    {
        "text": "that might be one of the examples how",
        "start": 348.4,
        "duration": 2.88
    },
    {
        "text": "the data help",
        "start": 350.4,
        "duration": 2.48
    },
    {
        "text": "i It's mostly down to data quality I",
        "start": 351.28,
        "duration": 2.88
    },
    {
        "text": "think if we had more computer we would",
        "start": 352.88,
        "duration": 3.52
    },
    {
        "text": "train for longer I think we ultimately",
        "start": 354.16,
        "duration": 4.56
    },
    {
        "text": "see that as a like just like something",
        "start": 356.4,
        "duration": 3.92
    },
    {
        "text": "we would want to do And especially with",
        "start": 358.72,
        "duration": 3.039
    },
    {
        "text": "big models you need to have more",
        "start": 360.32,
        "duration": 3.52
    },
    {
        "text": "compute because we talk about having",
        "start": 361.759,
        "duration": 3.201
    },
    {
        "text": "more parameters and we talk about",
        "start": 363.84,
        "duration": 2.32
    },
    {
        "text": "knowledge and essentially there's a",
        "start": 364.96,
        "duration": 3.2
    },
    {
        "text": "ratio where big models can absorb more",
        "start": 366.16,
        "duration": 4.159
    },
    {
        "text": "from data and you're going to you get",
        "start": 368.16,
        "duration": 4.0
    },
    {
        "text": "more benefit out of this It's it's like",
        "start": 370.319,
        "duration": 3.681
    },
    {
        "text": "one of these any logarithmic graph in",
        "start": 372.16,
        "duration": 3.68
    },
    {
        "text": "your mind is like a small model will",
        "start": 374.0,
        "duration": 3.84
    },
    {
        "text": "level off sooner if you're measuring",
        "start": 375.84,
        "duration": 4.0
    },
    {
        "text": "tons of tokens and bigger bigger models",
        "start": 377.84,
        "duration": 4.72
    },
    {
        "text": "need more But mostly is we aren't",
        "start": 379.84,
        "duration": 4.079
    },
    {
        "text": "training that big of models right now",
        "start": 382.56,
        "duration": 3.12
    },
    {
        "text": "with AI2 and getting the highest quality",
        "start": 383.919,
        "duration": 4.4
    },
    {
        "text": "data we can is the natural starting",
        "start": 385.68,
        "duration": 3.12
    },
    {
        "text": "point",
        "start": 388.319,
        "duration": 2.561
    },
    {
        "text": "i Is there something to be said uh about",
        "start": 388.8,
        "duration": 4.08
    },
    {
        "text": "the topic of data quality Is there some",
        "start": 390.88,
        "duration": 4.48
    },
    {
        "text": "lowhanging fruit there still where the",
        "start": 392.88,
        "duration": 3.599
    },
    {
        "text": "quality could be improved",
        "start": 395.36,
        "duration": 2.72
    },
    {
        "text": "i It's like turning the crank So I think",
        "start": 396.479,
        "duration": 3.28
    },
    {
        "text": "historically in the open there's been",
        "start": 398.08,
        "duration": 4.48
    },
    {
        "text": "like a canonical best restraining data",
        "start": 399.759,
        "duration": 5.201
    },
    {
        "text": "set that has moved around between who",
        "start": 402.56,
        "duration": 4.079
    },
    {
        "text": "has the most recent one or the best",
        "start": 404.96,
        "duration": 3.76
    },
    {
        "text": "recent effort like AI2's doll was very",
        "start": 406.639,
        "duration": 4.161
    },
    {
        "text": "early with the first mo and hugging face",
        "start": 408.72,
        "duration": 4.64
    },
    {
        "text": "had fine web and there's a DCLM project",
        "start": 410.8,
        "duration": 5.04
    },
    {
        "text": "which has been kind of like a which is",
        "start": 413.36,
        "duration": 4.64
    },
    {
        "text": "it stands for data come language model",
        "start": 415.84,
        "duration": 4.639
    },
    {
        "text": "there's been data come for other machine",
        "start": 418.0,
        "duration": 4.319
    },
    {
        "text": "learning projects and they have had a",
        "start": 420.479,
        "duration": 5.041
    },
    {
        "text": "very strong data set and a lot of it is",
        "start": 422.319,
        "duration": 5.201
    },
    {
        "text": "the internet is becoming fairly closed",
        "start": 425.52,
        "duration": 3.76
    },
    {
        "text": "off So we have common crawl which I",
        "start": 427.52,
        "duration": 3.119
    },
    {
        "text": "think is hundreds of trillions of tokens",
        "start": 429.28,
        "duration": 3.039
    },
    {
        "text": "and you filter it and it looks like",
        "start": 430.639,
        "duration": 3.521
    },
    {
        "text": "being a lot of scientific work where",
        "start": 432.319,
        "duration": 4.081
    },
    {
        "text": "you're training classifiers and making",
        "start": 434.16,
        "duration": 4.24
    },
    {
        "text": "decisions based on how do you prune down",
        "start": 436.4,
        "duration": 4.48
    },
    {
        "text": "this this data set into the highest",
        "start": 438.4,
        "duration": 3.919
    },
    {
        "text": "quality stuff and the stuff that suits",
        "start": 440.88,
        "duration": 3.12
    },
    {
        "text": "your tasks So previously language",
        "start": 442.319,
        "duration": 4.241
    },
    {
        "text": "models were tested a lot more on like",
        "start": 444.0,
        "duration": 4.08
    },
    {
        "text": "knowledge and just kind of",
        "start": 446.56,
        "duration": 3.039
    },
    {
        "text": "conversational things but now they're",
        "start": 448.08,
        "duration": 3.44
    },
    {
        "text": "expected to do math and code So to",
        "start": 449.599,
        "duration": 3.281
    },
    {
        "text": "train a reasoning model you need to",
        "start": 451.52,
        "duration": 3.36
    },
    {
        "text": "remix your whole data set And there's a",
        "start": 452.88,
        "duration": 3.599
    },
    {
        "text": "lot of actually wonderful scientific",
        "start": 454.88,
        "duration": 3.68
    },
    {
        "text": "methods here where you can you can like",
        "start": 456.479,
        "duration": 3.921
    },
    {
        "text": "take your gigantic data set you sample",
        "start": 458.56,
        "duration": 3.359
    },
    {
        "text": "a lot of really tiny things from",
        "start": 460.4,
        "duration": 2.96
    },
    {
        "text": "different sources So you say you have",
        "start": 461.919,
        "duration": 4.0
    },
    {
        "text": "GitHub, Stack Exchange, Reddit,",
        "start": 463.36,
        "duration": 4.48
    },
    {
        "text": "Wikipedia, you can sample small things",
        "start": 465.919,
        "duration": 3.68
    },
    {
        "text": "from them and you train small models on",
        "start": 467.84,
        "duration": 3.28
    },
    {
        "text": "each of these mixes and measure their",
        "start": 469.599,
        "duration": 3.04
    },
    {
        "text": "performance on your evaluations And you",
        "start": 471.12,
        "duration": 3.12
    },
    {
        "text": "can just do like basic linear regression",
        "start": 472.639,
        "duration": 3.12
    },
    {
        "text": "and it's like here's your optimal data",
        "start": 474.24,
        "duration": 3.359
    },
    {
        "text": "set But if your evaluations change",
        "start": 475.759,
        "duration": 3.521
    },
    {
        "text": "your data set changes a lot So a lot of",
        "start": 477.599,
        "duration": 4.32
    },
    {
        "text": "old mode 3 was new sources for reasoning",
        "start": 479.28,
        "duration": 4.88
    },
    {
        "text": "to be better at math and code to and",
        "start": 481.919,
        "duration": 4.0
    },
    {
        "text": "then you do this mixing procedure and it",
        "start": 484.16,
        "duration": 3.039
    },
    {
        "text": "gives you the answer And I think that's",
        "start": 485.919,
        "duration": 3.201
    },
    {
        "text": "a lot of that's happened at labs this",
        "start": 487.199,
        "duration": 3.68
    },
    {
        "text": "year like there's new hot things whether",
        "start": 489.12,
        "duration": 3.84
    },
    {
        "text": "it's like coding environments or web",
        "start": 490.879,
        "duration": 3.44
    },
    {
        "text": "navigation and you just need to bring in",
        "start": 492.96,
        "duration": 2.72
    },
    {
        "text": "new data you need to change your whole",
        "start": 494.319,
        "duration": 3.041
    },
    {
        "text": "restraining so your post-raining can",
        "start": 495.68,
        "duration": 3.519
    },
    {
        "text": "work better and stuff like this So",
        "start": 497.36,
        "duration": 4.559
    },
    {
        "text": "that's like the constant re revolution",
        "start": 499.199,
        "duration": 4.56
    },
    {
        "text": "and the redetermining of what they care",
        "start": 501.919,
        "duration": 3.68
    },
    {
        "text": "about as their for their models Are",
        "start": 503.759,
        "duration": 5.28
    },
    {
        "text": "there fun anecdotes of what sources of",
        "start": 505.599,
        "duration": 5.201
    },
    {
        "text": "data are particularly high quality that",
        "start": 509.039,
        "duration": 4.0
    },
    {
        "text": "we wouldn't expect You mentioned Reddit",
        "start": 510.8,
        "duration": 4.4
    },
    {
        "text": "sometimes can be a source",
        "start": 513.039,
        "duration": 6.24
    },
    {
        "text": "i Reddit was very useful I think that um",
        "start": 515.2,
        "duration": 6.56
    },
    {
        "text": "like PDFs is definitely one",
        "start": 519.279,
        "duration": 3.521
    },
    {
        "text": "i especially archives",
        "start": 521.76,
        "duration": 3.28
    },
    {
        "text": "i Yeah. So like AI2 has run semantic",
        "start": 522.8,
        "duration": 5.2
    },
    {
        "text": "scholar for a long time which is a um",
        "start": 525.04,
        "duration": 4.799
    },
    {
        "text": "like a what you can say is a competitor",
        "start": 528.0,
        "duration": 3.519
    },
    {
        "text": "to Google Scholar with a lot more",
        "start": 529.839,
        "duration": 4.241
    },
    {
        "text": "features And to do this AI2 has found",
        "start": 531.519,
        "duration": 4.641
    },
    {
        "text": "and scraped a lot of PDFs for openly",
        "start": 534.08,
        "duration": 4.64
    },
    {
        "text": "accessible papers that might not be um",
        "start": 536.16,
        "duration": 4.799
    },
    {
        "text": "like behind the closed paid garden of a",
        "start": 538.72,
        "duration": 4.08
    },
    {
        "text": "certain publisher So like truly open",
        "start": 540.959,
        "duration": 4.241
    },
    {
        "text": "scientific PDFs and if you like you sit",
        "start": 542.8,
        "duration": 4.24
    },
    {
        "text": "on all of these and you process it and",
        "start": 545.2,
        "duration": 3.44
    },
    {
        "text": "you can get value out of it And I think",
        "start": 547.04,
        "duration": 4.88
    },
    {
        "text": "that like a lot of that style of work",
        "start": 548.64,
        "duration": 5.199
    },
    {
        "text": "has been done by the Frontier Labs much",
        "start": 551.92,
        "duration": 3.84
    },
    {
        "text": "earlier And it's just like you need to",
        "start": 553.839,
        "duration": 4.56
    },
    {
        "text": "have a pretty skilled researcher that",
        "start": 555.76,
        "duration": 4.88
    },
    {
        "text": "understands how things change models and",
        "start": 558.399,
        "duration": 4.0
    },
    {
        "text": "they bring it in and they clean it and",
        "start": 560.64,
        "duration": 4.0
    },
    {
        "text": "it's that's a lot of labor that like I",
        "start": 562.399,
        "duration": 3.681
    },
    {
        "text": "think of a lot of frontier labs when",
        "start": 564.64,
        "duration": 2.96
    },
    {
        "text": "they scale researchers a lot more goes",
        "start": 566.08,
        "duration": 3.92
    },
    {
        "text": "into data you have people like if you",
        "start": 567.6,
        "duration": 3.679
    },
    {
        "text": "want to make if you join a frontier lab",
        "start": 570.0,
        "duration": 2.72
    },
    {
        "text": "and you want to have impact the best way",
        "start": 571.279,
        "duration": 3.361
    },
    {
        "text": "to do it is just make find new data",
        "start": 572.72,
        "duration": 4.08
    },
    {
        "text": "that's better and then like the fancy",
        "start": 574.64,
        "duration": 4.48
    },
    {
        "text": "glamorous algorithmic things like",
        "start": 576.8,
        "duration": 4.32
    },
    {
        "text": "figuring out how to make 01 is like the",
        "start": 579.12,
        "duration": 4.08
    },
    {
        "text": "sexiest thought of a scientist of like",
        "start": 581.12,
        "duration": 4.24
    },
    {
        "text": "oh I figured out to scale RL and there's",
        "start": 583.2,
        "duration": 3.6
    },
    {
        "text": "a group that did that but I think most",
        "start": 585.36,
        "duration": 3.36
    },
    {
        "text": "of the contributions is like",
        "start": 586.8,
        "duration": 3.44
    },
    {
        "text": "i I'm going to make the data better or I'm",
        "start": 588.72,
        "duration": 2.799
    },
    {
        "text": "going to make the infrastructure better",
        "start": 590.24,
        "duration": 3.12
    },
    {
        "text": "so that everybody in my team can run",
        "start": 591.519,
        "duration": 3.521
    },
    {
        "text": "experiments i faster",
        "start": 593.36,
        "duration": 3.12
    },
    {
        "text": "i at the same time I think it's also one",
        "start": 595.04,
        "duration": 3.12
    },
    {
        "text": "of the closest guarded secrets what",
        "start": 596.48,
        "duration": 3.12
    },
    {
        "text": "you're training data is for legal",
        "start": 598.16,
        "duration": 2.96
    },
    {
        "text": "reasons and so there's also I think a",
        "start": 599.6,
        "duration": 3.359
    },
    {
        "text": "lot of work that goes into hiding what",
        "start": 601.12,
        "duration": 4.24
    },
    {
        "text": "your trading data was essentially like",
        "start": 602.959,
        "duration": 5.041
    },
    {
        "text": "trying the model to not give away the",
        "start": 605.36,
        "duration": 4.159
    },
    {
        "text": "sources because yeah of legal reasons",
        "start": 608.0,
        "duration": 3.44
    },
    {
        "text": "the other thing to be complete is that",
        "start": 609.519,
        "duration": 3.521
    },
    {
        "text": "some people are trying to train on only",
        "start": 611.44,
        "duration": 4.079
    },
    {
        "text": "licensed data where common crawl is a",
        "start": 613.04,
        "duration": 5.12
    },
    {
        "text": "scrape of like the whole internet so um",
        "start": 615.519,
        "duration": 6.0
    },
    {
        "text": "if I I host multiple websites I happy to",
        "start": 618.16,
        "duration": 5.119
    },
    {
        "text": "have them train language models but I'm",
        "start": 621.519,
        "duration": 4.56
    },
    {
        "text": "not explicitly licensing what governs it",
        "start": 623.279,
        "duration": 4.721
    },
    {
        "text": "and therefore this l the common crawl is",
        "start": 626.079,
        "duration": 4.561
    },
    {
        "text": "large unlicensed which means that your",
        "start": 628.0,
        "duration": 4.16
    },
    {
        "text": "consent really hasn't been provided for",
        "start": 630.64,
        "duration": 2.879
    },
    {
        "text": "how to use the data There's another",
        "start": 632.16,
        "duration": 3.119
    },
    {
        "text": "idea where you can train language models",
        "start": 633.519,
        "duration": 4.241
    },
    {
        "text": "only on data that has been licensed",
        "start": 635.279,
        "duration": 4.321
    },
    {
        "text": "explicitly So that kind of governing",
        "start": 637.76,
        "duration": 3.44
    },
    {
        "text": "contract is provided and I'm not sure if",
        "start": 639.6,
        "duration": 3.76
    },
    {
        "text": "appetite is the copyright thing or the",
        "start": 641.2,
        "duration": 3.759
    },
    {
        "text": "license thing I know that the reason",
        "start": 643.36,
        "duration": 3.36
    },
    {
        "text": "that they did it was for an EU",
        "start": 644.959,
        "duration": 3.12
    },
    {
        "text": "compliance thing where they wanted to",
        "start": 646.72,
        "duration": 3.679
    },
    {
        "text": "make sure that their model um fit one of",
        "start": 648.079,
        "duration": 6.081
    },
    {
        "text": "those checks And so on that note also",
        "start": 650.399,
        "duration": 5.44
    },
    {
        "text": "for example there's also the distinction",
        "start": 654.16,
        "duration": 5.52
    },
    {
        "text": "between um the licensing So some people",
        "start": 655.839,
        "duration": 6.081
    },
    {
        "text": "like you said they just purchase the",
        "start": 659.68,
        "duration": 4.32
    },
    {
        "text": "license say they buy a book online",
        "start": 661.92,
        "duration": 4.24
    },
    {
        "text": "let's say an Amazon Kindle book or let's",
        "start": 664.0,
        "duration": 3.36
    },
    {
        "text": "say a monkeying book or something and",
        "start": 666.16,
        "duration": 2.4
    },
    {
        "text": "then use that in the training data and",
        "start": 667.36,
        "duration": 2.56
    },
    {
        "text": "that is like the gray zone because you",
        "start": 668.56,
        "duration": 3.279
    },
    {
        "text": "paid for the content and you might want",
        "start": 669.92,
        "duration": 3.84
    },
    {
        "text": "to train it but then there are also",
        "start": 671.839,
        "duration": 3.841
    },
    {
        "text": "restrictions where even that shouldn't",
        "start": 673.76,
        "duration": 3.28
    },
    {
        "text": "be allowed and so that that is like",
        "start": 675.68,
        "duration": 4.159
    },
    {
        "text": "where where it gets a bit fuzzy and yeah",
        "start": 677.04,
        "duration": 5.68
    },
    {
        "text": "I think that is right now still a hot",
        "start": 679.839,
        "duration": 5.201
    },
    {
        "text": "topic and also big companies like open",
        "start": 682.72,
        "duration": 4.48
    },
    {
        "text": "they approached private companies for",
        "start": 685.04,
        "duration": 4.239
    },
    {
        "text": "their proprietary data and private",
        "start": 687.2,
        "duration": 4.56
    },
    {
        "text": "companies they become more and more",
        "start": 689.279,
        "duration": 5.441
    },
    {
        "text": "let's say uh protective of their data",
        "start": 691.76,
        "duration": 4.079
    },
    {
        "text": "because they know okay this is going to",
        "start": 694.72,
        "duration": 3.679
    },
    {
        "text": "be my mode in in a few years and I do",
        "start": 695.839,
        "duration": 4.881
    },
    {
        "text": "think um that's like the interesting",
        "start": 698.399,
        "duration": 4.161
    },
    {
        "text": "question where",
        "start": 700.72,
        "duration": 4.32
    },
    {
        "text": "if LLMs become more commodities and I",
        "start": 702.56,
        "duration": 4.08
    },
    {
        "text": "think a lot of people learn about LLM",
        "start": 705.04,
        "duration": 3.359
    },
    {
        "text": "there will be a lot more people able to",
        "start": 706.64,
        "duration": 2.96
    },
    {
        "text": "train LLM of course there are",
        "start": 708.399,
        "duration": 2.56
    },
    {
        "text": "infrastructure challenges but if you",
        "start": 709.6,
        "duration": 3.6
    },
    {
        "text": "think of big industries like",
        "start": 710.959,
        "duration": 4.641
    },
    {
        "text": "pharmaceutical industries law finance",
        "start": 713.2,
        "duration": 4.16
    },
    {
        "text": "industries I do think they at some point",
        "start": 715.6,
        "duration": 4.799
    },
    {
        "text": "will hire people from other frontier",
        "start": 717.36,
        "duration": 4.719
    },
    {
        "text": "labs to build their unhouse house",
        "start": 720.399,
        "duration": 3.761
    },
    {
        "text": "models on their proprietary data which",
        "start": 722.079,
        "duration": 4.32
    },
    {
        "text": "will be then again another unlock with",
        "start": 724.16,
        "duration": 3.919
    },
    {
        "text": "restraining that is currently not there",
        "start": 726.399,
        "duration": 3.68
    },
    {
        "text": "because even if you wanted to you can't",
        "start": 728.079,
        "duration": 4.161
    },
    {
        "text": "get that data you can't get access to",
        "start": 730.079,
        "duration": 4.0
    },
    {
        "text": "clinical trials most of the time and",
        "start": 732.24,
        "duration": 4.0
    },
    {
        "text": "these types of things so I do think",
        "start": 734.079,
        "duration": 3.681
    },
    {
        "text": "scaling in that sense might be still",
        "start": 736.24,
        "duration": 4.48
    },
    {
        "text": "pretty much alive if you also look in",
        "start": 737.76,
        "duration": 4.56
    },
    {
        "text": "domain specific applications because we",
        "start": 740.72,
        "duration": 3.6
    },
    {
        "text": "are still right now in this year just",
        "start": 742.32,
        "duration": 4.16
    },
    {
        "text": "looking at general purpose LLMs on on",
        "start": 744.32,
        "duration": 4.0
    },
    {
        "text": "chipedia anthropic and so forth they are",
        "start": 746.48,
        "duration": 4.159
    },
    {
        "text": "just general purpose they're not even I",
        "start": 748.32,
        "duration": 3.68
    },
    {
        "text": "think scratch touching the surface of",
        "start": 750.639,
        "duration": 3.121
    },
    {
        "text": "what an LM can do if it is really",
        "start": 752.0,
        "duration": 3.92
    },
    {
        "text": "specifically trained and designed for a",
        "start": 753.76,
        "duration": 3.199
    },
    {
        "text": "specific task",
        "start": 755.92,
        "duration": 2.8
    },
    {
        "text": "i I think on the data thing some this is",
        "start": 756.959,
        "duration": 2.721
    },
    {
        "text": "one of the things where like this",
        "start": 758.72,
        "duration": 2.48
    },
    {
        "text": "happened in 2025 and we totally forget",
        "start": 759.68,
        "duration": 3.44
    },
    {
        "text": "it is Enthropic lost in court and was",
        "start": 761.2,
        "duration": 5.68
    },
    {
        "text": "owed $1.5 billion to authors Anthropic",
        "start": 763.12,
        "duration": 5.76
    },
    {
        "text": "I think bought thousands of books and",
        "start": 766.88,
        "duration": 4.959
    },
    {
        "text": "scanned them and was cleared legally for",
        "start": 768.88,
        "duration": 5.04
    },
    {
        "text": "that because they bought the books and",
        "start": 771.839,
        "duration": 3.361
    },
    {
        "text": "that is kind of going through the",
        "start": 773.92,
        "duration": 2.479
    },
    {
        "text": "system And then the other side they",
        "start": 775.2,
        "duration": 2.639
    },
    {
        "text": "also tormented some books and I think",
        "start": 776.399,
        "duration": 3.921
    },
    {
        "text": "this tormenting was the path where the",
        "start": 777.839,
        "duration": 4.401
    },
    {
        "text": "courts said that they were then culpable",
        "start": 780.32,
        "duration": 3.519
    },
    {
        "text": "to pay this billions of dollars to",
        "start": 782.24,
        "duration": 2.8
    },
    {
        "text": "authors which is just like such a",
        "start": 783.839,
        "duration": 3.12
    },
    {
        "text": "mind-boggling lawsuit that kind of just",
        "start": 785.04,
        "duration": 4.244
    },
    {
        "text": "came and went like that is so much money",
        "start": 786.959,
        "duration": 2.961
    },
    {
        "text": "laughter",
        "start": 789.284,
        "duration": 3.516
    },
    {
        "text": "from the VC ecosystem These are court",
        "start": 789.92,
        "duration": 4.32
    },
    {
        "text": "cases that will define the future of",
        "start": 792.8,
        "duration": 3.44
    },
    {
        "text": "human civilization because it's clearly",
        "start": 794.24,
        "duration": 4.0
    },
    {
        "text": "that data drives a lot of this and",
        "start": 796.24,
        "duration": 3.839
    },
    {
        "text": "there's this very complicated human",
        "start": 798.24,
        "duration": 3.92
    },
    {
        "text": "tension of I mean you can empathize",
        "start": 800.079,
        "duration": 3.121
    },
    {
        "text": "you're both",
        "start": 802.16,
        "duration": 2.64
    },
    {
        "text": "i authors",
        "start": 803.2,
        "duration": 4.0
    },
    {
        "text": "and there's some degree to which I mean",
        "start": 804.8,
        "duration": 4.159
    },
    {
        "text": "you put your heart and soul and your",
        "start": 807.2,
        "duration": 4.0
    },
    {
        "text": "your sweat and tears into the the",
        "start": 808.959,
        "duration": 4.0
    },
    {
        "text": "writing that you do",
        "start": 811.2,
        "duration": 4.879
    },
    {
        "text": "i uh it feels a little bit like theft",
        "start": 812.959,
        "duration": 5.041
    },
    {
        "text": "i for somebody to train your data without",
        "start": 816.079,
        "duration": 2.961
    },
    {
        "text": "giving you credit",
        "start": 818.0,
        "duration": 2.959
    },
    {
        "text": "i and there like Nathan said also two",
        "start": 819.04,
        "duration": 4.16
    },
    {
        "text": "layers to Someone might buy the book and",
        "start": 820.959,
        "duration": 4.641
    },
    {
        "text": "then train on it which is could be",
        "start": 823.2,
        "duration": 3.92
    },
    {
        "text": "argued fair or not fair but then there",
        "start": 825.6,
        "duration": 3.84
    },
    {
        "text": "are literally straight up um companies",
        "start": 827.12,
        "duration": 4.64
    },
    {
        "text": "who use pirated books where it's not",
        "start": 829.44,
        "duration": 4.079
    },
    {
        "text": "even compensating the author is that",
        "start": 831.76,
        "duration": 3.92
    },
    {
        "text": "that is I think where people got a bit",
        "start": 833.519,
        "duration": 3.281
    },
    {
        "text": "angry about it specifically",
        "start": 835.68,
        "duration": 2.24
    },
    {
        "text": "i Yeah. But there has to be some kind of",
        "start": 836.8,
        "duration": 2.8
    },
    {
        "text": "compensation scheme This is like moving",
        "start": 837.92,
        "duration": 3.279
    },
    {
        "text": "towards",
        "start": 839.6,
        "duration": 3.52
    },
    {
        "text": "i towards something like Spotify streaming",
        "start": 841.199,
        "duration": 4.161
    },
    {
        "text": "did originally for music You know what",
        "start": 843.12,
        "duration": 3.6
    },
    {
        "text": "does that competition look like You",
        "start": 845.36,
        "duration": 2.88
    },
    {
        "text": "have to define those kinds of models",
        "start": 846.72,
        "duration": 5.52
    },
    {
        "text": "You have to think through all of that",
        "start": 848.24,
        "duration": 4.0
    }
]