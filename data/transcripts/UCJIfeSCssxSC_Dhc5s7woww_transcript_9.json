[
    {
        "text": " I think this might be a good place to define pre-training, mid-training and post-training. So restraining is the classic training one next token prediction at a time You have a big corpus of data and Nathan probably also has a very interesting insights there because of three It's a big portion of the paper focuses on the right data mix So restraining is essentially just you know train across entropy loss training on next token prediction on a a vast corpus of internet data books papers and so forth It has changed a little bit over the years in the sense people used to throw in everything they can Now it's not just raw data it's also synthetic data where people re um let's say rephrase certain things Uh so synthetic data doesn't necessarily mean purely AI makeup data It's also taking something from an article Wikipedia article and then rephrasing it as a Q&A question or um summarizing it rewarding it and and making uh better data that way Cuz I think of it also like with humans if someone let's say reads a book compared to a messy I don't know no offense but like Reddit post or something like that I do think you learn laughter you no offense but I think i there's going to be a post about this laughter i Well, some Reddit data is very coveted and excellent for training You just have to filter it laughter i Yeah. i I think that's the idea Uh I I think it's like if someone took that and rephrases that in a let's say more concise and structured way Yeah, I think it's higher quality data that gets the LLM maybe the same You get the same LLM out of it at the end but it gets there faster It trains faster because the let's say if the grammar and the punctuation is correct it already learns the correct way versus getting information from a messy way and then learning later how to correct that and stuff like that So I think that is how restraining evolved and how um how still while why scaling still works is that it's not about just the amount of data It's also the tricks to make that data better for you in a sense And then mid-training is I mean it used to be called pre-training. It's I think it's called mid training because it was awkward to have restraining and post training but nothing in the middle right it sounds a bit weird You have restraining and post training but what's the actual training So the mid-training is usually similar to uh restraining but you know it's a bit more I would say specialized in pre-training. It's the same algorithm but what you do is you focus for example on long context like one example you have long context documents The reason you don't do that during just pure restraining is because you don't have",
        "start": 2.96,
        "duration": 310.159
    },
    {
        "text": "know it's a bit more I would say specialized in pre-training. It's the same algorithm but what you do is you focus for example on long context like one example you have long context documents The reason you don't do that during just pure restraining is because you don't have have a specific phase and one problem of LMS is also still it's a neurons network It has the problem of catastrophic forgetting So you teach it something it forgets other things And you want to it's not 100% forgetting but you know it's like no free lunch You can't It's also the same with humans If you ask me some math I learned 10 years ago I don't know I would have to look at it again i Oh, Nathan was actually saying that he's consuming so much content that there's a catastrophic forgetting issue i Yeah, I'm like trying to learn so much about AI. I was like I was learning about restraining parallelisms I'm like I lost something and I don't know what laughter it was I don't want to uncomorphize LLMs but it's I think the same kind of in that sense how humans learned I mean the quantity is not always better because yeah it's like being selective and I in the mid training is being selective in terms of quality content at the end So the last thing the LM has seen is the quality stuff and then post training is all the uh fine-tuning supervised finetuning uh DPO um reinforcement learning with verifiable rewards with human feedback and so forth So the refinement stages and it's also interesting it's like the cost thing right I mean it's like restraining you spend a lot of money on that right now RL a bit less RL you don't really I would say teach it knowledge it's more like unlocking the knowledge it's more like a skill learning like how to solve problems with the knowledge that it has from restraining there are paper actually three papers this year last year 2025 on RL for restraining but I I mean I don't think anyone does that in production i toy examples for now i toy examples right but to generalize RL Well, post training is more like the skill unlock where restraining is like soaking up the knowledge essentially Yeah. i A few things that could be helpful for people A lot of people get like think of synthetic data as being bad for training the models You mentioned like the deep sea got OCR which is optical character recognition paper A lot of labs did AI2 had one like had multiple And the reason that each of these labs has these is because there's vast amounts of PDFs and other digital documents on the web that are in formats that aren't encoded with text easily So you use these almost CR these or deeper and we called ours CR to extract what",
        "start": 157.84,
        "duration": 571.1189999999999
    },
    {
        "text": "the reason that each of these labs has these is because there's vast amounts of PDFs and other digital documents on the web that are in formats that aren't encoded with text easily So you use these almost CR these or deeper and we called ours CR to extract what candidate data for restraining and restraining data sets is on the order of trillions is measured in trillions of tokens smaller models from researchers can be something like 5 to 10 trillion Um Quen has documented going up to like 50 trillion and there's rumors that these closed labs can go to like 100 trillion tokens And just getting this potential data to put in I think they they have a very big funnel and then the data you actually train the model on is a small percentage of this like the this character recognition data would be described as synthetic data for restraining in a lab And then there's also the things like chat GPT now gives wonderful answers and you could train on those best answers and that's synthetic data It's very different than like early chat GPT lots of hallucinations data when people became grounded in synthetic data One interesting question is if I recall correctly 3 was trained with less data than specifically some other overweight models maybe even two but you still got better performance and that might be one of the examples how the data help i It's mostly down to data quality I think if we had more computer we would train for longer I think we ultimately see that as a like just like something we would want to do And especially with big models you need to have more compute because we talk about having more parameters and we talk about knowledge and essentially there's a ratio where big models can absorb more from data and you're going to you get more benefit out of this It's it's like one of these any logarithmic graph in your mind is like a small model will level off sooner if you're measuring tons of tokens and bigger bigger models need more But mostly is we aren't training that big of models right now with AI2 and getting the highest quality data we can is the natural starting point i Is there something to be said uh about the topic of data quality Is there some lowhanging fruit there still where the quality could be improved i It's like turning the crank So I think historically in the open there's been like a canonical best restraining data set that has moved around between who has the most recent one or the best recent effort like AI2's doll was very early with the first mo and hugging face had fine web and there's a DCLM project which has been kind of like a which is it stands for data come language model there's been data come for other machine",
        "start": 290.08,
        "duration": 825.5189999999993
    },
    {
        "text": "one or the best recent effort like AI2's doll was very early with the first mo and hugging face had fine web and there's a DCLM project which has been kind of like a which is it stands for data come language model there's been data come for other machine very strong data set and a lot of it is the internet is becoming fairly closed off So we have common crawl which I think is hundreds of trillions of tokens and you filter it and it looks like being a lot of scientific work where you're training classifiers and making decisions based on how do you prune down this this data set into the highest quality stuff and the stuff that suits your tasks So previously language models were tested a lot more on like knowledge and just kind of conversational things but now they're expected to do math and code So to train a reasoning model you need to remix your whole data set And there's a lot of actually wonderful scientific methods here where you can you can like take your gigantic data set you sample a lot of really tiny things from different sources So you say you have GitHub, Stack Exchange, Reddit, Wikipedia, you can sample small things from them and you train small models on each of these mixes and measure their performance on your evaluations And you can just do like basic linear regression and it's like here's your optimal data set But if your evaluations change your data set changes a lot So a lot of old mode 3 was new sources for reasoning to be better at math and code to and then you do this mixing procedure and it gives you the answer And I think that's a lot of that's happened at labs this year like there's new hot things whether it's like coding environments or web navigation and you just need to bring in new data you need to change your whole restraining so your post-raining can work better and stuff like this So that's like the constant re revolution and the redetermining of what they care about as their for their models Are there fun anecdotes of what sources of data are particularly high quality that we wouldn't expect You mentioned Reddit sometimes can be a source i Reddit was very useful I think that um like PDFs is definitely one i especially archives i Yeah. So like AI2 has run semantic scholar for a long time which is a um like a what you can say is a competitor to Google Scholar with a lot more features And to do this AI2 has found and scraped a lot of PDFs for openly accessible papers that might not be um like behind the closed paid garden of a certain publisher So like truly open scientific PDFs and if you like you sit on all of these and you process it and",
        "start": 420.479,
        "duration": 1073.3599999999994
    },
    {
        "text": "this AI2 has found and scraped a lot of PDFs for openly accessible papers that might not be um like behind the closed paid garden of a certain publisher So like truly open scientific PDFs and if you like you sit on all of these and you process it and that like a lot of that style of work has been done by the Frontier Labs much earlier And it's just like you need to have a pretty skilled researcher that understands how things change models and they bring it in and they clean it and it's that's a lot of labor that like I think of a lot of frontier labs when they scale researchers a lot more goes into data you have people like if you want to make if you join a frontier lab and you want to have impact the best way to do it is just make find new data that's better and then like the fancy glamorous algorithmic things like figuring out how to make 01 is like the sexiest thought of a scientist of like oh I figured out to scale RL and there's a group that did that but I think most of the contributions is like i I'm going to make the data better or I'm going to make the infrastructure better so that everybody in my team can run experiments i faster i at the same time I think it's also one of the closest guarded secrets what you're training data is for legal reasons and so there's also I think a lot of work that goes into hiding what your trading data was essentially like trying the model to not give away the sources because yeah of legal reasons the other thing to be complete is that some people are trying to train on only licensed data where common crawl is a scrape of like the whole internet so um if I I host multiple websites I happy to have them train language models but I'm not explicitly licensing what governs it and therefore this l the common crawl is large unlicensed which means that your consent really hasn't been provided for how to use the data There's another idea where you can train language models only on data that has been licensed explicitly So that kind of governing contract is provided and I'm not sure if appetite is the copyright thing or the license thing I know that the reason that they did it was for an EU compliance thing where they wanted to make sure that their model um fit one of those checks And so on that note also for example there's also the distinction between um the licensing So some people like you said they just purchase the license say they buy a book online let's say an Amazon Kindle book or let's say a monkeying book or something and then use that in the training data and",
        "start": 547.04,
        "duration": 1311.2799999999982
    },
    {
        "text": "for example there's also the distinction between um the licensing So some people like you said they just purchase the license say they buy a book online let's say an Amazon Kindle book or let's say a monkeying book or something and then use that in the training data and paid for the content and you might want to train it but then there are also restrictions where even that shouldn't be allowed and so that that is like where where it gets a bit fuzzy and yeah I think that is right now still a hot topic and also big companies like open they approached private companies for their proprietary data and private companies they become more and more let's say uh protective of their data because they know okay this is going to be my mode in in a few years and I do think um that's like the interesting question where if LLMs become more commodities and I think a lot of people learn about LLM there will be a lot more people able to train LLM of course there are infrastructure challenges but if you think of big industries like pharmaceutical industries law finance industries I do think they at some point will hire people from other frontier labs to build their unhouse house models on their proprietary data which will be then again another unlock with restraining that is currently not there because even if you wanted to you can't get that data you can't get access to clinical trials most of the time and these types of things so I do think scaling in that sense might be still pretty much alive if you also look in domain specific applications because we are still right now in this year just looking at general purpose LLMs on on chipedia anthropic and so forth they are just general purpose they're not even I think scratch touching the surface of what an LM can do if it is really specifically trained and designed for a specific task i I think on the data thing some this is one of the things where like this happened in 2025 and we totally forget it is Enthropic lost in court and was owed $1.5 billion to authors Anthropic I think bought thousands of books and scanned them and was cleared legally for that because they bought the books and that is kind of going through the system And then the other side they also tormented some books and I think this tormenting was the path where the courts said that they were then culpable to pay this billions of dollars to authors which is just like such a mind-boggling lawsuit that kind of just came and went like that is so much money laughter from the VC ecosystem These are court cases that will define the future of human civilization because it's clearly that data drives a lot of this and there's this very complicated human",
        "start": 668.56,
        "duration": 1571.7599999999989
    },
    {
        "text": "such a mind-boggling lawsuit that kind of just came and went like that is so much money laughter from the VC ecosystem These are court cases that will define the future of human civilization because it's clearly that data drives a lot of this and there's this very complicated human you're both i authors and there's some degree to which I mean you put your heart and soul and your your sweat and tears into the the writing that you do i uh it feels a little bit like theft i for somebody to train your data without giving you credit i and there like Nathan said also two layers to Someone might buy the book and then train on it which is could be argued fair or not fair but then there are literally straight up um companies who use pirated books where it's not even compensating the author is that that is I think where people got a bit angry about it specifically i Yeah. But there has to be some kind of compensation scheme This is like moving towards i towards something like Spotify streaming did originally for music You know what does that competition look like You have to define those kinds of models You have to think through all of that",
        "start": 800.079,
        "duration": 1670.8799999999992
    }
]