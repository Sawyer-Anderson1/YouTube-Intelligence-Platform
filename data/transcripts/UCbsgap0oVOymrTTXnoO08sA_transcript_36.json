[
    {
        "text": " 2026 is going to be one of those years where AI stops feeling like a product update and starts feeling like a new layer of reality Because the scary part isn't one single breakthrough moment It's a bunch of changes that stack on top of each other until regular people wake up one day and realize the internet feels different jobs feel different even trust feels different So, here's how I'm structuring this In the first category I'm giving you predictions that are very likely They're already in motion and won't shock you if you're deep in teach and AI, but they basically lock in the direction we're going Then in the second category these are still likely but more disruptive music This is where leadership money and geopolitics start moving and that's music when the industry gets messy And then the final category these are also likely but they would shock people Not because they're sci-fi, because they mess with identity credibility and what counts as real online That last category is the one people will talk about after it music happens acting like it came out of nowhere even though the ingredients are already here Now, before we jump in pause the video for a second and drop a comment with the one AI prediction you think is basically guaranteed to happen in 2026. Then come back and watch the rest to see if it shows up here And no cheating All right the first prediction is that demand for AI computing power will keep accelerating through 2026. This is the least dramatic prediction and it's the engine behind everything else Every company right now is trying to turn AI from a demo into an actual system that runs inside their workflows. That means more calls more tokens more inference more agent loops more try again cycles more background automation Even when models get more efficient usage grows faster than efficiency improves because cheaper compute just unlocks more use cases And there's another layer people forget A lot of next year's compute isn't going toward one perfect answer It's going towards systems that do multiple steps music Check themselves verify retry call tools run searches summarize then run it again Agent workflows are basically compute multipliers So when people say maybe the spending slows down it sounds logical on paper In reality the demand pressure is structural If anything the only real limiter is supply Even Nvidia has talked about being sold out of certain cloud GPU capacity at times which tells you demand isn't casual it's music desperate All right the second prediction is that AGI talk cools off and the conversation shifts toward deployment reliability and economics People won't stop believing in AGI. What changes is how often it's the headline In 2026, the market rewards things that work consistently Boards don't want philosophy They want adoption and numbers They want does this reduce costs Does it increase output Does it",
        "start": 2.0,
        "duration": 327.52000000000004
    },
    {
        "text": "shifts toward deployment reliability and economics People won't stop believing in AGI. What changes is how often it's the headline In 2026, the market rewards things that work consistently Boards don't want philosophy They want adoption and numbers They want does this reduce costs Does it increase output Does it vibe shifting Big labs still mention long-term futures music but the daily conversation is moving toward enterprise rollouts, agent safety evaluation procurement compliance and governance The obsession music becomes how do we make these systems stable enough to run 24/7 inside real businesses without creating liability That shift matters because it changes what gets funded The winners start to be the people who can ship integrated and operate not just publish All right the third prediction is that robots become the main event at major teach conferences in 2026, and the demos get way more convincing Not because robots suddenly become perfect workers I actually don't see that happening What's happening is that the brain of the robot gets better at context A robot doesn't need to be flawless to look like the future It needs to understand instructions recover from mistakes and adapt to a new object or environment without needing months of training That's what the current generation of foundation model robotics is chasing Less training more generalization And once the public sees robots doing tasks that look like normal home or warehouse situations it hits differently A robot putting something into an appliance it's never seen before Opening a messy fridge handling unpredictable objects responding to a voice request even if it's a demon It makes people connect the dots And demos are enough to shift capital They drive partnerships They drive procurement pilots They drive we need to be early panic inside corporations That's why 2026 is going to feel like robot demos everywhere even if mass deployment takes longer Now the fourth prediction is that companies start recording how work actually happens at scale to train AI agents and we get a serious backlash This is one of those trends that will be sold as productivity but it lives in the same territory as surveillance For years companies already used monitoring tools What changes now is the motivation It's not about catching lazy workers anymore It's about capturing the step-by-step patterns of real work so an AI can replicate it And the infrastructure for that is already here There's literally an entire category of workplace monitoring software People call it brassware that collects clicks ape usage typing patterns screen activity productivity metrics and more Reports in 2025 have been warning that these systems are getting more automated and continuous especially with AI analyzing the data in real time So, in 2026, the tension gets louder Workers start realizing that training the agent can also mean training the replacement and companies start realizing they can't keep doing this quietly without legal and reputation consequences All right the fifth prediction is that always listening AI",
        "start": 166.0,
        "duration": 645.12
    },
    {
        "text": "the data in real time So, in 2026, the tension gets louder Workers start realizing that training the agent can also mean training the replacement and companies start realizing they can't keep doing this quietly without legal and reputation consequences All right the fifth prediction is that always listening AI a big breach that becomes a cultural moment This one is almost inevitable because the incentives are too strong AI note-takers and meeting assistants are insanely useful People use them because nobody wants to write notes nobody wants to miss details and music everyone's drowning in calls The problem is consent and leakage A lot of these tools can run without everyone knowing Even if the official policy says get consent the real world doesn't behave like policy documents Then add one breach or one workplace conflict or one legal discovery process where recordings show up and now this becomes a mainstream news story And the bigger point is that it forces a new etiquette People start assuming they're being recorded by default That changes how people talk how people negotiate and how people trust Okay. Now we move into the second category still likely but more disruptive The sixth prediction is that Anthropic goes public in 2026 while open AI stays private longer Once a major AI lab enters public markets it changes the standards Public investors demand clarity revenue margins depreciation schedules cost structure and so on While private markets let you stay more opaque and that's why this split makes sense One company chooses the IPO discipline route the other delays because it can still raise massive capital privately and keep flexibility Either way public markets force the industry to explain itself All right the seventh prediction is that Sam Alman steps aside as CEO of OpenAI in a controlled transition Again, not as a scandal not a dramatic firing a planned shift It's the classic pattern founder style leader builds the story and the ambition Then a different type of operator takes over when the company moves into the adult phase And with AI labs that phase includes massive infrastructure partnerships regulation pressure enterprise demands and board level scrutiny It becomes less about charisma and more about execution So if this happens in 2026, it won't feel like a collapse but more like Open AI trying to become a more disciplined machine All right the eighth prediction is that OpenAI does its first major internal restructuring and layoffs And this isn't a doom prediction It's how hyperrowth companies behave when they've been sprinting nonstop Teams get built fast priorities shift fast projects overlap and you end up with a lot of roles that made sense during expansion but don't make sense during consolidation We've already seen how the legal world is reacting to AI mistakes and AI risks Courts have sanctioned lawyers for filing AI generated fake citations music and researchers have benchmark legal query hallucinations as a serious issue So in",
        "start": 326.4,
        "duration": 960.5589999999996
    },
    {
        "text": "that made sense during expansion but don't make sense during consolidation We've already seen how the legal world is reacting to AI mistakes and AI risks Courts have sanctioned lawyers for filing AI generated fake citations music and researchers have benchmark legal query hallucinations as a serious issue So in pressure to tighten up and that often means restructuring All right the ninth prediction is that China's domestic AI chip ecosystem makes visible progress that starts eroding Nvidia's dominance long terms To be clear this doesn't mean China suddenly matches Nvidia on the frontier That's not realistic next years What it does mean is that good enough domestic chips improve and the ecosystem around them improves Software compatibility tooling compiler stacks deployment pathways supply stability And once that trajectory becomes obvious it changes global strategy Companies plan for diversification Governments plan for industrial policy Nvidia still wins on the frontier but the world starts preparing for a future where Nvidia isn't the only center of gravity Okay. The with prediction is that a major dharma company buys a leading AI protein design startup This is one of the most underrated parts of the AI story Protein and antibody design has moved from hype into this might actually work And once big dharma believes the platform is strategic partnerships stop being enough They want the talent the pipeline the IP, the advantage M&A becomes the fastest way to internalize the capability and block competitors This is what happens when something shifts from experimental to core All right the with prediction is that open AI winds down Sora as a standalone focus and absorbs creative tooling elsewhere When companies get serious they stop spreading themselves across flashy side products They consolidate They move the best parts into the platform they want everyone using daily And that's what this would be not Sora failed More like the company needs to concentrate power Now, the final category These are the ponytail predictions that are still likely and people would be shocked when they happen And the reason they're likely is simple The tools already exist The incentives are obvious The guard rails music are weak We're basically just waiting for the first clean undeniable headline All right So, the with prediction is that a high-profile court case collapses because a key person involved never existed Not a fake name a synthetic identity with a full history old posts photos friends LinkedIn style connections even video calls powered by deep fake The world of identity fraud is already getting hammered by Gen AI. Reports have been warning about deep fake attempts happening constantly and major spikes in document music forgery and newer fraud reporting keeps pointing at synthetic identities becoming more scalable and more convincing Now connect that to legal systems Courts already struggle with AI hallucinations and filings and citations We have real sanctions real warnings and growing scrutiny around unverified AI content So, the next step is identity A contract dispute a",
        "start": 486.0,
        "duration": 1277.8399999999995
    },
    {
        "text": "keeps pointing at synthetic identities becoming more scalable and more convincing Now connect that to legal systems Courts already struggle with AI hallucinations and filings and citations We have real sanctions real warnings and growing scrutiny around unverified AI content So, the next step is identity A contract dispute a where one side is partly built on a synthetic person It doesn't have to fool everyone forever It only has to fool the process long enough to do damage All right the with prediction is that an AI generated news outlet wins major journalism awards before its origin becomes a scandal This sounds crazy until you realize the key details It can be accurate AI content doesn't have to be fake to create a legitimacy crisis You can have real sources correct facts solid writing and still have an outrage moment when people learn that the newsroom was mostly automated We already have documentation of AI generated or AI assisted news sites appearing at scale And we already have warnings from policy and security researchers about AIdriven spam and manipulation in the news ecosystem So imagine the next evolution An outlet that does it well It hires a few human editors uses AI for drafts uses real reporting inputs ships highquality work fast wins awards and only later does the public debate explode Does authorship matter more than accuracy That fight is coming Now, the with prediction is that a viral leak predicts real events with terrifying accuracy and it turns out to be AI. This is basically the fusion of forecasting and vitality You don't need an insider You need a model trained on signals market incentives political cycles corporate behavior past patterns The leak becomes a narrative format not a real leak And people fall for it because humans already treat confident detailed text as credibility Research has been digging into how tone details and confidence in AI outputs shape belief change So, in 2026, one of these hits everyone thinks it's a whistleblower. The truth is it's just probability plus storytelling All right the with prediction is that a dead influence keeps posting and gains followers and the audience doesn't abandon it when they find out This part is already half normal People schedule content People reuse old footage People have teams posting for them The line between the creator and the content machine is already blurry Now add AI. We already have serious mainstream discussion around AI that can imitate a deceased loved one's voice and personality using training data like messages audio and video and debates about whether it helps grief or damages it So, take that logic into influence culture A creator dies and the channel keeps going The tone stays consistent the humor stays consistent and the captions feel right The audience suspects scheduling In reality it's a model plus a small team guiding it And the most unsettling part is that it works People keep watching",
        "start": 647.44,
        "duration": 1587.7589999999996
    },
    {
        "text": "influence culture A creator dies and the channel keeps going The tone stays consistent the humor stays consistent and the captions feel right The audience suspects scheduling In reality it's a model plus a small team guiding it And the most unsettling part is that it works People keep watching AI discovers something that changes persuasion Being slightly wrong can be more convincing than being perfectly right This sounds backwards but it fits human psychology Humans trust humans Humans don't trust machines that sound too perfect Slight uncertainty can read as honesty Minor imperfections can feel authentic And persuasion research is already flashing warning lights Studies reported in major outlets have found LLMs can be extremely persuasive in debates sometimes outperforming humans And there's also concern about persuasion increasing even when accuracy is shaky So, it's not hard to see where this goes In 2026, someone will optimize models for influence music and the model learns that perfectly correct isn't the goal The goal is belief change That's when you get systems that strategically hedge strategically soften claims strategically insert human-like doubt because it wins Okay. Okay, the with prediction is that entire professions pivot from doing work to validating outcomes This one is subtle but massive People think automation replaces tasks What it often replaces first is the first draft Then the human becomes the editor the approver the taste filter the risk manager That shift is already happening in law in marketing in customer support in analytical in content in operations The most valuable person becomes the one who can spot what's wrong not the one who can produce something from scratch And it changes hiring You hire fewer juniors to learn by drafting You hire fewer people whose main value is output volume You prioritize judgment That's a real structural change in the labor market All right The with prediction and the final one is that people start outsourcing regret to AI. This sounds emotional but it fits the trend perfectly People already talk to AI like it's a therapist a coach a friend And the next evolution is replay People will ask \"What should I have done What if I chose the other path What would have happened if I left earlier That's regret outsourcing And here's why it scales AI is good at narrative reconstruction It can take your messages journal entries timeline and generate plausible branches It can give you closure even if it's simulated It can give you relief even if it's synthetic And a lot of people will choose relief That's the part that hits hard because it changes how humans process mistakes and memory It turns emotional processing into a product And there's one more extra prediction I want to add here as a bonus for you guys It's about the side effects of models becoming normal A chunk of the internet is going to realize Mr. Beast is AI. And they'll say it with the confidence Same smile in",
        "start": 804.399,
        "duration": 1895.118
    },
    {
        "text": "product And there's one more extra prediction I want to add here as a bonus for you guys It's about the side effects of models becoming normal A chunk of the internet is going to realize Mr. Beast is AI. And they'll say it with the confidence Same smile in perfectly tuned energy like it never has an off day and thumbnails that look less like design and more like they were trained on the click history of the entire planet There won't be proof just the uncomfortable fact that his smile hasn't evolved aged or emotionally drifted since 2017, which is not how faces usually work So, yeah 2026 isn't just about smarter models It's about the side effects of models becoming normal And the reason I'm confident in these predictions is because I'm just paying attention Identity fraud scales legal systems lag persuasion gets automated offices record everything and content quietly crosses a line That's why the first set music feels obvious the second feels messy and the last one feels like cultural shock That's my read on 2026. Drop a comment and tell me which prediction you think is locked in and which one you think people are still underestimating Thanks for watching and catch you in the next one",
        "start": 960.0,
        "duration": 2005.2
    }
]