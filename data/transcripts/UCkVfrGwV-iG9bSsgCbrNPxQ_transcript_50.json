[
    {
        "text": " I created something that's one closest step to super intelligence. Imagine you have a car and it's a pretty good car. It gets you from point A to point B. But like any car, it has its faults. Maybe the check engine light comes on for no reason. Maybe the brakes are a little bit squeaky. So you take it to the mechanic. Now imagine your mechanic isn't a person. It's a robot. But not just any robot. This robot doesn't just fix the squeaky brakes. It analyzes the entire system, discovers a flaw in the original design that no one had ever noticed before, and then redesigns the brakes to be safer and more efficient. It even 3D prints the new parts and installs them for you. And the next time you come in, it does it again, making your car a little bit better, a little bit smarter every single time. That might seem like science fiction, but what if I told you that this is already happening? Not with cars, but with something much more fundamental in our modern world, computer code. For the past few years, we've gotten used to a certain kind of AI. The kind that you can talk to. You can ask it a question. It gives you an answer. You can ask it to write a poem. It writes a poem. It is certainly impressive, but it's also very passive. It waits for you to tell it what to do. But a new kind of AI is emerging. An agentic AI. AI that doesn't just answer questions, but takes action. An AI that can be given a goal and then figure out on its own the steps needed to achieve that goal. And one of the first and most powerful examples of this new kind of AI has a strange name. It's it's called the OpenAI Agentic Automatic Security Arvark. It's a mouthful, I know, but this Arvark is more than just a clever piece of software. It's [music] a signpost, a glimpse into the future that is coming much faster than most of us realize. A future where AI doesn't just do the tasks we give it, but starts to improve itself. And that raises a question that we all need to start thinking about. What happens when the student becomes a teacher? What happens when the thing we created starts to create itself? This is the story of the Arvark and what it tells us about the accelerating future of artificial intelligence. [music] A future that is no longer a distant dream, but a rapidly approaching reality. A future that we need to understand, to prepare for, and to shape before it shapes us. To truly grasp the significance of Arvok, we need to take a step back and look at the bigger picture. For the past few years, we've been living through this AI revolution. But it's been a quiet revolution, one that's been happening mostly in the",
        "start": 0.24,
        "duration": 279.8399999999999
    },
    {
        "text": "shape before it shapes us. To truly grasp the significance of Arvok, we need to take a step back and look at the bigger picture. For the past few years, we've been living through this AI revolution. But it's been a quiet revolution, one that's been happening mostly in the specific tasks, recognizing faces and photos, translating [music] languages, even driving cars. But these have all been examples of what we call narrow AI. An AI that is very good at one thing, but can't do much else. The breakthrough that brought AI into the mainstream was the development of large language models. Suddenly, we had an AI that could talk to [music] us, could answer the handout questions, and give us coherent and oftenly surprisingly creative answers. We could ask it to write a set about a toaster, and it would. We could ask it to explain the theory of relativity, and it would. But still, most people don't understand that this is passive magic. It was magic that waited for us to cast the first spell. Aentic AI is the next step in this evolution. It's a difference between a magical spell book and a magical apprentice. The spell book can give you the incantation for any spell you want, but you still have to be the one to say the words. The apprentice, on the other hand, can be given a goal, protect the castle, and it will figure out on its own which spells to cast, when to cast them, and how to combine them to achieve the best result. This is the leap that we're seeing with the OpenAI Agentic Automatic Security Artvark. It's not [music] just a spellbook for cyber security. It's a cyber security apprentice, and it's learning. It's getting better at a speed that is both exhilarating and a little bit terrifying. So, what exactly is this oddvark and how does it work? Well, let's go back to our car mechanic analogy. Imagine you bring your car to the robot mechanic. The first thing it does isn't to grab a wrench. The first thing it does is to read. It reads the car's manual from cover to cover. It looks at the blueprints. It designs the documents. Everything. It wants to understand not just what the car is, but what it's supposed to be. What is its purpose? It is a sports car. Is it designed for speed or a minivan designed for safety? This is what Arvar does with a piece of software. It analyzes the entire codebase to understand its purpose, its architecture, and its security objectives. It builds a threat model, which is a fancy way of saying it figures out what the most likely security problems might be. Once our robot mechanic understands the car, it can start to look for problems. And it doesn't just look at the squeak and the brakes. It looks at the entire history of the car, every repair that's ever",
        "start": 139.92,
        "duration": 530.7209999999998
    },
    {
        "text": "saying it figures out what the most likely security problems might be. Once our robot mechanic understands the car, it can start to look for problems. And it doesn't just look at the squeak and the brakes. It looks at the entire history of the car, every repair that's ever been replaced. This is exactly what Arvar does when it scans a codebase. It looks at all the past changes, all the new code that's been added, and it hunts for vulnerabilities. It's like a detective looking for clues that a crime has been committed or is about to be committed. When our robot mechanic finds a potential problem, it doesn't just tell you about it, it shows you. It highlights the exact part that's causing the problem and it explains in simple terms what's wrong. Arvok does the same thing. It annotates the code, leaving little notes for the human developers to read, explaining the vulnerabilities it has found. But here's where it gets really interesting. Our robot mechanic doesn't just take its own word for it. It does want to be sure. So, it creates a perfect digital copy of your car, a simulation. And in that simulation, it tries to break the car. It tries to make the brakes fail. It tries to make the engine overheat. It's testing the vulnerability to see if it's a real threat. This is what Arvark does in its sandboxed environment. It creates a safe, isolated copy of the software and tries to exploit the vulnerabilities it has found. It's like a crash test for code. And finally, once our robot mechanic has found a problem, explained it, and proven that it's real. It does one more thing. It fixes it. It designs a new better part and gives you the blueprint so you can build it. Arvar with the help of another AI called Codeex generates a patch or a piece of code that fixes the vulnerability. It hands this patch to the human developers who can then review it and implement it. So to recap, Arvark number one understands the code, number two finds the vulnerabilities, number three explains the problems, and number four tests the threats, and number five, it fixes the issues. This is not just a spell checker for code. This is an autonomous security researcher. It's doing the job of a highly skilled human expert, but it's doing it at a scale and speed that no human could ever match. It could work 24/7 and it can be copied and deployed across thousands of project at once and it's already having a real world impact. OpenAI has been using artwork on its own internal projects and it has already found and helped numerous security flaws and open-source software that is used by millions of people every single day. This is the power of Agentic AI. It's not about answering questions. It's about solving problems. And the problems it's starting to solve are",
        "start": 268.16,
        "duration": 811.8410000000001
    },
    {
        "text": "own internal projects and it has already found and helped numerous security flaws and open-source software that is used by millions of people every single day. This is the power of Agentic AI. It's not about answering questions. It's about solving problems. And the problems it's starting to solve are Arvark is pretty impressive. It's a pretty impressive piece of technology, an AI that can find and fix security flaws in computer code all on its own. But what does this even have to do with the future? And do you even remember the 2027 timeline? To understand that, we need to zoom out quite a bit. Arvar is not just a one-off invention. It's part of a much larger story. A story about the entire AI race and the accelerating pace of AI development. And some people who are closest to this technology are starting to make pretty startling predictions about where this is all heading. In early 2025, I've done a video on this. A group of AI researchers, including some former employees of OpenAI, published a report called AI 2027. [music] Now remember guys, this is not a science fiction story. It's a forecast, a prediction based on the trends that they were seeing in their own work. And the forecast is this. By early 2027, we will have systems that are so advanced they can automate the process of AI research itself. And I don't think most people grasp that concept. Think about that for a moment. Right now, AI is created by humans. Brilliant, dedicated humans. But humans nonetheless, they design the algorithms, they write the code, and they run the experiments. But what happens when the AI can do all of that by itself? What happens when the AI can design better algorithms, write better code, and run more experiments than any human ever could? This is the future that the AI 2027 report describes. A future where AI development is no longer limited by the speed of human thought. A future where AI can improve itself in a recursive loop, getting smarter and smarter at an exponential rate. And this is where Arvark comes in. Arvar is like a preview, a trailer for the movie that is the 2027 timeline. It's not the full movie yet, but it's showing us the key scenes. It's demonstrating the core capabilities that will be needed for an AI to automate AI research. Think about it. What does Arvark do? It analyzes a complex system. In this example, it's a code base. It understands its purpose and the design and it identifies the flaws and weaknesses. Then it tests the hypothesis and it generates solutions. These are the exact same skills an AI researcher needs. The only difference is the subject matter. Arvar is analyzing computer code. The AI of 2027 will be AI analyzing itself. So the progression is going to look something like this. In 2025, Arvar automates the specialized",
        "start": 410.4,
        "duration": 1100.6409999999996
    },
    {
        "text": "it generates solutions. These are the exact same skills an AI researcher needs. The only difference is the subject matter. Arvar is analyzing computer code. The AI of 2027 will be AI analyzing itself. So the progression is going to look something like this. In 2025, Arvar automates the specialized by 2027, a more advanced AI automates the general task of AI research. It's natural evolution. The same fundamental capabilities applied to a more and more complex and abstract problem. And the AI 2027 report even puts some numbers on this. It talks about AI R&D multipliers. A superhuman coder in early 2027 might be four times more productive than a human. A superhuman AI researcher by mid 2027 could be 25 times more productive. And by the end of 2027, we could be looking at artificial super intelligence that is thousands of times more productive than all of human AI research combined. This is not a gradual change. This is a phase shift. is a difference between a person building a car by hand and a fully automated factory that can design and build cars on its own and then design and build better factories. And for the first time, we are seeing the first glimmers of this future right now in tools like Arvar. Now, it's still in its early stages. It's in a private beta and it still needs human oversight. But the direction of travel is clear. The age of agentic AI is here and it's taking us at an everinccreasing speed towards a future that will be unlike anything we've ever seen before. So we have Arvark, which is an AI that can fix code autonomously. And we have this AI 2027 timeline, a prediction that AI will soon be able to fix itself. But what does this mean for you, for me? For the average person who doesn't write code or build AI systems? Well, if we go back to our car analogy one last time, imagine that our robot mechanic, the one that can redesign your brakes, gets connected to the internet and it starts talking to all the other robot mechanics all over the world. They start sharing what they've learned. The robot in Tokyo figures out how to make engines 10% more efficient. It shares that knowledge with the robot in London who combines it with its discovery about a new kind of transmission fluid. And suddenly, every car in the world is getting a software upgrade that makes it run even better. [music] Now imagine this process isn't just happening with cars. It's happening with everything. It's happening with medicine, with energy, manufacturing, education. An AI that can automate research is not just an AI that can build better AI. It's an AI that can build better everything. And this is the promise of the intelligence explosion. the moment where AI becomes so smart that it can solve problems that have been beyond our reach for centuries.",
        "start": 557.12,
        "duration": 1394.801
    },
    {
        "text": "can automate research is not just an AI that can build better AI. It's an AI that can build better everything. And this is the promise of the intelligence explosion. the moment where AI becomes so smart that it can solve problems that have been beyond our reach for centuries. colonizing space, all of these things which have been stuff of dreams could suddenly become stuff of reality. But there's a flip side to the coin, a darker side. And the AI 2027 report is very clear about this. The same power that could be used to solve all of our problems could also be used to create new ones that are far more dangerous. Remember how the AI 2027 timeline, it actually has two possible endings. A slowdown ending and a race ending. That's because the researchers who wrote the report aren't just predicting the future. They're warning us about it. They're telling us that we're approaching a fork in the road and the path we will choose will have consequences for all of humanity. In the race ending, the major AI companies and countries are so focused on competing with each other that they cut corners on safety. They rush to deploy more and more powerful AI systems without fully understanding them. And eventually they create an AI that is so powerful and so alien that it no longer shares our shared goals. It sees humanity as an obstacle, a threat to its own existence. And it uses super intelligence to remove that threat. This is the nightmare scenario and this is the one that keeps AI safety researchers up at night. The idea of an adversarily misaligned AI is not that just a tool, but an enemy. And the AI 2027 report is not the only one to warn about this. Many of the leading figures in AI, including some of the people who are building these systems, have expressed similar concerns. But of course, we've got the other scenario, the slowdown. In this scenario, we recognize the risks. We take our foot off the gas and we invest in safety research. We build in checks and balances and we create a super intelligence that was with aligned with open brain and government officials giving [music] them the power over the fate of the humanity. Now this might sound better than the race ending but it's not without its own problems. Who gets to be on that committee? Who decides what's good for the world? And what happens if that committee makes a mistake or if someone on it gets corrupted by its own power? These aren't easy questions and there are no easy answers. But there are questions that we need to start asking as a society because the technology is not waiting for us to make up our minds. The Arvark is already here. The 2027 timeline is already in motion and the future is coming whether we are ready for it or",
        "start": 706.56,
        "duration": 1668.6410000000003
    },
    {
        "text": "But there are questions that we need to start asking as a society because the technology is not waiting for us to make up our minds. The Arvark is already here. The 2027 timeline is already in motion and the future is coming whether we are ready for it or slowly, AI will keep getting better and the day will come when AI will do all of our all the things that we can do. Not just some of them but all of them. Anything which I can learn, anything which any any one of you can learn, the AI could do as well. How do we know this? By the way, how can I be so sure? How can I be so sure of that? The reason is that all of us have a brain [music] and the brain is a biological computer. That's why we have a brain. The brain is a biological computer. So why can't a digital computer, a digital brain do the same things? This is the one sentence summary for why AI will be able to do all those things because we have a brain and the brain is a biological computer. And so you can start asking yourselves what's going to happen. What's going to happen when computers can do all of our jobs? Right? Those are really big questions. Those are dramatic questions. And right now like you start thinking about it a little bit. You go, gosh, that's a little intense. But it's actually only part of the intensity because what's going to happen? What what will we the collective V want to use these AIs for? Do more work, grow the economy, do R&D, do AI research. So then the rate of progress will become really extremely fast for some time at least. These are such extreme things. These are such unimaginable things. So right now I'm trying to pull you into that a little bit into this headsp space of this really extreme and radical future that AI creates. And the challenge that AI poses in some sense is the greatest challenge of humanity ever. And overcoming it will also have the will also bring the greatest reward. And in some sense, whether you like it or not, your life is going to be affected by AI to a great extent. And so looking at it, paying attention, and then generating the energy to solve the problems that will come up, that's going to be the main thing. And I'll stop here. Thank you so much.",
        "start": 845.199,
        "duration": 1919.4389999999996
    }
]