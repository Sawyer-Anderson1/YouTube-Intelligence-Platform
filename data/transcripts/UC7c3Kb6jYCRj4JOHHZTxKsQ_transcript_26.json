[
    {
        "text": " Gemini 3 is here and my goodness, it was worth the wait. It is an incredible model. And not only that, Google basically built it into every product and service they offer. Google launched Gemini 3, Gemini 3 Pro Preview, and Gemini 3 Deep Think. And let's start with the benchmarks because they absolutely blow the other Frontier models out of the water. Here's Humanity's last exam. 37.5% with no tools and 45.8% with code execution and search. That is as compared to Gemini 2.5 Pro at 21%, but that's an older model. Here's Cloud Sonnet 4.5 at 13% and GBT 5.1 at 26.5%. Here's Arc AGI 2 31% versus 413 and 17 respectively for their competitor models. Amy 2025 aced it 100% with code execution and the only benchmark that they did not get number one on SWEBench verified and of course that went to Claude Sonnet 4.5 at 77.2 but closely following Gemini 3 Pro 76.2% 2%. And they also did incredibly well on vending bench. Remember, vending bench is a benchmark in which the model controls a vending machine. It has to plan out how to make the most money by stocking products, by making sure it has the right products for the right customers. And its net worth was $5,478.16 where second place Cloud Sonic 4.5 at 3,800. and Box.com, the sponsor of today's video, ran their own benchmark on the ability to extract insights from documents and use those insights to complete multi-step logic and reasoning problems. So, here is Gemini 2.5 Pro versus Gemini 3 Pro. Gemini 3 Pro is in yellow. And for the full data set, we had a 22 point jump in performance versus Gemini 2.5 Pro. So, here it is, 63% versus 85%. And for the industry subsets, healthcare and life sciences 45 to94, media and entertainment 47 to 92, and financial services 51 to 60. But what does that benchmark actually mean for you? Well, of course, Box.com all about enterprise use cases. And so this is really where Gemini 3 excelled. So this new benchmark by Box focus on complex multi-step reasoning in addition to extraction eval. It highlights complex task automation. In this eval, we ask the models to analyze multiple documents and solve complicated problem sets on the unstructured data that resemble what a person may do within their daily workflows. So keep that in mind when you're seeing this massive jump from Gemini 2.5 Pro to Gemini 3. So you can get started with Gemini 3 on Box today with Box AI Studio or build on top of it in the Box API. We use Box at my company. I suggest you use it at yours. Give it a try. They've been a fantastic partner. And let's continue on the benchmarks. Google has also released Gemini 3 Deep Think. It is exactly what it sounds like. It is more tokens spent in the thinking phase. Thus, it performs better. Let me show you. So, here's",
        "start": 0.16,
        "duration": 385.9180000000002
    },
    {
        "text": "yours. Give it a try. They've been a fantastic partner. And let's continue on the benchmarks. Google has also released Gemini 3 Deep Think. It is exactly what it sounds like. It is more tokens spent in the thinking phase. Thus, it performs better. Let me show you. So, here's reasoning and knowledge benchmark, and it scores a 41% versus 37.5 for Gemini 3 Pro. We have Claude Sonnet 4.5 down at 13%, GPT5 Pro at 30%, and GPT 5.1 at 26.5%. Really a substantial improvement on these benchmarks. Here's GPQA, the Scientific Knowledge benchmark, coming in at number one, 93.8%. Number two, of course, Gemini 3 Pro, and then the GPT5 family of models coming in third and fourth. But here's really where it stands out. Arc AGI2 visual reasoning puzzles. I've covered this a bunch on my channel. Here it is again. It gives you an input and an output kind of a transformation puzzle and then it gives you another one and you have to figure out what the transformation is. It is the best implementation of seeing if a model can actually learn and generalize from that learning. This is the most important thing for determining whether it is generalized intelligence. And Gemini 3 performs incredibly well. Look at this. We have Gemini 3 Deepthink at 45.1% as compared to GPT 5.1 17%. GBT 5 Pro 15% Claude Sonnet 4.5 13.6%. And look at the relative improvement from Gemini 2.5 Pro, their last frontier model. A massive 10x improvement. and it supports multiple modalities much like many other frontier models, but it does do one thing very special. I'll get to that in a second. So, it supports text, images, video, audio, and code. And the important one, the unique one is video. Coming in at 1 million input tokens, it is really good at understanding video. And it's not just looking at the transcript. It is literally looking frame by frame at the video unlike any other model that I have seen to date. It can load a full YouTube video and understand it frame by frame. You can ask it questions about things in the actual video. And I use this all the time for helping me create chapter markers for my YouTube videos. In fact, let me just show you it in action. So, here's a link to my last YouTube video. I simply paste it in and it immediately starts loading it. Obviously, because Google owns YouTube, they also own Gemini and AI Studio, all of these things just seamlessly work together. So, I don't have to download the video, upload the video, although I could. I simply just put the link in and it extracts it. 111,000 tokens, but of course, we have plenty to work with, and we can just start asking it questions. So, I asked it to describe the frame at 3 minutes. The frame at 3 minutes features a split screen layout. On the",
        "start": 195.599,
        "duration": 734.6400000000002
    },
    {
        "text": "put the link in and it extracts it. 111,000 tokens, but of course, we have plenty to work with, and we can just start asking it questions. So, I asked it to describe the frame at 3 minutes. The frame at 3 minutes features a split screen layout. On the short curly hair wearing a light blue button-down shirt, is speaking into a microphone. And on the left side, there's a graphic displaying a snippet of text from a report likely the anthropic paper being discussed. The text is clearly legible and reads and then it puts it there. So, there's me on the right side of the screen with a blue button-down shirt, of course. Yes, I have curly hair. And here is the anthropic paper that it described. And now let's talk about Google search because that seems like the biggest change. On day zero of the Gemini 3 launch, it is now available in AI mode in Google search and it's incredible. It actually dynamically generates user interfaces based on your query. Look at this. So here we have a paper. We turn on AI mode's thinking mode. We drop the paper in and we can ask a question. So, it's thinking and it will actually generate a search result page with a dynamic UI generated. And so, that's what we're seeing here. This was written by Gemini 3. So, this part of Google search did not exist. And now it does. And now, obviously, this is only going to appear in AI mode, but I think sooner than we all realize, we are going to start seeing dynamically generated Google search pages for the vast majority of people who use Google search. custom search results more so than we've ever seen with traditional search products. And that's not it. They also launched anti-gravity, which is their own VS Code fork, a brand new aentic coding platform competing with cursor, with windsurf, with replet, with factory. This is their own vibe coding platform. And here it is. Yes, it looks very familiar. Yes, it is a VS Code fork and it supports not only Gemini models, but basically any model that you want, including GPTOSS, the open source model from OpenAI and the Sonnet family of models from Anthropic. But of course, here's Gemini 3 Pro High. That's what we'll be testing. Video coming soon. All right, now back to Gemini 3 again. It is especially good at long horizon planning as shown by the vending bench to benchmark. And remember, the vending bench benchmark tasks AI to control a vending machine that plans the inventory, understands what people are buying, what people aren't buying, knows when to refill the inventory, and the purpose of this benchmark is to test these AI systems in realworld economic environments. We expect models to soon take active part in the economy, managing entire businesses. But to do so, they have to stay coherent and efficient over very long time horizons.",
        "start": 372.4,
        "duration": 1067.52
    },
    {
        "text": "to refill the inventory, and the purpose of this benchmark is to test these AI systems in realworld economic environments. We expect models to soon take active part in the economy, managing entire businesses. But to do so, they have to stay coherent and efficient over very long time horizons. about. And Gemini 3 did incredibly well. Look at this. The blue line is Gemini 3. And its net worth over time reached over $5,000. And over 1 year we see that Gemini 3 is number one with number two being Claude Sonnet 4.5 and kind of down here GPT 5.1 and a massive improvement on Gemini 2.5 Pro which is way down at the bottom over here. Basically plateaued and starting to lose money over time. But long horizon, look at that. After one year, it's still going up. And that's not it. And I feel like I said this multiple times in the video, but that's not it. Gemini 3 can now complete tasks on your behalf in the Gemini Agent product. So the newly updated Gemini app comes with Gemini 3, of course, but it now also has the Gemini agent capability, which is the ability for this agent to complete tasks, real tasks on your behalf. And just like in AI mode, it creates views. It creates UIs dynamically based on what you're asking it to do, but also it can complete tasks as I said. Let me show you that. So here it is. So you go to tools, you select agent, which is still a lab feature, organize my inbox. So obviously it has access to your Gmail. Here it's putting together a plan. It's retrieving all of your unread emails. Then it puts together a dynamic view for you to basically review the emails and perform actions in bulk. And so it gives you a bunch of suggestions based on your emails on what you should do. You can accept all. You can go through each reject, accept each one individually. Here it can actually write emails for you, email responses that are contextual based on your conversation in that email thread. So very, very impressive. This is something that I haven't had a lot of time to play with yet, but I will very soon starting this week. And last, Google also published their model card. Although, of course, there's not a ton of information in it, but we have a few new details that we can find. So, number one, this model is not a modification or fine-tune of a prior model. This is a brand new foundation model, Gemini 3. the inputs, text, images, audio, video files, and a token context window of up to a million and output tokens of 64,000. It is a sparse mixture of experts model built on Google's own custom TPU architecture, not only for pre-training, but also for inference. Again, a huge differentiator, a huge moat for Google",
        "start": 540.48,
        "duration": 1376.8809999999999
    },
    {
        "text": "audio, video files, and a token context window of up to a million and output tokens of 64,000. It is a sparse mixture of experts model built on Google's own custom TPU architecture, not only for pre-training, but also for inference. Again, a huge differentiator, a huge moat for Google TPU chips that run AI incredibly well. So, that's it for today. Check out Gemini 3. I'm going to be testing it. Make sure you're subscribed. So, when I drop that testing video, you get notified. If you enjoyed this video, please consider giving a like and subscribe. and I'll see you in the next",
        "start": 698.0,
        "duration": 1409.041
    }
]