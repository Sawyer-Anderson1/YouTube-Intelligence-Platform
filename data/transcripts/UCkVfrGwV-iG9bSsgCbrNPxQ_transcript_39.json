[
    {
        "text": " Amazon is making some incredible new AI glasses, and nobody's talking about it. So, picture this. You're wearing regular looking glasses, but these bad boys are secretly showing you directions, scanning your packages, warning you about that dog that's about to charge at you, and basically making you feel like you're living in a sci-fi movie. No, I'm not talking about some concept from Iron Man. I'm talking about what Amazon just dropped on us last month. And this is the kicker. This is not a fancy consumer toy that will cost you a kidney. Amazon is actually rolling these out to delivery drivers first. Yeah, the people bringing your packages are about to look like they're from the future. But before you think this is all just about making deliveries faster, let me tell you how this technology is about to change [music] everything about how we interact with the world. It's pretty crazy. Like when I was researching this video, I couldn't believe the stuff I found. So what are these things actually? Well, let's break this down. Okay, Amazon's new AI glasses in plain English. No tech bro, no jargon. So think about this for a second. When you're doing something, anything, you need to look at your phone, right? checking directions, phone, reading instructions. You looked down at your phone. Who's calling me? Oh, I got to look at my phone. Your phone has become a nuisance. It's become this thing you're constantly pulling out of your pocket, looking down at, then looking back up, then looking down at again. It's like this weird dance that we do 50 times a day. Now, what if all of that information we seek appeared in front of your eyes like you're just looking straight ahead, living your life, and then boom, there's the information you need right in your field of view. That's basically what these glasses do. Amazon calls these glasses smart delivery glasses, but that name doesn't really capture how well the tech is. These things pack cameras, artificial intelligence, [music] computer vision, GPS navigation, and heads-up display all into something that looks pretty much like regular glasses. Well, maybe slightly chunkier than regular glasses, but we'll get to that. Here's how they work in the real world. An Amazon driver wakes up, puts on their glasses, which by the way can actually have prescription lenses if they need them. Amazon actually thought of that, and heads to their delivery van. The moment they park at a delivery stop, the glasses automatically wake up. No buttons, no Hey Alexa, no nothing. The glasses know they're at a delivery location. And then the display lights up right in their vision. Not blocking what they see, but just adding to it. It's called augmented reality or AR, which is just a fancy way of saying adding computer stuff to real life. The display shows them exactly which packages to grab from the van. Like it will",
        "start": 0.08,
        "duration": 282.6400000000001
    },
    {
        "text": "up right in their vision. Not blocking what they see, but just adding to it. It's called augmented reality or AR, which is just a fancy way of saying adding computer stuff to real life. The display shows them exactly which packages to grab from the van. Like it will Once they grab the packages, the glasses guide them to the front with turnbyturn directions. Not driving directions, walking directions. Step by step, like walk 20 ft forward, turn left at the garden gnome. Watch out for that step. The door is right there. All of this appears in their vision while they're walking. They never have to look down at a phone. But wait, it actually gets even better. These glasses use AI to scan the environment. They can detect hazards like, \"Hey, there's a sprinkler you're about to walk into,\" or, \"Cevil, there's a dog in the yard, and they can even help drivers navigate those nightmare apartment complexes where every building looks the same, and apartment 3C is somehow in building 7.\" Those glasses will guide you through the maze. Now, when they get to the door, the glasses can scan the package barcode hands-free, take proof of delivery through a photo, and then guide them back to the van for the next delivery. And all of this happens without the driver ever pulling out their phone. Their hands stay free to carry packages, open gates, whatever. And their eyes stay focused on where they're walking instead of bouncing between a screen and the ground. Now, let's actually talk about the hardware for a second. These aren't some clunky VR headsets. They're glasses. You'll walk past someone wearing them and maybe not even notice anything weird. Except maybe they look a tiny bit more substantial than normal glasses. They've got tiny cameras embedded in them for the computer vision stuff. They've got a small display that projects information right in your field of view. And Amazon uses something called headsup display technology, which is similar to what fighter pilots use. They've got microphone and tiny speakers built into the arms of glasses. Although you're not listening to music during deliveries, this is pretty much all business. Now, here's something really cool. These glasses connect to a small controller that clips onto the delivery vest. And this controller has all the battery power, the computing guts, and get this, even an emergency button. If a driver gets into trouble, they can hit that button and immediately call for help. The battery is swappable, too. So, if drivers work all day without worrying about running out of juice, and Amazon even made the lenses adjustable. They support prescription lenses, and they have transitional lenses that automatically darken in bright sunlight. So, if you're delivering packages in Florida at noon, you're not going to be blinded. if you need glasses to see anyway, and you don't need contacts or risk bonking into mailboxes. The whole",
        "start": 141.36,
        "duration": 562.5600000000001
    },
    {
        "text": "adjustable. They support prescription lenses, and they have transitional lenses that automatically darken in bright sunlight. So, if you're delivering packages in Florida at noon, you're not going to be blinded. if you need glasses to see anyway, and you don't need contacts or risk bonking into mailboxes. The whole hundreds of actual delivery drivers. Amazon didn't just cook this up in some lab and throw it at workers. They had drivers test early versions and give feedback about everything from comfort to how clear the display was to whether the glasses stayed put when drivers bent over to grab packages. One driver who actually tested them said something interesting. He said that I felt safer the whole time because glasses have the info right in my field of view. Instead of having to look down at my phone, you can keep your eyes forward and look past the display. You're always focused on what's ahead. And that quote sounds super super simple, but it's kind of big when you think about it. Think about how many times you've almost walked into something because you were looking at your phone. Now imagine doing that 50, 60 times a day while carrying packages and trying to hit tight delivery windows. That's the reality for delivery drivers and the glasses solve that problem. Why Amazon built these? Now you might be wondering, so why did Amazon build them and why are they giving them to delivery drivers instead of giving them to consumers who actually would love tech toys? Well, the answer is pretty straightforward. Time and money. Amazon delivers millions of packages every single day. We're talking an absolutely insane scale of logistics. In 2025, Amazon's delivery network handles over 10 million packages daily in just the United States. Every second saved on every delivery adds up to massive time savings across the entire operation. [music] If we even do some basic napkin math, if a delivery driver makes 200 stops a day, which is pretty normal, and these glasses save even 10 seconds per stop, that's over 33 minutes saved per driver per day. and multiply that thousands of drivers and suddenly Amazon is saving thousands of labor hours every single day. But it's not just about speed. It's actually a little bit about accuracy. You see, when drivers have to juggle their phone and packages, mistakes happen. You get wrong packages delivered to wrong houses. [music] You get packages dropped in the wrong spot. You get drivers walking into hazards because they were looking at their phones instead of where they were going. And all of these tiny mistakes cost Amazon money in redely, customer service calls, and potentially injury claims if a driver manages to get hurt. The glasses reduce all of that. [music] AI guides the drivers to the exact location, warns about the hazards, and actually confirms they've scanned the right package before they leave at a door. And there's actually another",
        "start": 283.28,
        "duration": 838.4800000000004
    },
    {
        "text": "service calls, and potentially injury claims if a driver manages to get hurt. The glasses reduce all of that. [music] AI guides the drivers to the exact location, warns about the hazards, and actually confirms they've scanned the right package before they leave at a door. And there's actually another drivers. This is the perfect testing ground. These drivers work in every possible environment. city apartments, suburban houses, rural areas, sketchy neighborhoods, mansions, you name it. They deal with every weather condition, every lighting situation, every type of obstacle you can imagine. And if the glasses work for delivery drivers, they'll work for pretty much anyone. Amazon gets to test and refine the technology and the most demanding real world conditions possible before eventually bringing it to regular consumers. Now, make no mistake, consumer versions are coming. Amazon already sells smart glasses called Echo Frames that let you talk to Alexa and listen to audio. And these glasses cost around $270, but don't have any display cameras. They're basically Bluetooth headphones built into frames. Now, the delivery driver glasses are way more advanced. Once Amazon works out all the kinks and gets the manufacturing cost down, you can bet they release a consumer version. Imagine walking around with these things, getting directions to restaurants, having information about stores appear as you walk by them, getting real-time translations of foreign signs, or even having your calendar and messages appear in your vision. Before that ever happens, Amazon needs to nail this technology and and the delivery drivers are basically the perfect guinea pigs. I mean, valued partners in innovation. How the tech actually works. So, okay, so it's nerdy time, and I promise I'm going to actually keep this understandable. So, these glasses combine several different technologies that are all working together in real time. It's actually pretty impressive when you think about what's happening under the hood. First up is computer vision. So, these glasses, they have the ability to see the world. The cameras aren't just recording video. They're analyzing it constantly. Like, the AI has been trained to recognize specific things, packages, barcodes, house numbers, hazards, pets, stairs, obstacles, all sorts of stuff. And when you're wearing the glasses, the cameras are capturing everything you're looking at. That video feed goes to an AI, probably in that controller vest thing, which analyze it in real time and identifies important objects. It's like having a really smart assistant who's watching the same thing you are and pointing out all the important details. All of this analysis happens in fractions of a second. And the AI has to be fast because, well, you're moving. The world is moving, lighting is moving, changing stuff is happening. And if the AI was slow, the information would be useless. You'd already be past the hazard by the time it warned you. Second, we have augmented reality display. The glasses use something called a heads up display, which is borrowed from military and",
        "start": 423.84,
        "duration": 1131.3609999999994
    },
    {
        "text": "is moving, changing stuff is happening. And if the AI was slow, the information would be useless. You'd already be past the hazard by the time it warned you. Second, we have augmented reality display. The glasses use something called a heads up display, which is borrowed from military and had this for decades. Important information projected onto their helmet visors or windcreens, so that they can see flight data without looking down at instruments. Now, Amazon has adapted this for walking around. The display projects information through your line of sight, but it's designed so that you can see through it to the real world. It's not blocking your vision. is actually adding to it. And this is actually pretty tricky to get right. The display needs to be bright enough to see in sunlight, but not so bright that it's distracting. It needs to show information without cluttering your whole field of view. And it needs to update instantly as you move as the AI identifies new thing. And Amazon uses what's called optical waveguide technology. Don't worry about the specifics, but it basically just means that the display appears to float in space in front of you. It's like a hologram from Star Wars, except it's not really a hologram. It's more like carefully controlled light that only you can see. And third, we've got GPS and geospatial mapping. The glasses know exactly where you are down to a few feet. They use GPS, but also something more advanced called geospatial technology. And this is Amazon's proprietary system that maps the world in incredible detail. Amazon doesn't just know addresses. They know exactly where front doors are, how to navigate driveways, which path to take through an apartment complex, where hazards are likely to be. And they've built this database over years of deliveries. Now, that information is fed directly into the glasses. When the glasses give you walking directions, they're using this detailed map combined with your real-time location. Walk forward, turn 30 ft, turn at left at the mailbox, the door is on your right. This way is more precise than your car's GPS because, well, it has to be. You're walking and you're not driving. A 10-ft error in a car's GPS is actually not that big of a deal. But a 10-ft error when you're walking could send you into the wrong house. And fourth is the AI integration. The AI is the brain that ties everything together. It's processing the camera feed, making the decisions about what to show you, predicting what you'll need next, adjusting the display based on lighting conditions, and learning from every delivery. Now, here's what it gets, you know, super interesting. AI improves over time. Every delivery teaches something. It learns which types of hazards are most common. It learns which apartment complex layouts confuse people. And it learns which dogs are actually friendly despite looking somewhat scary. Well, maybe not that",
        "start": 571.92,
        "duration": 1400.9619999999986
    },
    {
        "text": "Now, here's what it gets, you know, super interesting. AI improves over time. Every delivery teaches something. It learns which types of hazards are most common. It learns which apartment complex layouts confuse people. And it learns which dogs are actually friendly despite looking somewhat scary. Well, maybe not that It kind of just looks at everything. Now, Amazon mentioned future versions of the glasses will have even smarter features. Like the AI might notice you're delivering a package to apartment 3C, but you're walking to apartment 3B and it might say, \"Hey, this is the wrong door.\" Or it might notice that you're walking in low light and automatically adjust the lens tint. Or it might detect that there's a pet in the yard before you touch the gate. Now, this is all powered by machine learning, which means the system is going to get smarter the more people use it. and every driver's experience feeds back into the central AI, making it better for everyone. And now, of course, number five, the human interface. So, all of this technology would be useless if it was annoying to use. Amazon has spent quite a lot of money making sure the glasses felt natural. The display doesn't blast information at you constantly. It's context aware, meaning it only shows you what you need to know when you need to know it. If you're driving to the next stop, then the display is off. If you're parking the van, then it automatically activates. If you're at the front door, then it shows you the delivery confirmation. And if you're walking back to the band, it shows you the next address. And the glasses kind of have to be physically comfortable. Delivery drivers are going to be wearing these things for 8 to 10 hour shifts. And if they give you a headache, pinched your nose, or made your ears sore, then nobody's going to use them. Amazon tested dozens of different designs with actual drivers to find ones that worked all day long. So, what does this mean for the future? Well, Amazon has fancy glasses for their delivery drivers, but why should you care if you're not delivering packages? Well, think about it like this, guys. This is just the beginning. What Amazon's doing with delivery drivers is a preview for where all of us are headed with technology. Think about it. For the past 15 years, smartphones have been the device. Everyone has one. You're probably watching this video right now on one. We're all constantly looking down as these little rectangles in our hand. And don't get me wrong, smartphones are amazing, but they're also kind of a pain. You have to physically hold them. You have to look away from the world to use them. And they're kind of fragile. They die at inconvenient times. They're addictive in a way also that isn't great for us. You become those people walking around",
        "start": 709.36,
        "duration": 1633.3619999999978
    },
    {
        "text": "they're also kind of a pain. You have to physically hold them. You have to look away from the world to use them. And they're kind of fragile. They die at inconvenient times. They're addictive in a way also that isn't great for us. You become those people walking around Smart glasses actually solve a lot of those problems. The information comes at you instead of you having to go get it. And your hands stay free. Your eyes stay on the real world. You're not hunched over at a glowing rectangle. You're standing upright, engaged with your surroundings, just with extra information available when you need it. And this is actually what the tech industry has called ambient computing. technology that fades into the background of your life instead of demanding your constant attention. The computer is still helping you, but it's not at the center of your attention anymore. So, you have to understand this is going to change your life in the future. Think about when you're about to go grocery shopping. Imagine it. You're walking through the store and as you look at the products, information appears. This cereal is on sale. This brand has better reviews. You're allergic to an ingredient in this item and you bought this product last month and it reminds you that you didn't like this all without pulling up your phone. So, you just stop normally and the glasses enhance your experience. Imagine you're traveling in a foreign country. You're walking through Tokyo and you don't speak Japanese, but the signs automatically translate as you look at them. Restaurant menus appear in English in your vision and directions on your hotel guide you through the streets. Emergency phrases appear if you need them. The entire experience becomes less stressful and more accessible. I mean, imagine when you're driving, navigations appear on your actual windshield or in your glasses if you're wearing them. Hazard warning signs show up before you can even process what you're seeing. speed limits, directions, incoming calls, all visible without taking your eyes off the road. Now, remember guys, this isn't science fiction. This technology exists right now. The glasses are [music] working and Amazon proves that it works in real demanding conditions. And it's only a matter of time before consumer versions hit the market. I mean, we've already seen Meta's, you know, Ray-B band glasses that have cameras and AI built in. [music] And these cost around $300. They can take photos, record video, make calls, play music, and answer actual questions using Meta's AI. They don't have a full display like Amazon's delivery glasses yet, but Meta announced in September 2025 that display versions are coming. And Apple is rumored to be working on their own smart glasses, although they're being very secretive about it. Google tried this a decade ago with a Google Glass, but the technology wasn't ready. And I think now the tech world and social acceptance have",
        "start": 826.56,
        "duration": 1890.4019999999975
    },
    {
        "text": "that display versions are coming. And Apple is rumored to be working on their own smart glasses, although they're being very secretive about it. Google tried this a decade ago with a Google Glass, but the technology wasn't ready. And I think now the tech world and social acceptance have guys. Within the next 5 to 10 years, smart glasses will probably be as common as smartphones are today. They'll get cheaper, lighter, more stylish, and more capable. Eventually, they might replace smartphones entirely for a lot of toss.",
        "start": 958.0,
        "duration": 1914.8029999999976
    }
]