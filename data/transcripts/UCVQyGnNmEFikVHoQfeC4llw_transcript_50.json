[
    {
        "text": " [music] So imagine two massive cricket stadium, one in Bengaluru, one in Chennai. Now connected so perfectly that every player on both grounds plays as one single team. Depends which pavilion are they coming out from. Anyway, that's actually what Microsoft just did. The world's most valuable software company turned two data centers separated by 700 miles into one giant AI supercomput. Not a cloud region, not a cluster, a virtual super machine that behaves like a single system. And Microsoft didn't just announce this, it unveiled an entirely new class of AI infrastructure. Today's headline is simple. Microsoft launches the world's first AI superactory and it spans multiple states. So let us take a moment to actually absorb that now now that we have earlier this year Microsoft announced fairwater a special class of data centers purposebuilt for AI. Today they went further. Fairwater Wisconsin plus Fairwater Atlanta is equal to one AI superactory. And this unified system brings hundreds of thousands of Blackwell GPUs, 5 plus million optical connections inside a single site. 12,000 mi of new AI fiber connecting regions 800 Gbps GPU toGPU bandwidth twotory GPU racks to cut cable length closed loop liquid cooling with near zero water waste. This as we can clearly understand is a redesign of physics around AI compute and yes training jobs that took months now take weeks. In his post announcing fair water, Satya Nadella said this. Fairwater is our vision for a fungeible fleet infrastructure that can actually serve any workload anywhere with maximum performance and efficiency. Clearly for Microsoft, this is about making millions of GPUs behave as one organism. Nadella also revealed over 100,000 Nvidia GB300 GPUs coming online this quarter for inference fair water built for pre-training fine-tuning RL synthetic data generation. So all sites connected by a continent spanning AI van which basically is every gigawatt converted into maximum useful AI tokens. So it's a new philosophy. Not every gigawatt is created equal. But Microsoft wants every gigawatt to behave like one. What makes this different from traditional crowd? Well, here it is. A normal data center runs millions of small jobs. Fairwater runs one colossal job across continents. So in Microsoft's words, it's not one site training a model. It's actually a network of sites supporting a single job. End quote. Each site contributes to the same frontier model, the same training loop, the same compute graph, the same memory state. And this is model parallelism at a planetary scale. No hyperscaler has shown this publicly before. And you know what? Microsoft just did. Microsoft's AI superactory delivers rack scale NV link between 72 Blackwell GPUs, 1.8 8 TB per second GPU bandwidth per rack 14 plus TB pulled memory per GPU two-tier Ethernet backend sonic powered vendor neutral switching 140 kW per rack power density twotory architecture for low latency cable pl parts I'm sorry plus a closed loop cooling system that uses less water in",
        "start": 0.654,
        "duration": 508.81800000000004
    },
    {
        "text": "8 TB per second GPU bandwidth per rack 14 plus TB pulled memory per GPU two-tier Ethernet backend sonic powered vendor neutral switching 140 kW per rack power density twotory architecture for low latency cable pl parts I'm sorry plus a closed loop cooling system that uses less water in consume annually. This solves the biggest physics challenge in AI today which is distance, heat, bandwidth, latency, power density. So fairwater answers all of them at once. And here is the industry shockwave. Competitors are building too. Amazon's project rea 1200 acres 2.2 gaw. Google, multi-billion dollar TPU campuses, Meta, massive training grids, OpenAI, Anthropic, dedicated GPU cities. But you know what? Microsoft strategy is actually different. Turn every data center into part of one global AI fleet, fully elastic, fully funible, fully interconnected. Nadella puts it quite bluntly in his internal meetings, which is, \"We must 10x training capacity every 18 to 24 months.\" End quote. Fairwater is the infrastructure to hit that curve. Frontier AI is no longer trained in a building. It's trained across geographies because models aren't doubling. They're exploding. 100 trillion parameters, 200 trillion parameters, synthetic data regimes, reinforcement learning pipelines, multimodal active agents. A single data center can't handle the next decade. But a superactory spanning states can definitely do that and soon spanning continents. And here is of course the final take on front page. Microsoft hasn't just connected two data centers. It has connected two power grids, two regions, two GPU mega clusters, two training fabrics, two generations of AI systems into one elastic compute organism designed for trillion parameter intelligence, 700 miles apart, mind you, acting like one. This is not cloud as we mentioned. This is infrastructure for AGI. Yes, we said that. And it marks the beginning of a new era. Planet scale AI superactories. Not tomorrow, not in 5 years, today. Please do let us know what you think in the comments below. [music]",
        "start": 257.759,
        "duration": 803.7180000000003
    }
]