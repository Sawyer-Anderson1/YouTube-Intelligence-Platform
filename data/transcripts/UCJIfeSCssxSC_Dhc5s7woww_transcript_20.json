[
    {
        "text": "We should also say on the Opus 45 hype",
        "start": 2.879,
        "duration": 7.601
    },
    {
        "text": "there's the layer of uh something",
        "start": 7.2,
        "duration": 7.2
    },
    {
        "text": "being the darling of the X echo chamber",
        "start": 10.48,
        "duration": 6.719
    },
    {
        "text": "on Twitter echo chamber and the actual",
        "start": 14.4,
        "duration": 4.4
    },
    {
        "text": "amount of people that are using the",
        "start": 17.199,
        "duration": 3.84
    },
    {
        "text": "model I think it's probably fair to say",
        "start": 18.8,
        "duration": 5.04
    },
    {
        "text": "that IGBT and Gemini are focused on the",
        "start": 21.039,
        "duration": 6.0
    },
    {
        "text": "broad user base that just want to solve",
        "start": 23.84,
        "duration": 5.679
    },
    {
        "text": "problems in their daily lives and that",
        "start": 27.039,
        "duration": 5.52
    },
    {
        "text": "user base is gigantic So the hype about",
        "start": 29.519,
        "duration": 5.121
    },
    {
        "text": "the coding may not be represented the",
        "start": 32.559,
        "duration": 5.601
    },
    {
        "text": "actual used I would say also um a lot of",
        "start": 34.64,
        "duration": 5.599
    },
    {
        "text": "the usage patterns are like you said",
        "start": 38.16,
        "duration": 4.96
    },
    {
        "text": "name recognition brand uh and and stuff",
        "start": 40.239,
        "duration": 5.681
    },
    {
        "text": "but also muscle memory almost where um",
        "start": 43.12,
        "duration": 4.88
    },
    {
        "text": "you know like JPD has been around for a",
        "start": 45.92,
        "duration": 3.6
    },
    {
        "text": "long time people just got used to using",
        "start": 48.0,
        "duration": 3.039
    },
    {
        "text": "it and it's kind of like almost like a",
        "start": 49.52,
        "duration": 3.039
    },
    {
        "text": "flywheel they recommend it to other",
        "start": 51.039,
        "duration": 3.441
    },
    {
        "text": "users and that stuff One interesting",
        "start": 52.559,
        "duration": 4.961
    },
    {
        "text": "point is also the customization of LLMs.",
        "start": 54.48,
        "duration": 5.68
    },
    {
        "text": "For example CHP has a memory feature",
        "start": 57.52,
        "duration": 4.48
    },
    {
        "text": "right And so you may have a",
        "start": 60.16,
        "duration": 4.24
    },
    {
        "text": "subscription and you use it for personal",
        "start": 62.0,
        "duration": 3.76
    },
    {
        "text": "stuff but I don't know if you want to",
        "start": 64.4,
        "duration": 3.039
    },
    {
        "text": "use that same thing at work you know",
        "start": 65.76,
        "duration": 3.28
    },
    {
        "text": "because that's a boundary between",
        "start": 67.439,
        "duration": 3.04
    },
    {
        "text": "private and work If you're working at a",
        "start": 69.04,
        "duration": 3.04
    },
    {
        "text": "company they might not allow that or",
        "start": 70.479,
        "duration": 3.361
    },
    {
        "text": "you may not want that And I think",
        "start": 72.08,
        "duration": 3.52
    },
    {
        "text": "that's also an interesting point where",
        "start": 73.84,
        "duration": 3.2
    },
    {
        "text": "you might have multiple subscriptions",
        "start": 75.6,
        "duration": 4.48
    },
    {
        "text": "One one is just clean code it keeps has",
        "start": 77.04,
        "duration": 5.36
    },
    {
        "text": "nothing of your personal images that you",
        "start": 80.08,
        "duration": 3.84
    },
    {
        "text": "or hobby projects in there It's just",
        "start": 82.4,
        "duration": 2.88
    },
    {
        "text": "like the work thing and then the other",
        "start": 83.92,
        "duration": 3.28
    },
    {
        "text": "one is your personal thing So I think",
        "start": 85.28,
        "duration": 3.68
    },
    {
        "text": "that's also something where two",
        "start": 87.2,
        "duration": 3.52
    },
    {
        "text": "different use cases and it doesn't mean",
        "start": 88.96,
        "duration": 4.159
    },
    {
        "text": "you only have to have one It's it's I",
        "start": 90.72,
        "duration": 4.64
    },
    {
        "text": "think the future is also multiple ones",
        "start": 93.119,
        "duration": 4.721
    },
    {
        "text": "i What model do you think won 2025 and",
        "start": 95.36,
        "duration": 3.84
    },
    {
        "text": "what model do you think is going to win",
        "start": 97.84,
        "duration": 3.919
    },
    {
        "text": "26? I think in the context of a consumer",
        "start": 99.2,
        "duration": 4.48
    },
    {
        "text": "chat bots is a question of are you",
        "start": 101.759,
        "duration": 5.601
    },
    {
        "text": "willing to bet on Gemini over chat",
        "start": 103.68,
        "duration": 6.24
    },
    {
        "text": "which I would say in my gut feels like a",
        "start": 107.36,
        "duration": 5.039
    },
    {
        "text": "bit of a risky bet because open AAI has",
        "start": 109.92,
        "duration": 4.08
    },
    {
        "text": "been the incumbent and there's so many",
        "start": 112.399,
        "duration": 5.601
    },
    {
        "text": "benefits to that in teach I think the",
        "start": 114.0,
        "duration": 6.079
    },
    {
        "text": "momentum if you look at 2025 was on",
        "start": 118.0,
        "duration": 3.759
    },
    {
        "text": "Gemini's side but they were starting",
        "start": 120.079,
        "duration": 4.561
    },
    {
        "text": "from such a low point I think on RIP",
        "start": 121.759,
        "duration": 6.321
    },
    {
        "text": "Bard and these earlier attempts of of",
        "start": 124.64,
        "duration": 5.039
    },
    {
        "text": "getting started I",
        "start": 128.08,
        "duration": 3.36
    },
    {
        "text": "Huge credit for them for powering",
        "start": 129.679,
        "duration": 4.001
    },
    {
        "text": "through the organizational chaos to make",
        "start": 131.44,
        "duration": 4.48
    },
    {
        "text": "that happen But also it's hard to bet",
        "start": 133.68,
        "duration": 4.8
    },
    {
        "text": "against OpenAI because they always come",
        "start": 135.92,
        "duration": 5.36
    },
    {
        "text": "off as so chaotic But they're very good",
        "start": 138.48,
        "duration": 5.36
    },
    {
        "text": "at landing things And I think like",
        "start": 141.28,
        "duration": 4.16
    },
    {
        "text": "personally I have very mixed reviews of",
        "start": 143.84,
        "duration": 4.32
    },
    {
        "text": "GPT5, but it had to have saved them so",
        "start": 145.44,
        "duration": 5.04
    },
    {
        "text": "much money with the sideline feature",
        "start": 148.16,
        "duration": 4.079
    },
    {
        "text": "being a router where most users are no",
        "start": 150.48,
        "duration": 4.72
    },
    {
        "text": "longer charging like charging their GPU",
        "start": 152.239,
        "duration": 5.441
    },
    {
        "text": "costs as much So I think it's very hard",
        "start": 155.2,
        "duration": 5.36
    },
    {
        "text": "to dissociate the things that I like out",
        "start": 157.68,
        "duration": 4.48
    },
    {
        "text": "of models versus the things that are",
        "start": 160.56,
        "duration": 5.28
    },
    {
        "text": "going to actually be a general public",
        "start": 162.16,
        "duration": 4.719
    },
    {
        "text": "differentiator",
        "start": 165.84,
        "duration": 2.96
    },
    {
        "text": "i What do you think about 2026? Who's",
        "start": 166.879,
        "duration": 2.561
    },
    {
        "text": "going to win",
        "start": 168.8,
        "duration": 2.0
    },
    {
        "text": "i I'll say something even though it's",
        "start": 169.44,
        "duration": 2.96
    },
    {
        "text": "risky I will say that I think Gemini",
        "start": 170.8,
        "duration": 3.439
    },
    {
        "text": "will continue to take progress on chat",
        "start": 172.4,
        "duration": 3.839
    },
    {
        "text": "GPT. I think Google scale when both of",
        "start": 174.239,
        "duration": 4.321
    },
    {
        "text": "these are operating at such extreme",
        "start": 176.239,
        "duration": 4.64
    },
    {
        "text": "scales and like Google has the ability",
        "start": 178.56,
        "duration": 4.959
    },
    {
        "text": "to separate that research and product a",
        "start": 180.879,
        "duration": 3.761
    },
    {
        "text": "bit better where you hear so much about",
        "start": 183.519,
        "duration": 4.161
    },
    {
        "text": "open AI being chaotic operationally and",
        "start": 184.64,
        "duration": 4.56
    },
    {
        "text": "chasing the high impact thing which is a",
        "start": 187.68,
        "duration": 3.76
    },
    {
        "text": "very startup culture and then on the",
        "start": 189.2,
        "duration": 3.92
    },
    {
        "text": "software and enterprise side I think",
        "start": 191.44,
        "duration": 3.92
    },
    {
        "text": "anthropic will have continued to success",
        "start": 193.12,
        "duration": 5.039
    },
    {
        "text": "as they've again and again been set up",
        "start": 195.36,
        "duration": 4.959
    },
    {
        "text": "for that and obviously Google's cloud",
        "start": 198.159,
        "duration": 4.08
    },
    {
        "text": "has a lot of offerings but I think this",
        "start": 200.319,
        "duration": 3.761
    },
    {
        "text": "kind of like Gemini name brand is",
        "start": 202.239,
        "duration": 3.761
    },
    {
        "text": "important for them to build and and",
        "start": 204.08,
        "duration": 3.76
    },
    {
        "text": "Google's cloud will continue to do well",
        "start": 206.0,
        "duration": 4.56
    },
    {
        "text": "but that's kind of a more complex thing",
        "start": 207.84,
        "duration": 4.72
    },
    {
        "text": "to explain in the ecosystem because",
        "start": 210.56,
        "duration": 3.679
    },
    {
        "text": "that's competing with the likes of Azure",
        "start": 212.56,
        "duration": 3.92
    },
    {
        "text": "and AWS rather than on the model",
        "start": 214.239,
        "duration": 5.201
    },
    {
        "text": "provider side So infrastructure you",
        "start": 216.48,
        "duration": 5.92
    },
    {
        "text": "think TPUs give an advantage",
        "start": 219.44,
        "duration": 5.2
    },
    {
        "text": "i largely because the margin on NVIDIA",
        "start": 222.4,
        "duration": 5.119
    },
    {
        "text": "chips is insane and Google can develop",
        "start": 224.64,
        "duration": 4.72
    },
    {
        "text": "everything from top to bottom to fit",
        "start": 227.519,
        "duration": 4.241
    },
    {
        "text": "their stack and not have to pay this",
        "start": 229.36,
        "duration": 4.239
    },
    {
        "text": "margin and they've had a head start in",
        "start": 231.76,
        "duration": 3.36
    },
    {
        "text": "building data centers So all of these",
        "start": 233.599,
        "duration": 3.28
    },
    {
        "text": "things that have both high lead times",
        "start": 235.12,
        "duration": 4.08
    },
    {
        "text": "and very high margins on high costs",
        "start": 236.879,
        "duration": 4.161
    },
    {
        "text": "Google has just kind of a historical",
        "start": 239.2,
        "duration": 4.16
    },
    {
        "text": "advantage there And if there's going to",
        "start": 241.04,
        "duration": 4.08
    },
    {
        "text": "be a new paradigm it's most likely to",
        "start": 243.36,
        "duration": 3.519
    },
    {
        "text": "come from OpenAI where they're kind of",
        "start": 245.12,
        "duration": 3.679
    },
    {
        "text": "their research division again and again",
        "start": 246.879,
        "duration": 4.801
    },
    {
        "text": "has kind of shown this ability to land a",
        "start": 248.799,
        "duration": 5.041
    },
    {
        "text": "new research idea or a product I think",
        "start": 251.68,
        "duration": 5.279
    },
    {
        "text": "like deep research Sora, 01 thinking",
        "start": 253.84,
        "duration": 5.2
    },
    {
        "text": "models like all these definitional",
        "start": 256.959,
        "duration": 3.761
    },
    {
        "text": "things have come from OpenAI and that's",
        "start": 259.04,
        "duration": 5.12
    },
    {
        "text": "got to be one of their top traits as an",
        "start": 260.72,
        "duration": 4.88
    },
    {
        "text": "organization So it's kind of hard to",
        "start": 264.16,
        "duration": 3.68
    },
    {
        "text": "bet against that But I think a lot of",
        "start": 265.6,
        "duration": 4.08
    },
    {
        "text": "this year will be about scale and",
        "start": 267.84,
        "duration": 4.079
    },
    {
        "text": "optimizing what could be described as",
        "start": 269.68,
        "duration": 4.0
    },
    {
        "text": "low hanging fruit in models",
        "start": 271.919,
        "duration": 4.081
    },
    {
        "text": "i And clearly there's a tradeoff between",
        "start": 273.68,
        "duration": 5.04
    },
    {
        "text": "intelligence and speed This was what",
        "start": 276.0,
        "duration": 4.479
    },
    {
        "text": "Chad GPT5",
        "start": 278.72,
        "duration": 5.039
    },
    {
        "text": "was trying to solve behind the scenes",
        "start": 280.479,
        "duration": 4.72
    },
    {
        "text": "It's like do people actually want",
        "start": 283.759,
        "duration": 3.921
    },
    {
        "text": "intelligence the broad public or do they",
        "start": 285.199,
        "duration": 4.961
    },
    {
        "text": "want speed I think it's a nice variety",
        "start": 287.68,
        "duration": 4.64
    },
    {
        "text": "actually or the option to have a toggle",
        "start": 290.16,
        "duration": 4.56
    },
    {
        "text": "there I mean first for my personal",
        "start": 292.32,
        "duration": 4.56
    },
    {
        "text": "usage most of the time when I look",
        "start": 294.72,
        "duration": 4.24
    },
    {
        "text": "something up I use JGBT to ask a quick",
        "start": 296.88,
        "duration": 3.52
    },
    {
        "text": "question get the information I want it",
        "start": 298.96,
        "duration": 4.32
    },
    {
        "text": "fast for you know most daily tasks I use",
        "start": 300.4,
        "duration": 5.04
    },
    {
        "text": "the quick model nowadays I think the",
        "start": 303.28,
        "duration": 3.68
    },
    {
        "text": "auto mode is pretty good where you don't",
        "start": 305.44,
        "duration": 3.52
    },
    {
        "text": "have to specifically say thinking or you",
        "start": 306.96,
        "duration": 4.32
    },
    {
        "text": "know nonthinking and stuff then again I",
        "start": 308.96,
        "duration": 4.239
    },
    {
        "text": "also sometimes want the pro mode very",
        "start": 311.28,
        "duration": 3.6
    },
    {
        "text": "often what I do is when I have something",
        "start": 313.199,
        "duration": 5.201
    },
    {
        "text": "written I put it into JGBT and say hey",
        "start": 314.88,
        "duration": 6.319
    },
    {
        "text": "do a very thorough check is are all my",
        "start": 318.4,
        "duration": 4.079
    },
    {
        "text": "references correct are all my thoughts",
        "start": 321.199,
        "duration": 3.121
    },
    {
        "text": "what's correct Uh, did I make any",
        "start": 322.479,
        "duration": 3.921
    },
    {
        "text": "formatting mistakes And are the figure",
        "start": 324.32,
        "duration": 3.84
    },
    {
        "text": "numbers wrong or something like that",
        "start": 326.4,
        "duration": 4.16
    },
    {
        "text": "And I don't need that right away It's",
        "start": 328.16,
        "duration": 4.08
    },
    {
        "text": "something okay I finish my stuff",
        "start": 330.56,
        "duration": 3.6
    },
    {
        "text": "maybe have dinner let it run come back",
        "start": 332.24,
        "duration": 4.239
    },
    {
        "text": "and go through this And I think see",
        "start": 334.16,
        "duration": 4.0
    },
    {
        "text": "this is where I think it's important to",
        "start": 336.479,
        "duration": 3.44
    },
    {
        "text": "have this option I would go crazy if",
        "start": 338.16,
        "duration": 3.52
    },
    {
        "text": "for each query I would have to wait 30",
        "start": 339.919,
        "duration": 3.441
    },
    {
        "text": "minutes or 10 minutes even laughter",
        "start": 341.68,
        "duration": 2.0
    },
    {
        "text": "me",
        "start": 343.36,
        "duration": 1.76
    },
    {
        "text": "i Yeah.",
        "start": 343.68,
        "duration": 3.2
    },
    {
        "text": "i Um, I'm like saying over here losing my",
        "start": 345.12,
        "duration": 3.44
    },
    {
        "text": "mind that you use the router and the",
        "start": 346.88,
        "duration": 3.52
    },
    {
        "text": "nonthinking model I'm like how do you",
        "start": 348.56,
        "duration": 3.12
    },
    {
        "text": "how do you live with how do you live",
        "start": 350.4,
        "duration": 3.92
    },
    {
        "text": "with that It's like my reaction I'm",
        "start": 351.68,
        "duration": 6.4
    },
    {
        "text": "been heavily on chat for a while Um,",
        "start": 354.32,
        "duration": 5.84
    },
    {
        "text": "never touched five nonthinking I find",
        "start": 358.08,
        "duration": 5.2
    },
    {
        "text": "its tone and then it's propensity of",
        "start": 360.16,
        "duration": 4.64
    },
    {
        "text": "errors It's just like has a higher",
        "start": 363.28,
        "duration": 2.8
    },
    {
        "text": "likelihood of errors Some of this is",
        "start": 364.8,
        "duration": 4.16
    },
    {
        "text": "from back when opening released 03 which",
        "start": 366.08,
        "duration": 4.959
    },
    {
        "text": "was the first model to do this deep",
        "start": 368.96,
        "duration": 3.44
    },
    {
        "text": "search and find many sources and",
        "start": 371.039,
        "duration": 3.041
    },
    {
        "text": "integrate them for you So, I became",
        "start": 372.4,
        "duration": 3.519
    },
    {
        "text": "habituated with that So, I will only",
        "start": 374.08,
        "duration": 5.04
    },
    {
        "text": "use GPT 5.2 into thinking or pro when",
        "start": 375.919,
        "duration": 4.961
    },
    {
        "text": "I'm finding any sort of information",
        "start": 379.12,
        "duration": 4.16
    },
    {
        "text": "query for work whether that's a paper",
        "start": 380.88,
        "duration": 5.28
    },
    {
        "text": "or some code reference that I found and",
        "start": 383.28,
        "duration": 4.88
    },
    {
        "text": "it's just like I I will regularly have",
        "start": 386.16,
        "duration": 3.599
    },
    {
        "text": "like five pro queries going",
        "start": 388.16,
        "duration": 3.759
    },
    {
        "text": "simultaneously each looking for one",
        "start": 389.759,
        "duration": 3.681
    },
    {
        "text": "specific paper or feedback on an",
        "start": 391.919,
        "duration": 3.361
    },
    {
        "text": "equation or something I have a funny",
        "start": 393.44,
        "duration": 4.0
    },
    {
        "text": "example where I just needed to answer as",
        "start": 395.28,
        "duration": 5.12
    },
    {
        "text": "fast as possible for this podcast before",
        "start": 397.44,
        "duration": 5.36
    },
    {
        "text": "I was going on the trip Um, I have like",
        "start": 400.4,
        "duration": 4.32
    },
    {
        "text": "a local GPU running at home and I wanted",
        "start": 402.8,
        "duration": 5.119
    },
    {
        "text": "to run a long uh RL experiment And",
        "start": 404.72,
        "duration": 5.36
    },
    {
        "text": "usually I also unplug things because you",
        "start": 407.919,
        "duration": 3.12
    },
    {
        "text": "never know if you're not at home you",
        "start": 410.08,
        "duration": 2.399
    },
    {
        "text": "don't want to have things plugged in",
        "start": 411.039,
        "duration": 4.241
    },
    {
        "text": "And I accidentally unplugged the GP. It",
        "start": 412.479,
        "duration": 4.481
    },
    {
        "text": "was like my wife was already in the car",
        "start": 415.28,
        "duration": 3.28
    },
    {
        "text": "and it's like \"Oh, danger And then",
        "start": 416.96,
        "duration": 4.799
    },
    {
        "text": "basically I wanted as fast as possible a",
        "start": 418.56,
        "duration": 5.52
    },
    {
        "text": "bash script that runs my different uh",
        "start": 421.759,
        "duration": 4.641
    },
    {
        "text": "experiments in the evaluation And I did",
        "start": 424.08,
        "duration": 4.32
    },
    {
        "text": "something I know I learned how to use",
        "start": 426.4,
        "duration": 5.28
    },
    {
        "text": "the bash uh interface or bash terminal",
        "start": 428.4,
        "duration": 5.84
    },
    {
        "text": "but in that moment I just needed like 10",
        "start": 431.68,
        "duration": 3.76
    },
    {
        "text": "seconds give me the command",
        "start": 434.24,
        "duration": 2.799
    },
    {
        "text": "i This is a hilarious situation but yeah",
        "start": 435.44,
        "duration": 2.8
    },
    {
        "text": "so what did you used",
        "start": 437.039,
        "duration": 3.761
    },
    {
        "text": "i So I did the nonthinking fastest model",
        "start": 438.24,
        "duration": 5.28
    },
    {
        "text": "it gave me the bash command I to chain",
        "start": 440.8,
        "duration": 5.119
    },
    {
        "text": "different uh scripts to each other and",
        "start": 443.52,
        "duration": 4.799
    },
    {
        "text": "then the thing is like you have the t",
        "start": 445.919,
        "duration": 4.641
    },
    {
        "text": "thing where you want to route this to a",
        "start": 448.319,
        "duration": 4.32
    },
    {
        "text": "lo file top of my head I was just like",
        "start": 450.56,
        "duration": 3.28
    },
    {
        "text": "in a hurry I could have thought about",
        "start": 452.639,
        "duration": 2.641
    },
    {
        "text": "it By the way I don't know if there's",
        "start": 453.84,
        "duration": 3.199
    },
    {
        "text": "a representative case wife waiting in",
        "start": 455.28,
        "duration": 3.44
    },
    {
        "text": "the care You have to run you unplug the",
        "start": 457.039,
        "duration": 3.28
    },
    {
        "text": "GPU, laughter you have to generate a",
        "start": 458.72,
        "duration": 3.84
    },
    {
        "text": "bash script It sounds like a movie",
        "start": 460.319,
        "duration": 2.961
    },
    {
        "text": "impossible",
        "start": 462.56,
        "duration": 2.32
    },
    {
        "text": "i I use Gemini for that So, I use",
        "start": 463.28,
        "duration": 3.039
    },
    {
        "text": "thinking for all the information stuff",
        "start": 464.88,
        "duration": 3.599
    },
    {
        "text": "and then Gemini for fast things or stuff",
        "start": 466.319,
        "duration": 4.401
    },
    {
        "text": "that I could sometimes Google, which is",
        "start": 468.479,
        "duration": 3.681
    },
    {
        "text": "like it's good at explaining things and",
        "start": 470.72,
        "duration": 3.44
    },
    {
        "text": "I trust that it has this kind of",
        "start": 472.16,
        "duration": 4.159
    },
    {
        "text": "background of knowledge and it's simple",
        "start": 474.16,
        "duration": 3.68
    },
    {
        "text": "And the Gemini ape has got a lot better",
        "start": 476.319,
        "duration": 3.201
    },
    {
        "text": "and it's good for that sort of things",
        "start": 477.84,
        "duration": 3.28
    },
    {
        "text": "And then for code and any sort of",
        "start": 479.52,
        "duration": 3.679
    },
    {
        "text": "philosophical discussion I use claude",
        "start": 481.12,
        "duration": 4.72
    },
    {
        "text": "opus 4.5 also always with extended",
        "start": 483.199,
        "duration": 4.641
    },
    {
        "text": "thinking extended thinking and inference",
        "start": 485.84,
        "duration": 3.6
    },
    {
        "text": "time scaling is just a way to make the",
        "start": 487.84,
        "duration": 5.12
    },
    {
        "text": "models um marginally smarter and I will",
        "start": 489.44,
        "duration": 5.36
    },
    {
        "text": "always edge on that side when the",
        "start": 492.96,
        "duration": 3.2
    },
    {
        "text": "progress is very high because you don't",
        "start": 494.8,
        "duration": 3.28
    },
    {
        "text": "know when that's unlock a new use case",
        "start": 496.16,
        "duration": 4.4
    },
    {
        "text": "and then sometimes use rock for um",
        "start": 498.08,
        "duration": 4.16
    },
    {
        "text": "mealtime information or finding",
        "start": 500.56,
        "duration": 3.759
    },
    {
        "text": "something on AI Twitter that I knew I",
        "start": 502.24,
        "duration": 4.0
    },
    {
        "text": "saw and I need to dig up and I just",
        "start": 504.319,
        "duration": 4.801
    },
    {
        "text": "fixated on although when Grock 4 came",
        "start": 506.24,
        "duration": 5.919
    },
    {
        "text": "out the Gro for what is super heavy",
        "start": 509.12,
        "duration": 4.88
    },
    {
        "text": "which was like their pro variant was",
        "start": 512.159,
        "duration": 3.201
    },
    {
        "text": "actually very good and I was pretty",
        "start": 514.0,
        "duration": 2.64
    },
    {
        "text": "impressed with it and then I just kind",
        "start": 515.36,
        "duration": 3.679
    },
    {
        "text": "of like muscle memory lost track of it",
        "start": 516.64,
        "duration": 4.639
    },
    {
        "text": "with having the chat ape open So I",
        "start": 519.039,
        "duration": 3.36
    },
    {
        "text": "use many different things",
        "start": 521.279,
        "duration": 5.921
    },
    {
        "text": "i Yeah, I actually do use Gro 4 heavy for",
        "start": 522.399,
        "duration": 7.12
    },
    {
        "text": "debugging for like hardcore debugging",
        "start": 527.2,
        "duration": 4.079
    },
    {
        "text": "that the other ones can solve I find",
        "start": 529.519,
        "duration": 4.401
    },
    {
        "text": "that it's the best at and I it's",
        "start": 531.279,
        "duration": 5.041
    },
    {
        "text": "interesting cut you say JBT is the best",
        "start": 533.92,
        "duration": 3.919
    },
    {
        "text": "interface",
        "start": 536.32,
        "duration": 3.84
    },
    {
        "text": "uh for me for that same reason but this",
        "start": 537.839,
        "duration": 5.12
    },
    {
        "text": "could be just momentum uh Gemini",
        "start": 540.16,
        "duration": 5.119
    },
    {
        "text": "i is the better interface for me I think",
        "start": 542.959,
        "duration": 5.201
    },
    {
        "text": "because I fell in love with their best",
        "start": 545.279,
        "duration": 4.961
    },
    {
        "text": "needle in the haystack if I ever put",
        "start": 548.16,
        "duration": 3.92
    },
    {
        "text": "something that has a lot of context but",
        "start": 550.24,
        "duration": 3.36
    },
    {
        "text": "I'm looking for very specific kinds of",
        "start": 552.08,
        "duration": 3.04
    },
    {
        "text": "information make sure it tracks all of",
        "start": 553.6,
        "duration": 5.12
    },
    {
        "text": "it I find at least uh the Gemini for me",
        "start": 555.12,
        "duration": 7.04
    },
    {
        "text": "has been uh the best So, it's funny with",
        "start": 558.72,
        "duration": 5.28
    },
    {
        "text": "some of these models if they win your",
        "start": 562.16,
        "duration": 4.56
    },
    {
        "text": "heart over for one particular feature at",
        "start": 564.0,
        "duration": 4.64
    },
    {
        "text": "one on a one particular day",
        "start": 566.72,
        "duration": 5.04
    },
    {
        "text": "i for that particular query that prompt",
        "start": 568.64,
        "duration": 4.879
    },
    {
        "text": "you're like \"This model is better And",
        "start": 571.76,
        "duration": 3.759
    },
    {
        "text": "so you'll just stick with it for a bit",
        "start": 573.519,
        "duration": 4.401
    },
    {
        "text": "until it does something really dumb",
        "start": 575.519,
        "duration": 4.641
    },
    {
        "text": "There's like a threshold effect some",
        "start": 577.92,
        "duration": 4.0
    },
    {
        "text": "smart thing and then you fall in love",
        "start": 580.16,
        "duration": 3.28
    },
    {
        "text": "with it and then it does some dumb",
        "start": 581.92,
        "duration": 2.56
    },
    {
        "text": "thing and you're like you know what",
        "start": 583.44,
        "duration": 2.56
    },
    {
        "text": "I'm going to switch and try Claude or",
        "start": 584.48,
        "duration": 3.28
    },
    {
        "text": "Chad GPT and all that kind of stuff",
        "start": 586.0,
        "duration": 4.24
    },
    {
        "text": "This is exactly like you use it until it",
        "start": 587.76,
        "duration": 4.639
    },
    {
        "text": "breaks until you have a problem and then",
        "start": 590.24,
        "duration": 5.2
    },
    {
        "text": "then you change uh the LM and I think",
        "start": 592.399,
        "duration": 5.12
    },
    {
        "text": "it's the same how we use anything like",
        "start": 595.44,
        "duration": 4.16
    },
    {
        "text": "our favorite text editor um operating",
        "start": 597.519,
        "duration": 4.241
    },
    {
        "text": "systems or the browser I mean there are",
        "start": 599.6,
        "duration": 4.32
    },
    {
        "text": "so many browser options Safari, Firefox,",
        "start": 601.76,
        "duration": 4.8
    },
    {
        "text": "Chrome all the relatively similar but",
        "start": 603.92,
        "duration": 4.4
    },
    {
        "text": "then there are edge cases maybe",
        "start": 606.56,
        "duration": 3.44
    },
    {
        "text": "extensions you want to use and then you",
        "start": 608.32,
        "duration": 4.16
    },
    {
        "text": "switch but I don't think there is any",
        "start": 610.0,
        "duration": 5.279
    },
    {
        "text": "one who types the same thing like the",
        "start": 612.48,
        "duration": 4.32
    },
    {
        "text": "website into different browsers and",
        "start": 615.279,
        "duration": 3.041
    },
    {
        "text": "compares You only do that when the",
        "start": 616.8,
        "duration": 2.88
    },
    {
        "text": "website doesn't render if something",
        "start": 618.32,
        "duration": 3.199
    },
    {
        "text": "breaks I think so That's that's a good",
        "start": 619.68,
        "duration": 3.279
    },
    {
        "text": "point I think you use it until it",
        "start": 621.519,
        "duration": 2.801
    },
    {
        "text": "breaks and then you explore other",
        "start": 622.959,
        "duration": 2.32
    },
    {
        "text": "options I think",
        "start": 624.32,
        "duration": 2.56
    },
    {
        "text": "i on the long context thing I was also a",
        "start": 625.279,
        "duration": 4.081
    },
    {
        "text": "Gemini user for this but the GPT 5.2",
        "start": 626.88,
        "duration": 4.639
    },
    {
        "text": "release blog had like crazy long context",
        "start": 629.36,
        "duration": 3.44
    },
    {
        "text": "scores where a lot of people were like",
        "start": 631.519,
        "duration": 2.641
    },
    {
        "text": "did they just figure out some",
        "start": 632.8,
        "duration": 3.599
    },
    {
        "text": "algorithmic change It went from like",
        "start": 634.16,
        "duration": 4.56
    },
    {
        "text": "30% to like 70% or something in this",
        "start": 636.399,
        "duration": 4.321
    },
    {
        "text": "minor model update So, it's also very",
        "start": 638.72,
        "duration": 3.6
    },
    {
        "text": "hard to keep track of all of these",
        "start": 640.72,
        "duration": 4.32
    },
    {
        "text": "things But now I'm look more favorably",
        "start": 642.32,
        "duration": 5.12
    },
    {
        "text": "at GPT 5.2's two is long context that",
        "start": 645.04,
        "duration": 4.479
    },
    {
        "text": "it's just kind of like how do I actually",
        "start": 647.44,
        "duration": 5.2
    },
    {
        "text": "get to testing this",
        "start": 649.519,
        "duration": 4.481
    },
    {
        "text": "never ending battle",
        "start": 652.64,
        "duration": 3.52
    },
    {
        "text": "i It's interesting that none of us talked",
        "start": 654.0,
        "duration": 5.04
    },
    {
        "text": "about the Chinese models from a user",
        "start": 656.16,
        "duration": 5.359
    },
    {
        "text": "usage perspective What does that say",
        "start": 659.04,
        "duration": 4.0
    },
    {
        "text": "Does that mean the Chinese models are",
        "start": 661.519,
        "duration": 3.281
    },
    {
        "text": "not as good or does that mean we're just",
        "start": 663.04,
        "duration": 4.88
    },
    {
        "text": "very biased and us focused",
        "start": 664.8,
        "duration": 5.279
    },
    {
        "text": "i I do think that that's currently the",
        "start": 667.92,
        "duration": 4.4
    },
    {
        "text": "discrepancy between just the model and",
        "start": 670.079,
        "duration": 4.801
    },
    {
        "text": "the platform So I I think the open",
        "start": 672.32,
        "duration": 4.48
    },
    {
        "text": "models they are more known for the open",
        "start": 674.88,
        "duration": 3.36
    },
    {
        "text": "weights not their platform yet",
        "start": 676.8,
        "duration": 2.88
    },
    {
        "text": "i There are also a lot of companies that",
        "start": 678.24,
        "duration": 3.039
    },
    {
        "text": "are willing to sell you the open model",
        "start": 679.68,
        "duration": 3.36
    },
    {
        "text": "inference at a very low cost I think",
        "start": 681.279,
        "duration": 3.601
    },
    {
        "text": "like open router it's easy to do the",
        "start": 683.04,
        "duration": 3.76
    },
    {
        "text": "look at multimodel things You could run",
        "start": 684.88,
        "duration": 4.399
    },
    {
        "text": "deepseeek on perplexity I think all of",
        "start": 686.8,
        "duration": 4.64
    },
    {
        "text": "us sitting here are like we use open",
        "start": 689.279,
        "duration": 4.8
    },
    {
        "text": "GPT5 pro consistently We're all willing",
        "start": 691.44,
        "duration": 4.72
    },
    {
        "text": "to pay for the marginal intelligence",
        "start": 694.079,
        "duration": 4.32
    },
    {
        "text": "gain and anyone that's like the these",
        "start": 696.16,
        "duration": 5.679
    },
    {
        "text": "models from the US are better and in",
        "start": 698.399,
        "duration": 5.12
    },
    {
        "text": "terms of the outputs I think that the",
        "start": 701.839,
        "duration": 4.401
    },
    {
        "text": "question is will they stay better for",
        "start": 703.519,
        "duration": 4.481
    },
    {
        "text": "this year and for years going but it's",
        "start": 706.24,
        "duration": 3.36
    },
    {
        "text": "like so long as they're better I'm going",
        "start": 708.0,
        "duration": 3.68
    },
    {
        "text": "to pay for it to use them I think",
        "start": 709.6,
        "duration": 3.76
    },
    {
        "text": "there's also analysis that shows that",
        "start": 711.68,
        "duration": 3.76
    },
    {
        "text": "like the",
        "start": 713.36,
        "duration": 4.159
    },
    {
        "text": "way that the Chinese models are served",
        "start": 715.44,
        "duration": 3.6
    },
    {
        "text": "this you could argue due to export",
        "start": 717.519,
        "duration": 3.361
    },
    {
        "text": "controls or not is that they use fewer",
        "start": 719.04,
        "duration": 4.08
    },
    {
        "text": "GPUs for replica which makes them slower",
        "start": 720.88,
        "duration": 4.079
    },
    {
        "text": "and have different errors and it's like",
        "start": 723.12,
        "duration": 3.839
    },
    {
        "text": "speed and intelligence if these things",
        "start": 724.959,
        "duration": 4.0
    },
    {
        "text": "are in your favor as a user I think in",
        "start": 726.959,
        "duration": 4.241
    },
    {
        "text": "the US a lot of users will go for this",
        "start": 728.959,
        "duration": 3.921
    },
    {
        "text": "and I think that that is one thing that",
        "start": 731.2,
        "duration": 4.56
    },
    {
        "text": "will spur these Chinese companies to",
        "start": 732.88,
        "duration": 4.56
    },
    {
        "text": "want to compete in other ways whether",
        "start": 735.76,
        "duration": 4.4
    },
    {
        "text": "it's like free or substantially lower",
        "start": 737.44,
        "duration": 5.44
    },
    {
        "text": "costs or it'll breed creativity in terms",
        "start": 740.16,
        "duration": 4.799
    },
    {
        "text": "of offerings which is good for the",
        "start": 742.88,
        "duration": 3.68
    },
    {
        "text": "ecosystem but I just think the simple",
        "start": 744.959,
        "duration": 3.041
    },
    {
        "text": "thing is that US models are currently",
        "start": 746.56,
        "duration": 3.6
    },
    {
        "text": "better and we use them and I try Chinese",
        "start": 748.0,
        "duration": 3.6
    },
    {
        "text": "I try these other open models and I'm",
        "start": 750.16,
        "duration": 4.16
    },
    {
        "text": "like fun but not going to I don't go",
        "start": 751.6,
        "duration": 5.039
    },
    {
        "text": "back to",
        "start": 754.32,
        "duration": 2.319
    }
]