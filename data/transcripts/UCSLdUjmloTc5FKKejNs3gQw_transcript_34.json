[
    {
        "text": " New model alert. New model alert. That's right. A new model has dropped and this one might actually be interesting as it's Claude Haiku. That's right. After nearly a full year of being on the shelf, Haiku is back with promises of Claude Sonic 4 performance at a third of the price and twice the speed. Finally, Anthropic have released a reasonably priced model. Although hilariously, they've actually raised the price of Haiku from last year. But it's the best we're going to get. So, let's take a look. First, I ran a quick rudimentary race of the model in Cursor because I've actually used Grock fast a lot in Cursor. So, I was super curious to see what Haiku would feel like. And in this case, I'm actually comparing it to Claude Sonic 4 as Anthropic actually said this would have roughly the same level of intelligence, even sometimes beating it. We'll see that in the benchmarks later. While the race is going on, I can tell you that the new Haiku model is actually the first Haiku model that supports reasoning, and it has a 200,000 token context window and 64,000 maximum output. If we jump to the end of the test, overall Haiku won by over a minute. So their claims of speed do seem to be true. And I even reran this in Claude code with similar results just to make sure that that cursor to do feature wasn't a major factor in slowing down Sonic 4. When it comes to the actual typing games they produced, though on initial reaction, I do like Haiku's design more, but the words were a little fast, but oh wow, Sonic 4 unlocks a whole new level here. So yeah, it definitely is faster than Sonic 4 and I'll probably play around with this a little bit more, but I do think this might become my default cheap and fast model, especially if it has the intelligence level that they are seeing in the benchmarks. You can see on S.Bench, it beats Sonic 4, which is pretty crazy. But it even beats GPT5 as well. And on the rest of their benchmarks, it's a similar story where it beats Sonic 4 on nearly all of the benchmarks besides these four, which to me shows that they really did focus this model on coding, making trade-offs in other areas. When we take a look at the external benchmarks though, this is where things get a little bit more disappointing. On artificial analysis, you can see it's usually up there behind Sonet 4 with only two points in it on the coding index when you have reasoning on. But GP5 Mini High scores nine points higher and GLM 4.6 is a point ahead. And both those models are still significantly cheaper than Haiku. For context, Haiku's pricing is going to be $1 per million input tokens and $5 per million output tokens. And this is slightly more expensive than Haiku was",
        "start": 0.16,
        "duration": 268.801
    },
    {
        "text": "High scores nine points higher and GLM 4.6 is a point ahead. And both those models are still significantly cheaper than Haiku. For context, Haiku's pricing is going to be $1 per million input tokens and $5 per million output tokens. And this is slightly more expensive than Haiku was cents for a million input and $4 for a million output. But even worse, if we take a look at GPT5 prices for comparison, where mini is 25 cents for a million input tokens and $2 for a million output tokens, and even GLM 4.6, which is 50 cents for a million input tokens and $1.75 for a million output tokens, the story doesn't look too good. If we put all of that info together and take a look at intelligence versus cost, GP5 mini looks like it's going to be the best option. And even GLM 4.6 is still a little bit better than Haiku. And it's even a similar story when we take a look at intelligence versus output speed. As it seems when reasoning is on, Haiku is still very close to GLM 4.6. So I'm not too sure what to think personally. As I mentioned, I'll try this out for a bit as I do trust anthropic model when it comes to real world code usage in my codebase. And the fact that it can be used in clawed code is obviously a massive plus. And I guess it's just not anything groundbreaking, but that can be okay. This is just Anthropic responding to competition from OpenAI and models like GLM 4.6. And competition in these cheaper models seems like it's going to be an absolute win for us. What do you think? Let me know in the comments down below. While you're there, subscribe and as always, see you in the next one.",
        "start": 134.8,
        "duration": 405.2019999999999
    }
]