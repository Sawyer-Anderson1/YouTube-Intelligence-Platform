[
    {
        "text": " The clause code team have recently upgraded to-dos to tasks, which is huge news because it means each task has its own JSON file that can be updated and committed to GitHub. These tasks can run in parallel with sub agents and multiple Claude Code sessions can share the same task list. Perfect for complex projects that have multiple tasks and need lots of sessions. But what does this mean for the super popular Ralph Wigum Loop? Does this make it obsolete? Not quite. Hit subscribe and let's get into it. Opus 4.5 changed the game in many ways. One thing it can do that you might not know about is its ability to run autonomously for much longer, keeping track of its state better than other models. Which means the classic to-do list you've seen in Claude Code before is pretty much not needed for small tasks. But for longer tasks, it still has a 200k context window, meaning it does have a smart zone and a dumb zone. So, it will output dumb results over the 80% mark. Check out my Ralph Wigum video to learn more about the smart and dumb area for a model based on its context. Now, at this stage, you may grab a tool like beads, which stores tasks inside an SQite database and puts them in a JSON L file to be committed for version control. The beads tool is what greatly inspired the Claude code team to upgrade to-dos to this new task management system which does a bunch of things from storing tasks in JSON files to letting you run them in multiple sessions and much more. But as cool as this upgrade is, it does work a bit differently from beads and Ralph Wigan. In fact, let me show you. So, here is a plan file written by Claude Code containing three major changes I want to add to a tool called XDL to help you download videos from X or Twitter using a CLI. And for tasks to work, you need to be on Claude Code version 2.1.6 or higher, which contains these task management related tools. So, I'm going to ask Claude to turn the plan file into a set of tasks to complete. And you can see here it's created the tasks. It's added some dependencies. So tasks that are blocked by other tasks and it's put them here. So it's highlighted in yellow the tasks that block the specific tasks. And if we go to the broad directory on the root of our machine, we can see a tasks folder with another folder for our project. And if we open it, we can see all the tasks that have been created with an ID, subject, description, and what other tasks block this task, all the tasks that are blocked by this task. And now we're going to ask Claude to run each task in a sub agent, which it's gone",
        "start": 0.08,
        "duration": 331.52099999999996
    },
    {
        "text": "it, we can see all the tasks that have been created with an ID, subject, description, and what other tasks block this task, all the tasks that are blocked by this task. And now we're going to ask Claude to run each task in a sub agent, which it's gone done, and so is task 8, 9, and 10 since they're not blocked by other tasks. And we can also see up here the different sub aents working on different tasks. And now that all the tasks are done, I could check how much context was used and we can see only 18% was used because all the tasks were done in sub agents. But here's something else you can do with the new task management system. If I wanted to run multiple sessions of claws, in this case in different split panes, but you could have them in different tabs or different servers having access to the same task list. What I could do is run this environment variable claude code task list ID and give it the ID that matches the directory of the task list I want to use. So here Claude should have access to all the tasks in that directory and I could do the same in this session. So here I could ask one session to go through the tasks and another session to verify the task has been completed. If I run the session on the left, the session on the right should be able to see the progress of each task. And now that it's done on this side, this session over here can go ahead to verify that the task has been completed. This is actually really cool because you could start working on a task on one machine, stop, commit those tasks to GitHub or whatever version control system you prefer and then on another machine, pull those tasks and continue from exactly where you left off. which if you have experience with beads then you'll know this is similar to how it works but not exactly because beads stores the tasks in an SQLite database for very fast retrieval and it also syncs database tasks to a single JSONL file not multiple JSON files. So you can add this single file to your project and share it with your team members. This is also a bit different from the Ralph Wigum loop purely because of the philosophy. So with the Ralph loop, you have a single prompt and you have a list of tasks and these tasks are supposed to help you achieve that prompt which you send to the model over and over again. But with this new task management system, you have a list of tasks and you ask the model to go ahead and pick the next one that it needs to do. So it reads through all the tasks to find out which one is next. This is somewhat alleviated if you",
        "start": 165.68,
        "duration": 603.7610000000002
    },
    {
        "text": "with this new task management system, you have a list of tasks and you ask the model to go ahead and pick the next one that it needs to do. So it reads through all the tasks to find out which one is next. This is somewhat alleviated if you task. But if you want an autonomous loop that can go for as long as you want where the model follows a northstar which is in your prompt MD file to continuously improve the project even with tasks you haven't added then the new tasks management system isn't view. There's also the issue of documentation because at the time of recording all the information about this feature is inside a single tweet and compared to beads there isn't much in the way of a visualization tool or a canban type tool to see the progress of each task but I'm sure the claude code community is working on this right now and with all these new tool management systems creating new software you're going to need a way to make sure you're not shipping errors to your users and this is where better stack comes in which gives you a way to track errors on the back end and front end of your project using an AI native error tracker as well as a status page to inform your users if your site goes down and a great incident management system. So go ahead and check out Better Stack",
        "start": 304.24,
        "duration": 732.801
    }
]