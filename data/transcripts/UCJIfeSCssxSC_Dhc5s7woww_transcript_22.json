[
    {
        "text": " I guess the big question here is we talked quite a bit here on the architecture behind the pre-training. Are the scaling laws holding strong across pre-training, post training inference context size data synthetic data i I like to start with the technical definition of scaling law which kind of informs all of this The scaling law is a power law relationship between you can think of the x-axis. So kind of what you are scaling is a combination of compute and data which are kind of similar and then the axis is like the held out prediction accuracy over next token So we talk about models being auto regressive It's like if you keep a set of text that the model has not seen how accurate will it get when you will train And the idea of scaling laws came when people figured out that that was a very predictable relationship And I think that that technical term is continuing And then the question is like what do users get out of it And then there are more types of scaling where um OpenAI's 01 was famous for introducing inference time scaling and I think less famously for also showing that you can scale reinforce learning training and get kind of this log axis and then a linear increase in performance on ya axis So there's kind of these three axes now where the traditional scaling laws are talk talked about for restraining which is how big your model is and how big your data set is and then scaling reinforcer learning which is like how long can you do this trial and error learning that we we'll talk about we'll define more of this and then this inference time compute which is just letting the model generate more tokens on a specific problem So I'm kind of bullish where they they're all really still working but the low hanging fruit has mostly been taken especially in the last year on um reinforce learning with verifiable rewards which is this RLVR and then inference time scaling which is just why these models feel so different to use where previously you would get that first token immediately and now they will go off for seconds minutes or even hours generating these hidden thoughts before giving you the first word of your answer and that's all about this inference time scaling which such a wonderful kind of step function in terms of how the models change abilities They kind of enabled this tool use stuff and enabled this much better software engineering that we were talking about And this when we say enabled almost entirely downstream of the fact that this reinforce learning was verifiable rewards training just kind of let the models pick up these skills very easily So it let the models learn And so if you look at the reasoning process when the models are generating a lot of tokens what it'll",
        "start": 2.879,
        "duration": 298.64
    },
    {
        "text": "downstream of the fact that this reinforce learning was verifiable rewards training just kind of let the models pick up these skills very easily So it let the models learn And so if you look at the reasoning process when the models are generating a lot of tokens what it'll looks at what it gets back It tries another API, it sees what it gets back and if it solves the problem So the models when you're training them very quickly learn to do this And then at the end of the day that gives this kind of general foundation where the model can use CLI commands very nicely in your rep and handle git for you and move things around and organize things or search to find more information which if we're sitting in these chairs a year ago is something that we didn't really think of the models being doing So, this is just kind of something that has happened this year and has totally transformed how we think of using AI, which I think is very magical was such an interesting evolution and just so unlock so much value but it's it's like it's not clear what the next avenue will be in terms of unlocking stuff like this I think that there's there's we'll get to continual learning later but there's a lot of buzz around certain areas of AI, but no one knows when the next step function will will really come i So, you you've actually said quite a lot of things there and said profound things quickly It would be nice to unpack them a little bit You said you're bullish basically on every version of scaling So, can we just even start at the beginning pre-training? Are we kind of implying that the lowhanging fruit on restraining scaling has been picked Is is restraining hit a plateau or is even restraining still you're bullish on i Pre-training has gotten extremely expensive I think to scale up pre-training, it's also implying that you're going to serve a very large model to the users So I think that it's been loosely established the likes of GPT4 and similar models were around one trillion like this order of trillion parameters at the biggest size There's a lot of rumors that they've actually gotten smaller as training has gotten more efficient You want to make the model smaller because then your costs of serving go down proportionally These models the cost of training them is really low relative to the cost of serving them to hundreds of millions of users I think DeepS had this famous number of about i million for restraining at cloud market rates I think three um section 2.4 in the paper we just detailed how long we had the GPU clusters sitting around for training which includes engineering issues multiple seeds and it was like about i million to rent the cluster to like deal",
        "start": 152.239,
        "duration": 572.3999999999999
    },
    {
        "text": "million for restraining at cloud market rates I think three um section 2.4 in the paper we just detailed how long we had the GPU clusters sitting around for training which includes engineering issues multiple seeds and it was like about i million to rent the cluster to like deal training a model So these models are pretty like a lot of people could get to $10 million to train a model but the recurring costs of serving millions of users is really billions of dollars of computer I think that you can look at close like a thousand GPU rental you can pay 100 grand a day for and these companies could have millions of GPUs like you can look at how much these things cost to sit around So that's kind of a big thing and then it's like if scaling is actually giving you a better model like is it going to be financially worth it and I think it'll kind of slowly will push it out as AI solves more compelling tasks So like the likes of cloud opus 4.5 making cloud code just work for things I think I I launched this project called like the atom project which is like American truly open models in July and that was like a true vibecoded website and like I have a job um make plots and stuff and then I came back to refresh it in the last few weeks and it's like claw opus 4.5 versus whatever model at the time was like just crushed all the issues that I had from building in June and July and like might be a bigger model there's a lot of things that go into this but that's like there's still progress coming So, so what you're speaking to is the nuance of the axis of the scaling laws that the way it's experienced versus on a benchmark the actual intelligence is might might be different but still your intuition about restraining if you scale the the size of compute will the models get better not whether it's financially viable but just from the law aspect of it do you think the models will get smarter i yeah and I think that there's and this sometimes comes off as like almost like disillusioned from people leadership at AI companies saying this but they're like it's held for 13 orders of magnitude of computers something like why would it ever end So I think fundamentally it is pretty unlikely to stop It's just like eventually we're not even going to be able to test the bigger scales because of all the problems that come with more computer I think that there's a lot of talk on how 2026 is a year when very large Blackwell compute clusters like gigawatt scale facilities hyperscalers are coming online and these were all contracts for power and data centers that were signed and sought out in like 22 and 2023. So before or",
        "start": 291.36,
        "duration": 845.3589999999998
    },
    {
        "text": "that there's a lot of talk on how 2026 is a year when very large Blackwell compute clusters like gigawatt scale facilities hyperscalers are coming online and these were all contracts for power and data centers that were signed and sought out in like 22 and 2023. So before or to three year lead time to build these bigger clusters to train the models Well, there's obviously immense interest in building even more data centers than that So, that is like kind of the crux that people are saying is like these new clusters are coming The labs are going to have more compute for training They're going to utilize this But, it's not a given And it's like I I've seen so much progress that I expect it and I expect a little bit bigger models And I expect um I would say it's more like we will see a $2,000 subscription this years We've seen $200 subscriptions It's like that could six again And these are the kind of things that could come and they're all downstream of this like bit big bit bigger model that offers just a little bit more cutting edge i So you know it's reported that XAI is going to hit that uh 1 await scale early 26 and full 2 await by year end How do you think they'll utilize that in the context of scaling laws Is is a lot of that inference is a lot of that training it ends up being all of the above So I think that all of your decisions when you're training a model come back to pre-training. So if you're going to scale RL on a model you still need to decide on your architecture that enables this We're talking about like other architectures than using different types of attention We're also talking about mixture of experts models This sparse nature of models makes it much more efficient to do um generation which becomes a big part of um post training And it's like you need to have your architecture ready so that you can actually scale up this computer I still think most of the compute is going in at restraining because you can still make a model better You still want to go and revisit this You still want the best base model that you can and in a few years that's saturate and the the RL compute will just go longer Is there people who disagree with you that say basically restraining is dead It's all about scaling inference scaling pulse training scaling context continual learning uh scaling data synthetic data i People vibe that way and describe it in that way but I think it's not the practice that is happening i It's just the general vibe of people saying the things i the excitement is elsewhere So the lowhanging fruit in RL is elsewhere Like for example we released our model in November for every company has",
        "start": 429.599,
        "duration": 1114.3170000000002
    },
    {
        "text": "in that way but I think it's not the practice that is happening i It's just the general vibe of people saying the things i the excitement is elsewhere So the lowhanging fruit in RL is elsewhere Like for example we released our model in November for every company has November with and our for that our our run was 5 days which compared to 2024 is a very long time to just be doing post training at a model of like 30 billion parameters It's not a big model and then in December we had another release which was just we let the RL run for go for another three and a half weeks and the model got notably better so we release it and like that's a big amount of time to just allocate to like something that is going to be your um peak for the years So it's like there's these types of decisions that happen when they're training a model where they just like can't they can't leave it forever You have to keep i you have to keep pulling in the improvements you have from your researchers So that's like you redo pre-training. You'll do this post-training for a months but then you need to give it to your users You need to do safety testing So there's kind of just like I think there's a lot in place that reinforces this cycle of just keep updating the models There's things to improve if you get a new compute cluster that lets you do something maybe more stably or faster It's like you hear a lot about Blackwell having fallout issues where at AI2 most of the models we're restraining are on like 1 to 2,000 GPUs, but when you're restraining on 10,000 or 100,000 GPUs, you hit very different failures So GPUs are known to break in weird ways And doing a 100,000 GPU run is like you're pretty much guaranteed to always have at least one GPU that is down And you need to have your training code handle that redundancy which is just a very different problem Whereas like what we're doing like I'm playing with post training on DJX Spark or you have your book It's like or people learning ML. It's like what they're battling to train these biggest models is just like mass distributed scale and it's a very different but that's somewhat different than like are these like that's a systems problem in order to enable the scaling laws especially at restraining you need all of these GPUs at once When we shift to reinforcement learning it actually lends itself to heterogeneous compute because you have many copies of the model And to do a primer for language model reinforcer learning what you're doing is you have two sets of GPUs. One is you can call it the actor and one you call the learner The learner is where your actual reinforcer learning updates are",
        "start": 566.399,
        "duration": 1369.2790000000002
    },
    {
        "text": "have many copies of the model And to do a primer for language model reinforcer learning what you're doing is you have two sets of GPUs. One is you can call it the actor and one you call the learner The learner is where your actual reinforcer learning updates are policy gradient algorithms Um, proximal policy optimization PO and group relative policy optimization GRPO are the two popular classes and on the other side you're going to have actors which are generating completions and these completions are the things that you're going to grade So reinforcement learning is all about optimizing reward And in practice what you can do is that you can have a lot of different actors in different parts of the world doing different types of problems and then you send it back to this highlyorked compute cluster to do this actual learning where where you take the where you take the gradients and you need to have a tightly meshed network where you can do different types of parallelism and spread out your model for efficient training So there's just like a lot of every different type of training and serving has these considerations you need to scale Like we talked about pre-training, we talked about RL and then inference time scaling is like how do you serve a model that's thinking for an hour to 100 million users I'm like I don't really know about that but I know that's a hard problem and in order to give people this intelligence there's all the systems problems and we need more compute and you need more stable compute to do it But you're bullish on all of these kinds of scaling is what I'm hearing on the inference on the reasoning even on the pre-training. i Yeah. So that's a a big can of worms here So there basically two the knobs are the training and the inference scaling where you can get gains and so in in a world where we had let's say infinite compute resources you want to do all of them like so you have training you have inference scaling and training is like a hierarchy it's restraining mid-training post-raining changing the model size more training data making training a bigger model gives you more knowledge in the model than the model um let's say has a better it's like a better base model back in the day or still we call it foundation model and it unlocks So you but you don't let's say have the model be able to solve your most complex task tasks during restraining or after pre-training. You still have these other unlock phases where you have mid-training non-context for example post training with LRVR that unlocks capabilities that the model has in terms of just knowledge in the restraining and I think sure if you so do more restraining you get a better base model that you can unlock later but",
        "start": 695.44,
        "duration": 1635.1190000000006
    },
    {
        "text": "unlock phases where you have mid-training non-context for example post training with LRVR that unlocks capabilities that the model has in terms of just knowledge in the restraining and I think sure if you so do more restraining you get a better base model that you can unlock later but expensive so we don't have infinite compute so you have to decide do I want to spend that compute more on making the model larger but you know it's like a tradeoff it's it's like in ideal world you want to do all of them and I think in that sense scaling is still pretty much alive You would still get a better model but like we saw with GPD 4.5, it's just not worth it I mean it's like cut you can let's say you can unlock more performance with other techniques at that current moment especially um if you look at inference scaling That's one of the biggest gains this year with 01 um where it took a smaller model further than restraining a larger model like GBD 4.5. So it's like I wouldn't say restraining scaling is dead It's just like there are other more attractive ways to scale right now at the moment But at some point you know you will still want to make some progress on the pre-training. The thing is also to consider um where you where do you want to spend your money If you spend it more on the pre-training, it's like a fixed cost You train the model and then it has this capability forever You can always use it and so forth With inference scaling you don't spend money during training you spend money later per query and then it's also like the math how long is my model going to be on the market if I replace it in half a year maybe it's not worth spending million 10 million $100 million on the training it longer maybe it's just I will just do more inference scaling and get the performance from there it maybe cost me 2 million in terms of user queries it becomes a question of how many users you have and then doing the math um and I think that's also where it's interesting where JGBD is in a position I think they have a lot of users where they need to go a bit cheaper where they have that uh GP5 model that is a bit smaller other companies that have as if your customers have other uh other um tradeoffs For example there was also the math olympiad or some of these these math problems where JJBT or they had a proprietary model and I'm pretty sure it's just like a model has been maybe fine-tuned a little bit more but most of it was during inference scaling to achieve this peak performance in certain tasks where you don't need that all the time and but yeah long story short I do",
        "start": 830.48,
        "duration": 1885.520000000001
    },
    {
        "text": "model and I'm pretty sure it's just like a model has been maybe fine-tuned a little bit more but most of it was during inference scaling to achieve this peak performance in certain tasks where you don't need that all the time and but yeah long story short I do mid-training post-training infant scaling they are all still things you want to do it's just finding at the moment in this years it's finding the right ratio that gives you the best bang for the bucks Basically,",
        "start": 956.959,
        "duration": 1909.200000000001
    }
]