[
    {
        "text": " The physical AI is where Jenny AI models and and ends transforming instinct into response and this is a new discipline and the next speaker is going to talk just about that. Please a very warm welcome CEO of Navio Gregori Ferosski AI physical AI technology the name of the presentation [music] [music] [music] [music] [applause] Hi everyone, my name is Gregori. I'm a CEO of Navia company. Today I'm going to talk about Genai, [snorts] how it comes to our physical world. We are living in very exciting times. The times that start changing very quickly. We can see genai in various areas of our life. Today you have seen a dancing robot. You have seen giga chat today as well. Today I'm going to talk about physical AI technology and physical relay for the AI technology. 2025 was a major year of major shifts for our company. everything has changed the way we work, our technology landscape, our products but currently we do not see one even one commercially successful product. So today I would like to explain why that happens and why we don't see driverless cars on the roads. How many of you raise your hand? How many of you have come here on autonomous vehicle on driverless vehicle? Well, maybe I was the only one because I work on that. Our industry started in 2009 when Google launched its first driverless cars. For the first 15 years, the industry was very promising and exciting. all the industry said that in 3 years, every time they said in three years the trucks will be driveralist. We will go around by driverless cars. We're going to use driverless buses to commute to work. But unfortunately, it has never happened. Now, my task today is to tell you why we failed to deliver and why and how the industry has changed and what started to appear, what new developments we started to see as Genai was ushered in this area. Now the industry in 15 years one slide more than $50 billion dollar were invested overall the US Europe China and Russia has created more than 10,000 driverless vehicles more than 30,000 research papers were published and there were zero commercially successful products and I want to talk just about that why that happened, how the industry will change and what will be the next steps. Before we go there, I'm going to show you a couple of videos. And I'm going to tell you why and I mean how the experts of the industry see these changes and I'll show you some of the leadersh and I'll show you what were their success stories until 2025. Andre Karpov very famous scientists he for some time headed AI in Tesla and he was one of the co-founders of open AI for about a 30inut drive around Palo Alto highways streets and so on and this drive was perfect there was zero interventions and this was 2013 which is",
        "start": 8.0,
        "duration": 476.4990000000001
    },
    {
        "text": "Karpov very famous scientists he for some time headed AI in Tesla and he was one of the co-founders of open AI for about a 30inut drive around Palo Alto highways streets and so on and this drive was perfect there was zero interventions and this was 2013 which is me because at the time when I had this perfect drive this perfect demo I felt like wow soft driving is imminent because this just worked. This is incredible. but here we are 12 years later and we are still working on autonomy. Right. So Andre is talking about how he was driving a VMA car in California in 2013. The car went around the town. They were driving for 30 minutes, made all the turns and he said imminent. Imminent meaning that okay like in a couple of years this technology will become ubiquitous because the car was doing everything. Google 2024 a way car an industry leader lost the the point I'm going to talk about the the the maps later. It has lost it and you can see the person inside. Please bear with me while I am. Yeah, I got a flight to catch. Why is this thing going in a circle? I'm getting dizzy. It's Look at what it's doing. I understand. I'm really, really sorry, Mike. We're currently working with the situation of a vehicle. Is it circling around a parking lot? Right. It's circling around a parking lot. I got my seatelt on. I can't get out the car. Has this been hacked? What's going on? I feel like I'm in the movies. Scab calling from what to show. Right. And this is another favorite video of mine. I will I will let you know why why I'm doing this, why I'm showing all these videos to you. So, there's this guy with a stop mark on his t-shirt and he found out that all these driverless cars stop when when they see when they see him when they [clears throat] see the mark. And my own example from my own personal experience, I went to China at the invitation of BU. They have one of the biggest autonomous car parks in in the world. 1,500 driverless cars in Wuhan. They showed me the technology, their cars, and 3 minutes later, this happened. The car wrongly detected an object and it drove into the solid lane markings area and just stopped. It thought it was standing at the traffic lights and it thought everything was fine. So, it's not detecting an issue. It's just standing there. It doesn't understand the environment, the context. It doesn't know that I need to go somewhere. It just stopped and wasn't budging. So a person had to to intervene and and start driving. Why is all this happening? Why are we and the whole world investing a huge amount of resources and time and money into it and we achieved this point where",
        "start": 291.919,
        "duration": 835.6180000000004
    },
    {
        "text": "to go somewhere. It just stopped and wasn't budging. So a person had to to intervene and and start driving. Why is all this happening? Why are we and the whole world investing a huge amount of resources and time and money into it and we achieved this point where issues. Let's have a look at a couple of lines of code. It's very straightforward, a very simple scenario. It's based on an algorithmic approach. When we are writing a code, we we do this manually. Each action of a car is written manually as a code. It says here, if you see a pedestrian, stop. If you see another car, [snorts] stop. It's very simple. But if we start writing code for everything that might happen in public rows, we can look at this code scrolling down for 15 years and there will still be more code. There is this term in industry long tail. The longtail problem, what does it mean? First, it starts very quickly, very easily. As Andre Karpov said in the video, he said 2012 in 2013, Google was taking leaps forward and there were driverless cars in the streets of the cities. They they took another step forward. They invested millions and millions. Okay, we have code for everything. What else can arise? And then we have this guy with a stop mark on his t-shirt and the car fails. It loses its point. It stops unexpectedly and this is just San Francisco. So there are more and more scenarios coming up and you cannot code for each and every scenario manually. You can't code for anything that might happen in the world. You go from San Francisco to Moscow and you have new cultural context to to factor in new new signs etc. We've been writing this code for 15 years and we're still not finished. So presumably it's not even possible, but it's not that bad. We have a new approach based on Gen AI that I'm going to to talk about. We see that the industry is changing very rapidly since 2024 and this is one of the examples Tesla has started to deliver cars. You buy a car online, you click the button, you pay for the car, the the car leaves the factory, and it goes straight to your house. Tesla also launched this taxi service in Texas. They invested $5.6 billion. Wave is this new startup. from 2018 they started off the article called attention is all you need and they decided to develop their own software on AI algorithms. They decided to take Genai transformer architecture and decided to build their own software. And as of today or rather at the end of 2024, they announced that they would bring their cars to 500 different cities across the globe and then they will start the car and without any preparation the car will drive around each one of the 500 cities. Then BU started to scale up",
        "start": 476.96,
        "duration": 1234.9780000000003
    },
    {
        "text": "or rather at the end of 2024, they announced that they would bring their cars to 500 different cities across the globe and then they will start the car and without any preparation the car will drive around each one of the 500 cities. Then BU started to scale up forth. Those are just some of the examples. 2024 became a year of a lot of changes and disruptions. We saw that a lot of tech companies started to scale up their business very rapidly, changing very rapidly. Let's have a look at the changes. What I told you in the beginning the algorithmic approach. Let's have a look at how it works. sensors have cars, radars, cameras. All of the information they collect goes to the block called perception, the perception of the environment. This block reads the information and sends it down the line to prediction and planning along with high accuracy information from maps and localization information. I highlighted the blocks called prediction and planning. When they worked based on algorithmic approach, you had to program each and every action of a car manually. I told you why that doesn't work. But it's not that bad. What Google started to do and BU and Yandex back in 2024 was they started adopting Gen AI models and they started integrating transformers into their technology. We took the problem fraud block, we integrated a transformer into it and started to train that block with a transformer and with information about human behavior. And then it started to handle complicated situations like accidents or unexpected emergency situations. But still the guy with a stop sign on his t-shirt is still a problem. Why? Because to solve the problem, the car needs to be able to understand the environment, the the world. The developers said, \"We can train the perception block to make it perceive that guy with a stop sign and make sure the car doesn't stop in response.\" We try to do this and we see that there is the stop sign. There is a person nearby just smoking a cigarette and the block perception says do not stop. The conclusion from this is that to solve the problem of self-driving cars and to implement this on mass next time I ask you this question who drove here in a driverless car I hopefully we will see more hands hopefully we will have had people who used Navio or or other cars we need a technology ology that understands the world. This technology at the moment is VA as many companies including ours find promising. I will briefly out outline how this works and how we are creating this VA. We take Zbar's model and based on this we create the VLA model. So has giga chat the LLM model that works with language. Then the model turned into Giga vision. Andre Bft have talked about this today. This model is called VLM vision language",
        "start": 681.76,
        "duration": 1629.8969999999997
    },
    {
        "text": "we are creating this VA. We take Zbar's model and based on this we create the VLA model. So has giga chat the LLM model that works with language. Then the model turned into Giga vision. Andre Bft have talked about this today. This model is called VLM vision language it and turned it into VLA. What does it enable you to do? So, we do driverless cars, but this approach, this model can also be used to control robots, drones. You saw a dancing robot robot today. It's sophisticated model. You didn't see drones today, but you can imagine how they work. So, this approach works for everything. We apply this to transport but this architecture can be applied to any physical object. Let's have a look at the technology in more detail. How does it work? We collect big data from the world text, audio, video, label data, data that we put into a car to make it distinguish between a person and a sign and another car. We pack it into a big data set, training data set. We fine-tune the model or we or rather we pre-train the model. it's a generalized model that you can use at a later stage to create applied technology and then we have our VA model which we fine-tune with reinforcement learning and all kinds of things. lots of fine-tuning methods. I will not give you the details of the architecture because we do not have the time for it. We have a photo realistic simulator that helps us test and validate models. But we also use synthetic data to train the model. Complex data from the world. Moscow for example. I'm sure you've never seen a an elephant on the roads of Moscow, but in Thailand, you may see it. We don't want to go to Thailand and collect data there. Instead, we have the simulator. We can create or recreate this scene, this environment, and use it to train the model. And then importantly, this part called optimization and distillation. Before the model reaches a physical object, they work without connection to the internet. This model runs on a small computing unit to make sure it works efficiently with a low latency. We need to optimize the model and to make it small and and powerful. It's a very big area [snorts] of expertise. And then this optimized model with the reasoning with the understanding of the environment can be used to control all kinds of physical objects. Navia used the model to control transport. Starting from starting in 2024, we started to integrate Gen AI into our solutions. We were doing mainstream cargo transportation and we had successful solutions there based on the algorithmic approach I talked about in the beginning but we couldn't make our cars drive in the city. 170 driverless cars running around the city but not in commercial operation. This year we have done a number of breakthroughs, incredible technological",
        "start": 896.16,
        "duration": 2032.6950000000006
    },
    {
        "text": "and we had successful solutions there based on the algorithmic approach I talked about in the beginning but we couldn't make our cars drive in the city. 170 driverless cars running around the city but not in commercial operation. This year we have done a number of breakthroughs, incredible technological technology can help us bring our products taxi cars, buses, into the urban environment onto city roads. I'm sure you've noticed our bus, the shuttle bus. I would like to show you a video of it. It's not a mockup. We have several cars like this. We've been testing it. it is there driving along city roads. I want to show you what Genai enabled us to do in with our products. Heat. [music] Heat. [music] [music] Thank you very much. Round of applause for Gregori Forestski. [music]",
        "start": 1107.36,
        "duration": 2113.0160000000014
    }
]