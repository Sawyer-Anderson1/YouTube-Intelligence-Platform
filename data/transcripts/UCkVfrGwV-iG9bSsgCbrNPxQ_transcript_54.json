[
    {
        "text": " So, OnX Robotics just introduced their new AI humanoid robot companion, [music] and we have to talk about it. So, this is the new robot that was just released, and it's honestly taken over Twitter in the last 24 hours. I've seen many different comments, many different statements, and I have to say, by far, this is once again one of the most impressive humanoid robots for a number of different features. I mean, it's incredible. It's engineered to perform everyday chores, personalized assistance, and leverage real world data to continuously improve its capabilities. Now, I think most people are underestimating the [music] impact of this because they don't realize the significance of a humanoid robot that is home ready, but in this video, I'm actually going to try and communicate that to you as best as possible. So, what I will do is I will play for you guys the first section of the video and then I can dive into the seven sections that are the most important for [music] understanding truly why this is such an impactful release. Neo was engineered from the ground up for safety. Its tendon-driven body is quiet and lightweight. Its low energy motions make it uniquely safe for you and your home. But safe doesn't mean limited. Neo's hardware comes packed with features like human level dexterity and a 55lb carrying capacity so that can handle any of your chores reliably. We also worked really hard to make Neo's design friendly and comfortable to be around. Each Neo comes with a machine washable knit suit, a head, and shoes that you can customize to fit your style. As for using your Neo, we made the experience simple. Out of the box, the core of your experience is fully autonomous. The chores feature lets you schedule a time for your Neo to do all of your chores so you can come back to a cleaner home every day. With the AI companion feature, you can talk to your Neo to get assistance with anything from a hard question to a household task. With Neo's autonomy, you can get access to all of its latest AI features to get help [music] with tasks on demand. And the Neo app lets you interact with your Neo from anywhere, but all you have to do to get started is turn on your Neo and introduce yourself. So, one of the first features is essentially called chores. Now, what chores allows you to do is have the Neo to perform specific household tasks on demand according to a set schedule. You know, you can assign chores through a mobile app, voice command, or preset routines. And typical chores involve tidying rooms, folding laundry, carrying items, watering plants, and even operating appliances. So yes, that means it can operate any machine that you'd like. Now, what's really cool is that even if it doesn't know how to, you know, really, really, really do your strange and weird",
        "start": 0.08,
        "duration": 304.4799999999999
    },
    {
        "text": "typical chores involve tidying rooms, folding laundry, carrying items, watering plants, and even operating appliances. So yes, that means it can operate any machine that you'd like. Now, what's really cool is that even if it doesn't know how to, you know, really, really, really do your strange and weird and telly operate the task it hasn't mastered yet, which essentially just means that a human can, you know, control the robot from a facility and it will be able to get the task done. So, what's really cool about that is that the system manages to learn over time when a human operator helps with a new task and then Neo can practice and eventually automate that task for future requests. And I think it's really cool because you not only have a robot that's able to learn over time. Imagine when you have this really strange issue and the robot is able to solve it remarkably quickly because someone else who had a neo robot also encountered the same issue. And one of the things I think is really cool is that, you know, once your robot is doing all of these chores, you can literally just pop out your phone, see what it's doing while you're out at maybe your, you know, dinner or it is whatever it is you're doing, maybe you're at work, and you can see literally what your Neo is getting up to. And another thing as well is that it has selfcharge [music] enabled. Now, on the website, it didn't really have much information on the runtime, but I was able to find a tweet from Eric Jang, who works on the AI at 1x Tech, and essentially he said that the robot does charge quickly, and the goal is to minimize the time spent charging versus the time working, and that in-home charger is never far away. So, I'm guessing that the robot doesn't have a ridiculous amount of runtime. And the 2 to 4 hour thing, I really don't think it's as bad as most people think. Now, here's where we have companion mode, which is really cool because this moves the robot from just an actual, you know, cleaner or someone who does your laundry to an actual friend and an actual helper. And I think this is pretty useful for a variety of different use cases that I will talk about later on in the video. But I think this demo is relatively useful for showing you what the future of AI human collaboration will be on a completely different level. Everyone talks about AI human collaboration at work and what they're going to do for the economy. But what about those tasks that are simple? The ones that are in your home or your house where you know you do need a little bit of help and an AI could easily easily help you with that situation. Take a look at the first",
        "start": 151.76,
        "duration": 576.4799999999996
    },
    {
        "text": "do for the economy. But what about those tasks that are simple? The ones that are in your home or your house where you know you do need a little bit of help and an AI could easily easily help you with that situation. Take a look at the first this is something that most people will find is genuinely a pleasant surprise. I can't seem to find my glasses. Is this paprika? No, that's cayenne pepper. Also, your glasses are on your shirt. Could I use this in my chili? They're both made from chili peppers, and you could put cayenne in your chili, but it is much spicier. Neo is a speech enabled AI companion made for any kind of conversation. Where other AI assistants are confined to your phone or computer, Neo lives with you in your physical space, and has the ability to see, hear, and remember things about your surrounding environment to provide you with uniquely helpful assistance. For example, it can suggest what to cook based on what you have in the fridge, remember your progress while teaching you new language, and even give you interior design advice. The gestures and the light rings express Neo's intentions. Its audio intelligence can also pick up on whether you are addressing it or someone else in the room to decide if it should respond or not. As you might expect from a home robot, talking to Neo with natural language is the primary user interface for all of Neo's functionality, including autonomy. Now, what I really like about 1X's Neo is the fact that they've been really intentional with their design. We can see that Neo is really soft in how it's built. I mean, if you look at other humanoid robots, they are mechanical. They've got visible joints, rigid frames, and 1X took the complete opposite approach. They essentially went internal. Instead of building a robot that looks human, they built one that actually feels human to interact with. It has these soft edges, the quiet motors, a very gentle grip. So when Neo reaches out to help someone, there's no jarring sound. There's no cold metal. It's motion that feels safe. So that, you know, internal design philosophy allows Neo to exist comfortably in homes, hospitals, and care centers, which is exactly the kind of space where people need the trust and not the tension. Now, you have to understand that there are people with mobility challenges and even the smallest tasks can become daily obstacles. Picking up dropped items, carrying groceries, opening doors. Neo was trained using reinforcement learning and human demonstration to perform those actions naturally, not like a machine, but like a companion. And those built-in sensors allowed for fine-tuned pressure control, meaning it can hold a glass of water as carefully as it can lift a heavy object. And with its built-in, you know, visual recognition system and AI decision system, it can really easily identify",
        "start": 290.639,
        "duration": 862.7189999999995
    },
    {
        "text": "a machine, but like a companion. And those built-in sensors allowed for fine-tuned pressure control, meaning it can hold a glass of water as carefully as it can lift a heavy object. And with its built-in, you know, visual recognition system and AI decision system, it can really easily identify being asked. And another thing that you might miss is that they didn't stop at the physical design. Of course, they focus deeply on the communication. The speech interface is warm and responsive, and it's actually built to interpret natural human language, tone, and emotion. For people with speech impairments or cognitive challenges, Neo adapts not just responding to words, but to patterns and gestures. And this is subtle empathy. And it's not synthetic. It's intentional. And that's why I believe that this product is truly truly revolutionary. It's probably the gold standard for what will be a multi-billion dollar industry. Now, this is where we take a look at the full autonomous mode. Now, autonomous mode uses Redwood AI to let Neo operate independently, navigating, manipulating objects, and performing complex multi-step tasks without human guidance. The robot uses its vision language action model and reinforcement learning to assess its environment, plan actions, and dynamically adjust movements for cleaning, fetching, organizing, and more. And in this mode, Neo can move throughout the house, avoid obstacles, handle unexpected scenarios, and even generalize to entirely new situations. And as it learns, it continuously improves its performance at real world chores and interaction by uploading data for ongoing model refinement, closing the autonomy gap with each deployment. And these modes make Neo [music] so flexible. You've got full autonomy, AI companion mode, and you've got the chores mode. Take a listen to what they say because I think once again this is, you know, where we have essentially that exponential. Robots are going to be in homes collecting data. They improve and the entire fleet becomes more effective over time. Your Neo comes with Redwood AI, enabling it to do basic household tasks autonomously. Yeah. No, for sure. Okay. One sec. All right. Yeah. Hey, Neo, can you get the door, please? Neo's autonomy works by taking requests like, \"Hey, Neo, can you take this cup to the sink for me?\" and breaking it down into simple steps [music] such as walking to the person, grabbing the cup, and then walking the cup to the kitchen, and then putting it away. Neo's autonomy improves with diverse data and real world experience. As Neo does more chores, you'll receive updates to your Redwood model that increase the complexity of tasks that Neo can handle, such as finding your keys and wallet or doing a full laundry cycle end to end. Eventually, Neo will become fully autonomous, capable of helping you with anything around the house. The Neo you get today will only get better and as we keep shipping features, it'll be more and more useful in your everyday life.",
        "start": 436.24,
        "duration": 1160.079999999999
    },
    {
        "text": "wallet or doing a full laundry cycle end to end. Eventually, Neo will become fully autonomous, capable of helping you with anything around the house. The Neo you get today will only get better and as we keep shipping features, it'll be more and more useful in your everyday life. Redwood AI, it's really cool because it's actually their breakthrough vision language transformer. It's actually customuilt for their neohumoid to achieve real world autonomy in household environments. Essentially, Redwood AI merges vision language understanding and whole body manipulation into a single neural model. has about 160 million parameters and runs fully on board Neo's embedded GPU, enabling privacy, low latency, and offline action execution. Even if verbal commands still rely on cloud for processing, it fuses vision tokens from cameras, language embeddings, and prop prior, which are joint and force data for an integrated understanding of the robot's physical space and commands. And this Redwood AI essentially empowers Neo to perform end-to-end mobile manipulation, fetching objects from new or unseen locations, opening doors, and the model is able to generalize to novel subjects and spatial arrangements, not just memorizing scenarios from the training data. And what's really cool about this is that each deployed Neo acts as a real-time data factory. And one of the things that I know people will say is that is this thing fully autonomous? Is this thing, you know, doing all the tasks by itself? And honestly, that isn't entirely true. This is a later point, but I'm going to bring it up now. One of the issues, maybe not issues, but one of the things is that these Neo bots, a lot of the time in those scenarios where you're going to have an expert mode, people are going to have privacy concerns. Number one, because, you know, you're going to have someone else who's able to see inside your house. You know, I mean, I'm all [music] for privacy and of course, a random person. and you don't know who they are. They're just in an office somewhere controlling a robot and now they are in your house and they're able to pretty much do anything that the robot can realistically physically do. That is of course a privacy concern because you know you might be doing something. Now of course you will have to approve this privacy mode, this expert mode and enable this person. But I think another reason that there are, you know, these privacy concerns is because in areas where the robot may fail or, you know, there might be some catastrophic failure where they need to intervene, people are wondering how that data is going to be stored if they're, of course, going to be using that to train other fleets. Now, this is a very valid concern. We do know that many, many tech companies in the past haven't been able to really secure our data and have even sold it in some extreme",
        "start": 587.36,
        "duration": 1443.8679999999995
    },
    {
        "text": "to be stored if they're, of course, going to be using that to train other fleets. Now, this is a very valid concern. We do know that many, many tech companies in the past haven't been able to really secure our data and have even sold it in some extreme how that is, but they have actually cleared this up on the website and they have said that for example, Neo's emotive earrings will change to a color while the expert operator is active and owners have full control over each session. And you know, the experts are not some random people in some, you know, random office. They're fully verified 1x employees that are physically present in the USA. and the fact that Neo works without the need for data sharing in autonomous mode. And in an autonomous mode, limited sensor data might be sent to their servers to fulfill a request. So, it isn't stored. And of course, you're able to opt out for sharing and improving Neo's performance. So, when you see these demos of the robots being teleyoperated, which is essentially being controlled by another human, you might think that hm are we being sold something that is, I guess you could say, maybe not a scam, but maybe too good to be true. I guess I wouldn't say so. I haven't actually used the robot yet, so I wouldn't know. But I do say I'm extremely optimistic for this. Now, another thing that you may be wondering is how much does this robot cost? Well, the robot costs around $20,000 for early access or you can wait for the standard roll out in I think mid2026 for $499 per month. Now, that's fascinating because most humanoid robots are ridiculously expensive and they don't come with as nearly as much features as this kind of robot. So, for the price, you are getting an absolute steal. Now, this isn't a sponsored video, but honestly, $499 for a robot that can basically act as a second helper around the house that has access to onboard cuttingedge AI is able to help you pick things around. I mean, it will seem like a no-brainer for certain care homes and the elderly, especially since a lot of those tasks are physically demanding. And I do think that this is actually a pretty good thing because if this was too expensive, then maybe the people who needed this the most wouldn't be able to afford it. So, I'm actually glad that they're able to price this effectively so that consumers can get their hands on this because honestly, some of the other humanoid robots, I've seen them and they're like $250,000, $100,000. And I understand robotics is extremely expensive. So, to be able to produce this at scale is a remarkable feat. So, let me know what you think about the 1x humanoid robotics. I think it's actually pretty interesting. I think most people are underestimating",
        "start": 730.988,
        "duration": 1732.6680000000003
    },
    {
        "text": "them and they're like $250,000, $100,000. And I understand robotics is extremely expensive. So, to be able to produce this at scale is a remarkable feat. So, let me know what you think about the 1x humanoid robotics. I think it's actually pretty interesting. I think most people are underestimating this is probably kicked off a very interesting area where humanoid robots are going to be in the house. Most people have seen humanoid robots in the factories and that's of [music] course the big juicy application for all of these tech companies. But in the home, it's going to be a super niche market that I think soft body robots are going to completely dominate.",
        "start": 877.199,
        "duration": 1769.7080000000003
    }
]