[
    {
        "text": " So, this is Sema 2, Google's new AI agent. It can play video games it's never seen before. It can understand drawings and emojis and natural language, and it can think about its goals, talk to you, and even improve itself without any human help. And today, I'm going to be showing you guys why this might be one of the most important steps towards AGI that Google has ever taken. So, what you're seeing on screen is not a human playing a video game, but rather Google's latest iteration of their SEMA agent, an AI agent that plays and reasons in virtual worlds. I think most people don't realize just how incredible this thing is because the implications of this technology are truly profound. An AI agent that can reason, plan, and achieve tasks in a virtual world is not that far off from an agent that can do that in the physical real world. Now, understand that this AI agent is Google's second iteration, and it can do a variety of different things that the previous iteration can do, and it's a relatively large jump in terms of performance capabilities. Take a look at Sema 1 compared to Sema 2. In this first example, you can see that Sema 1 is asked to go up and slightly left to the little cave and mine to get some coal. it completely fails that goal. But Sema 2 is able to complete that goal to a T. It's able to do the goal completely successfully on its own after being prompted. Understanding that you can give an AI agent a small goal in a virtual world and it's able to complete that is absolutely incredible. Now remember the reason that this is incredible is because the SEMA agent has never seen this task before. It's not been trained on this task in the way that previous AI models are usually trained. who was only asked go up here do this task and it goes ahead and successfully executes the task. Now remember this is a big jump from SEMA 1 to SEMA 2 and that's why I think this is truly profound. Take a look at task completion success rates. Look at SEMA 1. Sema 1 is at a 31% success rate whereas SEMA 2 nearly doubles in performance at a 65% rate only a mere 10% away from human performance at a 75%. Understanding that this AI agent is 10% less successful than a human would be at agentic tasks in video games. I think you have to understand that an AI agent almost reaching human performance in just nearly two iterations is completely incredible. What do you think happens on SEMA 3 or SEMA 4 or maybe SEMA 5 or SEMA 6? It's probably going to be very close to 100% on those benchmarks if we map things out into the future. And you have to understand this is pretty incredible. This is a model",
        "start": 0.16,
        "duration": 312.0800000000001
    },
    {
        "text": "do you think happens on SEMA 3 or SEMA 4 or maybe SEMA 5 or SEMA 6? It's probably going to be very close to 100% on those benchmarks if we map things out into the future. And you have to understand this is pretty incredible. This is a model unseen environments. Compare SEMA 1 to SEMA 2 and you'll see that in previously unseen environments, SEMA is able to successfully perform an increasing number of tasks in those unseen environments. Remember, a lot of the times the reason for benchmark scrutiny on current gen AI tools is because the AIs may have seen the tests before and thus the benchmarks aren't truly representative of what the model may do. But we know in these tasks that the AI agent had not seen the benchmarks before and it's playing the game for the first time and we can see a rapid jump from Sema 1 to Sema 2 in previously unseen environments. Take a look again. Look at Sema 1 being asked to find a campfire. It, you know, runs around, runs into the wall. It realistically can't find out where that campfire is, but Sema 2 is able to navigate the terrain, rotate around, look around, see the campfire in the top left, then drag the character all the way there and find it. Truly incredible. Now, what's also interesting is that we do have Genie 3. Now, if you don't know what Genie 3 is, Genie 3 is Google's AI simulation software. In order for you to understand why this is so amazing is because Sema 2 was able to successfully navigate terrains in Genie 3. Genie 3 is the groundbreaking AI model developed by Google which is essentially a world model with real-time interactivity. Unlike previous AI models that produce static or short video, Gen3 allows people to not only generate the digital worlds, but explore dynamically, modify and interact with them for several minutes at a time. Genie 3 has world memory, meaning you're able to perform tasks in this digital world that you just generated and the AI is able to remember those tasks with world memory. So if you, you know, draw some paint on a wall and then you come back to that section of the wall, the paint will still remain there, which is a really impressive tool because this allows us in the future to train agents potentially in an environment that would otherwise be quite difficult to. Now, what's cool about this is that, of course, we saw the SEMA 2 agent being able to complete tasks successfully in this virtual world of Genie 3. And I think this is once again a remarkable achievement, just showcasing how incredible this technology is. Sema 2 is successfully able to see a flower, fly over to the flower, and identify it, and then, of course, tell the user what kind of flower that is. You have to",
        "start": 156.72,
        "duration": 596.48
    },
    {
        "text": "And I think this is once again a remarkable achievement, just showcasing how incredible this technology is. Sema 2 is successfully able to see a flower, fly over to the flower, and identify it, and then, of course, tell the user what kind of flower that is. You have to two technologies. Genie3, the world simulator, and of course, Sema 2, the AI agent that can explore virtual and digital worlds to showcase just how effective this AI agent is. Now, what's impressive about Sema 2 is that it's able to perform long context tasks. As you know, if we want an AI agent to successfully be able to act and reason in the real world or even to act as a brain for humanoid robotics, it's going to have to be able to, of course, complete long context tasks such as going ahead and doing different tasks that have multiple different steps in order to achieve certain goal. Most goals are broken up into sub goals, and we can see that Sema 2 successfully manages to do this in this video game. You can see it's able to refuel the torch. is able to go to the window and complete a remarkable number of different activities provided the user continues to enter the prompts. I think this is once again one of those areas where this is pretty surprising. Often times you would think that the initial model Sema 1 was just relatively limited because you could only prompt it to go and do one thing. However, with Sema 2, they have the ability to now do long context tasks. Meaning that if your task requires a lot more steps, Sema 2 is able to understand that long goal, continue to perform those actions that will eventually reach you to set goal. This is of course, like I said, extremely important in the real world. Environments are constantly changing, things are constantly happening, and you have to ensure that your agent is robust enough to reach the end goal while still staying on task and not getting distracted. The fact that Sema 2 can already do this is remarkably impressive. Now, one of the most impressive things is the self-improvement. This is something that I think most people skipped on the announcement of Sema 2. You see, SEMA 2 has a self-improvement cycle. And this diagram shows how Sema 2 teaches itself using Gemini as its brain supervisor. Think of it as an AI life cycle where the AI agent plays the games, learns what's wrong, evaluates itself, then gets better, and that repeats. So, we can break this down. We of course first have the AI agency. This is the AI player that is actually acting inside the 3D world. It does things like look at the screen using the vision. It uses the virtual keyboard, the mouse controls to move, explore, interact, and it talks to the user through the chatbot. Now,",
        "start": 301.04,
        "duration": 870.3989999999997
    },
    {
        "text": "have the AI agency. This is the AI player that is actually acting inside the 3D world. It does things like look at the screen using the vision. It uses the virtual keyboard, the mouse controls to move, explore, interact, and it talks to the user through the chatbot. Now, gameplay experience. Number two is we have the task setter, which is Gemini. This is Gemini giving the agent the tasks. Find wood, go build a shelter, mine stone. It doesn't just tell Sema what to do, it tells the goal and the action steps. In effect, Gemini is the mission designer. Then, of course, three, we have the reward model. This is where you evaluate how well the agent performed. Did SEMA 2 achieve the task? How good were its actions? Was it going in the right direction? And the human doesn't even need input here. The reward comes from the entire model itself. And this is where you've got the self-generated experience. Every action the agent takes, every success and failure is stored here. This is Sema's memory of everything it has tried, the examples stored, what's worked, what strategies were efficient, what actions led nowhere, and later this data is fed back into the training to make SEMA 2 smarter. And this is important because this means that no human gameplay needed. There's no handl data required. AI improves from its own actions and this scales to infinite worlds via Gen3. And remember, this is the foundation of self-improving AI agents, which is the core requirement for AGI. Take a look at this example of self-improvement with SEMA 2. At first, it tries to extinguish the campfire, and then it gets it wrong. But after a little bit of training itself, it can then go ahead realize which tool it's supposed to use, which button it's supposed to press, and then it's able to extinguish the campfire. Imagine an agent that is existing in a digital world and it's able to quickly figure out the different ways that it can modify that world, the different ways that it can move in that world, and all of the different possible capabilities in order to achieve its goal. Now, imagine not only is an agent able to do that, but remember this is a self-improving agent. What we just talked about was the ability to play video games, but not only that, but also in Genie 3. Now remember, Genie3 is a world model simulator, which means that what if an AI agent was able to dream up a world of our exact reality. And of course, this is a very far-fetched idea. But imagine it was able to train itself in that idea, try and achieve its goals, see where it would fail, and then successfully when deployed in the public know exactly where to go. That is, of course, a far-fetched idea. But if it's able to do this in a video game where it",
        "start": 440.8,
        "duration": 1135.7599999999995
    },
    {
        "text": "able to train itself in that idea, try and achieve its goals, see where it would fail, and then successfully when deployed in the public know exactly where to go. That is, of course, a far-fetched idea. But if it's able to do this in a video game where it retries, imagine it's able to do that in its own world model, planning, plotting, thinking about what it's going to do, and thus self-improving on the fly. This is incredible when you think about the future implications. Remember, Simma 2 can transition to learning new games exclusively through self-directed play. Meaning that a lot of the times what you can see from Simma 2 is that it doesn't need to have played the game before in order to be able to be successful at that game. It was able to develop skills in previously unseen worlds without adding human generated data. To me, that sounds like some of the percentage points you need in order to get to AGI. SEMA 2 was also able to understand different languages, understand different commands, understand different emojis, meaning that it isn't limited by poorly written goals. It's able to understand a diverse set of prompts, and a diverse set of goals, meaning that it could really understand the nuance of what you do want. And I think this is remarkably important because many prompting systems, you know, that we currently use are remarkably fragile. But an agent that can, you know, truly understand what your goal is. And even if you don't write the prompt in the right language or it's, you know, the one that it was trained on in most ways, it can still go ahead and achieve said goal to a remarkable degree. And remember, we discussed that, you know, it can generalize across different games. It's able to complete tasks on games that it simply hasn't played before. So if it's able to do this, we can imagine what the future implications of this are. If an AI agent is able to generalize those capabilities where it trained in one environment and transfer those to another environment and achieve successfully those goals, that is a profound discovery. You have to understand that every single game has different rules, different objects, different physics, and different controls. If an AI can understand a task in Minecraft, then apply that same concept to a different game, and then use it in a world that it has never seen before, it means that the AI isn't simply memorizing, it's thinking. And crossgame reasoning means that it has some form of general intelligence. Now, remember, it makes it really hard. Minecraft is voxal based. The other game, Ascar, uses different realistic physics, and Hydronir, the other game they used, has resource chains. Tearown has destructive voxal physics and the Genie3 worlds that they're generating aren't even real. It's all AI generated randomness. In order for the AI to successfully reason across all of these,",
        "start": 575.04,
        "duration": 1417.037999999999
    },
    {
        "text": "The other game, Ascar, uses different realistic physics, and Hydronir, the other game they used, has resource chains. Tearown has destructive voxal physics and the Genie3 worlds that they're generating aren't even real. It's all AI generated randomness. In order for the AI to successfully reason across all of these, concepts and map those to a totally new environment and adapt when those things don't work. So remember, AGI is not about passing a math test. It's about understanding your environments and behaving intelligently inside them. And SEMA 2 does some of those things needed for AGI. perception. It can see the world like a human. Action. It controls games using keyboards and mouse, not hidden APIs. It can also reason. And it can also generalize. And this is the big one. Generalization across different games. Applying those concepts to new worlds is a core AGI benchmark. And that's things that humans do automatically that AI almost never does. Which means the SEMA 2 is closing the gap. Now, you have to understand that this is truly impressive for robotics. You see, robots live in the real world, but the real world is basically a game engine with infinite complexity. A robot needs to understand spaces, navigate unpredictable environments, manipulate objects, achieve goals, and recover from its mistakes. This is exactly what SEMA 2 trains for inside of 3D games. Virtual worlds are safe, cheap, and there's infinite training grounds for embodied intelligent. So if an AI agent can see, act, reason, adapt, and learn new tasks inside any digital world, it's learning the same principles that a robot needs. And crossgame reasoning could arguably be transferred to cross environment robotics. You see, the problem that we currently have with robotics is that robots fail when you take them out of their training environment. Sema 2 shows the ability to learn concepts in one world and reuse them in a totally different world and adapt instantly. And this is what a real robot must do when moving from the factory floor to a home, from one kitchen layout to another, from structured tasks to open-ended human environments. And this level of abstraction is the missing link for household robotics. And the self-improvement also means that robots can learn without manual human training. Human label data is expensive. Real robot world training is slow and dangerous. Simo 2 does self-play, self-critique, self-reward, and self-training. That means future robots can learn like this. They can try an action, evaluate themselves, improve on themselves and then repeat. No massive data sets, no massive teleoperators, no lab technicians. This unlocks scalable robotic learning which is the biggest bottleneck today. And SEMA 2 doesn't use API commands. It moves using virtual hands, virtual eyes, virtual movement controls. And this is the digital equivalent of a robot using arms, sensors, actuators, and joints. Learning to control complex actions via pixels is basically the same as mapping directly to robots controlling limbs via sensor",
        "start": 717.279,
        "duration": 1722.638999999999
    },
    {
        "text": "2 doesn't use API commands. It moves using virtual hands, virtual eyes, virtual movement controls. And this is the digital equivalent of a robot using arms, sensors, actuators, and joints. Learning to control complex actions via pixels is basically the same as mapping directly to robots controlling limbs via sensor worlds, it can master the real one. Robotics is the ultimate problem. The world is too complex to train in and the simulations are too limited. But Genie 3 and Sema 2 shows that unbounded simulated worlds, infinite variety with no human data, continuous improvement. This could potentially be the dream pipeline. Now, there are a few limitations such as a relatively short memory and it must use a limited context window in order to achieve a low latency interaction. And of course, it's still challenging to achieve some goals. I do think that this is certainly the right step on the path to AGI.",
        "start": 872.0,
        "duration": 1788.160999999999
    }
]