[
    {
        "text": " Yesterday was dominated by Chad GPT Atlas, OpenAI's new agentbased browser can control the browser on your behalf. But Google launched something incredibly interesting. They released a vibe coding product built on top of Gemini. Simply type in what you want built and it will build it for you within the browser from idea all the way to production. All of the code is there. You can roll back, you can roll forward, and it is specifically built for AI applications. And so here it is. This is what it actually looks like. You can use it right now for free. So you can select the model right here. Of course, I'm going to select Gemini 2.5 Pro. You can also hit the I'm feeling lucky button, which basically just builds you something completely random, or you can look through all of their examples, which they provide down here. So Nano Banana Powered app. Let's go ahead and click that. And then we describe our idea. But rather than describing it, let's hit I'm feeling lucky. And there we go. So, build a mobile first web app for generating phone wallpapers. Users describe their current desired vibe. And the app generates four variations in 9x6 aspect ratio. Let's go ahead and click build and I'll show you what that looks like. So, here on the left side, we can actually see how long it's running for. We can see that it's thinking. We can click in and see its chain of thought, which is really nice. And then down here is where we can make changes, add new features, and so on. And it's already building. So this is kind of the beginning of the application. You can switch the device preview. So if you want to see it on a desktop versus a phone, if we click the little code button here, we can actually see the code being built out. Look at that. Lightning fast. Gemini is just so great for coding. We switch back to the preview. Still just building out all the files. Now, let's fast forward. Let me show you the completed product. And here it is. So you can see down here we can view the diff. We can restore checkpoints. But for now, rainy, cyberpunk, loi. Let's do it. Generate. And there we go. We have four different wallpapers. Actually, these look quite good. So we can download it. We can remix it. And again, this was built in 78 seconds. That is nuts. Now, from here, you can copy the app, you can download the app, you can save it to GitHub, you can deploy it so people can use it. And it is so easy. You really don't have to write any code at all. Logan Kilpatrick replied to one of the comments asking about features that are coming. So, let me share that with you so you know what's coming. The real challenge is integration things like",
        "start": 0.08,
        "duration": 298.3199999999999
    },
    {
        "text": "use it. And it is so easy. You really don't have to write any code at all. Logan Kilpatrick replied to one of the comments asking about features that are coming. So, let me share that with you so you know what's coming. The real challenge is integration things like authentication, and API building. And all of this is coming. So, congratulations to Google and Logan. This is awesome. I'm definitely going to be playing around with it. All right. Next, Unitry has released a new robot. This is the Unit H2 Destiny Awakening. And so, let me show you what it can do because the demo video is actually quite impressive. Unitry continues to have one of the most impressive humanoid robot fleets out there, and it's actually purchasable. You can actually buy these things, but I'm still waiting for the figure robot. And by the way, if you love large language models and you want to give them superpowers, check out the sponsor of today's video, Zapier. Zapier just launched unified co-pilot and it makes it dead simple to automate your entire workflows. The Zapier UI is already easy, but they went ahead and made it even more simple by allowing a conversational interface to just describe the automation you want built and it does it for you. So just type in what you want and Copilot creates it for you across zaps, tables, interfaces, and agents all at once. Copilot understands the context across your entire Zapier stack. Plus, they added human in the loop so you can make sure that you're checking in at the vital points of your workflow creation. Zapier also rolled out 30 plus new integrations including perplexity, mistrol, and cursor. So, with over 8,000 apps and integrations, enterprisegrade security, and fully managed hosting, Zapier makes AI automation accessible to everybody. So, check out Unified Copilot. Let me know what you think. Make sure to click the link down below. That lets them know I sent you. It helps us. It helps them. Thanks in advance. Now, back to the video. All right. And next, Gemini 3.0 rumors have been heating up. So, it really seems like we're going to be getting Gemini 3.0 imminently. And apparently, the new Gemini 3.0 models are available in LM Studio under the code names Orion Mist and Lithium Flow. And they are extremely good. So, according to DD partner at Menllo Ventures, extremely good with web UI, no purple tinge, very aesthetic, rounded corners, state-of-the-art at SVGs, and 3D Minecraft meshes. So, here's an example of Orion Mist. Here's Voxil Sim City. And there we go. You can see it's pretty nice. Can zoom into it. Here's a Rick and Morty episode, Zeroshot coded by Orion Mist. Let's check this out. URRP infinite scalability. Oh man, Rick, what's the back quote div back quote doing? Okay, that's not so good. But remember, this is just completely vibecoded. It is not a video generation model. So, very",
        "start": 149.92,
        "duration": 628.8799999999997
    },
    {
        "text": "Here's a Rick and Morty episode, Zeroshot coded by Orion Mist. Let's check this out. URRP infinite scalability. Oh man, Rick, what's the back quote div back quote doing? Okay, that's not so good. But remember, this is just completely vibecoded. It is not a video generation model. So, very soon. You know, I'm going to be testing it and I'll share those tests with you. Next, Apple released three products refreshed with the brand new M5 chip. If you haven't been using Apple Silicon to run your inference, it is incredibly powerful. And now with the M5 chip, we get even more power. And they are really leaning into the fact that these chips are excellent at running inference locally. Listen to this. Apple unleashes M5, the next big leap in AI performance for Apple silicon. M5 delivers over four times the peak GPU compute performance for AI compared to M4. Featuring a next generation GPU with a neural with a neural accelerator with a neural accelerator in each core. a more powerful CPU, a faster neural engine, and higher unified memory bandwidth. Now, a lot of people have been talking about the Nvidia DGX and comparing it to Apple's Mac Mini. And of course, there are a lot of comparisons. For pure inference, though, the Apple Mac Mini and other Apple devices are going to be faster. Now, the DJX has its place. I'm putting together a few thoughts on where that kind of very unique device should live in your stack. So, stay tuned for that. So, I mentioned there are three products getting the updated M5 chip, and those are the 14-inch MacBook Pro, which I am so tempted to buy right now, the iPad Pro, and the Apple Vision Pro. So, Apple has really everything they need to do something very special in artificial intelligence. The only thing they don't have is the actual artificial intelligence. So, I'm really just hoping every single day they do something major in the space. So, I'm really just hoping every single day they finally invest heavily into building a better version of Siri and really embracing artificial intelligence because until now they haven't. Next, we got a new model from 10 cents Hyan. Today we are open sourcing Hyun World 1.1, a universal feed forward 3D reconstruction model. This new version significantly expands the input scope by unlocking video to 3D and multiv- view to 3D world creation. And remember the Hanyan world models are exactly that. They are world simulation models. So it is open source. It is open weights. So go have fun, download it, play around with it. Let me know what you think. All right. Next, I want to talk about the Andre Carpathy interview with Dwarkh that continues to be on the tip of everybody's tongue in Silicon Valley and the AI world. Now, PJ on Twitter put together a list of quotes from the interview from his follow-up",
        "start": 341.44,
        "duration": 951.7599999999994
    },
    {
        "text": "what you think. All right. Next, I want to talk about the Andre Carpathy interview with Dwarkh that continues to be on the tip of everybody's tongue in Silicon Valley and the AI world. Now, PJ on Twitter put together a list of quotes from the interview from his follow-up Now, I don't agree with that, but these quotes are very interesting. Let's go over them. So, first, LM don't work yet. They don't have enough intelligence. They're not multimodal enough. They can't use computers and they don't remember what you tell them. They're cognitively lacking. It'll take about a decade to work through all of that. Now, a lot of that is being solved with scaffolding, with actual memory, with tool use. But Carpathy is right that the core model, the actual weights of the model can't do any of that, but that's not really necessary. And continuing on that point, when you boot them up, they always start from zero. But again, they don't have to. All of the scaffolding around them allows them not to have a cold start every single time. But maybe it's necessary. Maybe the weights of the model do need to update and do need to remember things. What's stored in their weights is only a hazy recollection of the internet. This I kind of agree with. They're just really memorizing what they've seen. It's just a compressed blur of 15 trillion tokens squeezed into a few billion parameters. Their context window is just short-term working memory. They're also good at imitation, terrible at going off the data manifold. So, they're relying too much on their memory, and they're not able to generalize nearly enough. Next, tying it to the human brain, we've probably recreated the cortical tissue, pattern learning, and general, but we're still missing the rest of the brain. No hippocampus for memory, no amygdala for instincts, no emotions or motivations. They memorize perfectly but generalize poorly. And anything truly new, code that's never been written before, ideas that have no template, they stumble. I don't know. We've already seen models come up with novel scientific ideas. In fact, it came up with an improved matrix multiplication algorithm, and we've already seen it be a co-author on certain research papers. I just wanted to share this with you, kind of giving you both sides of the argument. I don't think we're anywhere near the peak of the AI bubble. And even if we are, the upside over the next decade or two are so large, I'm not even worried about it. And a quick thank you to Dell Technologies for sponsoring this portion of the video. Check out the new Dell Promax workstation with Nvidia RTX Pro Blackwells built in. This thing is an absolute beast for AI workloads. With NVIDIA RTX Pro, you now have a supercomput sitting on your desk, and it can do more with local AI than ever before. So, learn more about Dell Pro",
        "start": 503.52,
        "duration": 1250.5599999999993
    },
    {
        "text": "new Dell Promax workstation with Nvidia RTX Pro Blackwells built in. This thing is an absolute beast for AI workloads. With NVIDIA RTX Pro, you now have a supercomput sitting on your desk, and it can do more with local AI than ever before. So, learn more about Dell Pro below to let them know I sent you. And speaking of scientific breakthroughs, our next story, Google has announced their quantum computer has reached a new milestone. Sundar Pitchai today on Twitter. New breakthrough quantum algorithm published in Nature. Today, our Willow chip, which we talked about a few months ago, has achieved the first ever verifiable quantum advantage. Willow ran the algorithm, which we've named quantum echoes, 13,000 times faster than the best classical algorithm, on one of the world's fastest supercomputers. This new algorithm can explain interactions between atoms in a molecule using nuclear magnetic resonance, paving a path towards potential future uses in drug discovery and material science. And the result is verifiable, meaning its outcome can be repeated by other quantum computers or confirmed by experiments. This breakthrough is a significant step toward the first real world application of quantum computing and we're excited to see where it leads. And Elon Musk commented, \"Congrats. Looks like quantum computing is becoming relevant, which is awesome.\" Now, quantum computing has narrow use cases as compared to more traditional computing. But for those use cases, they are incredibly powerful and important. Martin Skrey says, \"Contrived results still not faster/advantage.\" So, little bit of both sides of the argument there. I'm incredibly excited for quantum computing, but also I'm optimistic generally on technology. So, of course, I'm excited for it. And in our last story, Meta's Alexander Wang, their new head of artificial intelligence, as of a couple months ago, has started laying off folks in the fair division, FIR. That is the division run by Yan Lun. Meta is cutting several hundred roles from its AI unit even as it continues to hire for its newer TBD lab. Axios has learned the company concluded that its long-standing AI efforts had become overly bureaucratic and hopes the reorganization will create a more agile operation. According to an internal memo seen by Axios, here is a quote. By reducing the size of our team, fewer conversations will be required to make a decision and each person will be more loadbearing and have more scope and impact. Meta chief AI officer Alexander Wang wrote in the memo. The cuts will affect the company's fair AI research product related AI and AI infrastructure units. But here's the interesting part. The company is encouraging affected employees to apply for other jobs within Meta and expects most will find another position internally. So, the Alexander Wang shakeup continues. So, that's it for today. If you enjoyed this video, please consider giving a like and subscribe.",
        "start": 656.079,
        "duration": 1572.7179999999992
    }
]