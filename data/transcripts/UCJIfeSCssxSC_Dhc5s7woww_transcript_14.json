[
    {
        "text": " Let's talk about timeliness Uh specifically timeline to AGI or ASI. Is it fair like as a starting point to say that nobody really agrees on the definitions of AGI and ASI? I kind of think there's a lot of disagreement but among I've been getting push back where a lot of people kind of say the same thing which is like a a thing that could reproduce most digital economic work So like the remote remote worker is a fairly reasonable example And I think OpenAI's definition is somewhat um related to that which is like an AI that can do a lot of con like a certain number of economically valuable tasks which I don't really love as a definition but I think it could be a grounding point because um language models today while immensely powerful are are not this remote worker drop in and there are things that you could think of that are could be done by an AI that are way harder than remote work which are like solving a finding an unexpected scientific if discovery that you couldn't even posit Which would be an example of something that somebody says is like an artificial super intelligence problem or like taking in all medical records and finding linkages across certain illnesses that people didn't know or figuring out that some common drug can treat some niche cancer Like they would say that that is like a super intelligence thing So these are kind of natural tears My problem with it is that it becomes deeply entwined with like the quest for meaning of AI and this religious aspects to it So there's kind of different there's different paths you can take it And I don't even know if the remote work is a good definition cut what exactly is that It's like perfect tool used I actually I mean I like I don't know if you like the originally titled AI 27 report They focus more on code and research taste So the the target there is the superhuman coders So they have several several milestone systems Superhuman coders superhuman AI researchers then super intelligent AI researcher and uh then the full ASI artificial super intelligence But the after you develop the superhuman coders everything else falls quickly There the task is to have a fully autonomous like automate coding So any kind of coding you need to do in order to perform research is fully automated and from there humans would be doing AI research together with that system and they will quickly be able to develop a system that's actually can do the research for you That's the idea and then and initially their prediction was 2027 28 and now they've pushed it back by 3 to four years to to uh 2031 mean prediction probably my prediction is even beyond 2031. But at least you can in a concrete way think about how difficult it is to fully automate programming",
        "start": 2.96,
        "duration": 358.239
    },
    {
        "text": "and initially their prediction was 2027 28 and now they've pushed it back by 3 to four years to to uh 2031 mean prediction probably my prediction is even beyond 2031. But at least you can in a concrete way think about how difficult it is to fully automate programming presumptions and dynamics on how it would play out Um, but I think they did a good like they did good work in the scenario defining milestones that are concrete and to tell a useful story which is why the reach for this AI 2027 document well transcended Silicon Valley is because they told a good story and they did a lot of rigorous work to do this I think the camp that I fall into is that like AI is like so-called jagged which will be excellent at some things and really bad at some things I think that when they're close to this automated software engineer what it will be good at is that traditional ML systems and front end the model is excellent at But the distributed ML, the models are actually really quite bad at because there's so little training data on doing large scale distributed learning and things and this is something that we already see and I think this will just get amplified and then it's kind of messier in these tradeoffs and then there's like how do you think AI research works and so on So you think basically superhuman coder is almost unachievable meaning like because of the jagged nature of the thing you're just always going to have gaps in capabilities I i I think it's assigning completeness to something where the models are kind of superhuman at some types of code and I think that will continue and people are creative so they'll utilize this like incredible abilities and like to fill in the weaknesses of the models and move really fast There'll always kind of be this I've perceived for a long time this dance between the humans are enabling this thing that the model can't do and the best the best AI researchers the ones that can enable this superpower and I think this aligns like to what we already see I think like cloud code for building a website you can stand up a beautiful website in a few hours or do data analysis and I don't think it's going to keep getting better at these things and it'll pick up some new code skills and stuff that it'll get along the way and kind of linking to what's happening in in big teach is This AI 2027 report is like it leans into the singularity idea where I think research is messy and social and largely in the data in ways that AI models can't process But like what we do have today is really powerful and these teach companies are all collectively buying into this with tens of billions",
        "start": 182.64,
        "duration": 616.3999999999999
    },
    {
        "text": "it leans into the singularity idea where I think research is messy and social and largely in the data in ways that AI models can't process But like what we do have today is really powerful and these teach companies are all collectively buying into this with tens of billions going to get some much better version of chat GBT a much better version of cloud code than we already have I think that it's just like hard to predict where that is going But the like bright clarity of that future is why some of the most powerful people in the world are putting so much money into this And I think it's just kind of small differences between like we don't actually know what a better version of TIGBT is but also like can it automate AI research I would say probably not at least in this time frame like big teach is going to spend $und00 billion much faster than we get a automated AI researcher that enables a AI research singularity i So you think your prediction would be what like if this is even a useful milestone we're more than 10 years out i I would say less than that on the software side but I think longer than that on the things like research Let's just like for fun try to imagine a world where all software writing is fully automated Like can you imagine that world i By the end of this years the amount of software that's be automated will be so high But it's like it'll be the things of like you're trying to train a model with RL and you need to have multiple bunches of GPUs communicating with each other That'll still be hard but I think it'll be much easier One of the ways to think about this the full automation of programming is just think of like lines of useful code written The fraction of that to the number of humans in the loop So presumably there's be for a long time humans in the loop of software writing is just be fewer and fewer relative to the amount of code written right And the the the SC superhuman coder I think the the presumption there is it goes to zero the number of humans in the loop What does that world look like when the number of humans in the loop is in the hundreds not in the hundreds of thousands i I think software engineering will be driven more to system design and goals of outcomes where I do think software is largely going to be come on I think this has been happening over the last few weeks where people have gone from a month ago of like oh AI agents are kind of sloppy which is a famous carpentry quote to like the what is a little bit of a meme of like the industrialization of software when anyone can just create",
        "start": 313.44,
        "duration": 894.3999999999994
    },
    {
        "text": "over the last few weeks where people have gone from a month ago of like oh AI agents are kind of sloppy which is a famous carpentry quote to like the what is a little bit of a meme of like the industrialization of software when anyone can just create think we are closer to that side of things and it takes direction and like understanding how the systems work to extract that best from the language models and I think it's hard to like accept the gravity of how much is going to change with software development and how many more people can do things without ever looking at it I think what's interesting is to think about whether these systems will be um independent like completely independent in the sense that well I have no doubt that LMS will kind of at some point solve coding in a sense like calculators solve calculating right so at some point humans developed a tool that you know you never clears throat need a human to calculate that number you just type it in and it's an algorithm you you can do it in a in that sense and I I think that's the same probably for coding but the question is so I think what will happen is yeah you will just say build that website it will make a really good website and then you maybe refine it But will it do things independently where so will you be still having humans asking the AI to do something like will there be a person say build that website or will there be AI that just builds websites or something or whatever i I think using talking about building websites is the i too simple It's just like there there's the the the problem with websites and the problem with the web you know HTML and all that kind of stuff i It's very resilient to just i slope It will show you slop as good as showing slope i I would rather like think of like safety critical systems like i uh asking AI to end to end generate something that manages logistics i or manages cars a fleet of cars all that kind of stuff So end to end generates that for you I think a more intermediate example is take something like Slack or Microsoft Word. I think if the organizations allow it AI could very easily implement features end to end and do a fairly good job for like things that you want to try You want to add a new like tab in Slack that you want to used And I think AI will be able to do that pretty well i Actually, that's a really great example How far away are we from that i Like this years i See, I don't I don't know I don't know I I guess I don't know how bad production code bases are but I think that",
        "start": 454.96,
        "duration": 1161.1189999999992
    },
    {
        "text": "able to do that pretty well i Actually, that's a really great example How far away are we from that i Like this years i See, I don't I don't know I don't know I I guess I don't know how bad production code bases are but I think that lot of people are going to be pushed to be more of like a designer and product manager where you have multiple of these agents that can try things for you and they might take one to two days to implement a feature or attempt to fix a bug and you have these dashboards which I think Slack is actually a good dashboard where your agents will talk to you and you'll then give feedback But things like like I make a website it's like you want to make a logo that's passable Like I think these like cohesive design things and this style is going to be very hard for models and deciding on what to add the next time i I just Okay, so I hang out with a lot of programmers and some of them are a little bit on the skeptical side in general That's just vibe wise they're like that I just think there's a lot of complexity involved in adding features to complex systems Like if you look at the browser Chrome, i if I wanted to add a feature if I wanted to have tabs as as opposed to up top I want them on the left side i Mhm. i interface right You I think we're not this is not a next year thing One of the Claude releases this years one of their tests was we give it a piece of software and leave claude to run to recreate it entirely and it could almost rebuild sir like slack from scratch just given the parameters of the software and left in a sandbox environment i The scratch part I like almost better i So it might be that the smaller newer companies are advantaged and they're like we don't have to have the bloat and complexity and therefore this future exists And I think this gets to the point that you mentioned that some people are you talk to are skeptical and I think that's not because the LM can't do XYZ. It's because people don't want it to do it this way Some of that could be a skill issue on the human side Unfortunately, we have to be honest with ourselves and some of that could be an under specification issue So programming like you're like you're just assuming this is like in in relationships and friendships communication type of issue You're assuming the LM somehow is supposed to read your mind I think this is where spec driven design is really important Like you just using natural language specify like what you want i I think that's like if you talk to",
        "start": 589.839,
        "duration": 1426.4789999999996
    },
    {
        "text": "in relationships and friendships communication type of issue You're assuming the LM somehow is supposed to read your mind I think this is where spec driven design is really important Like you just using natural language specify like what you want i I think that's like if you talk to their training in production code Like cloud code is built with cloud code and they all use these things extensively and Daario talks about how much clouds code own and it's like these people are slightly ahead in terms of the capabilities they have and they probably spend on inference they could spend 10 to 100 plus x as much as we're spending like we're on a lowly$100 or $200 a month plan like they truly let it rip and I think that that like with the pace of progress that we have it it seems like like where a year ago we didn't have cloud code and we didn't really have reasoning models and it's like the difference between sitting here today and what we can do with these models and it seems like there's a lot of like there's a lot of low hanging fruit to improve them the failure modes are pretty dumb It's like Claude you tried to use the CLI command I don't have installed 14 times and then then I sent you the command to run It's like that thing from a modeling perspective is pretty fixable i So I I i I agree with you be been uh becoming more and more bullish in general Speaking to what you're articulating I think it is a human skill issue So, Anthropic is leading the way in or other companies in understanding how to best use the models for programming Therefore, they're effectively using them I think there's a lot of programmers on the outskirts They're like they don't I mean there's not a really good guide on how to use them people trying to figure it out Exactly. i It might be very expensive Like it might be that the entry point for that is $2,000 a months which is only teach companies and rich people which is like like that could be it i but it might be worth it I mean if if if the final result is is a working software system that might be worth it But by the way it's funny how we converge from the discussion of timeline to AGI to something more pragmatic and and useful Is there anything concrete and interesting and useful and profound to be said about timeline to AGI and ASI or are these discussions a bit too detached from the day-to-day? There's interesting bets So there's a lot of people trying to do reinforcement learning with verifiable rewards but in real scientific domains where there's startups that are spending like they have hundreds of millions of dollars of funding and they have wet labs where they're having language models propose",
        "start": 725.2,
        "duration": 1699.8389999999984
    },
    {
        "text": "day-to-day? There's interesting bets So there's a lot of people trying to do reinforcement learning with verifiable rewards but in real scientific domains where there's startups that are spending like they have hundreds of millions of dollars of funding and they have wet labs where they're having language models propose world And I I would say that I think they're very early or they're early but with the pace of progress it's like i yeah i maybe they're early by six months and they make it because they were there first or maybe they're early by eight years You don't really know So I think that that type of moonshot to um branch this momentum into other other sciences is like okay like that would be very transformation if like alphafold moments happen in all sorts of other scientific domains by like a startup solving this I think there are startups I think maybe harmonic is one where they're going all in on language models plus lean for math I think you had another podcast guest where we talked about this recently and it's like we don't know exactly what's going to fall out of spending $100 million on that model and most of them will fail but a couple of them might be big breakthroughs that are very different than try GPT or cloud code type software experiences like a tool that's only good for a PhD mathematician but makes them 100x effective like i okay I agree I think this will happen in a lot of domains especially also like domains that have a lot of um you know resources like finance and legal and pharmaceutical companies but then again is it really AGI again because we are now specializing it again and then again is it really that much different from back in the day how we had specialized algorithms I think it's just the same thing more way more sophisticated but I don't know is there a threshold when we call it AGI I guess I think the the real cool thing is here that we have like the foundation models that we can specialized I think that that's like the breakthrough at some point Right now I think we're not there yet because well first it's too expensive but also you know like chi doesn't just give away their chad to customize it I think once that's going to be true in some way and I think I can imagine this as a business model that JPD open says at some point like hey you know bank of America for 100 million we will do your custom model or something like that and I think that will be the huge economic uh value add The other thing though is also companies I mean right now what is the differentiating factor I mean if everyone uses the same LLM if everyone uses JPD they will all do the same thing",
        "start": 863.76,
        "duration": 1975.5189999999986
    },
    {
        "text": "something like that and I think that will be the huge economic uh value add The other thing though is also companies I mean right now what is the differentiating factor I mean if everyone uses the same LLM if everyone uses JPD they will all do the same thing moving in lock step but usually companies they want to have a competitive advantage and I think there's no way around using some of their private data and experimenting and maybe specializing it's going to be interesting yeah i sitting in the pace of progress it does just feel like things are coming I don't think the AGI and ASI thresholds are particularly useful I I think I guess the real question and this takes us to the remote worker thing is when are we going to see a a big obvious leap in e economic impact cut currently there's not been an obvious leap in economic impact of LLM models for example and that's you know aside from AGI or ASI or all that kind of stuff there's a real question of like when are we going to see a GDP like i Mhm. Mhm. i junk i Yeah. It's like what is the GDP made up of Like a lot of it is like financial services So like I don't I don't know what this is It's just hard for me to think about the i GDP bump But like I say that software development becomes valuable in a different way when you no longer have to look at the code anymore So when when it is like cloud will make you a small business which is essentially cloud can set up your website your bank account your email and your whatever else and like you just have to express like what you're trying to put into the world like that's not just a enterprise market but it is a hard like I don't know how you get people to try doing that I guess if chat can do it like people are trying i I think it boils down to the the scientific question of how hard is tool use to solve Because a lot of the stuff you're implying the remote work stuff is to tool used It's like how computer use like how you have an LM that goes out there this argentic system and does something in the world and only screws up i of the time i Computer use is a good example of what labs care about and we haven't seen a lot of progress on We saw multiple demos in 2025 of like Claude can use your computer or OpenAI had KUA and they all suck i Yeah. i So like they're also investing money in this And I think that would be a good example where that's actually something where it just seems pretty like taking over the whole screen seems a lot harder than having an API",
        "start": 1002.72,
        "duration": 2262.1589999999987
    },
    {
        "text": "OpenAI had KUA and they all suck i Yeah. i So like they're also investing money in this And I think that would be a good example where that's actually something where it just seems pretty like taking over the whole screen seems a lot harder than having an API some of that is you have to then set up a different environment for the model to work in Like they're not working on your MacBook. they are individually interfacing with Google and Amazon and Slack and they handle all these things in a very different way than humans do So some of those might be structural blockers also like specification wise I think the problem is also for you know arbitrary tasks uh well you still have to specify what you want your LLM to do and how do you do that in a what is the environment how do you specify you can say what the end goal is but if it can't solve the end goal with LLMs if you ask it for text you can always you know clarify do subsets what is how how do you put that information into a system that let's say books a travel trip for you you can say \"Well, you screwed up my credit card information But even to get it to that point like how do you like as a user guide the model before like it can't even attempt that I think the interface is really hard i Yeah, it has to learn a lot about you specifically i and about this goes to continue learning about the general mistakes that are made throughout and then mistakes that are made through you All the AI interfaces are getting set up to ask humans for input I think cloud code we talk about a lot It asks feedback on questions If it doesn't have enough specification on your plan or your desired it starts to ask questions Would you rather Um, we talked about memory which saves across chats which i it's first implementation is kind of odd where it be like it'll mention my dog's name or something like in a chat I'm like you didn't need to be subtle about this like I don't care But the like things that are emerging are chat GBT has the pulse feature i which is like um a curated couple paragraphs with links to something to look at or to talk about and people talk about how the language models are going to ask you questions which I think is a very it's probably going to work The language model is like it knows you had a doctor appointment or something It's like hey how are you feeling after that Which is like i um again goes into the territory of humans are very susceptible to this and there's a lot of social change to come But also like they're experimenting with having the models engaged Some people",
        "start": 1149.039,
        "duration": 2521.119000000001
    },
    {
        "text": "appointment or something It's like hey how are you feeling after that Which is like i um again goes into the territory of humans are very susceptible to this and there's a lot of social change to come But also like they're experimenting with having the models engaged Some people it processes your chats and automatically searches for information and puts it in the chat GBT happy So there's a lot of things coming i I used that feature before and I always feel bad because laughter it does that every day and I rarely check it out It's like how much money like I mean compute is burned on something I don't even look at you know where it's like it's kind of i there's also a lot of idle compute in the world so don't feel too i laughter",
        "start": 1280.32,
        "duration": 2572.799000000002
    }
]