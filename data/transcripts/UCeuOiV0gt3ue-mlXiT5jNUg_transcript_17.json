[
    {
        "text": " And we are continuing when there's a lot of data and not a lot of time. Not only results but the way you train neural networks is important from classical black prop with its deepness and the limitations in the industry to stochcastics configurations. what works in a more stable way on the real production line and we will learn that just now. Professor of the University of Science and Technology of Tinta, Jan Huay questions, problems and developments in the field of machine learning. Hello. very glad to have opportunity to talk something in Russian. So that's my first time in this country. I I think I spent some time travel around in the last two days. I found Moscow is a quite expensive place. Okay. I think today I will share my knowledge and my research experience on machine learning. Okay. So what I will say issue challenges and development. All right. So so this is especially for application for industry. Okay. people talk a lot about machine learning deep learning in the past. but from my perspective for real industry application okay or we talk about industry AI I think not enough people start being wearing a ve something okay but where is the solution so that's really I think significant for further development now I think let's see where I'm living. Indeed I'm Australia citizen. Okay. My home is in Melbourne, Australia. but now for some reason I came back. now I'm leaving here. Okay. So here is a Beijing and here is a Chinda. Right. Here is a Moscow. So this is a city where I'm living in now Chinda. Okay. So is a cast city. Okay. very good environments. That's a university I'm working now. I think some philosophy for doing research. I think different people have different opinion. Okay. To me I think we need to understand something. everything we hear is opinion probably not the facts everything we see is perspective not the truth okay so this is from Marcus Roma employer today I will talk I think three things challenging development and perspective that's from my personal point of view okay I think in the end for doing research I believe logic will work and the great tools are always simple. Okay, that means if you make the learning algorithms very complex I don't think is a good solution. Okay. Now I think let's talk something about AI technology means process industry. Okay. composition of process in industry. We have a device, we have a material and then we have parameter. Okay. so this process parameter really matter. So will affect maybe the power the energy you you you used also will affect affect the the quality stability of your products. Okay, that's obvious. Then we have some association with machine learning about this how we can make these products stable and how to save energy. So here we have several things including modeling, automation and intelligent",
        "start": 8.32,
        "duration": 588.7999999999998
    },
    {
        "text": "you you used also will affect affect the the quality stability of your products. Okay, that's obvious. Then we have some association with machine learning about this how we can make these products stable and how to save energy. So here we have several things including modeling, automation and intelligent backgrounds from computation math and went to control theory and the end my PhD is industry automation. So that's why so I can understand this stuff. Okay. now take a look lightweing lightweight model we need in next generation of industry automation. Okay. So there goes scalability. So that means we use age computing based IoT based application. Okay. So we have a system adaptation. So we need a very fast tuning of your your machine learning models. Okay. And then real time automization. So far we have a neuronet solution different haristic solutions but to my opinion I probably should go to randomized approach. Okay. So randomized approach not we never say optimal solution but feasible solution. Okay. And control algorithms. So nowadays I think very popular people use P and sometimes for delay system P doesn't work. So most of industry partners they told me they are interested in de developing nonlinear or adaptive MPCA. So model predictive control. So in model predictive control what's a big deal the big deal comes from the model predictive model. So that's is say modeling you build predictive model so the model can work with a high accuracy and robustness okay against some external environments change but this is very important for industry okay so all things I think are certain okay probably from the sensor probably from the careless of the operators nobody knows suddenly changed uncertain. Okay. So in such environments how we use the collected data to build a model. So the model can perform as expected. Now so the first part let's talk a little thing about issues and challenges in machine learning. the first paper very influ I think published in nature okay 1986 so 96 this paper is talking something about this type of neuronets and ideally the neuronets fe forward fully connected we called multi-perceptive model right but this model cannot be trained because The active function is step function. because people feel very difficult how to we understand the model is capable to solve some problem but the key is we don't know how to find the parameter of the model okay so that time I think the paper come out published in nature and people talking about we can use this sigma model function to do sim approximation of the step function. So in this way we can use the bregation greater than descent approach very simple mathematical optimization solution right so that's all time after this p work published I got thousand thousand word publish in different way to improve the learning algorithm even use fuzzy logic okay how to change the learning rates, how to",
        "start": 308.32,
        "duration": 1115.6009999999994
    },
    {
        "text": "can use the bregation greater than descent approach very simple mathematical optimization solution right so that's all time after this p work published I got thousand thousand word publish in different way to improve the learning algorithm even use fuzzy logic okay how to change the learning rates, how to And then the next year 1987, so three group of people from Japan, from United States, from Germany, they publish a piece of work. Okay. Talking about universal approximation property of such network model. Now I think two years ago a group of people from Cambridge for a UK they they have a workshop talking about these kind of things neuronets robust reliable how to improve these performances. Then I gave a talk I think in the end people after discussing we conclude something. So universal approximation property just give people hope but nothing to do with design. Okay. Because here I believe probably you know neuronets you train neuronets and put this model into practice. Okay. But the first thing appear on top of your mind is how to design. Okay. How many neurons in the head layer? How many layers? Nobody can give a very clear guideline. Okay. So this is the current status. now because of this so people already when I can't say exactly wrong direction I have to obser learning algorithm promote these AI developments but I can't say too much about this maybe wrong direction okay now you say Why brooation? I will show you a simple example, numerical example. Then you understand what's why we have to use think the bregation is something. Okay. now let's have a look at this simple numerical approximation function approximation. Okay. So the blue is the function to be approximated. Now we run MATLAB a standard tools. Okay, I saw you different epochs. So 50 epochs and then the neuronet model perform like this the red line. Okay. So I don't think you you will be happy with the performance right after I think 2,000 epochs training we spent 35 seconds. Do you think you are happy with the performance? I don't think lot of people talk too much about learning deep learning but nobody really pay attention. So this is totally wrong. We have no trust, no confidence you can get a model well trained to perform your task. Okay, so this is a very simple numerical example. You can imagine if the the task became so complicated how you can believe your model your training algorithm works. Okay. Now another practical case study. So the data is I think from northeastern university. we p try to predict these three parameters. So this material these three parameters play key roles. So let's try to use a bergation mop with a bergation. Okay. So you look we made 100 trials the green is the error for generalization prediction. Okay, that's I think you can see very unstable. Okay, what's wrong with this burggation? Because initialization make a",
        "start": 575.04,
        "duration": 1660.1609999999991
    },
    {
        "text": "parameters play key roles. So let's try to use a bergation mop with a bergation. Okay. So you look we made 100 trials the green is the error for generalization prediction. Okay, that's I think you can see very unstable. Okay, what's wrong with this burggation? Because initialization make a the weights can raise a new model and the model converging to local minima. Okay, whatever. Done. Finish. So then I test the the model. Okay. So you get 100 trials and then the error very unstable demonstrate this unstability. So when people talking about reliability do you think the reliability of this MLP with fabrication is good? I don't think so. Very unstable. So we I have developed with my students some we call the stoastic configuration network and then the performance comparing with this bregation based MLP I think much improved okay so you can tell that's a prediction performance okay now let's say something development of this machine learning techniques that's my I'm citing my enough. Okay. that's a stcastic configuration network. now that's I think some I feel is a original innovative and then real time data processing and then we try to interpretate the process how we construct this model incrementally. Okay. Now I just show you the example the same example for function approximation. I use just 33 epochs. I spend the time 0.36. I can build a model exactly like this 100 times faster. But I can make very accurate approximation as you can see. Right. So this simple example shows something demonstrate. So this is stcastic configuration network really can work. Okay. Especially is a lightweight model. Okay. That's why today I came here. I spent nine hours and 40 minutes from China flying here. I share with the knowledge with you. Okay. Now I I just let me introduce briefly what I say it is. we have a different versions. you can find it even you can download the code from my home research homepage. So this is we have a term called a bridge mop multi-layer perceptive model but we have a bridge MIP. So that means from input layer to the output we have a direct link also each layer we have a link to the output. So this is a bridge the only the lines in right we need to evaluate other parameters for example in the in the in the black random assignment finish one pass and also we have this incrementally constructed rather than given architecture you tune the parameter doesn't work. Okay, even you think mathematically doesn't work. at least so the air for the learning it cannot be zero cannot be free zero free but this way I can result the model very quickly build a model and then mathematically we proved so that's error free that means universal approximation property holds okay now this is a key contribution from my group So that's published in 2017 in cybernetic cybernetics. So here",
        "start": 851.279,
        "duration": 2180.2809999999995
    },
    {
        "text": "zero free but this way I can result the model very quickly build a model and then mathematically we proved so that's error free that means universal approximation property holds okay now this is a key contribution from my group So that's published in 2017 in cybernetic cybernetics. So here randomized learning. So they have no constraint illogical thinking simply they assign random parameter here in the black lines. Okay. and evaluate the right line just using this square. So very fast you can see thousand thousand publications about this. I I I do believe somehow is misleading or poor understanding. Okay. So I'm the person just broke this illogical understanding and I think I draw a a right direction for this randomized learning. Okay. let's have a look. sorry because this is a diamond I don't know how to control this. doesn't matter. Okay. So let's share some practical application. So real case study. Okay. So you can have a little bit more belief about this action. Okay. So this we have a datadriven software sensing system. So that's a widely used for industry. Okay. we that's a inputs and then we try to predict this grading parel particle size okay so currently this still I'm in the loop still in process this project with a big company okay so now what I'm trying to show you is the comparison results with the well-known MMP okay trained I bergation you look mop this is a training performance a test performance and ours so RVI files is a constraint free randomized learning algorithm so random microfunctional link are still a lot of people around the world they still trying to use this RV file but theoretically ally I can prove okay can I always outperforms than RV file so this is the work we published in transaction industry informatics last year okay so averse so our can outperform now is another example so currently I got involved I'm the director for these the the the key contributor for developing intelligent control system. Okay. So this system is very difficult to to be controlled very vable but very challenging. Okay. So this is poly silicon reduction furnace probably you don't know you can check after this meeting okay conference now let's use the closed loop data to model okay because I have no open loop data available only closed loop data available okay let's use a closed loop data to build and see what's happen. Okay. so this is the inputs and then we have the output. So in total we have 44 42 inputs but these inputs we sampling okay some inputs in different in time instant and we have 15 output. So this wattage and itization level. So this is very important because we can't measure the temperature on surface. So no other ways we have to do some indirect way to control the system. So hopefully this design this mop will have a good performance. Okay.",
        "start": 1118.88,
        "duration": 2739.6409999999996
    },
    {
        "text": "we have 15 output. So this wattage and itization level. So this is very important because we can't measure the temperature on surface. So no other ways we have to do some indirect way to control the system. So hopefully this design this mop will have a good performance. Okay. already. Now let's have a look the performance. Okay. So we set up we exper set up the the experiments like this. So 24 and the first layer 93 and the second layer 304 neurals. Okay. Then we spend probably two hours time we got the the neuronet stuff. if we run MOP the same architecture using fabrication forget it maybe you'll get maybe one day time okay converging very slowly and then the performance very poor okay so let's have a look what are the results we obtained by using stocastic configuration network so indeed is a deep version we applied these terminal conditions and stop early stopping. Okay. also we apply the regular regularization we pro the smart pertibbation then now 40 runs the real runs from the industry we collect the data right and then we use another 20 runs data to do testing. So you look so this is the I think just for one wattage you can see that's a closed loop data so we can predict model perfect right you look at this atomization level using right the tools backgrounds and the model output are must fitting very well so this is I think two K industry case studies I saw you right now I think the last parts I express my perspective this machine learning is partially for industry application for next generation of automation. Okay first I think scalability and the flexibility here scalability everyone understand. So we goes the machine to be controlled maybe not a single one a group right a group attacks. So we have to consider how you design the control system. If flex I think IoT based okay control system design rather than like a before single one and also flexibility here refers to adaptation capability because the data we collect just like a closed loop data offline but in the real time when we do this modeling we have to tune the model using the near nearly collected data right so this step that's we call adaptation so we need the very fast tuning you think imagine if we have neuronets with millions parameters can we do the job in real time because the sampling is very limited for example 3 minutes even seconds you have to get the the job done. Okay. Tuning the parameter adaptation the model. Now I think AI and machine learning offer more intelligent solution. so this I think we can't avoid in the future next generation of industry automation system design. So now I think we have [snorts] this AI algorithm on my hand our hands to further develop. Okay. A lot of people think maybe generative model large scale",
        "start": 1406.24,
        "duration": 3260.440999999999
    },
    {
        "text": "offer more intelligent solution. so this I think we can't avoid in the future next generation of industry automation system design. So now I think we have [snorts] this AI algorithm on my hand our hands to further develop. Okay. A lot of people think maybe generative model large scale this is for social not for industry. H you think of this for industry. Do you think that's a big deal more important than social information technology? You're right. Trail with interactive. so this is I think people have to consider this. I heard a lot of competition among the nations in the future is how you can produce lightweight model. Okay. So st stochcastic configuration network itself is live weights already. So I can use binarized weights in the in the model as well. Okay. Now I think physics informed the neuronets already became in the past 10 years publish a lot in nature science and relent generous. So that idea is we have governing equations. So basically is try to solve the problem limited data subsides cannot generate a good learning model with good generalization. So this is the idea. So we have something constrain we have some data available collected. So how we use these two information and to build a machine learning model. So here is something I read a lot of publications but I find still something wrong. Okay. Not not enough. also I believe my personal opinion I think knowledge based informed the neuronets should be a very promising direction in the future. For example, we understand output variable is monotonic with respect of special inputs and what to do. Can we embiding such knowledge into learning process? Okay, very important key conference reference that's my master supervisor my pure my lifetime friend Ian Turkey from Scott okay I appreciate a lot we discuss a lot and collaborate personally and professionally thank you all for listening attention Okay. [applause] yeah, thank you so much. my contact information dh.1 at deep.com my research homepage my WeChat if you are using WeChat and here some advertisement opportunities for taking posttock position under my supervision in China if you like. Okay. no limits. The number is open now. we have CIC scholarship available. I think now is still opening. if you like you can apply online. So here the last line is in Russia so you can rate easily. Thank you so much. Okay. [music] Thank you so much. Thank you for sharing your experience with us. Thank you. [music]",
        "start": 1669.6,
        "duration": 3697.8989999999976
    }
]