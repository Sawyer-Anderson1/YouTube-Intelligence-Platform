[
    {
        "text": " Thanks to Recraft for sponsoring this video. More on them later. Anthropic has released Claude for Chrome, taking a much more direct approach than Perplexity Comet. You can install Claude for Chrome just by using a Chrome extension. Now, it's currently being released as a research preview. I actually got access and I'm testing it out right now. So, be sure to subscribe so you could be the first to know when I drop the video reviewing it. Cloud4 Chrome allows Claude to control your browser, specifically Chrome. So, check this out. You click the little button in the top right for the extension. It opens up. Feels very similar to Perplexity Comet. You type in what you want and then it actually will control your browser. So here's Zillow. Here's a doc. Here's Door Dash. Let you order Salesforce entries. So again, we're getting to this place in which agents are more and more going to control the browsing experience for humans. But of course, in very anthropic style, they are rolling it out very slowly. As I mentioned, research preview first because there are a lot of dangers, not only for the AI agent to actually do something it shouldn't, but bad actors on the internet exploiting that. All models can be jailbroken and people can exploit that simply by changing the website that you want your AI agent to browse. And so it says right here, browser use brings several safety challenges, most notably prompt injection. So, if you're on the Max plan for Claude, you can sign up to join the wait list right now. I'll drop a link down below for that and it seems like we're getting a ton of small models lately. Nvidia has released Neatron Nano 9B V2 and according to artificial analysis, it is a small 9 billion parameter reasoning model that scores 43 on the artificial analysis intelligence index, the highest yet for a sub 10 billion parameter model. It is the first model pre-trained by Nvidia themselves and it is a hybrid Mamba transformer architecture. So not pure transformer. I've not actually heard of this hybrid technique but sounds very cool. Mamba in the past has not performed well for me. Hopefully this is different. So key facts 128k token context window supports reasoning and non-reasoning with the /nouink setting. It is released under the Nvidia open model license. And if you want to see where it lands, it is right here at 43, right below Solar Pro, right below GPT5 minimal and above Quen 30B, Llama for Maverick, sorry, Llama, and Magestral Small. So again, this isn't supposed to be a top performing model because it's a tiny model that you can probably run on most consumer grade computers. And if you were completely offline yesterday, you probably didn't see all of the bananas that have been posted on Twitter. Nano Banana. This incredible image editing model was released by Google. It is Gemini 2.5",
        "start": 0.08,
        "duration": 342.80000000000007
    },
    {
        "text": "it's a tiny model that you can probably run on most consumer grade computers. And if you were completely offline yesterday, you probably didn't see all of the bananas that have been posted on Twitter. Nano Banana. This incredible image editing model was released by Google. It is Gemini 2.5 well. Look at the scores on LM Arena. So, you can see all the top models on the bottom and in almost every category, especially in overall performance, Gemini 2.5 Flash image is way better than the others. And from my own personal experience testing it, which I put out a testing video yesterday, it is really incredible. So, if you haven't checked it out, you can try it in AI Studio and in Gemini. And by the way, if you gain a lot of value from playing with image models, you should check out the sponsor of today's video, Recraft. Looking for AI design tools that actually deliver production ready assets? ReCraft generates real SVGs, not just PGs. That means fully editable vector graphics with clean layers and scalable quality. No more manual tracing or pixelation issues. Rec now integrates seamlessly with model context protocol MCP connecting directly to agents like cursor and claude. That means you can generate and refine designs easily through a conversational interface and you maintain precise creative control whether you're creating logos, marketing materials, product markups, it doesn't really matter. Recraft can do it all and it will deliver productionready files with the consistency that professionals need. Try it yourself for free right now. Link in the description below. Thank you again to Recrafted. Now back to the video. Next, Meta Super Intelligence Labs seems to be losing key staff already. According to Business Insider, some of Meta AI staff are exiting its new super intelligence division. These departures follows Meta's push to compete with OpenAI and Google. And Meta says the departures are mostly from longtime AI employees, and some attrition is normal. Now, I have read that people who just joined left 2 months later to go back to open AI. We don't actually have anything confirmed, it seems, but it's interesting to see how the talent wars continue to heat up. At least eight employees, including researchers, engineers, and a senior product leader have left the company less than two months after CEO Mark Zuckerberg announced a brand new division called Meta Super Intelligence Labs. Now, this is bound to happen whenever you have a mass influx of new people on the team. Whenever you have a giant reorganization, which just happened under AI CEO Alexander Wang, some friction is bound to happen. Not everybody's going to be happy and some people are going to leave. We have Bert Mayor who spent 12 years at Meta and just left earlier this week to join Anthropic. This same person helped develop PyTorch, which is an incredibly popular open source library to help with AI and ML workloads. Tony Louu announced",
        "start": 171.2,
        "duration": 662.1610000000002
    },
    {
        "text": "and some people are going to leave. We have Bert Mayor who spent 12 years at Meta and just left earlier this week to join Anthropic. This same person helped develop PyTorch, which is an incredibly popular open source library to help with AI and ML workloads. Tony Louu announced than eight years. He worked on the PyTorch GPU systems and a number of other folks left as well. I'll keep you updated on all of these different trades from Frontier AI Labs. Next, Nouse Research released an open weights open-source model for you to use. It is another hybrid reasoning model. Check this out. NASA research presents Hermes 4, our latest line of hybrid reasoning models. Hermes 4 builds on our legacy of user aligned models with expanded testime compute capabilities. Special attention was given to making these models creative and interesting to interact with. Unencumbered by censorship, so if you're into that, this is a great model for that. And neutrally aligned while maintaining state-of-the-art level math, coding, and reasoning performance for openweight models. So you can try it out right now. chat.nressearch.com. And this is the first chat interface that actually looks different from others. Check this out. This looks really interesting. Kind of old school internet vibes, but I like anyone who tries something new. They also released the full technical report which I'll link to down below. It comes in two sizes, a 70 billion and a 405 billion parameter version along with reasoning and non-reasoning versions. And you can see here percentage of questions answered refusal bench much higher than literally every other model on the market. That means it is uncensored. Next, Grock Code has come out, a small version of it at least with basically no announcement from XAI or Gro, but it just started showing up in places like Windsurf, Cursor, and other agentic coding platforms. So, here it is. Grock code is now available in cursor. It is 20 cents per million input, $1.5 per million output. It is very fast and very cheap. Some initial testing that my team has done shows that it is not quite as good as the Claude family of models, but for the speed and for the price, it's quite compelling. And of course, it's only going to be getting better. We're currently doing some more testing. We may put together a full testing video. Let me know down below if you want to see that. All right, in some space and rocketry news, SpaceX has done it again. They've landed an incredible rocket on a tiny platform in the middle of the ocean. This is the future. This is science fiction at its peak. And not only that, we actually got video of it. So, you could see it's landing right there. It does fall over, but it did land. And they said it was successful in every possible way. Very cool to see. Congratulations to the SpaceX team. That",
        "start": 333.6,
        "duration": 960.082
    },
    {
        "text": "fiction at its peak. And not only that, we actually got video of it. So, you could see it's landing right there. It does fall over, but it did land. And they said it was successful in every possible way. Very cool to see. Congratulations to the SpaceX team. That asking, why isn't Apple buying other AI companies? And apparently, they've been talking about it, but just haven't pulled the trigger yet. They have hundreds of billions of dollars in cash just sitting around. They've done an insane amount of stock buyback, but why aren't they buying AI companies? Why aren't they making acquisitions? The biggest acquisition they've ever done was Beats by Dread Headphones, which is insane. They are seemingly so far behind on the AI front, they could simply buy another AI company. So, according to Reuters, Apple executives held internal talks about buying Perplexity. The discussions are at an early stage and may not lead to an offer. It's crazy that Bloomberg News, who reported this initially, got that scoop, which it's so early. Somebody leaked that for sure. Of course, Perplexity said, \"We have no knowledge of current or future M&A discussions involving Perplexity. Apple didn't immediately respond, but it has been reported. Hopefully, they do make a move like that soon because they are falling further behind every single day.\" And here's an example of why. Again, according to Reuters, Apple is in talks to use Google's Gemini AI to power revamped Siri. Bloomberg News reports, \"I actually think Siri has gotten worse during this whole AI boom for them, and now they might be tapping Google to help them out. But this wouldn't be the first time. Google has powered search on iPhones for a long time, basically paying Apple to be the default search engine. So, this might be another example of that. Apple recently approached Alphabet's Google to develop a custom AI model to power a redesigned Siri next year. Why next year? Just looking at how fast Elon Musk and the XAI team has moved to bring Grock to market and become a leading AI provider, it is just insane to think how far behind Apple really is. Apple remains weeks from deciding whether to stick with in-house Siri models or switch to an external partner and has not yet chosen. There have been rumors that it might be anthropic. There have been rumors it might be other companies. There has also been rumors that they might be acquiring Mistral and their models and their team. But at the end of the day, they need to do something. All right. Next, in something that I think is going to be actually quite underappreciated, Kiwi.com has released a flight search MCP server. So, if you want to book flights, and flight booking can be incredibly complicated, not only in comparing prices, but if you're doing multihop or anything like that, it just becomes really complex. and using the interface that traditional flight",
        "start": 483.52,
        "duration": 1258.961999999999
    },
    {
        "text": "quite underappreciated, Kiwi.com has released a flight search MCP server. So, if you want to book flights, and flight booking can be incredibly complicated, not only in comparing prices, but if you're doing multihop or anything like that, it just becomes really complex. and using the interface that traditional flight ownorous. So now set your agent and go search flights with Kiwi. So it exposes a single tool search flight and allows you to get information on roundtrip or oneway flights, origin destination, travel dates, flexibility of dates, number and types of passengers, cabin class, everything you need to do to book your flights. And I think this is really a hint of what's to come. More and more companies are going to expose MCP servers as agents proliferate the internet and really become the interaction layer between humans and the information on the internet. I really do believe humans and the internet are going to continue to be decoupled and it's really just going to be my agent on my behalf going to do things on the web. So there's a great step in that direction. Good job Kiwi. Check it out. Next, Nvidia continues to publish incredible open- source papers. This one makes LLM inference 50 plus times faster. Jackson Atkins on Twitter put together this great summary of how this works. So it is a technique called postneural architecture search and it's a revolutionary process for retrofitting pre-trained models. It freezes the knowledge. So it takes a model like Quen 2.5 and locks down its core MLP layers preserving its intelligence. Then it does surgical replacement to replace these slow layers. Then it optimizes for throughput. So the search keeps a few key full attention layers in the exact positions needed for complex reasoning creating hybrid model optimized for speed on H100 GPUs. Here is the result. Jet Neatron 2800 plus tokens per second with top tier model performance and a 47x smaller KV cache. This is what we need. Now, if you remember back to when DeepSseek dropped, everybody thought, \"Oh, wow. Deepseek was able to achieve so much more efficiency and such a lower cost. We should sell all of our Nvidia shares.\" Well, Nvidia didn't believe it at the time, and now the market understands that is ridiculous. What actually happens is as things get more efficient and cheaper, we use more of it. And that's why Nvidia has no problem publishing papers like this that show how to accomplish incredible efficiency. not investment advice obviously. So here's the paper jetron efficient language model with postnural architecture search. I'll drop it down in the description below if you want to check it out in detail. If you want me to do a breakdown video, let me know down below. And let's continue on some of the positive outcomes of deep investment into AI. According to RS Technica, Google's AI model just nailed the forecast for the strongest Atlantic",
        "start": 636.8,
        "duration": 1569.600999999999
    },
    {
        "text": "want to check it out in detail. If you want me to do a breakdown video, let me know down below. And let's continue on some of the positive outcomes of deep investment into AI. According to RS Technica, Google's AI model just nailed the forecast for the strongest Atlantic if continuing at this performance improvement, might become the gold standard of predicting severe weather. Why is this good? Well, you give people a heads up as to severe storms that are coming or tornadoes or really anything that might affect where they are. So, look at this. Internal testing shows that our models predictions for cyclone track and intensity are as accurate as and often more accurate than current physics-based methods. Now, this feels very similar to Deep Mind's AlphaFold project. Basically, rather than manually trying to guess all of the potential proteins and how they fold, the folding project, instead they used a predictive model to predict different proteins. And not only is it vastly more efficient, but it's also more accurate. And so, it seems like that is exactly what's happening here. Another cool project from the DeepMind team. Congratulations on that. All right. Next, codec CLA got a bunch of new updates. Check this out. Codeci, if you're not familiar, is OpenAI's command line interface coding agent. So, first image inputs landed in codec CLI update 0.24. It tried along with many other improvements. They also added web searched messages, copy paste and drag and drop images, transcript mode, simplified command approvals, better output diffs, and more. Use it with Brew install codecs, lots of updates. Check it out. Next, according to the New York Times, AI infrastructure spending is propping up the entire economy. The trillions of dollars that tech companies are pouring into new data centers are starting to show up in economic growth for now, at least. The article starts by pointing out the obvious that AI infrastructure spending is benefiting companies like, of course, Nvidia. But now, we're starting to see signs that it's propping up the entire economy. Companies will spend $375 billion globally in 2025 alone on AI infrastructure and that is projected to rise to 500 billion next year. Now, here's an interesting graphic. Here is spend on traditional offices and here is spend on data centers. So, all of these offices might be getting converted into data centers soon enough. And listen to this, the boom has also been good for electricians, engineers, and heavy equipment operators. So, it's not just white collar workers that are benefiting from this AI boom. Blueco collar workers are benefiting a lot from this and being an electrician right now is actually a very compelling career path to take because there is so much infrastructure that still needs to be built out. So, this is a great article if you're trying to understand what's happening both in the kind of AI economy and then also the",
        "start": 793.519,
        "duration": 1887.6009999999976
    },
    {
        "text": "an electrician right now is actually a very compelling career path to take because there is so much infrastructure that still needs to be built out. So, this is a great article if you're trying to understand what's happening both in the kind of AI economy and then also the infrastructure investment. I'll drop the link down below. Next, Microsoft released Vibe Voice, a Frontier open- source texttospech model. Listen to this. I can't believe you did it again. I waited for two hours. 2 hours. Not a single call, not a text. Do you have any idea how embarrassing that was just sitting there alone? Look, I know. I'm sorry. All right. Phenomenal. Really excellent. I mean, this is on par with advanced voice mode, which of course is by OpenAI and it's closed source, but this is absolutely incredible. The tone, the cadence, everything is customizable and it is contextaware as you heard. They released the weights, they released the research paper, the software, everything. So, awesome job from Microsoft on this. Now, look at the benchmarks. Here is human preference Viveoice 7B and 1.5B. These are very small models, but the 7B version outperforms Gemini 2.5 Pro Preview TTS 11 Labs V3 Pigs Audio and Sesame AI Labs, which is surprising because a lot of people say Sesame is the best. This just sounds excellent. And if you want to try it out, I'll drop a link down below. A couple more features that you should know about. A single generation of audio can be up to 90 minutes. That is essentially a full podcast again on a single generation. So you clip two generations together and now you have essentially infinite audio. It has support for four speaker dialogue scenarios. So not just two, which we're used to, but up to four. And it's multilingual, including decent Chinese performance. So give it a try. Let me know what you think. Maybe I'll create a tutorial on it. Let me know if you want that down below. And thanks once again to Recraft for sponsoring this video. I'll drop a link for them down below. Check them out. They've been a great partner to this channel. Let them know I sent you. If you enjoyed this video, please consider giving a like and subscribe.",
        "start": 955.68,
        "duration": 2113.520999999998
    }
]