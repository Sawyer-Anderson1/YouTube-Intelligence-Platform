[
    {
        "text": " So Elon Musk just revealed XAI's master plan and it goes way beyond chatbots. We are talking orbital data centers, moon factories, and compute infrastructure that could literally harness a fraction of the sun's energy. XAI is only 2 and 1/2 years old, but they're already topping leaderboards and moving faster than anyone in AI. In this video, you'll see the entire strategy, what they're building now, what's coming in the months, and the truly sci-fi stuff they're planning for the space. Let's dive in. We're going to start off by recapping the incredible progress that the XCI team has made in just two and a half years. it's really remarkable in pursuit of our goal of understanding the universe. So just going over our accomplishments since inception. it's important for to bear in mind that Xi is only two and a half years old, basically a toddler. and we've nonetheless achieved an incredible amount in a very short period of time. So our competitors are five 10 some cases 20 years old. they have much larger teams. They started off with far more resources and yet nonetheless we have achieved number one in many arenas in in just a few years. So we we've achieved number one in in voice in image and video generation. I think we now at this point are actually generating more images and video based on the last numbers I saw than all of our competitors combined. we are winning in terms of forecasting which is one of the key metrics of intelligence. so our the Grock 420 forecasting model beat all the other AIS in forecasting. and we've talked many leaderboards. we've got now a great app with the with with the imagine with the core Grock. We've made radical improvements to the X app. And we've launched a Graipedia which is on its way to far exceeding Wikipedia and ultimately be orders of magnitude more comprehensive and more accurate and have more information as well as video and and and image data that simply isn't there on Wikipedia. So it's it's intended ultimately to be encyclopedia Galactica, a distillation of all knowledge of yeah all knowledge. and we we've we're we're the first to achieve 100,000 H100 GPU training cluster and we're now about to achieve the first 100 I should say 1 million H100 GPU equivalents in training. So really an incredible amount of work in a very short period of time. And it's it's important to consider for competitiveness of any technology company what matters is not the position at any point in time but what is your velocity and acceleration and if you're moving faster than anyone else in any given technology arena you will be the leader and XAI is moving faster than any other company no one's even close so let's go to our team as we grow as a company, a natural thing that happens is you reorganize the company as it",
        "start": 0.0,
        "duration": 415.678
    },
    {
        "text": "than anyone else in any given technology arena you will be the leader and XAI is moving faster than any other company no one's even close so let's go to our team as we grow as a company, a natural thing that happens is you reorganize the company as it startup, you might have just a few dozen people and they all just chat amongst themselves. As you grow to several hundred people, you have to then add more structure. Just like an organism that grows from a single like we all just grew from a single cell and then to a blob of cells and then you get or organ differentiation, limbs, you grow a tail. of the pet tail disappears and then you become a baby. You go through these stages and so we're organizing because we've we've reached a certain scale we're organizing the company to be more effective at this scale. now naturally when when this happens there there's some people who are better suited for the early stages of a company and and less suited for the later stages and so and and for for the people that that have departed I'd just like to say thank you for contribution thank you for getting us this far and we wish you very well in your future endeavors. So now going on to the new structure of the company. the company is organized in four main application areas. There's there's Grock main and voice which is really the the the main Grock model. That's why it's called Grock main. then there's a coding specific model. There's an image and video model which is imagine and then macro hard which is intended to do full digital emulation of entire companies. and and then we've got the infrastructure layers. So I'd like to invite members of the teams to come up and talk about each of their areas. Hey, thanks Elon. So Grock main and voice are going to be merged into one team and you know on voice one anecdote is September 2024 open had this product you could talk to advanced voice mode and we had nothing no model of course in the product. we started much after that and in a span of few months 6 months we developed the model in-house from scratch without a bunch of people who knew audio and had a product that was surpassing open end 6 months fast forward six more months and now we have grock in more than 2 million Teslas we have a gro voice agent API you can do all kinds of amazing things in a span of one year we went from nothing to being leaders that kind of stuff is only possible in a place like XCI where you have small teams committed mission focused lots of compute. , and we really really want to keep pushing. Same story on the chat models. You know, we've always been at the forefront of",
        "start": 208.239,
        "duration": 715.7570000000002
    },
    {
        "text": "to being leaders that kind of stuff is only possible in a place like XCI where you have small teams committed mission focused lots of compute. , and we really really want to keep pushing. Same story on the chat models. You know, we've always been at the forefront of Grock 2, Grock 3. And we want to really move to a world where it's no longer about just question answering. We want to build an everything app. So, you should be able to come to it and really get done whatever you want. You know, ask a legal question, , make a slide deck or or, you know, solve a puzzle, stuff like that. Yeah. So I really think on the product side we're really going to see a huge transformation happening in a very short period of time. we're going to see work the magnitude of amount of work that all knowledge workers are going to be able to produce increase 10fold in the next short period of a few months. the models that we are building out are incredibly amazing and we have a lot on the way and we're really excited to share that with with you all. , and on a product side, the goal is to just build that portal that allows you to accomplish all of your work. And how do we amplify everyone to achieve much much more than what they can accomplish alone? And we're building that out and it's it's going to be an incredibly easy to use experience that just works seamlessly. , that being said, we are hiring and we're looking for intelligent and smart people. This is not an easy place to work, guys. like this is it's a grind but we have I guess like interstellar ambitions so it's it's not going to be easy right so I will say having come to XAI it has been an opportunity of a lifetime to work among really smart and really passionate people the vibes here are amazing and it's truly an environment where if you're a smart person you want to get done you can get done there isn't like organizational overhead getting your way or kind of I don't know like having to write docs and all this kind of stuff you just do stuff at least at least for me I just you know just you can do things here and that's amazing and I invite more people to come here and just do awesome things. Yeah. So with with the the Grock main the the sort of main foundation model the intent is that it's it's genuinely useful in a wide range of areas. So if you're doing engineering or law or trying or or medicine any anything it is useful to you in in in your job that's essential to understanding the universe and and making things as useful as possible like where when Grock gives",
        "start": 360.479,
        "duration": 990.9549999999999
    },
    {
        "text": "useful in a wide range of areas. So if you're doing engineering or law or trying or or medicine any anything it is useful to you in in in your job that's essential to understanding the universe and and making things as useful as possible like where when Grock gives Hey everybody, I'm MRO. So the world changed a lot recently in terms of coding. the coding models I was always complaining people were trying to convince me to use a coding model and I was like trusting it and I wasn't really convinced but as of recently the models they they actually produce good decent quality code. I mean you still need to review and give feedback but you can it's it's easy to see how they can accelerate you quite a lot. So it's not only about coding it's like they understand your intuition like much better than before. Like now when you when I describe a problem, I only have to phrase it like I would to an other colleague engineer who has already seen the codebase. That's a huge change. Before you kind of need to handhold a toddler to make a change and they don't only write your code, but they also can debug your code. So now we have I do like well we do like hours of grog code running continuously to make sure that a more complex change to the training system actually works in production. So it's easy to see for us that this is not only about accelerating us ourselves writing code and making us 10x more productive but we're really on this path for recursive self-improvement where the current generation of gro code is training the next generation of croc code and we see that this path we exponential takeoff here this path will continue. So we are doubling down on coding and making coding one of the highest priority efforts in the company. So if you're out there and you're excited about coding and you're either either very good at training modeling or you're a really good low-level software engineer interesting in systems design, this is the place to work. Like we have a million H100 equivalents to train the best coding metal in the world right now. So please join us. yeah, I'm God. I work pair with macro on coding. So it become more and more obvious to us like you know over time like we are on a path to singularity at least on coding. So we decided like you know have our best engineer in the company micro to lead the coding and we'll build the best coding model for everyone to empower everyone to build and for me like the main like limiting factor is probably computer and energy where they can run the best model to support everyone to empower everyone and with spec now we are one team and we will win on the compute and we are winning with space",
        "start": 502.319,
        "duration": 1290.955
    },
    {
        "text": "to build and for me like the main like limiting factor is probably computer and energy where they can run the best model to support everyone to empower everyone and with spec now we are one team and we will win on the compute and we are winning with space engineer Right? So if you are like writing kernel, if you're writing compiler, just think about like what is still worth it. Maybe you should join us, you know, for coding effort to automate yourself a little bit like to speed it yourself up. yeah, I think it's like really amazing year. basically what a year to to be alive and I can already feel the AGI feel the AI at least for coding. Yeah. Yeah. I I think actually things will move maybe even by the end of this year to where you don't even bother do doing coding the AI just creates the binary directly and the AI can create a much more efficient binary than can be done by any compiler. So just say create optimized binary for this particular outcome and and you actually bypass even traditional coding. there's there's no that that's an intermediate step that actually will not be needed probably by I'd say the end of this year. and we do expect Gro code to be state-of-the-art in 2 to 3 months. So it's happening very quickly. Yeah. yeah meanwhile also do imagineing so you know I mean what you do right after post AGI right you probably do like digital life so that's what we are doing here as well and we have the imagine team like started pretty much from scratch like six months ago we have a few people we decided we'll to do the imaging we do the video gen like yeah look at what we achieved today like you know like two weeks ago we released the imagine v1 we actually topped the leaderboard across like many of them and people loves our product, love our model and we have many more releases actually this month and next months. So yeah, to me there's like really high chance like we actually may build a metaverse before meta. yeah, I will also pass to try to to talk about like you know the the metrics we have the product. Yeah. Yeah. Like like Gorang said it's only been 6 months since we started working on imagine. We had we had no code internally for diffusion at all 6 months ago and basically now we've launched imagine on every product surface that we have including seamlessly integrating into X. So you can open the X app right now you can long press on any image you can edit the image you can make a video out of the image. we also ran a contest recently where we had some really funny submissions that I'm sure many of you have seen. so imagine is growing extremely extremely fast. and it's",
        "start": 653.6,
        "duration": 1594.0740000000012
    },
    {
        "text": "can long press on any image you can edit the image you can make a video out of the image. we also ran a contest recently where we had some really funny submissions that I'm sure many of you have seen. so imagine is growing extremely extremely fast. and it's iterate. Basically we do multiple product updates every day. We do model updates every other week and effectively what this has led to is now users are generating close to 50 million videos every day using imagine. and just to reiterate what Elon said earlier that to the best of our knowledge that is more than every other provider combined which again is an astonishing place to be compared to where we were 6 months ago. we are also generating 6 billion images in the last 30 days. nano banana you know Google recently posted that you know 1 billion images were generated using nano banana in 30 days so you know we're six times that right and and really the goal is it's not like we we don't just want to win we want to win like s like over a long period of time and have sustained greatness and so the goal with imagine is to take anything that you can you know imagine and turn it into reality and so that's that's what we're going to you know that we're going to speedrun that basically is the goal yeah hey I'm Hen. we as we keep scaling our model capabilities, building visual worlds that's indistinguishable from reality, we're also building system that unlocks much more possibility than what we have right now. they will be able to generate the videos that's much longer than what we have right now with stories or with souls of your imagine. And by the end of the year, we likely will be having models that allow you to generate videos of 10 minutes or 20 minutes in one shot without any intervention. You just need to give your imagination and our model, our agents will do it for you. And and moreover those are the videos we generate and we're also going to allow rendering those. We we're already the fastest in generating the videos and we're going to keep pushing the extreme where we're going to render those videos in real time and you will be able to imagine build and interact with your own world and the world the world will respond to you in real time and it is exciting future that we are going to build with ourself. Absolutely. I my prediction is that most of AI compute is going to be real- time video understanding and real-time video generation and and we expect to be the leaders in that. It's it's worth emphasizing these points that you know 6 months ago we didn't even have we we had basically nothing in in in or very weak in video and image",
        "start": 814.399,
        "duration": 1894.9550000000006
    },
    {
        "text": "be real- time video understanding and real-time video generation and and we expect to be the leaders in that. It's it's worth emphasizing these points that you know 6 months ago we didn't even have we we had basically nothing in in in or very weak in video and image months to number one spot. and in fact generating more more videos and images than everyone else combined. We're going to do the same thing with coding and we're going to do the same thing with macro hard. And and I think people will be be pretty impressed with the the Gro 4.2 model that's coming out. that's it's a it's a significant improvement. and that's really just that that's that's the small version of our new model. So we'll have a medium and a large version that are even more intelligent. All right. Hi everyone. I'm Toby and I work on MicroHart, the most serious of all product names. so arguably giving computers to humans was a good idea. So we're doing the same thing thing for AI. It's kind of like inception. We're giving computers to computers. so Macro is building a fully capable digital realtime very important human emulator. So it's able to do anything on a computer that a human is able to do including using advanced tools in engineering and medicine. So there should be rocket engines fully designed by AI. And in a sense it's one of the last few remaining areas where AI is significantly worse than humans which is why I think it's one of the most exciting areas to actually innovate in and actually change the change the field. Hi everyone. So yeah, my name is John and yeah, so we're building these strong reasoning models which are now going to control our CLI. Like we're actively using these every day. They are like tremendous like productivity boost to the whole team. I know the voice team is like killing it on that. And you know this is the reason why we need the compute you know we need the large scale compute to run these models to boost our own productivity. But you know 80 to 90 95% of the world world software has a GUI. so that's like you know great representation and you know to truly make people's lives easier we need to develop models that are capable of solving day-to-day tasks on GUI. So macro hard you know we will emulate a company where the output is digital and so this is the obvious next step for agents. macro hard will enable true endto-end orchestration across the desktop and it will lead to immense economic prosperity. so yeah, we're entering an era where we need to tackle the hardest of tech problems, but in order to solve this, we need to hire the best people. So, you know, think of the smartest people that you've worked with and and put them",
        "start": 965.759,
        "duration": 2219.1949999999997
    },
    {
        "text": "lead to immense economic prosperity. so yeah, we're entering an era where we need to tackle the hardest of tech problems, but in order to solve this, we need to hire the best people. So, you know, think of the smartest people that you've worked with and and put them you can't think of anybody like go through your phone book, go for your LinkedIn. you'll be surprised like how how big your actual network is. And they just need three properties obviously that we want to optimize for. Are they clever? Can they solve hard problems? And the second property is are they driven? Do they have the ambition? Do they want to win? And the third is are they a nice person? Like do you want to actually work with them? yeah so thank you. Yeah the mac the macro hard project is over time actually will probably be our most important project because what we're talking about is emulation of entire human companies. So when you look at the most valuable companies in the world they are their their output is digital. so they they don't actually make hardware. So it should be possible to completely emulate any company that where the output is digital. and this will usher in an age of prosperity likes which we could barely imagine at this point. You need imagine to imagine it. so this is a big this is a big deal and this is why the words macro hard are painted on the roof of the training cluster. because that's what it's going to bolt. So, it's also pretty funny. Yeah, meant to be a joke. It's me again. You might remember me from macro harding computer use from a long time ago, but I also actually work on core product infrastructure and API. In fact, this is what I've done for most time at XAI. So, anytime you use any of our products like grock.com API authentication, you go to status.x.ai. This is done by the core product infra team and a large portion of them actually sit in London and we work with Haime over there. So we keep the lights on at peak hour 4 p.m. every day. we get paged at night when stuff goes down. Also thank you to anyone in Palto getting paged. there's really important work reliability security core product infrastructure. So if you actually like if you're really interested in solving difficult distributed problems with like messy data, this is the team to join. Hey everyone, my name is Diego. yeah, so I think one one of the main bottlenecks in this next year for these models is going to be very high quality evals and training data. And one of the ways we solve that is by taking the world's foremost experts in these respective domains u bringing them here and having them evaluate the model. we do this for domains like medicine, finance,",
        "start": 1129.84,
        "duration": 2532.9559999999997
    },
    {
        "text": "these models is going to be very high quality evals and training data. And one of the ways we solve that is by taking the world's foremost experts in these respective domains u bringing them here and having them evaluate the model. we do this for domains like medicine, finance, video editors who contribute daily to making rock better. and yeah, we're going to be continuing to work on very high quality evals over the next few months. we have some exciting stuff in you know, the the frontier of useful tasks in finance and law. you know we're trying to build evals that are are are useful and training data that that represents useful work and and not necessarily proxies of intelligence I think a lot of the open source eval do today. yeah. Yeah. I' I'd like to say like we're we're shifting from using these sort of common internet evals which I think are actually not a real indicator of usefulness to having expert tutors in each domain. so every domain of engineering, medicine, law, whatever the case may be. and the the the actual eval is does the expert in that arena or does our group of experts in that arena human experts agree that Grock is extremely useful and that the results are correct? That's the that's actually the only eval that really matters. Yeah, exactly. in you you you'll see this in in Gro 420. but we've made some improvements because of that type of data in in truth seeeking and and kind of minimizing political bias. The responses are are much more cogent. , so yeah, that that's exciting. , and we are also working on Gracipedia. So the, , the goal of Rockedia is to create a distillation of all human knowledge. , I kind of like to think of this as like a modern day version of the Library of Alexandria. , and in the quest to build Encyclopedia Galactica, , which it will one day be called. , we've gone from essentially having nothing to around 6 million u, , articles. , for context, Wikipedia is around 7 million English articles. , and, , yeah, we're improving on hallucination. and our our our goal is essentially for rock 5 to not have to search out of the data center. so yeah so in the ML infra team we are building the training inference and tooling team tooling software for the company. So to give you an example when we were training Grock 3 we built the pre-training framework for this and it these are some some of the coolest system in my opinion that you can build as a software engineer. So, it's like we have 100k H100s at the time and they were just delivered and we didn't quite have the software. We thought we'd have the software, but then at 30K scale we we realized actually the software is not quite working and",
        "start": 1290.24,
        "duration": 2842.556000000002
    },
    {
        "text": "can build as a software engineer. So, it's like we have 100k H100s at the time and they were just delivered and we didn't quite have the software. We thought we'd have the software, but then at 30K scale we we realized actually the software is not quite working and halfway rewrite of the software because there's so much going on in a data center that you can't actually account for. , switches are switches are flapping, links are flapping, switches are going down, GPUs are just burning through, you have numeric issues. And it's a system where you want really 100k H100s to behave in log step. So a training step is like 5 seconds and you're going 5 seconds in log, but during that 5 seconds, everything can happen. So you need to write a system that makes progress despite all these things that can happen in the environment. And we did this successfully and it was one of the coolest times in my life where the the system was actually running at it was running at the same time my son was born. So that was extra excitement. but these problems like you don't find anywhere else like nobody has this kind of compute and also nobody has this kind of talent density. So at the time to give you a perspective we were like in overall team in pre-training we were probably like 15 people out of that maybe like seven people were working on the actual training system and we we still maintain that talent talent density in the team. So if you're interested in working on these problems and you don't want to be just like part of a bigger organization where you're one of like a thousand people working on this then this is the place like we are still a very small team with me is Leon Min from the RL and inference team. Yeah. Hi, I'm Lemi. So, at our team, we run a reinforcement learning training job and production inference at large scale on the earth and probably soon in space. , and we are kind of already design a lot of thing to to make it more resilient and scalable. So, we're building a system to scale from 100k chips to millions of chips. And we optimize every aspect of the stack like parallelism, prefill, decode and make resilient to every known and unknown hardware failure. so if if you are system hackers obsessed with extreme performance and reliability. So here is you'll find the most interesting problems to work with and I think actually like very similar to all kind of thing like you it's it's very important for you to first see the problem and then you will develop the solution that no one else can develop before. Yeah. Okay. I'll hand over to the tooling team. Hello. I'm Ashib from the tooling team. every software needs to have",
        "start": 1446.72,
        "duration": 3142.316000000004
    },
    {
        "text": "of thing like you it's it's very important for you to first see the problem and then you will develop the solution that no one else can develop before. Yeah. Okay. I'll hand over to the tooling team. Hello. I'm Ashib from the tooling team. every software needs to have useful. So as the tooling team we are responsible for building the platforms, frameworks and infrastructure which is required for humans as well as agents to be able to use our products. we started by building out the human data platform. This is a place where we collect all of our human data and eventually expanded on to build our internal engineering platform through which we basically run deployments run evaluations or like look at like what training results exist. So if you really care about building a good interface or providing a really useful framework for researchers for agents as well as our tutors then you should definitely join our team. So hi everyone I'm Yulom from the Jax team. So now Jax at XAI is a really small team with a a couple of engineers that working on Jax GPU to optimize our ultra large scale GPU training. So you can imagine that training at scale can be very complicated. Even you run hello world at scale it can be complicated right. So then we are actually responsible for supporting the entire companies from pre-training foundation models RLS and also multimodel to scale things to from first from 10k 100k then probably 1 million h100 equivalent equivalent GPU scale and we to implement a lot of you know pract practical optimizations we have to customize the entire Jacks stack from compiler and runtimes and there will be a lot of interesting problems. and also if you really want to you know u obsessed on optimizing the entire stack at scale that we are probably the best place to go because you know we really have very large scale GPU clusters and we have a lot of interesting problems to work with. Hey I'm Pangjul from the kernel team. Basically the kernel team sits at the very bottom of a training and serving stack. Our code runs inside the million equivalent GPUs that we have. And if you look inside the GPU, there's hundreds of thousands of threads. And these threads are trying to talk to each other to multiply matrices, compute attention scores, and some of them even talk to the million other GPUs that we have. And this is the low-level system that we have. And we like optimizing every single microcond in this. And we care deeply about squeezing every last drop of performance from these GPUs. So if you like this low-level systems problems algorithms, please join us. Let's see. Now we'll try to bring in Hiner and Spencer who are actually at our supercomput cluster in Memphis. Hey Hiner saying our job is to keep the computer",
        "start": 1599.6,
        "duration": 3457.9950000000053
    },
    {
        "text": "every last drop of performance from these GPUs. So if you like this low-level systems problems algorithms, please join us. Let's see. Now we'll try to bring in Hiner and Spencer who are actually at our supercomput cluster in Memphis. Hey Hiner saying our job is to keep the computer drug and serve AI. So users so used to work well a lot of ingredients have to come together mainly software and hardware. So there's all these jibby CPUs, nicks, switches of hundreds of thousands of operating systems running as one dick supercomputer and what we need is folks who really understand the really understand and really understand how computers work on a deep level. If that is you, reach out on X and I'm handing over to Dan. So we have 300,000 GB 300 platform GPUs here today. We're still growing, still building 847 miles of fiber per data hall. 12 data halls. If you want to be part of the world's largest supercomput, come join us. All right. So, it's it's quite marvelous what we've been able to do in less than one year's time here. we have once we're completely finished, we'll have north of a gigawatt of power online and running. We'll have the largest Tesla mega pack system in the world, larger than Hawaii or South Australia. and Zach is really quickly gonna talk a little bit about actually constructing the data center. Y so behind me you can see data hall 11. So one of the most incredible things about what we're doing here at Macroharts, how fast we do it, right? So, like they were saying before, over 850 miles of fiber at every single data hall, over 27,000 GPUs and over 200,000 connections. So, all of this that you can see behind me was put up in less than six weeks. We do that over and over and over again. We massively parallelize it. It's pretty much the most complex and consistent type of engineering design and construction project you can possibly imagine. So come join us. Yes. You know the the other really awesome thing about this is that everything is completely vertically integrated within this team. from architecture, mechanical, electrical structure, all the disciplines. and we also care a lot about efficiency while we're designing all of this too. So, it's not just about getting the most compute online the fastest, but also achieving the highest POE in the industry of using as much power smoothing technology as we can and being really good partners in the community here in Memphis with the Tesla mechaps and that we have going. You can check them out XAI Memphis. Back to you. All right. So, that was live live from the front lines in Memphis. so fundamental to any AI company's success is the compute advantage and what we've demonstrated over and over again is that XAI can actually deploy more AI compute faster than anyone else.",
        "start": 1759.919,
        "duration": 3797.3550000000064
    },
    {
        "text": "XAI Memphis. Back to you. All right. So, that was live live from the front lines in Memphis. so fundamental to any AI company's success is the compute advantage and what we've demonstrated over and over again is that XAI can actually deploy more AI compute faster than anyone else. Nvidia has said many times in interviews there is no one faster at getting AI compute online than XAI. So congratulations guys. Yeah, this is what it looks like. So that's really phase one which is 330,000 Grace Blackwells with macro hard written on the building that's not an image edit. It actually is on the roof of the building. and then macro hotter will be the building that you can see which has got the macro hotter with the rockets on it. and that will be another 220,000 GB300s. so all of this will be training the models that you that you experience. So the it's absolutely fundamental obviously to have large scale training compute in order to get the best models. Yeah, I'm sort of reminded of the the Jose meme where you see one guy digging and there's like seven people watching. , and one of the big differences between XAI and and other companies is we are actually Jose. All right. I'm Nikita. You might know me as a part-time ship poster, full-time customer support for X. , so we're now reaching over a billion people across our family of apps. , every time news breaks, it just becomes evident that this is the most important communication tool of our time. it's where the the the most influential people com convene. it's where truth is crystallized. Everything is downstream of X. The reason they say this is going to hit Facebook in a week, it's because it happens here. and I think we're only beginning to realize its full potential. we had a remarkable year for the app. we rolled up our sleeves and got a ton done. January was our biggest month ever for the app in terms of engagement. and then February is on track to beat that. much of the credit lies with the algorithm team. they've been putting in crazy hours. and it's clearly paying off, but there's still a huge amount of work to be done. on the top of funnel side, first-time downloads are up over 50% every month. , and we're exhibiting right now like basically the growth rates of an early stage consumer product. , we also made a ton of headway in solving one of the like 20-year-old problems of the app, which was ramping up new users. , new users are now spending 55% more time per day in the app than they were 6 months ago. , and on on the core product side, we're we're hitting our stride, too. , not only did we rebuild the algorithm, we rebuilt our onboarding flows, and we're seeing double-digit increases on all our key metrics. We",
        "start": 1930.96,
        "duration": 4140.953000000003
    },
    {
        "text": "time per day in the app than they were 6 months ago. , and on on the core product side, we're we're hitting our stride, too. , not only did we rebuild the algorithm, we rebuilt our onboarding flows, and we're seeing double-digit increases on all our key metrics. We , exch of the app has been rebuilt to be better than ever. , and it's clear that if we're focused, , we can move mountains and evolve this platform. just last month we did a little push on articles. and articles published are up 10x. articles read are up 17x. and on all other fronts like on over the holidays we did a big push on subscriptions. We just crossed a billion dollars in ARR there. I I think with the X app, you know, the there's very few unknowns like the path for us to win and become you know, the number one app in the world. we're it's it's we we know what to do. The ball's in our court. it's it's for us to win and it's just a matter of us executing. Yep. And yeah, so we've evolved the what used to be the old Twitter DM stack, which was unencrypted, basically just text, to a fully encrypted messaging system that it allows you to do audio and video calls. has you know, all the things you'd want from any messaging app. The disappearing disappearing me messages, screen screenshot blocks, like there's a whole all the features that you'd want want in an app. we and we will be open sourcing the code for this in the next few months as we are open sourcing the the recommendation algorithm code so people can actually see what we're doing. nothing beats nothing beats transparency for for believing in in a company. So we're we're the going to be the only recommendation algorithm that actually open sources. So you can see what it what it does and how it's evolving. with with Gro Chat it will also be open source so you can actually see if there are any vulnerabilities. There will be no hooks for advertising or anything else like that in in in Groch chat which is really intended to be a generalized communication system. and in the next few months we'll be releasing a standalone X chat app. So if you just want to do messaging you can just you can do that. You don't you don't have to go to the the core product. , and it will have desk desktop sharing and u multi-user so you can do you can do video calls with lots of people. It's really intended to be a a fully functional communication system with with Xhat. for X Money we're we've actually had XMoney live in closed beta within the company. and we expect in the next month or two to go to a limited external beta and then to go worldwide to all X",
        "start": 2106.72,
        "duration": 4480.713999999999
    },
    {
        "text": "to be a a fully functional communication system with with Xhat. for X Money we're we've actually had XMoney live in closed beta within the company. and we expect in the next month or two to go to a limited external beta and then to go worldwide to all X the place where all the money is the the central source of of all monetary transactions. So it's it's a it's really going to be a gamecher. and the reason we say 1 billion users is actually over a billion users. Is that while our monthly users are on average around 600 million, the number of people who have the X app installed is well over a billion. It's just that most people only occasionally come to the X app when there's some major world event. But as we give people more reasons to use the the X app, whether it's for communications for Grock or for X money, whatever the case may be, we we want it to be such that if you wanted to, you could live your life on the X app. And as we make it more and more useful, we'll obviously give people reasons, compelling reasons to use the app every day. and have my expectation is well over a billion daily active users. , in order to understand the universe, you must explore the universe. There's only so much you can learn from from just being on Earth with telescopes and and colliders on earth. Ultimately, you have to go out there and you have to explore the universe to understand it. And that's the motivation behind the combination of SpaceX and XAI. is to accelerate humanity's future in understanding the universe and extending the light of consciousness to the stars. So in the grand scheme of things, when you look at how much energy Earth is actually using for civilization, we're only right now using call it roughly 1% of the potential energy of Earth. , and if we wanted to use even a millionth of the sun's energy, that would be roughly a million times more energy than civilization currently uses. The only way to access that that energy, the energy of the sun, is to extend beyond Earth. Earth is really a tiny tiny dust moat in in a vast darkness. , you know, the sun is 99.8% of all mass in the solar system. So you you have to expand beyond the tiny dust moat that is earth to to make any significant dent in using the sun's energy. Like I said, it's you'd have to expand roughly a million times just to get to 1 millionth of our of our sun's energy and then going beyond that exploring ex extending to the galaxy and maybe someday even to other galaxies. So the the the the next step beyond Earth data centers is are our Earth orbital data centers. and we'll be launching with SpaceX orbital data centers at the",
        "start": 2281.68,
        "duration": 4838.313999999998
    },
    {
        "text": "our sun's energy and then going beyond that exploring ex extending to the galaxy and maybe someday even to other galaxies. So the the the the next step beyond Earth data centers is are our Earth orbital data centers. and we'll be launching with SpaceX orbital data centers at the cumulative, I mean per year. And ultimately we see a path to maybe launching as much as a terowatt per year of compute from earth. But what if you want to go beyond a mere terawatt per year? In order to do that, you have to go to the moon. So by having factories on the moon building AI satellites and having a mass driver, which is the kind of thing you really only learn about in or read about in science fiction, but we're going to make it real. we're actually going to have a mass driver on the moon. And if you do that, you can go several orders of magnitude greater. You can go to a thousand gigawatts or more per year. , and ultimately get to maybe a millionth and then a thousandth and maybe even a few percent of the sun's energy. It's difficult to imagine what an intelligence of that scale would think about, but it's going to be incredibly exciting to see it happen. I really want to see the mass driver on the moon that is shooting AI satellites into deep space. It's going like just one after the other. , I can't imagine anything more epic than a mass driver on the moon and a self-sustaining city on the moon and then going beyond the moon to Mars. , going throughout our solar system and ultimately going being out there among the stars and visiting all these star systems. Maybe we'll meet aliens. maybe we'll meet see some civilizations that lasted for millions of years and we'll find the remnants of ancient alien civilizations. But the only way we're going to do do that is if we go out there and we explore. And this is the path to making it happen.",
        "start": 2462.56,
        "duration": 5068.071999999997
    }
]