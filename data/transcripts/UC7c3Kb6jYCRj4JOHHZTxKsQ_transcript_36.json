[
    {
        "text": " You open up Chad GPT. You type in your prompt and you hit enter. What happens then? Every AI response you see is powered by a hidden backbone. Billions of dollars of massive warehouses cooled by air, sometimes water with enough electricity to run entire cities. These massive highstakes machines don't actually live in the cloud. They live in buildings. And these buildings are called data centers. And over the course of this video, I'm going to explain everything you need to know to understand what a data center is, how it works, and how it powers this incredible AI revolution. Just to give you an idea of the scale of the buildout happening in the data center industry right now. Open AAI, Oracle and SoftBank just partnered on a project called Stargate and their goal is to invest trillions that's trillions with a T dollars into building out AI infrastructure in the United States. Just recently, Nvidia pledged to give Open AI hundred billion dollars towards that goal. Every single major tech company is throwing as much money as they possibly can at building out what is becoming the next industrial revolution, the technological revolution. All right, so let's break it down. So whenever you hear the term in the cloud, what they're actually talking about are these massive data centers. And you can think of data centers as a factory for computation. The name doesn't change whether it's racks of GPUs which are used for AI use cases or CPUs which are used for other use cases. The facility still manages and serves data. And each of these data centers, these massive buildings are like little cities. Rows of servers and AI accelerators talking over high-speed switches, storage arrays holding pabytes of information, power generation, distribution, and batteries for keeping everything on and making sure that it stays on. And then cooling systems to take all of the heat generated by this massive amount of compute and move it out of the chips themselves so they don't overheat. And then last, incredibly sophisticated security to make sure bad actors can't get in physically to the building and digitally to try to hack the systems. If you've ever built your own PC, they are essentially enormously scaled up versions of that. You have a CPU, you have a GPU, you have memory, storage, power, and all of that. Just scale it up and multiply it by a billion. Just a few years ago, these data centers were not primarily focused on artificial intelligence. But since Chat GPT was released to the world in late 2022, everything has changed and trillions of dollars are flowing into building out data centers that specialize in the type of compute necessary to run artificial intelligence. And that is matrix multiplication. that matrix multiplication although it is very simple math basic multiplication needs to be done so many times that it does require highly sophisticated very expensive GPU chips to run AI workloads",
        "start": 0.08,
        "duration": 391.681
    },
    {
        "text": "centers that specialize in the type of compute necessary to run artificial intelligence. And that is matrix multiplication. that matrix multiplication although it is very simple math basic multiplication needs to be done so many times that it does require highly sophisticated very expensive GPU chips to run AI workloads absolute war between these tech companies and generative AI systems like chat GPT consume 10 to 30 times as much electricity than taskspecific AI these These are generalized systems. An AI image generation can use as much electricity as fully charging a phone. And each Chad GPT query draws roughly 2.9 W hours versus about.3 W hours for a traditional Google search. And those little numbers add up to massive numbers when you're talking about billions of AI prompts every single day. And a quick thank you to Dell Technologies for sponsoring this part of the video. Dell Technologies has a family of laptops and desktop PCs featuring Nvidia RTX Pro Blackwell chips which are absolute beasts for AI workloads. Check out the family of products linked down below. AI uses these massive data centers in different ways. First, there's training and that is when you're kind of baking the model. Those initial training runs are kind of like bursts of compute. They're high intensity but limited in the amount of time. Inference on the other hand, that's when you prompt a model like Chai GPT. It's thinking about the answer and then gives you the answer. That's called inference. Those run 247. And so to serve all of the needs of the customers of Chat GPT, of Google Gemini, Meta's Llama, and everything else, operators of these facilities have been ordering GPUs at massive scale. The supply cannot even keep up to demand in the slightest. Companies are planning to spend hundreds of billions of dollars each in AI optimized data center infrastructure buildout just over the next few years. So the underlying name hasn't changed. They're still data centers, but everything else inside is denser, hotter, more electricity hungry, and higher stakes. Now, let's talk about power because these things are power hungry. In 2023, which was really the beginning of the recent wave of AI infrastructure buildout, the Department of Energy estimates that data centers used 4.4% of the total electricity used in that year alone, in 2023 alone, and that could reach 7 to 12% by 2028. Electric company PJM forecasts about 30 gawatts of new peak electricity demand by 2030, largely from data centers. To put 30 gawatt into context, that's approximately how much 25 to 30 million households uses. A large nuclear plant produces about 1 gawatt. So you would need 30 of them to support that electricity use. But AI compute and AI usage is not the same as what we've had historically. It is not just okay let's scale up everything we've done historically with electricity generation. It is a very different beast. It's higher density. It's more",
        "start": 195.84,
        "duration": 767.6009999999999
    },
    {
        "text": "need 30 of them to support that electricity use. But AI compute and AI usage is not the same as what we've had historically. It is not just okay let's scale up everything we've done historically with electricity generation. It is a very different beast. It's higher density. It's more certain substations. So, as companies like Google, OpenAI, Microsoft think about where they're going to place their next data center, they have so many things to think about, but primarily, how are they going to generate enough electricity to power all of their chips? Then we have the actual racks. These are the metal frames that house all of the GPUs and all of the chips that run the GPUs. And these new AI racks are monsters. Nvidia's Reuben era systems will likely get up to about 600 kW per rack later this decade. That is 5 to 10 times what a conventional rack gets today. Today's high-end clusters already get between 80 and 120 kW per rack compared to the 10 to 15 kW just a few years ago. And because of the increased density, the increased electricity usage, the data center industry had to transition to better cooling. Because as electricity is running through all of these chips, they get really, really hot. And they need to dissipate that heat as quickly as possible to be able to run these chips all the time. And so they've started to shift more to direct liquid cooling, heavier power cables, thicker floors, and new service routines. Check out this clip from my tour of Cerebrus' data center where they're using liquid cooling effectively. Look how cool this looks. But let's get deeper into cooling. Because without cooling, these data centers would essentially shut off immediately. The heat generated by the chips would be overwhelming. The silicon would melt. Everything would go wrong. So, they need to keep everything nice and cool. And that is no small feat. And cooling is a design choice. Water cooling saves electricity. It is much more efficient than air cooling, but of course, you're using water. Air cooled and closed loop liquid systems save water, but often use more power. Typical water usage effectiveness across the industry is about 1.9 L per kilowatt hour. And when operators can use fully closed loop systems, they can aim for water use effectiveness as close to zero as possible. Let me put that into context. Google, which operates massive data centers around the world, disclosed that its Council Bluff's data center location consumed about a billion gallons of water in 2023. And again, it comes down to where the operators decide to put their data centers. Local policies, climate, community input, these all go into the calculus of deciding where the data center will be and what its design will be. But what does it actually look like to build out one of these data centers? Let's say you get the approval of the state, the city,",
        "start": 386.56,
        "duration": 1088.561
    },
    {
        "text": "policies, climate, community input, these all go into the calculus of deciding where the data center will be and what its design will be. But what does it actually look like to build out one of these data centers? Let's say you get the approval of the state, the city, choose the perfect site. What does that buildout actually look like? Behind every AI facility is a massive buildout sprint. And of course, it comes with high security. Building a hypers scale data center today takes about 18 to 30 months from concept to commissioning. However, the most famously fast project was Elon Musk and XAI team's Colossus project in which they built it in just 122 days, then unheard of and still yet to be replicated. A general data center project starts with a planning and feasibility assessment, which usually takes about 3 to 6 months. You have to find land with adequate power and fiber. Fiber for running the internet, of course. Then design and engineering follow which takes about 6 to 12 months. Then permits and approvals which overlapping take about 6 to 18 months. Construction which takes 1 to 2 years. And finally testing and commissioning which take an additional 3 to 6 months. and AI specific projects like Microsoft's Fairwater Supercomputer Campus sprawl hundreds of acres, pour miles of foundation, and install thousands of GPUs cooled by closed loop liquid systems. That's an investment that can run in the tens of billions of dollars. But once they're built, these buildings operate like fortresses. Tall fences, crash barriers, 247 security, the highest cyber security protection available on the planet, single entry points, two factor access using badges, plus biometrics, cameras everywhere, and locked cages for every single rack. Only pre-approved visitors get in, and server rooms are off limits except with an escort. So, where do they actually get placed? Why do they choose them? And what does the math look like to the local economy? Right now, Northern Virginia remains the world's largest data center market with near zero vacancy and gigawatts of new data centers being built out right now. Ludon County's budget explicitly says data centers generate about 38% of their general funds revenue. Because of that, they've actually been able to cut property taxes. So, in that sense, it is benefiting the local residents. But Phoenix, Chicago, Oregon, and Ohio are all rising as great places to invest to build out the next generation of data centers. And that's thanks to available land, power, and water. But here's the thing. While the buildout is occurring, there are a tremendous amount of jobs being created. Once the data center is done, it only takes a few dozen people to operate it. So, that is something for local governments to consider. But what if electricity goes out? What if natural gas seizes up? What if something happens? How do they back it up? Almost all large US data centers keep these",
        "start": 550.0,
        "duration": 1449.5209999999986
    },
    {
        "text": "done, it only takes a few dozen people to operate it. So, that is something for local governments to consider. But what if electricity goes out? What if natural gas seizes up? What if something happens? How do they back it up? Almost all large US data centers keep these backup. And we were lucky enough to see a few of them in our Cerebra store. This is what they looked like. And these incredible backup diesel generators are really rarely used, but when they are used, they do produce pollution. Operators are currently piloting alternatives, including gridbased batteries, on-site gas turbines, and in some sites, even hydrogen, and maybe in the future, nuclear energy. A really good data center buildout will have a lot of transparency, and this is good for the local community to know what they're getting into and what is happening. The best projects are power first, transparent on water, and integrated with the community. So first as they are choosing a site they look for power options abundant clean or firm power like the Nordics or the upper Midwest are best and then they collaborate with utilities companies to make sure that they generate and deliver the right amount of electricity at the right time and all of this heat being generated needs to be handled also. For example, Meta has a data center in Denmark and they are exporting 100 to 165 gawatt hours of heat per year to a district heating system. So, they're reusing that heat. They should also be publishing water use. This is critically important. Operators should be choosing closed loop systems when possible or dry cooling like air cool where appropriate. Modular design should be used and renewable energy whenever possible. Okay, so who are the biggest players in this game? Well, you've definitely heard all of them and you can probably guess who they are. The surge is led by a handful of hyperscalers and a hyperscaler is just a company that has multiple massive data centers. Amazon is currently building out project rainer using its own tranium 2 chips and AWS from Amazon has about 31% of the total share of the market where Microsoft Azure has about 24%. And Microsoft plans to invest $80 billion in 2025 alone. Google Cloud comes next at 11% and is committed to spending 75 billion building out data centers using their custom tensor processing units. Then we have companies like Oracle, Cloudwave, Meta, and a handful of others. So, let's bust a few myths. Do data centers cause blackouts? No. Grids plan years ahead to make sure that they have enough electricity to power these data centers. Plus, it's not going to disrupt the local communities and state. Are diesel stacks running all day? No, they're only there for backup and the backup only occurs in emergency situations. Are all data centers water guzzlers? That's a huge concern of a lot of people. No, they are not. Designs range from",
        "start": 732.16,
        "duration": 1780.1619999999982
    },
    {
        "text": "going to disrupt the local communities and state. Are diesel stacks running all day? No, they're only there for backup and the backup only occurs in emergency situations. Are all data centers water guzzlers? That's a huge concern of a lot of people. No, they are not. Designs range from closed loop water systems to high evaporation towers. And of course, where you fall on the spectrum really depends on the design and the local policies. And so AI's next chapter is not abstract. It is very clear-cut. We're talking about concrete, copper, silicon chips, water, and electricity. The challenge is how quickly we can scale these things up while minimally disrupting the communities they're built in. So the next time you type in a prompt to chat or another model, now you know exactly what happens. If you enjoyed this video, please consider giving a like and subscribe. and I'll see you in the next",
        "start": 900.48,
        "duration": 1860.6419999999982
    }
]