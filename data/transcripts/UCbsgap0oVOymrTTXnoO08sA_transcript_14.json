[
    {
        "text": " There's a revolution happening right now at the intersection of AI and biology. And it's coming from the same place that gave us AlphaFold. You probably remember that one. The AI system that figured out how proteins fold and basically changed structural biology almost overnight. That was about understanding the shapes of individual molecules. This time, Deep Mind is going after something even bigger. Not just proteins, not just single genes, the entire functional landscape of the human genome. The new system is called alpha genome. And the goal here is honestly wild when you stop and think about it. Instead of treating DNA like a long string of letters and stopping there, this model tries to understand what that DNA actually does inside a living cell. So not just the code itself, but the consequences of the code. which genes turn on, which ones stay quiet, how RNA is made, how the DNA is packed or loosened, and even how distant parts of the genome physically interact with each other inside the nucleus. All of that, starting from raw DNA sequence alone. Now, let's slow that down for a second. Your genome is about 3 billion letters long. Most of it does not directly code for proteins. In fact, over 98% of known human genetic variation happens in these so-called non-coding regions. For decades, that's been the really hard part of genetics. When a mutation shows up outside a gene, scientists often have to say, \"We're not really sure what this does.\" Alpha Genome is built to change that. It's designed to turn those mysterious regions into something we can actually interpret. The scale this thing operates on is one of the first big breakthroughs. Most previous AI models in genomics had to make a painful trade-off. Either they looked at short chunks of DNA, maybe 10,000 letters at a time, and made very precise predictions, or they looked at much bigger regions, hundreds of thousands of letters, and had to blur the details. Alpha Genome refuses to choose. It reads 1 million DNA letters at once, a full megabase, and still makes predictions down to individual bases. To make that possible, DeepMind built a hybrid AI architecture. Part of the model is designed to focus on very local details, short DNA patterns where specific proteins bind, kind of like recognizing individual words in a sentence. Another part of the model is built to understand long distance relationships, more like understanding how different chapters of a book connect to each other. In biology, this matters because DNA is not just a straight line. It's folded up in 3D space and regions that are far apart in the sequence can end up right next to each other inside the cell. Alpha Genome is built to capture both the close-up details and the long range communication at the same time. Inside the system, the DNA sequence gets turned into internal representations at multiple scales. Some of those are one-dimensional, matching",
        "start": 2.56,
        "duration": 333.19999999999993
    },
    {
        "text": "can end up right next to each other inside the cell. Alpha Genome is built to capture both the close-up details and the long range communication at the same time. Inside the system, the DNA sequence gets turned into internal representations at multiple scales. Some of those are one-dimensional, matching a single base pair or small blocks of bases. Others are two-dimensional, used to predict contact maps that describe how distant pieces of DNA physically come together in the nucleus. So alpha genome is not just reading the code. It's also trying to infer the spatial wiring diagram of the genome, how the DNA folds, and which parts are physically interacting. All right, now quick break for a short detour. If you work with AI a lot and end up jumping between different models just to see which one actually fits a task, today's sponsor, Mammoth, makes that whole workflow much easier. Mammoth brings most of the major AI models into one place. Claude, GPT, Gemini, Llama, Mistl, Grock, Deepseek, Perplexity for Deep Research, plus image models like Flux, Nano Banana, and Recraft. And everything runs inside a single dashboard. What really helps in day-to-day use is the comparison setup. You can send the same prompt to different models at the same time and instantly see how each one responds. That makes it easier to choose the right model for writing, research, analysis, or images without guessing. You can also create custom Mammoths, basically your own presets with specific instructions for recurring tasks and keep things organized in projects. On the privacy side, Mammoth is based in Europe with data hosted in Germany, fully GDPR compliant, and models aren't trained on your data. Prompts aren't retained by providers, and you can delete your history whenever you want. Plans start at around \u20ac10 per month, or roughly $12, and it's already used by hundreds of companies and public institutions. Check it out using the link in the description. All right, now back to the video. Now, here's where it gets even more powerful. Alpha Genome isn't trained to do just one biological task. It predicts 11 different kinds of measurements that scientists normally have to run separate experiments to get. That includes how active each gene is, where that activity starts, how open or closed the DNA is in different regions, which regulatory proteins are binding, how RNA is cut and stitched together during splicing, and even large-scale maps of which DNA regions touch each other in 3D. These things are measured in the lab using techniques with names like RNA seek, at seek, chipseek, and high. Instead of learning them separately, Alpha Genome learns all of them together from the same DNA input. In the human version alone, the model predicts 5,930 separate genome tracks across many tissues and cell types. The mouse version adds another 1,128 tracks. That's thousands of biological readouts, all coming from the same stretch of DNA. Instead of building one",
        "start": 168.8,
        "duration": 655.52
    },
    {
        "text": "of them together from the same DNA input. In the human version alone, the model predicts 5,930 separate genome tracks across many tissues and cell types. The mouse version adds another 1,128 tracks. That's thousands of biological readouts, all coming from the same stretch of DNA. Instead of building one expression, and another for DNA accessibility, this is one unified system learning shared rules about how DNA controls what a cell does. Training something at this scale is a massive engineering challenge. The model is built in jacks and runs on Google's TPUs, which are specialized AI chips. To handle the giant one megabase inputs, the DNA sequence is split into large chunks that are processed across multiple TPU devices in parallel with communication between them. Without tricks like that, the memory requirements would explode instantly. This is not just a biology project. It's a serious large-scale AI infrastructure project. The training itself happens in two main stages. First comes pre-training. They take real experimental genomic data and train multiple large teacher models. Some of these are trained with parts of the genome held out to make sure the models can generalize to regions they've never seen. Others are trained on the full genome to squeeze out as much performance as possible. Then comes distillation. They take an ensemble of those heavy teacher models and train a single student model to copy their predictions. During this phase, they also introduce artificial mutations and sequence variations. So the student model becomes really good at understanding how small changes in DNA lead to changes in biological function. The result is a single distilled model that can score the effects of a genetic variant across all those biological layers in one pass. And it's fast. On a high-end GPU, a variant can be evaluated in under a second. That's a big deal if you want to analyze millions of variants, which is exactly what researchers often need to do. Performance-wise, the results are honestly kind of ridiculous. For basic genome track prediction, meaning how well the model predicts real experimental signals on parts of the genome it never saw during training. Alpha Genome was tested on 24 different tasks. It outperformed the strongest existing model in 22 of them. It also beat highly specialized models that were designed for single tasks. For example, compared to Bour, another advanced multimodal genomics model, AlphaGenome showed a 14.7% relative improvement in predicting cell type specific gene expression changes. In genomics, jumps like that are not small. They can mean the difference between a vague hint and something researchers can actually rely on. Then there's variant effect prediction, which is where the medical and biological impact really shows up. They built 26 different benchmarks covering how well the model predicts the effects of mutations on gene expression, RNA splicing, chromatin accessibility, transcription factor binding, and more. Using the distilled student model, Alpha Genome matched or beat the best available external method in 25 out of",
        "start": 332.32,
        "duration": 983.12
    },
    {
        "text": "impact really shows up. They built 26 different benchmarks covering how well the model predicts the effects of mutations on gene expression, RNA splicing, chromatin accessibility, transcription factor binding, and more. Using the distilled student model, Alpha Genome matched or beat the best available external method in 25 out of improvements are huge. Splicing is one of the clearest examples of why this matters. Many diseases are caused by mutations that mess up how RNA is spliced. basically how the cell edits RNA before turning it into protein. Alpha Genome predicts splice donor and acceptor sites, how often they're used, and the actual splice junction red counts, all at base pair resolution. For gene expression, they tested how well the model predicts the effect of EQTLs, which are genetic variance known to influence how strongly genes are expressed. Using finemapped GTEX data, AlphaGenome improved the correlation between predicted and observed effect sizes from 0.39 to 0.49. That might sound like a modest change, but in complex biological systems, that's a significant leap in predictive power for predicting just the direction of effect whether a gene goes up or down. The performance also improved substantially at a threshold giving 90% accuracy. Alpha Genome recovered more than twice as many known EQTLs as the comparison model. They pushed this further into G-W was interpretation, which connects genetic variants to diseases and traits. Out of more than 18,000 G-W was credible sets, AlphaGenome could assign a confident direction of effect to at least one variant in nearly half of them. Interestingly, the sets it resolves don't overlap much with traditional statistical methods, meaning the AI is adding genuinely new biological insight rather than repeating what we already knew. The model also handles long range gene regulation where enhancers far away from a gene still control its activity. Using crisp enhancer gene linking data, Alpha Genome outperformed previous models in identifying which enhancers regulate which genes, especially when those enhancers are located tens of thousands of bases away. Its performance was almost as good as a model that was specifically trained for this one task. Despite alpha genome being a general purpose system, polyadenilation is another angle. Without being explicitly trained on polyadenilation data, alphagenome still captured patterns of alternative polyadenilation through its RNA seek predictions. On benchmarks, it significantly outperformed previous models in predicting how mutations affect where RNA transcripts end. for chromatin accessibility and transcription factor binding QTLs. It again beat both multimodal and specialized models. In some data sets, the correlation between predicted and observed mutation effects was very high and in silicone mutagenesis often revealed that predicted changes matched known DNA binding motifs for specific regulatory proteins. One of the most striking case studies is around the tal one anka gene in T- cell acute lymphoplastic leukemia. Several non-coding mutations are known to create new enhancer elements that drive tal one expression too high. Alpha genome predicted increased activating histone marks at those mutation sites, decreased",
        "start": 498.72,
        "duration": 1320.6400000000008
    },
    {
        "text": "proteins. One of the most striking case studies is around the tal one anka gene in T- cell acute lymphoplastic leukemia. Several non-coding mutations are known to create new enhancer elements that drive tal one expression too high. Alpha genome predicted increased activating histone marks at those mutation sites, decreased and increased RNA seek signal for tal 1 itself. When they compared real ankcogenic mutations to shuffled control sequences, the multimodal signatures clustered separately. In silicone, mutagenesis showed that an insertion created a myb binding motif, which matches previous experimental findings. That's the kind of deep mechanistic insight you normally only get after years of lab work. They didn't just show performance numbers, they also dissected why the model works. Studies showed that training at single base resolution really matters for tasks like splicing and accessibility. Having the full 1 megabase context improves results and shortening the context at inference time hurts performance. Distillation from many teachers allows the single student model to match or even beat large ensembles while being cheaper to run. And multimodal training consistently outperforms models trained on only one type of data, especially for predicting mutation effects. There are still challenges. Effects from very distant elements are harder to predict. Tissue specific patterns are not perfect. The training data is still biased toward protein coding genes. Even with those limits, AlphaGenome feels like a foundational step. One model, one sequence input, thousands of functional predictions, and state-of-the-art performance across almost every regulatory genomics task researchers care about. DeepMind also made it accessible through an API, a Python SDK, and a genome interpretation toolkit, so scientists can actually use it instead of just reading about it. All right, that's it for this one. Drop your take in the comments if you enjoyed this. Hit like, subscribe if you haven't already. Thanks for watching and I'll catch you in the next one.",
        "start": 669.68,
        "duration": 1523.2010000000007
    }
]