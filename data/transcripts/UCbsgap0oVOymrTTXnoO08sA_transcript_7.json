[
    {
        "text": " All right. So, a team at NVIDIA decides to run a wild experiment. Instead of engineers handwriting thousands and thousands of lines of deep learning system code, they let AI coding agents build the whole thing. And not just a small demo, but an actual deep learning engine that runs on GPUs, manages memory, handles training math, and can train real neural networks. And then they open source it. That system is called Vibe Tensor. And the story behind it feels like a preview of how software might get built in the future. So here's what makes this so fascinating. Deep learning frameworks, the tools like PyTorch that researchers and startups use every day are insanely complex under the hood. On the surface, you see a few lines of Python. Underneath there's C++ managing performance and below that specialized GPU code talking directly to hardware. There are systems that carefully manage memory so nothing slows down and engines that track millions of mathematical operations so AI models can learn from mistakes. Building something like that normally takes big teams and years of work. Now picture AI agents powered by large language models, writing and modifying that system code through an automated workflow, compiling it, running tests, and checking results without humans reviewing every single code change. That's exactly what happened here. Vibe Tensor is basically a full deep learning runtime stack. On the surface, it looks familiar to anyone who has used PyTorch. You write Python code, you create tensors, you run operations, and everything executes immediately instead of being pre-ompiled into a rigid structure. Underneath that friendly Python layer sits a C++ core that manages tensors, memory, and execution. And under that you have CUDA code controlling how work runs on NVIDIA GPUs, how tasks are scheduled, and how memory is allocated and reused. The wild part is that most of this code base came from AI agents proposing changes, compiling the system, running tests, and iterating over and over. Humans set highle goals like we need a tensor library that supports slicing without copying data or we need a smart GPU memory manager that shows diagnostics and the agents filled in the details sometimes thousands of lines at a time. Now vibe tensor is not trying to beat pietorch in performance or replace production frameworks. The goal is more like a giant proof of concept. It asks a very specific question. Can AI coding agents generate a coherent multi-layered system that stretches from high-level user code all the way down to low-level GPU memory management? And can we trust that system by validating it with builds and tests instead of line by line human review? Vibe Tensor shows that the answer is yes, at least to a surprising degree. Let's talk about what this system actually does. At its heart, Vibe Tensor has its own tensor and storage implementation. A tensor in this system knows its shape, how its data is laid",
        "start": 1.92,
        "duration": 364.55800000000005
    },
    {
        "text": "line human review? Vibe Tensor shows that the answer is yes, at least to a surprising degree. Let's talk about what this system actually does. At its heart, Vibe Tensor has its own tensor and storage implementation. A tensor in this system knows its shape, how its data is laid stores, and whether it lives on the CPU or GPU. It supports flexible views of data, meaning you can slice or reshape information without copying it, which is essential for performance in real AI models. The runtime also keeps track of version counters, so it can detect unsafe inplace edits, similar to how mature frameworks protect you from subtle bugs. Then there's a dispatcher which you can think of as the traffic controller for all operations. When you call something like add or matrix multiply from Python, the dispatcher figures out which version of that operation to run, whether on the CPU or GPU, and routes the call. It also wraps operations with extra logic when needed, like hooking them into the training system. This is deep system plumbing and the fact that AI agents wired up a functioning dispatcher that connects multiple layers of the stack is already impressive. On top of that sits a reverse mode autograd engine. This is the part that makes neural networks trainable. Every time you run a forward pass through a model, this engine quietly records how outputs depend on inputs. Later, during the backward pass, it walks that chain in reverse and computes gradients which tell the model how to adjust itself to get better. Vibe Tensor even experiments with multi-device setups where gradients can flow across different GPUs working together. All right, now quick break for a short detour. If you work with AI a lot and end up jumping between different models just to see which one actually fits a task, today's sponsor, Mammoth, makes that whole workflow much easier. Mammoth brings most of the major AI models into one place. Claude, GPT, Gemini, Llama, Mistl, Grock, Deepseek, Perplexity for Deep Research, plus image models like Flux, Nano Banana, and Recraft. And everything runs inside a single dashboard. What really helps in day-to-day use is the comparison setup. You can send the same prompt to different models at the same time and instantly see how each one responds. That makes it easier to choose the right model for writing, research, analysis, or images without guessing. You can also create custom Mammoths, basically your own presets with specific instructions for recurring tasks and keep things organized in projects. On the privacy side, Mammoth is based in Europe with data hosted in Germany, fully GDPR compliant, and models aren't trained on your data. Prompts aren't retained by providers, and you can delete your history whenever you want. Plans start at around \u20ac10 per month, or roughly $12, and it's already used by hundreds of companies and public institutions. Check it out using the link in the",
        "start": 184.159,
        "duration": 668.2380000000004
    },
    {
        "text": "and models aren't trained on your data. Prompts aren't retained by providers, and you can delete your history whenever you want. Plans start at around \u20ac10 per month, or roughly $12, and it's already used by hundreds of companies and public institutions. Check it out using the link in the video. Now, GPUs are where things get really interesting. Vibe Tensor includes a custom CUDA subsystem with streams, events, and support for CUDA graphs. In simple terms, this means the system can organize GPU work efficiently and even record sequences of operations to replay them faster later. The system also has a smart memory allocator designed specifically for GPU workloads. Instead of constantly asking the GPU for new memory and slowing things down, it reuses memory in safe ways and keeps detailed statistics so developers can see how memory usage changes over time. All of this was stitched together through an AI assisted workflow. The agents would propose code, build the project, run unit tests in both C++ and Python, and compare results against trusted systems like PyTorch. If a change passed the checks, it stayed. If something broke, the agents iterated and tried again. Humans guided priorities and reviewed highle direction, but the day-to-day code review was largely replaced by automated validation. The development process surfaced some very real system level bugs. GPU kernels would crash because they exceeded hardware limits. Numerical errors would appear because of subtle math differences like using the wrong formula in a stability trick. Training loops would suddenly diverge because a GPU buffer somewhere had been reused without proper initialization. Each time the workflow responded by adding targeted regression tests and rerunning everything slowly making the system more robust. Vibe Tensor also comes with an AI generated kernel suite. These are specialized GPU routines for tasks like layer normalization, rotary embeddings, and attention building blocks of modern AI models. Benchmarks compare these kernels against PyTorch baselines, sometimes showing big speedups in specific situations. For example, certain normalization and embedding routines run several times faster than the reference versions. Attention shows a more mixed story with gains in some large training setups and slower performance in smaller workloads. That variability highlights how performance depends heavily on hardware details and careful tuning. Beyond small tests, the team ran full training loops to see if everything works together. They trained a small transformer on a sequence reversal task, a vision transformer on the CR10 data set, and a mini GPT style model on Shakespeare text on both Hopper and newer Blackwell GPUs. Vibe tensor showed the same kind of learning curves as PyTorch. Loss decreased, accuracy improved, and text models became more coherent. That tells us the core pieces, tensors, autograd, optimizers, and GPU execution work together in realistic training. performance is slower, sometimes by a noticeable margin, which is expected for a prototype, but functional correctness at that scale is a big milestone. They even experimented with multi-GPU training using an experimental subsystem called Fabric and",
        "start": 338.479,
        "duration": 1003.1979999999996
    },
    {
        "text": "core pieces, tensors, autograd, optimizers, and GPU execution work together in realistic training. performance is slower, sometimes by a noticeable margin, which is expected for a prototype, but functional correctness at that scale is a big milestone. They even experimented with multi-GPU training using an experimental subsystem called Fabric and with Cutlass. This plugin is more of a research example than a replacement for production systems like NCCL, but it still managed to scale training across multiple GPUs with increasing throughput. that shows cross-device communication paths are wired up end to end. One of the most interesting lessons from this whole project is something the authors call a Frankenstein composition effect. Individual subsystems can look perfectly reasonable on their own, yet when you glue them together, you get unexpected global bottlenecks. In Vibe Tensor, certain safety first design choices in the training engine and operation routing introduced hidden slowdowns. For example, a global lock around parts of the backward pass made reasoning about correctness easier. But it also prevented multiple training tasks from running in parallel, leaving GPU power underused. These kinds of emergent inefficiencies are exactly the sort of thing humans and tools will need to watch for as AI generates more complex systems. There are also clear limitations. The API surface is incomplete compared to PyTorch. Many operations and distributed features are missing or only partially implemented. Performance tuning is minimal. The code sometimes shows inconsistent styles and redundant layers which are typical side effects of machine generated software. The authors openly position Vibe Tensor as a research and educational project not something to deploy in production. Still the significance of this project goes beyond raw speed. Vibensor acts like a living laboratory for AI assisted software engineering. It gives researchers and developers a real complex codebase to study how AI agents behave when building systems that span languages, abstraction layers, and hardware interfaces. It also highlights how crucial testing, comparisons against trusted systems, and reproducible benchmarks become when humans are no longer reading every line of code. From a broader perspective, this feels like an early glimpse of a new workflow. Engineers define goals and constraints. AI agents explore the solution space at scale, writing code, running builds, and validating behavior. Humans step in at the architectural and conceptual level, steering direction, and interpreting results. The combination can produce surprisingly sophisticated systems in far less time than traditional teams might need. So, when you hear AI just built its own deep learning engine, it's not hype about a magical, sentient programmer. It's a real demonstration that modern AI systems, guided carefully and boxed in by strong validation, can generate complex layered system software that actually runs, trains models, and talks directly to GPUs. All right, tell me what you think down in the comments. If you like big AI stories explained in a way that actually makes sense, subscribe and hit like so this reaches more people. Thanks for watching and",
        "start": 508.08,
        "duration": 1344.759
    },
    {
        "text": "system software that actually runs, trains models, and talks directly to GPUs. All right, tell me what you think down in the comments. If you like big AI stories explained in a way that actually makes sense, subscribe and hit like so this reaches more people. Thanks for watching and",
        "start": 680.16,
        "duration": 1344.759
    }
]