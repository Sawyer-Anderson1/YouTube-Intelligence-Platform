[
    {
        "text": " Okay. So, let me ask you. You said something recently that was quite provocative. You you said that China was winning the AI race, the AI competition. I know that you've got a powerful, you know, competitor in Huawei and Huawei has a lot of advantages you don't have. Why don't you describe this competition? Are we really losing? It was a very good headline. It was a great headline. Yeah. And and u apparently caught of a lot of attention. the the as you know with headlines, the disclaimer part the foundation part was left out of the headline. That's as we all know, Jensen Wong in effect delivering a quiet uncomfortable truth to Washington. This isn't just Chad GPD versus Deepseek. This is a much bigger contest across five layers, energy, chips, data centers, models, and applications. And here's the uncomfortable part. The US still leads where it matters most, which is advanced silicon. But China has been building strength somewhere else. China already has more power capacity. It builds data centers faster and it has real momentum in open-source AI models and applications. At the same time, Nvidia finds itself squeezed, restricted by policy on one side and quietly pushed by domestic alternatives on the other. Put that all together and a real risk emerges. The United States isn't losing a benchmark race. It actually risks losing access to the world's second largest AI market and watching China build a full AI stack at home, then sell that very stack to the rest of the world. Good evening, ladies and gentlemen. This is Front Page by A IM Network. So, for months now, we've been asking one core question. Who really controls the infrastructure of AI? Because AI today isn't just about models or chatbots. It's about electricity. It's about coding. It's about chips and it's about scale. And tonight, China has opened a new front in that battle. Not with faster electrons, but with light. Chinese researchers have published new work claiming that lightbased or photonic AI chips can outperform Nvidia's A100 GPUs by more than 100 times on specific vision and generative AI tasks while consuming only a fraction of the power. So let's be clear and upfront. This is not Nvidia is dead, but it actually genuinely matters because the headline system here is light gen developed by teams from Shingua University and Shanghai Giao Tong University. Alongside it is Axel, a hybrid photonic electronic accelerator. These chips don't work like GPUs. No, GPUs are digital, programmable, and flexible. They can train models, fine-tune them, run, inference, simulate physics, pretty much anything that you throw at them. That flexibility is also why they consume enormous power, generate massive heat, and depend on the most advanced fabs on the planet. Photonic chips take a very different approach. They use light waves to perform math through optical inference which is basically that makes certain operations image generation for example vision processing dn noising incredibly",
        "start": 0.32,
        "duration": 468.79999999999995
    },
    {
        "text": "they consume enormous power, generate massive heat, and depend on the most advanced fabs on the planet. Photonic chips take a very different approach. They use light waves to perform math through optical inference which is basically that makes certain operations image generation for example vision processing dn noising incredibly Think of GPUs as well generalpurpose power plants. They can run almost anything but they burn a lot of fuel doing that. What light genen does is different. It's like rewiring a specific part of the grid. So energy doesn't need to be converted at all. No detours, no waste. It can't power the whole city, but for the neighborhoods it's designed for, for example, vision, image synthesis, visual reasoning, it's dramatically faster, cleaner, and cheaper than a GPU could ever be. And that's why it won't train your next trillion parameter language model. But for certain visual and generative workloads, it doesn't compete with GPUs. It sidesteps what makes them inefficient. So why does this matter? And why does this matter right now? Because it's landing at a very sensitive geopolitical moment. The United States is easing restrictions to allow Nvidia's H200 chips back into China under licenses. The logic is pretty straightforward. Better China stays on Nvidia than fully decouples. But China isn't betting on one path alone. On one side, Hua Ascend is building a domestic electronic AI stack. On another, open weight models like Quen and Deep Seek are reducing dependence on US platforms. And now there is a third path which is the photonic shortcuts. Instead of chasing Nvidia node for node, China is effectively saying we'll win by being far more efficient where it actually counts. And that, ladies and gentlemen, has real consequences. Photonic accelerators could slash the cost of image and video AI. Data centers could become more mixed. GPUs for training, custom silicon for inference, photonix for vision, and the bottleneck shifts away from chip access toward how intelligently workloads are matched to hardware. This matters for policy makers too. Lower power draw means lower energy stress. Older fabs mean fewer choke points and specialized chips means sanctions don't always land where expected. So for countries like India, there's a quiet lesson here. The future of AI compute may not be about copying one dominant architecture but about choosing the right compute for the right job. So will this G change GPU clusters tomorrow? The answer is no. Big tech will keep buying GPUs. Clusters will keep growing. Training frontier models still needs that flexibility. But the question now being asked is a lot more subtle and more important. Where do GPUs truly make sense? And where does specialized compute quietly do the job better? That's how large systems actually mature. So in conclusion, here is the front page take. These light-based AI chips don't replace Nvidia, not at all. Where they do, what they do, sorry, is more interesting and nuanced. They show that the future of AI",
        "start": 234.64,
        "duration": 852.2409999999999
    },
    {
        "text": "compute quietly do the job better? That's how large systems actually mature. So in conclusion, here is the front page take. These light-based AI chips don't replace Nvidia, not at all. Where they do, what they do, sorry, is more interesting and nuanced. They show that the future of AI company, or for that matter, one physics model. The race is shifting from who has the fastest GPU to who can deliver the cheapest, cleanest compute at scale, whether it runs on electrons, photons, or something else entirely. Nvidia remains central for now. But the age of single stack AI world is maybe just maybe starting to fade. This is front page by A IM network. Like, share, subscribe, think AI and of course think A IM. [music]",
        "start": 429.52,
        "duration": 924.0809999999999
    }
]