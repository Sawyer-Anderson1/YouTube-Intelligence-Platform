[
    {
        "text": " [Music] Welcome to Zcass everyone. I'm Z Carval from ZK Research and here at Arthur Stadium at the US Open. IBM is a big sponsor here. I obviously the USDA use a lot of AI and their tennis fund. I'm going to talk to Miriam Ashuri VP of products for IBM about AI and and some of the stuff that we do with agents. And so before we get into that though, maybe just a quick intro on yourself and what you do with IBM. Absolutely. I'm running governance and AI for IBM. So that's a big job. What does that entail? So we are focusing on enterprise needs and what they need in production and scale. Exploring the use cases with them, figuring out the technology that they need to supply them, educating them about the risk associated with them and how we can go and in help to improve the adoption rate for them. Yeah. And when we were prepping this, I asked you what do you want to talk about? you said agents and that's a big topic and I I'm curious in your conversation with customers where are we in this whole agentic world when I when I look at the media it's all everybody talks about but when I talk to most customers they're thinking about it they like the idea but they're not really sure what to do what what's your sense of where customers are very good questions if you look into the numbers only 16 people 16% of the market have moved to production and escape so the rest of the market is still at the acceleration phase versus going to PC's versus going to production and seeing the real value. Why? What's going on in the market? Yeah. So, so there there are two wise that we can look into. Why the adoption rate is low and why there is excite excitement around agents. Let me start with the second one. Why agents? Why it's creating a lot of excitement in the market. 2023 was the year of exploration. Everyone was looking for a vow factor, aha moment. The primary use cases that we saw in enterprise were centered around really top six use cases. Information extraction, custom summarization, classification, content grounded question and answering, content generation, code generation. So if you have a use case that it can be accelerated with those, you're golden. Yeah. But that's just a small portion of enterprise use cases, right? That's why we started seeing the companies and enterprises really struggling to see the real value of Genai. Mid 2024, we started seeing LLM taking action and that was the window of opportunities for enterprise to bring that acceleration on those use cases to every single corner of their enterprise including the legacy systems through something that we call tool calling or function calling. Right? So that's really the trigger of excitement for the market that hey geni acceleration can be anywhere across an",
        "start": 0.04,
        "duration": 351.55999999999995
    },
    {
        "text": "enterprise to bring that acceleration on those use cases to every single corner of their enterprise including the legacy systems through something that we call tool calling or function calling. Right? So that's really the trigger of excitement for the market that hey geni acceleration can be anywhere across an Then we started seeing oh agents now we are talking about thinking mode reasoning capabilities that's additional compute you know additional compute translates to additional increased latency that's your response time power energy consumption carbon footprint and it translates to cost for the scale of enterprise so lots of efforts are on optimizations what does it mean to go at a scale with agents managing all the factors that we talked that but at the same time responsible implementation of AI right we're talking about the risk associated with LLMs that now are amplified because agents can potentially leak data agents can connect to external services agents can go and run delete some part of your code base right so things can go really wrong and it's essential for enterprises to understand what those risks are and how to mitigate them before they are able to go to production and scale. Yeah, I' I'm also seeing a lot of shadow AI use cases here where users want to use them and they're using these consumer grade ones and they're putting company data in them and it's creating a lot of risk for companies. and your your point on the models didn't say do I know the granite models the fact that IBM thing Arvin Christian CEO is very emphatic the future of AI is not more large models but small models that are more purpose-built and you know your whole granite family is built around that concept right exactly small models but also opens because you want to own the OSP to be able to tune these models the value of the small models is you fine-tune it on your proprietary data the data about your users your domain specific data to create something differentiated from the market that delivers the performance that you need for your target use case for a fraction of the cost. That's basically the story. So you need to own the IP. It needs to be open. It needs to be commercially permissible when it comes to licenses and you need to be able to trust the model. Does the company stand behind it for Grammy? We stand behind the models. Does the company provide visibility into how the model was trained or the data engineering pipeline? And that's really the core to the value of that. And so for people watching this, if they're thinking about it, they're excited about it. Where's a good starting point? You listed some use cases, but if there was a couple of places they should start, is it I hear contact center being used a lot, you know, for knowledge workers, maybe even",
        "start": 177.44,
        "duration": 650.76
    },
    {
        "text": "people watching this, if they're thinking about it, they're excited about it. Where's a good starting point? You listed some use cases, but if there was a couple of places they should start, is it I hear contact center being used a lot, you know, for knowledge workers, maybe even Where do you see the the lowhanging fruit that's high reward, low risk, or is or is that does that does that not exist? Well, I I I would change the question a little bit. I would say that be curious. Okay, information comes from everywhere. You don't need to chase the latest technology. You need to have a point of view of how it's going to help your business instead of chasing the best and latest because the market is evolving rapidly and you're just going to end up with fatigue and being exhausted chasing. So that's been a big problem for companies. They've told me they've been ready to move ahead with the project and then a model changes and then they load the new model and then as soon as they load the new model on the model changes again and they can't keep up. Right. Exactly. So here's the thing and I've been telling my customers the foundations and non-negotiables don't change for you. Like you know your problem state, you know the use case, you know the risk level that you can tolerate. The technology only gets better. So you have to be agile and nimble to be able to always pull the best of the technologies inside to your processes to be able to take advantage of that. So my my advice for the enterprises is look inside inside your org to see what is a good use case and problem that can benefit from there versus hey I need two agents by the end of the year looking for a use case to apply that to. And the second one, app change your processes to be nimbal because otherwise you can't take advantage of the best of the market. Yeah. And one of the other that comes up is skills, right? everyone's worried that AI is going to take jobs and and in actuality I do believe it takes some jobs, but I also think it creates other jobs. I'm just curious as to when you talk to customers how they're thinking through the skills. Well, AI is going to change all of our lives independent from the role. I started changing using AI in my job and I feel like when you learn how to get AI to work, you get so much more done. You feel empowered. You feel enabled. I feel like I can do way more the stuff that I've been working on. Actually, we ran a study. We talked to thousand AI application developers across the US that are building AI applications and we asked them, hey, do you use AI assisted",
        "start": 330.08,
        "duration": 919.3989999999999
    },
    {
        "text": "feel empowered. You feel enabled. I feel like I can do way more the stuff that I've been working on. Actually, we ran a study. We talked to thousand AI application developers across the US that are building AI applications and we asked them, hey, do you use AI assisted person, they said occasionally they use it. We are like perfect how much time saving are you getting out of that? The majority of them they said one to two hours. Four person they said about 6 hours. What does it tell you? It tells you if you have figured out how to use AI effectively to get it work to you. You can revolutionize the role that you can play. Free up your time to do more. So it's not about taking job. It's like empowering people to do way more and spend time on that. In fact, I read that in the IBM business value study. In fact, that underscores the point of when people say it's not AI that's going to take your job. It's the person that knows how to use AI that's going to take the job of the ones that are not using AI effectively. Yeah. It's a little bit like you wouldn't hire an accountant that doesn't know how to use Excel, right? It's just it's a tool. Yeah. Yeah. Yeah. All right. just last question then. from a a security and governance standpoint, what's some advice around there? I know everyone's excited about AI, but nobody wants their data to be, you know, used to build these to train these models and put on the internet. So, what are you advising customers there? How to make sure that they're protected? Very good question because only about 19% of the market today based on IBC stats is using looking at observability when it comes to AI. Is that right? Only 99, not 99%, 19%. What does it tell you? It tells you that enterprise hasn't yet moved to production. They are still exploring because if you can't move to production with all the risk associated with agents and things can go wrong without having that observability in place. So I I I I expect to see a lot more it is and I feel like there is going to be a lot more push on transparency and traceability of actions for agent behaviors. there's going to be a lot more push on optimization of the agent behavior. Like for example, managing the thinking mode. If you turn it on and you ask the model where is the capital of the par France, it's not going to just say Paris. It's going to think about okay so France is a country in Europe and basically it burns tokens for the scale of enterprise that translates to cost remember. So optimization plays a very important role in addition to observability. And is that one of the big value ads IBM",
        "start": 465.759,
        "duration": 1205.6389999999994
    },
    {
        "text": "Paris. It's going to think about okay so France is a country in Europe and basically it burns tokens for the scale of enterprise that translates to cost remember. So optimization plays a very important role in addition to observability. And is that one of the big value ads IBM lots of model providers, you got the models, you also have the security tools and the observability tools and you really take a full stack approach, right? Exactly. Exactly. And and specifically for managing risk and governance, you're looking for four buckets. The first one is pretory model, granite model that you mentioned. It's like the models that we can stand behind. The second bucket is automatically document the lineage of who touched the model for the agent at what point to do what. So you would be able to for the purpose of auditability go back and trace back to see what happened. The third one is the guard rails that we put in place. Guard rails like detecting PII, detecting toxic information, detecting information before they are going going to the agent and detecting information before they come out. We are also looking into risk and compliance. Looking into asking questions from the business is this an applicable practical state use case that it's okay to apply AI to that situation and if so regulations for different geographics and and basically having a solution versus just jumping on implementing an AI. All right. Well, thanks for the little primer here on agendic. Absolutely. Anything else you want to add? Just just be curious. Be curious and nimble. That's the key. And focus on your problems, not just chasing the technology. But don't forget about security and the compliance. Right. So, , and now we're going to watch a little tennis later, right? Absolutely. It's going to be a fun night. So, from Arthur Stadium on behalf of Sherry, I'm Zaval with ZK reaching. Thanks for watching. , give us a like and also hit that subscribe button. I'll see you next time on my next episode of Zcash. Thanks, Miam. Thank you. [Music]",
        "start": 612.0,
        "duration": 1416.538999999999
    }
]