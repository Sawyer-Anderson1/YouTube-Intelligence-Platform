[
    {
        "text": "We've had this fascinating conversation",
        "start": 3.12,
        "duration": 3.679
    },
    {
        "text": "that started with restraining and",
        "start": 4.72,
        "duration": 3.919
    },
    {
        "text": "mid-training. Let's get to",
        "start": 6.799,
        "duration": 4.72
    },
    {
        "text": "post-training. A lot of fun stuff in",
        "start": 8.639,
        "duration": 4.88
    },
    {
        "text": "post-training. So, what are some of the",
        "start": 11.519,
        "duration": 4.961
    },
    {
        "text": "interesting ideas in post-training? The",
        "start": 13.519,
        "duration": 5.68
    },
    {
        "text": "biggest one from 2025 is learning this",
        "start": 16.48,
        "duration": 4.559
    },
    {
        "text": "reinforcement learning with verifiable",
        "start": 19.199,
        "duration": 4.08
    },
    {
        "text": "rewards You can scale up the training",
        "start": 21.039,
        "duration": 4.16
    },
    {
        "text": "there which means doing a lot of this",
        "start": 23.279,
        "duration": 4.561
    },
    {
        "text": "kind of iterative generate grade loop",
        "start": 25.199,
        "duration": 5.281
    },
    {
        "text": "and that lets the models learn both",
        "start": 27.84,
        "duration": 4.64
    },
    {
        "text": "interesting behaviors on the tool use",
        "start": 30.48,
        "duration": 3.599
    },
    {
        "text": "and software side This could be",
        "start": 32.48,
        "duration": 3.52
    },
    {
        "text": "searching running commands on their own",
        "start": 34.079,
        "duration": 4.0
    },
    {
        "text": "and seeing the outputs and then also",
        "start": 36.0,
        "duration": 4.16
    },
    {
        "text": "that training enables this inference",
        "start": 38.079,
        "duration": 4.64
    },
    {
        "text": "time scaling very nicely And it just",
        "start": 40.16,
        "duration": 4.8
    },
    {
        "text": "turned out that this paradigm was very",
        "start": 42.719,
        "duration": 3.84
    },
    {
        "text": "nicely linked in this where it's this",
        "start": 44.96,
        "duration": 3.36
    },
    {
        "text": "kind of RL training enables inference",
        "start": 46.559,
        "duration": 3.761
    },
    {
        "text": "time scaling but inference time scaling",
        "start": 48.32,
        "duration": 3.36
    },
    {
        "text": "could have been found in different ways",
        "start": 50.32,
        "duration": 2.719
    },
    {
        "text": "So it's kind of this perfect storm of",
        "start": 51.68,
        "duration": 3.44
    },
    {
        "text": "the models change a lot in the way that",
        "start": 53.039,
        "duration": 5.441
    },
    {
        "text": "they're trained is a major factor in",
        "start": 55.12,
        "duration": 6.079
    },
    {
        "text": "doing so And this has changed how",
        "start": 58.48,
        "duration": 5.6
    },
    {
        "text": "people approach portraying dramatically",
        "start": 61.199,
        "duration": 5.28
    },
    {
        "text": "i Can you describe RVR popularized by",
        "start": 64.08,
        "duration": 4.88
    },
    {
        "text": "Deepseek R1? Can you describe how it",
        "start": 66.479,
        "duration": 3.121
    },
    {
        "text": "works",
        "start": 68.96,
        "duration": 2.72
    },
    {
        "text": "i Yeah, fun fact Um, I was on the team",
        "start": 69.6,
        "duration": 4.559
    },
    {
        "text": "that came up with the term RLVR, which",
        "start": 71.68,
        "duration": 4.88
    },
    {
        "text": "is from our Tulu 3 work before DeepSeek,",
        "start": 74.159,
        "duration": 4.161
    },
    {
        "text": "which is we don't take a lot of credit",
        "start": 76.56,
        "duration": 3.919
    },
    {
        "text": "for the being the people to popularize",
        "start": 78.32,
        "duration": 5.6
    },
    {
        "text": "the scaling RL, but as fun as what",
        "start": 80.479,
        "duration": 5.601
    },
    {
        "text": "academics get as an aside is the",
        "start": 83.92,
        "duration": 4.0
    },
    {
        "text": "ability to name and influence the",
        "start": 86.08,
        "duration": 4.0
    },
    {
        "text": "discourse because the closed labs can",
        "start": 87.92,
        "duration": 4.32
    },
    {
        "text": "only say so much that one of the things",
        "start": 90.08,
        "duration": 3.76
    },
    {
        "text": "you can do as an academic is like you",
        "start": 92.24,
        "duration": 3.36
    },
    {
        "text": "might not have the compute to train the",
        "start": 93.84,
        "duration": 4.239
    },
    {
        "text": "model but you can frame things in a way",
        "start": 95.6,
        "duration": 4.32
    },
    {
        "text": "that ends up being I describe it as like",
        "start": 98.079,
        "duration": 3.761
    },
    {
        "text": "a community can come together around",
        "start": 99.92,
        "duration": 3.92
    },
    {
        "text": "this RLVR term which is very fun and",
        "start": 101.84,
        "duration": 4.08
    },
    {
        "text": "then Deep Seek is the people that did",
        "start": 103.84,
        "duration": 3.919
    },
    {
        "text": "the training breakthrough which is they",
        "start": 105.92,
        "duration": 4.479
    },
    {
        "text": "scaled the reinforcer learning which was",
        "start": 107.759,
        "duration": 5.201
    },
    {
        "text": "you have the model generate answers and",
        "start": 110.399,
        "duration": 4.801
    },
    {
        "text": "then grade the completion if it was",
        "start": 112.96,
        "duration": 5.439
    },
    {
        "text": "right and then that accuracy is your",
        "start": 115.2,
        "duration": 5.12
    },
    {
        "text": "reward for reinforcement learning So",
        "start": 118.399,
        "duration": 4.641
    },
    {
        "text": "reinforcement learning is classically an",
        "start": 120.32,
        "duration": 4.799
    },
    {
        "text": "agent that acts in an environment and",
        "start": 123.04,
        "duration": 4.24
    },
    {
        "text": "the environment gives it a state and and",
        "start": 125.119,
        "duration": 4.161
    },
    {
        "text": "a reward back and you try to maximize",
        "start": 127.28,
        "duration": 3.759
    },
    {
        "text": "this reward In the case of language",
        "start": 129.28,
        "duration": 4.8
    },
    {
        "text": "models the reward is normally accuracy",
        "start": 131.039,
        "duration": 5.2
    },
    {
        "text": "on a set of verifiable tasks whether",
        "start": 134.08,
        "duration": 5.36
    },
    {
        "text": "it's math problems coding tasks and it",
        "start": 136.239,
        "duration": 5.681
    },
    {
        "text": "starts to get blurry with things like",
        "start": 139.44,
        "duration": 5.04
    },
    {
        "text": "factual domains like that is also in",
        "start": 141.92,
        "duration": 4.959
    },
    {
        "text": "some ways verifiable or constraints on",
        "start": 144.48,
        "duration": 5.44
    },
    {
        "text": "your instruction like respond only with",
        "start": 146.879,
        "duration": 5.041
    },
    {
        "text": "words that start with a Like all of",
        "start": 149.92,
        "duration": 4.64
    },
    {
        "text": "these things are verifiable in some way",
        "start": 151.92,
        "duration": 5.84
    },
    {
        "text": "And the core idea of this is you find a",
        "start": 154.56,
        "duration": 4.72
    },
    {
        "text": "lot more of these problems that are",
        "start": 157.76,
        "duration": 3.92
    },
    {
        "text": "verifiable and you let the model try it",
        "start": 159.28,
        "duration": 5.12
    },
    {
        "text": "many times while taking these RL steps",
        "start": 161.68,
        "duration": 6.0
    },
    {
        "text": "these RL gradient updates the",
        "start": 164.4,
        "duration": 4.72
    },
    {
        "text": "infrastructure evolved from this",
        "start": 167.68,
        "duration": 3.68
    },
    {
        "text": "reinforced learning from human feedback",
        "start": 169.12,
        "duration": 3.839
    },
    {
        "text": "where in that era the score they were",
        "start": 171.36,
        "duration": 3.599
    },
    {
        "text": "trying to optimize was a learned reward",
        "start": 172.959,
        "duration": 4.401
    },
    {
        "text": "model of aggregate human preferences So",
        "start": 174.959,
        "duration": 5.121
    },
    {
        "text": "you kind of change the problem domains",
        "start": 177.36,
        "duration": 5.04
    },
    {
        "text": "and that let the optimization go on to",
        "start": 180.08,
        "duration": 4.0
    },
    {
        "text": "much bigger scales which kind of",
        "start": 182.4,
        "duration": 4.08
    },
    {
        "text": "kickstart a major change in what the",
        "start": 184.08,
        "duration": 4.32
    },
    {
        "text": "models can do and how people use them",
        "start": 186.48,
        "duration": 4.8
    },
    {
        "text": "What kind of domains is uh RLVR",
        "start": 188.4,
        "duration": 3.919
    },
    {
        "text": "amendable to",
        "start": 191.28,
        "duration": 2.879
    },
    {
        "text": "i Math and code are the famous ones And",
        "start": 192.319,
        "duration": 4.801
    },
    {
        "text": "then there's a lot of work kind of on",
        "start": 194.159,
        "duration": 4.561
    },
    {
        "text": "what is called the rubrics which is",
        "start": 197.12,
        "duration": 3.28
    },
    {
        "text": "related to word people might have heard",
        "start": 198.72,
        "duration": 4.48
    },
    {
        "text": "as LM as a judge which is like for each",
        "start": 200.4,
        "duration": 5.199
    },
    {
        "text": "problem I'll have a set of problems in",
        "start": 203.2,
        "duration": 4.08
    },
    {
        "text": "my training data set I'll then have",
        "start": 205.599,
        "duration": 4.64
    },
    {
        "text": "another language model and ask it what",
        "start": 207.28,
        "duration": 4.72
    },
    {
        "text": "would a good answer to this problem look",
        "start": 210.239,
        "duration": 3.681
    },
    {
        "text": "like And then you could try the problem",
        "start": 212.0,
        "duration": 3.84
    },
    {
        "text": "a bunch of times over and over again and",
        "start": 213.92,
        "duration": 3.84
    },
    {
        "text": "assign a score based on this rubric So",
        "start": 215.84,
        "duration": 3.6
    },
    {
        "text": "that's not necessarily verifiable like a",
        "start": 217.76,
        "duration": 4.0
    },
    {
        "text": "math and code domain but this rubric's",
        "start": 219.44,
        "duration": 5.359
    },
    {
        "text": "idea and other scientific problems that",
        "start": 221.76,
        "duration": 4.96
    },
    {
        "text": "might be a little bit more vague is",
        "start": 224.799,
        "duration": 3.601
    },
    {
        "text": "where a lot of the attention is where",
        "start": 226.72,
        "duration": 3.439
    },
    {
        "text": "they're trying to push this set of",
        "start": 228.4,
        "duration": 4.0
    },
    {
        "text": "methods into these kind of more",
        "start": 230.159,
        "duration": 3.921
    },
    {
        "text": "openhanded domain so the models can",
        "start": 232.4,
        "duration": 2.559
    },
    {
        "text": "learn a lot more",
        "start": 234.08,
        "duration": 2.239
    },
    {
        "text": "i I think that's called reinforcement",
        "start": 234.959,
        "duration": 2.881
    },
    {
        "text": "learning with AI feedback right",
        "start": 236.319,
        "duration": 3.28
    },
    {
        "text": "i That's the older term from it that was",
        "start": 237.84,
        "duration": 4.16
    },
    {
        "text": "coined in anthropic constitutional AI",
        "start": 239.599,
        "duration": 4.401
    },
    {
        "text": "paper So it's like a lot of these",
        "start": 242.0,
        "duration": 4.08
    },
    {
        "text": "things come in cycles also just one",
        "start": 244.0,
        "duration": 5.28
    },
    {
        "text": "step back for the RLVR. So I think the",
        "start": 246.08,
        "duration": 5.2
    },
    {
        "text": "interesting beautiful thing here is that",
        "start": 249.28,
        "duration": 4.239
    },
    {
        "text": "you you ask the LM let's say a math",
        "start": 251.28,
        "duration": 3.92
    },
    {
        "text": "question and then you know the correct",
        "start": 253.519,
        "duration": 4.0
    },
    {
        "text": "answer and you let the LLM like you said",
        "start": 255.2,
        "duration": 4.559
    },
    {
        "text": "figure it out But how it does it I mean",
        "start": 257.519,
        "duration": 3.84
    },
    {
        "text": "you don't really constrain it much",
        "start": 259.759,
        "duration": 3.121
    },
    {
        "text": "There are some constraints you can add",
        "start": 261.359,
        "duration": 3.521
    },
    {
        "text": "like use the same language You don't",
        "start": 262.88,
        "duration": 3.92
    },
    {
        "text": "switch between Spanish and English. But",
        "start": 264.88,
        "duration": 3.84
    },
    {
        "text": "let's say you're pretty much hands off",
        "start": 266.8,
        "duration": 4.0
    },
    {
        "text": "You only give the question and the",
        "start": 268.72,
        "duration": 4.8
    },
    {
        "text": "answer and then the LM has to you know",
        "start": 270.8,
        "duration": 5.28
    },
    {
        "text": "just the task to arrive at the right",
        "start": 273.52,
        "duration": 4.32
    },
    {
        "text": "answer But the beautiful thing here is",
        "start": 276.08,
        "duration": 3.76
    },
    {
        "text": "what happens in practice is that the LM",
        "start": 277.84,
        "duration": 4.48
    },
    {
        "text": "will do a step-by-step description like",
        "start": 279.84,
        "duration": 4.639
    },
    {
        "text": "you know like as a student or like as a",
        "start": 282.32,
        "duration": 4.319
    },
    {
        "text": "yeah mathematician how you would derive",
        "start": 284.479,
        "duration": 4.16
    },
    {
        "text": "the solution it will give you or it will",
        "start": 286.639,
        "duration": 4.241
    },
    {
        "text": "use those steps and that helps actually",
        "start": 288.639,
        "duration": 5.361
    },
    {
        "text": "the model to improve its own accuracy",
        "start": 290.88,
        "duration": 4.4
    },
    {
        "text": "and then like you said the inference",
        "start": 294.0,
        "duration": 3.199
    },
    {
        "text": "scaling So inference scaling loosely",
        "start": 295.28,
        "duration": 4.32
    },
    {
        "text": "means basically spending more compute",
        "start": 297.199,
        "duration": 5.28
    },
    {
        "text": "during using the LM during inference and",
        "start": 299.6,
        "duration": 5.44
    },
    {
        "text": "here the inference scaling is that the",
        "start": 302.479,
        "duration": 4.641
    },
    {
        "text": "model would use more tokens and and also",
        "start": 305.04,
        "duration": 3.92
    },
    {
        "text": "I think in the R1 paper they showed the",
        "start": 307.12,
        "duration": 3.68
    },
    {
        "text": "longer they train the model the longer",
        "start": 308.96,
        "duration": 4.16
    },
    {
        "text": "the responses are they they grow over",
        "start": 310.8,
        "duration": 4.0
    },
    {
        "text": "time they use more tokens so it becomes",
        "start": 313.12,
        "duration": 3.359
    },
    {
        "text": "more expensive becomes more expensive",
        "start": 314.8,
        "duration": 4.32
    },
    {
        "text": "for simple tasks but these explanations",
        "start": 316.479,
        "duration": 4.321
    },
    {
        "text": "they help the model with the accuracy",
        "start": 319.12,
        "duration": 3.76
    },
    {
        "text": "there also interesting lot of papers",
        "start": 320.8,
        "duration": 4.32
    },
    {
        "text": "showing what the model explains does not",
        "start": 322.88,
        "duration": 4.0
    },
    {
        "text": "new does it have to be correct or maybe",
        "start": 325.12,
        "duration": 3.519
    },
    {
        "text": "it's even unrelated to the answer but",
        "start": 326.88,
        "duration": 3.44
    },
    {
        "text": "for some reason it still helps the model",
        "start": 328.639,
        "duration": 4.641
    },
    {
        "text": "like this this the fact that it is um",
        "start": 330.32,
        "duration": 4.8
    },
    {
        "text": "explaining and I think it's also again I",
        "start": 333.28,
        "duration": 3.359
    },
    {
        "text": "don't want to anthropomorphize these",
        "start": 335.12,
        "duration": 3.68
    },
    {
        "text": "LLMs but it's kind of like how we humans",
        "start": 336.639,
        "duration": 4.481
    },
    {
        "text": "operate right if there's a complex math",
        "start": 338.8,
        "duration": 4.8
    },
    {
        "text": "problem let's say in a math class you",
        "start": 341.12,
        "duration": 4.4
    },
    {
        "text": "usually have a note paper and you do it",
        "start": 343.6,
        "duration": 3.76
    },
    {
        "text": "step by step you cross out things and",
        "start": 345.52,
        "duration": 3.92
    },
    {
        "text": "the model also self-corrects and that",
        "start": 347.36,
        "duration": 4.16
    },
    {
        "text": "that was I think the aha moment in the",
        "start": 349.44,
        "duration": 3.759
    },
    {
        "text": "R1 paper they called it aha moment",
        "start": 351.52,
        "duration": 3.76
    },
    {
        "text": "because the model itself recognized that",
        "start": 353.199,
        "duration": 3.681
    },
    {
        "text": "made a mistake and then said \"Ah, I did",
        "start": 355.28,
        "duration": 3.199
    },
    {
        "text": "something wrong And so let me try",
        "start": 356.88,
        "duration": 4.72
    },
    {
        "text": "And I think that's just so cool that",
        "start": 358.479,
        "duration": 5.041
    },
    {
        "text": "this falls out of just giving it the",
        "start": 361.6,
        "duration": 4.24
    },
    {
        "text": "correct answer and having it figure out",
        "start": 363.52,
        "duration": 4.959
    },
    {
        "text": "how to do it that it kind of does in a",
        "start": 365.84,
        "duration": 4.72
    },
    {
        "text": "sense what a human would do Although,",
        "start": 368.479,
        "duration": 4.481
    },
    {
        "text": "LM don't think like humans It's kind of",
        "start": 370.56,
        "duration": 4.639
    },
    {
        "text": "like an interesting coincidence And the",
        "start": 372.96,
        "duration": 5.04
    },
    {
        "text": "the other nice side effect is it's great",
        "start": 375.199,
        "duration": 5.361
    },
    {
        "text": "for us humans often to see these steps",
        "start": 378.0,
        "duration": 4.56
    },
    {
        "text": "It builds trust but also we learn we",
        "start": 380.56,
        "duration": 3.84
    },
    {
        "text": "can double check things There's a lot",
        "start": 382.56,
        "duration": 3.52
    },
    {
        "text": "in here I think some of the debate",
        "start": 384.4,
        "duration": 2.96
    },
    {
        "text": "there's been a lot of debate this year",
        "start": 386.08,
        "duration": 3.839
    },
    {
        "text": "on if the language models like these aha",
        "start": 387.36,
        "duration": 4.24
    },
    {
        "text": "I think the aha moments are kind of fake",
        "start": 389.919,
        "duration": 3.921
    },
    {
        "text": "because in restraining you essentially",
        "start": 391.6,
        "duration": 4.159
    },
    {
        "text": "have seen the whole internet So you",
        "start": 393.84,
        "duration": 3.68
    },
    {
        "text": "have definitely seen people explaining",
        "start": 395.759,
        "duration": 3.761
    },
    {
        "text": "their work even verbally like a",
        "start": 397.52,
        "duration": 3.6
    },
    {
        "text": "transcript of a math lecture You try",
        "start": 399.52,
        "duration": 3.44
    },
    {
        "text": "this Oh, I messed this up And what",
        "start": 401.12,
        "duration": 4.0
    },
    {
        "text": "reinforce learning is this RLVR is very",
        "start": 402.96,
        "duration": 3.76
    },
    {
        "text": "good at doing is amplifying these",
        "start": 405.12,
        "duration": 3.199
    },
    {
        "text": "behaviors because they're very useful in",
        "start": 406.72,
        "duration": 3.599
    },
    {
        "text": "enabling the model to think longer and",
        "start": 408.319,
        "duration": 4.801
    },
    {
        "text": "to check its work And I agree that it",
        "start": 410.319,
        "duration": 4.401
    },
    {
        "text": "is very beautiful that this training",
        "start": 413.12,
        "duration": 3.44
    },
    {
        "text": "kind of the model learns to amplify this",
        "start": 414.72,
        "duration": 3.759
    },
    {
        "text": "in a way that is just so useful at the",
        "start": 416.56,
        "duration": 4.56
    },
    {
        "text": "final answers being better I can give",
        "start": 418.479,
        "duration": 4.081
    },
    {
        "text": "you also a hanson example I was",
        "start": 421.12,
        "duration": 4.639
    },
    {
        "text": "training the Gwen 3 base model with RLVR",
        "start": 422.56,
        "duration": 5.84
    },
    {
        "text": "on math 500. The base model had an",
        "start": 425.759,
        "duration": 6.56
    },
    {
        "text": "accuracy of about 15%. Just 50 steps",
        "start": 428.4,
        "duration": 6.72
    },
    {
        "text": "like in a few minutes with RLVR the",
        "start": 432.319,
        "duration": 6.241
    },
    {
        "text": "model went from 15% to 50% accuracy And",
        "start": 435.12,
        "duration": 5.28
    },
    {
        "text": "the more you can't tell me it's learning",
        "start": 438.56,
        "duration": 3.6
    },
    {
        "text": "anything about fundamentally about math",
        "start": 440.4,
        "duration": 2.16
    },
    {
        "text": "in",
        "start": 442.16,
        "duration": 1.759
    },
    {
        "text": "i the Quinn example is weird because",
        "start": 442.56,
        "duration": 2.8
    },
    {
        "text": "there's been two papers this years One",
        "start": 443.919,
        "duration": 2.881
    },
    {
        "text": "of which I was on that talks about data",
        "start": 445.36,
        "duration": 3.6
    },
    {
        "text": "contamination in Quinn and specifically",
        "start": 446.8,
        "duration": 3.92
    },
    {
        "text": "that they trained on a lot of this",
        "start": 448.96,
        "duration": 3.76
    },
    {
        "text": "special mid-training phase that we spent",
        "start": 450.72,
        "duration": 4.0
    },
    {
        "text": "like a minute on That's weird because",
        "start": 452.72,
        "duration": 4.08
    },
    {
        "text": "they train on problems that are almost",
        "start": 454.72,
        "duration": 2.879
    },
    {
        "text": "identical to that",
        "start": 456.8,
        "duration": 2.88
    },
    {
        "text": "i Exactly. And so you can see that",
        "start": 457.599,
        "duration": 4.561
    },
    {
        "text": "basically the RL it's not teaching the",
        "start": 459.68,
        "duration": 4.0
    },
    {
        "text": "model any new knowledge about math You",
        "start": 462.16,
        "duration": 2.96
    },
    {
        "text": "can't do that in 50 steps So the",
        "start": 463.68,
        "duration": 2.56
    },
    {
        "text": "knowledge is already there in the",
        "start": 465.12,
        "duration": 2.479
    },
    {
        "text": "pre-training. You're just unlocking it",
        "start": 466.24,
        "duration": 3.28
    },
    {
        "text": "I still disagree with the kind of",
        "start": 467.599,
        "duration": 3.201
    },
    {
        "text": "premise because there's a lot of weird",
        "start": 469.52,
        "duration": 3.44
    },
    {
        "text": "complexities that you can't prove",
        "start": 470.8,
        "duration": 4.56
    },
    {
        "text": "because one of the things that points to",
        "start": 472.96,
        "duration": 4.4
    },
    {
        "text": "weirdness is that if you take the queen 3",
        "start": 475.36,
        "duration": 4.16
    },
    {
        "text": "so-called base model and you can you",
        "start": 477.36,
        "duration": 3.839
    },
    {
        "text": "could Google on the screen you could",
        "start": 479.52,
        "duration": 3.519
    },
    {
        "text": "google like math data set hugging face",
        "start": 481.199,
        "duration": 3.84
    },
    {
        "text": "and you could take a problem and what",
        "start": 483.039,
        "duration": 4.16
    },
    {
        "text": "you do if you put it into queen 3 base",
        "start": 485.039,
        "duration": 4.0
    },
    {
        "text": "the all these math problems have words",
        "start": 487.199,
        "duration": 3.44
    },
    {
        "text": "so it would be like Alice has five",
        "start": 489.039,
        "duration": 4.081
    },
    {
        "text": "apples and takes one and gives three to",
        "start": 490.639,
        "duration": 3.521
    },
    {
        "text": "whoever and there are these word",
        "start": 493.12,
        "duration": 3.199
    },
    {
        "text": "problems with these Quenb base models",
        "start": 494.16,
        "duration": 4.0
    },
    {
        "text": "why people are suspicious of them is if",
        "start": 496.319,
        "duration": 3.44
    },
    {
        "text": "you change the numbers but keep the",
        "start": 498.16,
        "duration": 2.56
    },
    {
        "text": "words",
        "start": 499.759,
        "duration": 3.521
    },
    {
        "text": "i Quen will produce like a very high",
        "start": 500.72,
        "duration": 4.319
    },
    {
        "text": "without tools will produce a very high",
        "start": 503.28,
        "duration": 4.319
    },
    {
        "text": "accuracy like decimal representation of",
        "start": 505.039,
        "duration": 4.88
    },
    {
        "text": "the answer which means there's some like",
        "start": 507.599,
        "duration": 4.16
    },
    {
        "text": "at some time it was shown problems that",
        "start": 509.919,
        "duration": 4.161
    },
    {
        "text": "were almost identical to the test set",
        "start": 511.759,
        "duration": 4.481
    },
    {
        "text": "and it was using tools to get a very",
        "start": 514.08,
        "duration": 4.16
    },
    {
        "text": "high precision answer but a language",
        "start": 516.24,
        "duration": 4.88
    },
    {
        "text": "model without tools will never actually",
        "start": 518.24,
        "duration": 4.88
    },
    {
        "text": "have this So, it's kind of been this",
        "start": 521.12,
        "duration": 3.839
    },
    {
        "text": "big debate in the research community is",
        "start": 523.12,
        "duration": 3.6
    },
    {
        "text": "like how much of these reinforce",
        "start": 524.959,
        "duration": 3.281
    },
    {
        "text": "learning papers that are training on",
        "start": 526.72,
        "duration": 3.84
    },
    {
        "text": "Quen and measuring specifically on this",
        "start": 528.24,
        "duration": 4.32
    },
    {
        "text": "like math benchmark where there's been",
        "start": 530.56,
        "duration": 3.12
    },
    {
        "text": "multiple papers talking about",
        "start": 532.56,
        "duration": 2.64
    },
    {
        "text": "contamination is like how much can you",
        "start": 533.68,
        "duration": 3.12
    },
    {
        "text": "believe them And I think this is what",
        "start": 535.2,
        "duration": 3.68
    },
    {
        "text": "caused the reputation of RLVR being",
        "start": 536.8,
        "duration": 4.0
    },
    {
        "text": "about formatting because you can get",
        "start": 538.88,
        "duration": 4.079
    },
    {
        "text": "these gains so quickly and therefore it",
        "start": 540.8,
        "duration": 3.36
    },
    {
        "text": "must already be in the model But",
        "start": 542.959,
        "duration": 3.601
    },
    {
        "text": "there's a lot of complexity here that we",
        "start": 544.16,
        "duration": 3.92
    },
    {
        "text": "it's not really like controlled",
        "start": 546.56,
        "duration": 4.16
    },
    {
        "text": "experimentation so we don't really know",
        "start": 548.08,
        "duration": 5.28
    },
    {
        "text": "But if it weren't true um I would say",
        "start": 550.72,
        "duration": 4.08
    },
    {
        "text": "distillation wouldn't work right I",
        "start": 553.36,
        "duration": 3.12
    },
    {
        "text": "mean distillation can work to some",
        "start": 554.8,
        "duration": 4.24
    },
    {
        "text": "extent but the thing is that is I think",
        "start": 556.48,
        "duration": 4.4
    },
    {
        "text": "the biggest problem in LM research this",
        "start": 559.04,
        "duration": 3.04
    },
    {
        "text": "contamination because we don't know",
        "start": 560.88,
        "duration": 2.88
    },
    {
        "text": "what's in the data It's unless you have",
        "start": 562.08,
        "duration": 3.759
    },
    {
        "text": "a new data set it's really impossible",
        "start": 563.76,
        "duration": 4.96
    },
    {
        "text": "And the same you mentioned um math the",
        "start": 565.839,
        "duration": 4.721
    },
    {
        "text": "math data set which is a question and",
        "start": 568.72,
        "duration": 4.16
    },
    {
        "text": "then answer and an explanation is given",
        "start": 570.56,
        "duration": 3.76
    },
    {
        "text": "But then also even something simpler",
        "start": 572.88,
        "duration": 4.0
    },
    {
        "text": "like uh MMLU which is a multiple choice",
        "start": 574.32,
        "duration": 5.28
    },
    {
        "text": "benchmark if you just change the format",
        "start": 576.88,
        "duration": 6.8
    },
    {
        "text": "slightly um like I don't know you use a",
        "start": 579.6,
        "duration": 5.919
    },
    {
        "text": "dot instead of a parenthesis or",
        "start": 583.68,
        "duration": 3.599
    },
    {
        "text": "something like that the model accuracy",
        "start": 585.519,
        "duration": 3.121
    },
    {
        "text": "will vastly differ",
        "start": 587.279,
        "duration": 3.601
    },
    {
        "text": "i I think that that could be like a model",
        "start": 588.64,
        "duration": 4.48
    },
    {
        "text": "issue rather than a general issue",
        "start": 590.88,
        "duration": 3.519
    },
    {
        "text": "i It's not even malicious by the",
        "start": 593.12,
        "duration": 2.8
    },
    {
        "text": "developers of the LM like hey we want to",
        "start": 594.399,
        "duration": 3.041
    },
    {
        "text": "cheat at that benchmark It's just it",
        "start": 595.92,
        "duration": 3.039
    },
    {
        "text": "has seen something at some point and I",
        "start": 597.44,
        "duration": 3.2
    },
    {
        "text": "think the only fair way to evaluate an",
        "start": 598.959,
        "duration": 4.32
    },
    {
        "text": "LLM is to have a new benchmark that is",
        "start": 600.64,
        "duration": 4.879
    },
    {
        "text": "after the cutoff date when the LM was",
        "start": 603.279,
        "duration": 2.801
    },
    {
        "text": "deployed",
        "start": 605.519,
        "duration": 3.681
    },
    {
        "text": "i Can we lay out what would be the sort of",
        "start": 606.08,
        "duration": 4.64
    },
    {
        "text": "the recipe of all the things that will",
        "start": 609.2,
        "duration": 3.36
    },
    {
        "text": "be going into post training and you",
        "start": 610.72,
        "duration": 4.239
    },
    {
        "text": "mentioned our RLVR was a really exciting",
        "start": 612.56,
        "duration": 4.56
    },
    {
        "text": "effective thing Maybe we should",
        "start": 614.959,
        "duration": 4.721
    },
    {
        "text": "elaborate RHF still has a really",
        "start": 617.12,
        "duration": 5.2
    },
    {
        "text": "important component to play What kind",
        "start": 619.68,
        "duration": 4.08
    },
    {
        "text": "of other ideas are there on post",
        "start": 622.32,
        "duration": 1.84
    },
    {
        "text": "training",
        "start": 623.76,
        "duration": 1.68
    },
    {
        "text": "i I think you can kind of take this in",
        "start": 624.16,
        "duration": 4.16
    },
    {
        "text": "order I think you could view it as what",
        "start": 625.44,
        "duration": 5.12
    },
    {
        "text": "made 01 which was this first reasoning",
        "start": 628.32,
        "duration": 5.04
    },
    {
        "text": "model possible or what will the latest",
        "start": 630.56,
        "duration": 5.519
    },
    {
        "text": "model be and they actually have you're",
        "start": 633.36,
        "duration": 4.64
    },
    {
        "text": "going to have similar interventions at",
        "start": 636.079,
        "duration": 4.161
    },
    {
        "text": "these where you start with mid-training",
        "start": 638.0,
        "duration": 5.36
    },
    {
        "text": "and the thing that is rumored to enable",
        "start": 640.24,
        "duration": 5.44
    },
    {
        "text": "01 and similar models is really careful",
        "start": 643.36,
        "duration": 5.12
    },
    {
        "text": "data curation where you're providing a",
        "start": 645.68,
        "duration": 4.399
    },
    {
        "text": "broad set of like what is called",
        "start": 648.48,
        "duration": 4.479
    },
    {
        "text": "reasoning traces which is just the model",
        "start": 650.079,
        "duration": 5.841
    },
    {
        "text": "generating words in a forward process",
        "start": 652.959,
        "duration": 5.361
    },
    {
        "text": "that is reflecting like breaking down a",
        "start": 655.92,
        "duration": 3.919
    },
    {
        "text": "problem into intermediate steps and",
        "start": 658.32,
        "duration": 3.04
    },
    {
        "text": "trying to solve them So at mid-training",
        "start": 659.839,
        "duration": 4.321
    },
    {
        "text": "you need to have data that is similar to",
        "start": 661.36,
        "duration": 4.479
    },
    {
        "text": "this to make it so that when you move",
        "start": 664.16,
        "duration": 3.52
    },
    {
        "text": "into post training primarily with",
        "start": 665.839,
        "duration": 5.12
    },
    {
        "text": "this verifiable rewards it can learn and",
        "start": 667.68,
        "duration": 6.399
    },
    {
        "text": "then what is happening today is you're",
        "start": 670.959,
        "duration": 5.841
    },
    {
        "text": "figuring out which problems to give the",
        "start": 674.079,
        "duration": 5.601
    },
    {
        "text": "model and how long you can train it for",
        "start": 676.8,
        "duration": 5.2
    },
    {
        "text": "and like how much inference you can",
        "start": 679.68,
        "duration": 4.399
    },
    {
        "text": "enable the model to use when solving",
        "start": 682.0,
        "duration": 4.32
    },
    {
        "text": "these verifiable problems So as models",
        "start": 684.079,
        "duration": 5.521
    },
    {
        "text": "get better certain problems are no",
        "start": 686.32,
        "duration": 5.36
    },
    {
        "text": "longer like the model will solve them",
        "start": 689.6,
        "duration": 3.919
    },
    {
        "text": "100% of the time and therefore there's",
        "start": 691.68,
        "duration": 3.599
    },
    {
        "text": "very little signal in this If we pull",
        "start": 693.519,
        "duration": 3.841
    },
    {
        "text": "if we look at the GRPO equation this one",
        "start": 695.279,
        "duration": 4.481
    },
    {
        "text": "is famous for this because essentially",
        "start": 697.36,
        "duration": 5.52
    },
    {
        "text": "the reward given to the agent is based",
        "start": 699.76,
        "duration": 6.4
    },
    {
        "text": "on how good a given action a action is a",
        "start": 702.88,
        "duration": 5.04
    },
    {
        "text": "completion is relative to the other",
        "start": 706.16,
        "duration": 3.44
    },
    {
        "text": "answers to that same problem So if all",
        "start": 707.92,
        "duration": 3.12
    },
    {
        "text": "the problems get the same answer there's",
        "start": 709.6,
        "duration": 3.679
    },
    {
        "text": "no signal in these types of algorithms",
        "start": 711.04,
        "duration": 3.76
    },
    {
        "text": "So what they're doing is they're finding",
        "start": 713.279,
        "duration": 3.201
    },
    {
        "text": "harder problems which is why you hear",
        "start": 714.8,
        "duration": 3.52
    },
    {
        "text": "about things like scientific domains",
        "start": 716.48,
        "duration": 3.919
    },
    {
        "text": "which is like that's so hard like",
        "start": 718.32,
        "duration": 3.92
    },
    {
        "text": "getting anything right there If you",
        "start": 720.399,
        "duration": 3.281
    },
    {
        "text": "have a lab or something it just",
        "start": 722.24,
        "duration": 3.44
    },
    {
        "text": "generates so many tokens or much harder",
        "start": 723.68,
        "duration": 4.08
    },
    {
        "text": "software problems So the frontier",
        "start": 725.68,
        "duration": 3.839
    },
    {
        "text": "models are all pushing into these harder",
        "start": 727.76,
        "duration": 3.68
    },
    {
        "text": "domains and they can train on more",
        "start": 729.519,
        "duration": 3.681
    },
    {
        "text": "problems and the model will learn more",
        "start": 731.44,
        "duration": 4.8
    },
    {
        "text": "skills at once The RHF link to this is",
        "start": 733.2,
        "duration": 5.439
    },
    {
        "text": "kind of like RHF has been and still is",
        "start": 736.24,
        "duration": 3.839
    },
    {
        "text": "kind of like the finishing touch on the",
        "start": 738.639,
        "duration": 2.961
    },
    {
        "text": "models where it makes the models more",
        "start": 740.079,
        "duration": 4.88
    },
    {
        "text": "useful by improving the organization or",
        "start": 741.6,
        "duration": 4.88
    },
    {
        "text": "style or tone There's different things",
        "start": 744.959,
        "duration": 3.12
    },
    {
        "text": "that resonates to different audiences",
        "start": 746.48,
        "duration": 3.039
    },
    {
        "text": "Like some people like a really quirky",
        "start": 748.079,
        "duration": 3.44
    },
    {
        "text": "model and RHF could be good at enabling",
        "start": 749.519,
        "duration": 4.88
    },
    {
        "text": "that personality and some people hate",
        "start": 751.519,
        "duration": 6.0
    },
    {
        "text": "this like markdown billeted list thing",
        "start": 754.399,
        "duration": 4.641
    },
    {
        "text": "that the models do but it's actually",
        "start": 757.519,
        "duration": 2.88
    },
    {
        "text": "really good for quickly parsing",
        "start": 759.04,
        "duration": 4.0
    },
    {
        "text": "information in RHF this human feedback",
        "start": 760.399,
        "duration": 5.68
    },
    {
        "text": "stage is really great for just give",
        "start": 763.04,
        "duration": 4.72
    },
    {
        "text": "putting this into the model at the end",
        "start": 766.079,
        "duration": 4.481
    },
    {
        "text": "of the day So it's what made chat so",
        "start": 767.76,
        "duration": 5.04
    },
    {
        "text": "magical for people and that use has",
        "start": 770.56,
        "duration": 4.719
    },
    {
        "text": "actually remained fairly stable This",
        "start": 772.8,
        "duration": 5.68
    },
    {
        "text": "formatting can also help the models get",
        "start": 775.279,
        "duration": 5.841
    },
    {
        "text": "better at math problems for example So",
        "start": 778.48,
        "duration": 5.68
    },
    {
        "text": "it's like the border between style and",
        "start": 781.12,
        "duration": 5.519
    },
    {
        "text": "formatting and like the method that you",
        "start": 784.16,
        "duration": 5.679
    },
    {
        "text": "use to answer a problem is actually um",
        "start": 786.639,
        "duration": 5.2
    },
    {
        "text": "they're all very closely linked in terms",
        "start": 789.839,
        "duration": 3.361
    },
    {
        "text": "of when you're training these models",
        "start": 791.839,
        "duration": 3.44
    },
    {
        "text": "which is why ROF can still say make a",
        "start": 793.2,
        "duration": 3.6
    },
    {
        "text": "model better at math but these",
        "start": 795.279,
        "duration": 3.521
    },
    {
        "text": "verifiable domains are a much more",
        "start": 796.8,
        "duration": 3.76
    },
    {
        "text": "direct process to doing this because",
        "start": 798.8,
        "duration": 4.24
    },
    {
        "text": "it's kind of makes more sense with the",
        "start": 800.56,
        "duration": 4.24
    },
    {
        "text": "problem formulation which is why it kind",
        "start": 803.04,
        "duration": 3.44
    },
    {
        "text": "of ends up all forming together but to",
        "start": 804.8,
        "duration": 3.92
    },
    {
        "text": "summarize it's like mid-training is give",
        "start": 806.48,
        "duration": 4.479
    },
    {
        "text": "the model the skills it needs to then",
        "start": 808.72,
        "duration": 5.359
    },
    {
        "text": "learn RL and verifiable rewards is let",
        "start": 810.959,
        "duration": 5.361
    },
    {
        "text": "the model try a lot of time So put a",
        "start": 814.079,
        "duration": 3.76
    },
    {
        "text": "lot of compute into trial and error",
        "start": 816.32,
        "duration": 3.12
    },
    {
        "text": "learning across hard problems And then",
        "start": 817.839,
        "duration": 4.321
    },
    {
        "text": "RHF would be like finish the model make",
        "start": 819.44,
        "duration": 5.44
    },
    {
        "text": "it easy to use and kind of just round",
        "start": 822.16,
        "duration": 3.76
    },
    {
        "text": "the model out",
        "start": 824.88,
        "duration": 2.88
    },
    {
        "text": "i Can you comment on the amount of compute",
        "start": 825.92,
        "duration": 3.84
    },
    {
        "text": "required for RLVR?",
        "start": 827.76,
        "duration": 4.24
    },
    {
        "text": "i It's only gone up and up So I think",
        "start": 829.76,
        "duration": 4.96
    },
    {
        "text": "Grock 4 was famous for saying they use a",
        "start": 832.0,
        "duration": 3.839
    },
    {
        "text": "similar amount of compute for",
        "start": 834.72,
        "duration": 3.2
    },
    {
        "text": "restraining and post training Back to",
        "start": 835.839,
        "duration": 4.161
    },
    {
        "text": "the scaling discussion they involve",
        "start": 837.92,
        "duration": 3.84
    },
    {
        "text": "very different hardware for scaling",
        "start": 840.0,
        "duration": 3.68
    },
    {
        "text": "Pre-training is very computebound, which",
        "start": 841.76,
        "duration": 3.6
    },
    {
        "text": "is like this flops discussion which is",
        "start": 843.68,
        "duration": 3.839
    },
    {
        "text": "just how many matrix multiplications can",
        "start": 845.36,
        "duration": 4.08
    },
    {
        "text": "you get through in one time And because",
        "start": 847.519,
        "duration": 3.68
    },
    {
        "text": "RL you're generating these answers",
        "start": 849.44,
        "duration": 3.28
    },
    {
        "text": "you're trying the model in the real",
        "start": 851.199,
        "duration": 3.281
    },
    {
        "text": "world environments it ends up being",
        "start": 852.72,
        "duration": 3.28
    },
    {
        "text": "much more memory bound because you're",
        "start": 854.48,
        "duration": 3.599
    },
    {
        "text": "generating long sequences and the",
        "start": 856.0,
        "duration": 4.56
    },
    {
        "text": "attention mechanisms have this behavior",
        "start": 858.079,
        "duration": 4.801
    },
    {
        "text": "where you get a quadratic increase in",
        "start": 860.56,
        "duration": 4.399
    },
    {
        "text": "memory as you're getting to longer",
        "start": 862.88,
        "duration": 4.399
    },
    {
        "text": "sequences So the compute becomes very",
        "start": 864.959,
        "duration": 4.081
    },
    {
        "text": "different So you when in restraining",
        "start": 867.279,
        "duration": 3.281
    },
    {
        "text": "we would talk about a model I think if",
        "start": 869.04,
        "duration": 2.72
    },
    {
        "text": "we go back to like the Biden",
        "start": 870.56,
        "duration": 2.719
    },
    {
        "text": "administration executive order it's",
        "start": 871.76,
        "duration": 3.68
    },
    {
        "text": "like 10 to the with flops to train a",
        "start": 873.279,
        "duration": 4.401
    },
    {
        "text": "model If you're using flops in post",
        "start": 875.44,
        "duration": 3.68
    },
    {
        "text": "training it's a lot weirder because the",
        "start": 877.68,
        "duration": 3.519
    },
    {
        "text": "reality is just like how many hours are",
        "start": 879.12,
        "duration": 4.88
    },
    {
        "text": "you allocating how many GPUs for And I",
        "start": 881.199,
        "duration": 5.281
    },
    {
        "text": "think in terms of time the RL compute",
        "start": 884.0,
        "duration": 4.32
    },
    {
        "text": "is getting much closer because you just",
        "start": 886.48,
        "duration": 4.24
    },
    {
        "text": "can't put it all into one system like",
        "start": 888.32,
        "duration": 4.24
    },
    {
        "text": "restraining is so computationally dense",
        "start": 890.72,
        "duration": 3.52
    },
    {
        "text": "where all the GPUs are talking to each",
        "start": 892.56,
        "duration": 3.12
    },
    {
        "text": "other and it's extremely efficient where",
        "start": 894.24,
        "duration": 3.2
    },
    {
        "text": "RL has all these moving parts and it can",
        "start": 895.68,
        "duration": 4.08
    },
    {
        "text": "just take a long time to generate a",
        "start": 897.44,
        "duration": 4.72
    },
    {
        "text": "sequence of 100,000 tokens like if you",
        "start": 899.76,
        "duration": 5.36
    },
    {
        "text": "think about GBT 5.2 Pro taking an hour",
        "start": 902.16,
        "duration": 4.479
    },
    {
        "text": "it's like what if your training run has",
        "start": 905.12,
        "duration": 3.12
    },
    {
        "text": "a sample for an hour and you have to",
        "start": 906.639,
        "duration": 3.681
    },
    {
        "text": "make it so that's handled efficiently",
        "start": 908.24,
        "duration": 4.08
    },
    {
        "text": "So I think in GPU hours or just like",
        "start": 910.32,
        "duration": 4.8
    },
    {
        "text": "wall clock hours the RL runs are",
        "start": 912.32,
        "duration": 5.04
    },
    {
        "text": "probably approaching the number of days",
        "start": 915.12,
        "duration": 3.76
    },
    {
        "text": "as pre-training, but they probably",
        "start": 917.36,
        "duration": 3.599
    },
    {
        "text": "aren't using as many GPUs at the same",
        "start": 918.88,
        "duration": 3.84
    },
    {
        "text": "time There's rules of thumb where in",
        "start": 920.959,
        "duration": 3.12
    },
    {
        "text": "labs it's like you don't want your",
        "start": 922.72,
        "duration": 3.28
    },
    {
        "text": "restraining runs to last more than like",
        "start": 924.079,
        "duration": 3.281
    },
    {
        "text": "a month because they fail",
        "start": 926.0,
        "duration": 2.8
    },
    {
        "text": "catastrophically And if you were",
        "start": 927.36,
        "duration": 3.76
    },
    {
        "text": "planning a huge cluster to be held for 2",
        "start": 928.8,
        "duration": 6.0
    },
    {
        "text": "months and then it fails on day 50, the",
        "start": 931.12,
        "duration": 5.68
    },
    {
        "text": "opportunity cost is just so big So you",
        "start": 934.8,
        "duration": 4.159
    },
    {
        "text": "kind of don't want to just you people",
        "start": 936.8,
        "duration": 3.44
    },
    {
        "text": "don't want to put all their eggs in one",
        "start": 938.959,
        "duration": 3.361
    },
    {
        "text": "basket which is like GBT4 was like the",
        "start": 940.24,
        "duration": 3.839
    },
    {
        "text": "ultimate solo run and nobody ever wanted",
        "start": 942.32,
        "duration": 3.44
    },
    {
        "text": "to do it before where it took like 3",
        "start": 944.079,
        "duration": 3.521
    },
    {
        "text": "months to train and everybody was",
        "start": 945.76,
        "duration": 3.04
    },
    {
        "text": "shocked that it worked where I think",
        "start": 947.6,
        "duration": 2.32
    },
    {
        "text": "people are a little bit more cautious",
        "start": 948.8,
        "duration": 4.64
    },
    {
        "text": "and incremental now So RL VR is more",
        "start": 949.92,
        "duration": 5.919
    },
    {
        "text": "let's say unlimited how much you can",
        "start": 953.44,
        "duration": 4.88
    },
    {
        "text": "train or get still benefit where RLHF",
        "start": 955.839,
        "duration": 4.401
    },
    {
        "text": "because it's a preference tuning it you",
        "start": 958.32,
        "duration": 3.439
    },
    {
        "text": "reach a certain point where it doesn't",
        "start": 960.24,
        "duration": 3.36
    },
    {
        "text": "really make sense to spend more RL",
        "start": 961.759,
        "duration": 4.481
    },
    {
        "text": "budget on that So just a step back with",
        "start": 963.6,
        "duration": 4.32
    },
    {
        "text": "um preference tuning So there are",
        "start": 966.24,
        "duration": 4.08
    },
    {
        "text": "multiple people that can give multiple",
        "start": 967.92,
        "duration": 3.599
    },
    {
        "text": "let's say explanations for the same",
        "start": 970.32,
        "duration": 2.72
    },
    {
        "text": "thing and they can both be correct but",
        "start": 971.519,
        "duration": 3.361
    },
    {
        "text": "at some point you learn a certain style",
        "start": 973.04,
        "duration": 4.239
    },
    {
        "text": "and it doesn't make sense to you know",
        "start": 974.88,
        "duration": 4.319
    },
    {
        "text": "iterate on it My favorite example is",
        "start": 977.279,
        "duration": 4.48
    },
    {
        "text": "like if relatives ask me what laptop",
        "start": 979.199,
        "duration": 4.08
    },
    {
        "text": "they should buy I give them an",
        "start": 981.759,
        "duration": 3.041
    },
    {
        "text": "explanation or ask them like yeah what",
        "start": 983.279,
        "duration": 3.841
    },
    {
        "text": "is your um use case like they for",
        "start": 984.8,
        "duration": 5.279
    },
    {
        "text": "example prioritize battery life and",
        "start": 987.12,
        "duration": 4.639
    },
    {
        "text": "storage Other people like us for",
        "start": 990.079,
        "duration": 4.0
    },
    {
        "text": "example we would prioritize RAM and",
        "start": 991.759,
        "duration": 4.801
    },
    {
        "text": "compute and so but both both answers are",
        "start": 994.079,
        "duration": 4.32
    },
    {
        "text": "correct but different people require",
        "start": 996.56,
        "duration": 3.12
    },
    {
        "text": "different answers and with preference",
        "start": 998.399,
        "duration": 2.961
    },
    {
        "text": "tuning well you're trying to average",
        "start": 999.68,
        "duration": 4.0
    },
    {
        "text": "somehow like you are asking data",
        "start": 1001.36,
        "duration": 4.479
    },
    {
        "text": "labeler to give you the right well not",
        "start": 1003.68,
        "duration": 4.079
    },
    {
        "text": "the right the preferred answer and then",
        "start": 1005.839,
        "duration": 3.601
    },
    {
        "text": "you train on that but at some point yeah",
        "start": 1007.759,
        "duration": 3.52
    },
    {
        "text": "you learn that average preferred answer",
        "start": 1009.44,
        "duration": 4.56
    },
    {
        "text": "and there's no I think reason to keep",
        "start": 1011.279,
        "duration": 4.081
    },
    {
        "text": "training longer on it because you know",
        "start": 1014.0,
        "duration": 4.32
    },
    {
        "text": "it's just a style where with RLVR you",
        "start": 1015.36,
        "duration": 5.12
    },
    {
        "text": "literally give the model well you let",
        "start": 1018.32,
        "duration": 3.92
    },
    {
        "text": "the law model solve more and more",
        "start": 1020.48,
        "duration": 4.079
    },
    {
        "text": "complex difficult problems and so I",
        "start": 1022.24,
        "duration": 3.52
    },
    {
        "text": "think that it makes more sense to",
        "start": 1024.559,
        "duration": 5.36
    },
    {
        "text": "allocate more budget long-term to LRVR",
        "start": 1025.76,
        "duration": 7.919
    },
    {
        "text": "and also that right now we are in LRVR",
        "start": 1029.919,
        "duration": 6.0
    },
    {
        "text": "1.0 blend where it's still like that",
        "start": 1033.679,
        "duration": 4.4
    },
    {
        "text": "simple thing where we have a question",
        "start": 1035.919,
        "duration": 4.4
    },
    {
        "text": "and answer but we don't do anything with",
        "start": 1038.079,
        "duration": 5.041
    },
    {
        "text": "the one stuff in between So there also",
        "start": 1040.319,
        "duration": 4.88
    },
    {
        "text": "I mean multiple research papers also by",
        "start": 1043.12,
        "duration": 4.079
    },
    {
        "text": "Google for example on process reward",
        "start": 1045.199,
        "duration": 4.72
    },
    {
        "text": "models that also give scores for the",
        "start": 1047.199,
        "duration": 4.321
    },
    {
        "text": "explanation how correct is the",
        "start": 1049.919,
        "duration": 3.921
    },
    {
        "text": "explanation and I think that will be the",
        "start": 1051.52,
        "duration": 5.44
    },
    {
        "text": "next thing let's say our LVR 2.0 O for",
        "start": 1053.84,
        "duration": 5.76
    },
    {
        "text": "this year focusing in between question",
        "start": 1056.96,
        "duration": 4.719
    },
    {
        "text": "and answer like how to leverage that",
        "start": 1059.6,
        "duration": 3.52
    },
    {
        "text": "information the explanation to improve",
        "start": 1061.679,
        "duration": 3.521
    },
    {
        "text": "the explanation and help it to get",
        "start": 1063.12,
        "duration": 4.08
    },
    {
        "text": "better accuracy but then uh so that",
        "start": 1065.2,
        "duration": 3.68
    },
    {
        "text": "that's one angle and there was a",
        "start": 1067.2,
        "duration": 4.96
    },
    {
        "text": "deepseek math version two paper where",
        "start": 1068.88,
        "duration": 5.2
    },
    {
        "text": "they also had interesting uh inference",
        "start": 1072.16,
        "duration": 5.44
    },
    {
        "text": "scaling there where first they had um",
        "start": 1074.08,
        "duration": 5.68
    },
    {
        "text": "developed models that grade themselves a",
        "start": 1077.6,
        "duration": 4.079
    },
    {
        "text": "separate model and I think that that",
        "start": 1079.76,
        "duration": 3.68
    },
    {
        "text": "will be one aspect and the other like",
        "start": 1081.679,
        "duration": 4.561
    },
    {
        "text": "Nathan mentioned it will be for LRVR are",
        "start": 1083.44,
        "duration": 4.239
    },
    {
        "text": "branching into other domains",
        "start": 1086.24,
        "duration": 3.2
    },
    {
        "text": "i The place where people are excited are",
        "start": 1087.679,
        "duration": 4.081
    },
    {
        "text": "value functions which is pretty similar",
        "start": 1089.44,
        "duration": 4.239
    },
    {
        "text": "So process reward models",
        "start": 1091.76,
        "duration": 3.919
    },
    {
        "text": "i are kind of like process reward models",
        "start": 1093.679,
        "duration": 3.521
    },
    {
        "text": "assign",
        "start": 1095.679,
        "duration": 3.681
    },
    {
        "text": "how good something is to each kind of",
        "start": 1097.2,
        "duration": 4.08
    },
    {
        "text": "intermediate step in a reasoning process",
        "start": 1099.36,
        "duration": 4.0
    },
    {
        "text": "where value functions apply value to",
        "start": 1101.28,
        "duration": 3.68
    },
    {
        "text": "every token the language model",
        "start": 1103.36,
        "duration": 4.08
    },
    {
        "text": "generates Both of these have been",
        "start": 1104.96,
        "duration": 5.2
    },
    {
        "text": "largely unproven in the language",
        "start": 1107.44,
        "duration": 5.04
    },
    {
        "text": "modeling and this reasoning model era",
        "start": 1110.16,
        "duration": 4.24
    },
    {
        "text": "people are more optimistic about value",
        "start": 1112.48,
        "duration": 4.0
    },
    {
        "text": "functions forever for whatever reason",
        "start": 1114.4,
        "duration": 4.0
    },
    {
        "text": "now I think process reward models were",
        "start": 1116.48,
        "duration": 4.64
    },
    {
        "text": "tried a lot more in this prep",
        "start": 1118.4,
        "duration": 4.8
    },
    {
        "text": "pre-ereasoning model era and a lot of",
        "start": 1121.12,
        "duration": 3.36
    },
    {
        "text": "people had a lot of headaches with them",
        "start": 1123.2,
        "duration": 2.64
    },
    {
        "text": "So I think a lot of it is the human",
        "start": 1124.48,
        "duration": 4.319
    },
    {
        "text": "nature of like value models have a very",
        "start": 1125.84,
        "duration": 4.959
    },
    {
        "text": "deep history in reinforcement learning",
        "start": 1128.799,
        "duration": 3.281
    },
    {
        "text": "They're one of the first things that",
        "start": 1130.799,
        "duration": 3.521
    },
    {
        "text": "were core to like deep reinforce",
        "start": 1132.08,
        "duration": 4.0
    },
    {
        "text": "learning existing is like training value",
        "start": 1134.32,
        "duration": 3.92
    },
    {
        "text": "models in this So right now the",
        "start": 1136.08,
        "duration": 3.36
    },
    {
        "text": "literature people are excited about",
        "start": 1138.24,
        "duration": 2.64
    },
    {
        "text": "trying value models but there's very",
        "start": 1139.44,
        "duration": 3.359
    },
    {
        "text": "little proof in it and there are",
        "start": 1140.88,
        "duration": 3.76
    },
    {
        "text": "negative examples in trying to scale up",
        "start": 1142.799,
        "duration": 3.521
    },
    {
        "text": "process reward models These things",
        "start": 1144.64,
        "duration": 4.159
    },
    {
        "text": "don't always hold in the future I think",
        "start": 1146.32,
        "duration": 4.239
    },
    {
        "text": "we came to this discussion by talking",
        "start": 1148.799,
        "duration": 3.921
    },
    {
        "text": "about scaling and a simple way to",
        "start": 1150.559,
        "duration": 3.441
    },
    {
        "text": "summarize what you're saying with like",
        "start": 1152.72,
        "duration": 3.28
    },
    {
        "text": "you don't want to do too much RHF which",
        "start": 1154.0,
        "duration": 3.76
    },
    {
        "text": "is essentially the signal scales is",
        "start": 1156.0,
        "duration": 3.44
    },
    {
        "text": "people have worked on RHF for language",
        "start": 1157.76,
        "duration": 3.44
    },
    {
        "text": "models for years especially in intense",
        "start": 1159.44,
        "duration": 5.28
    },
    {
        "text": "infra after chat and this the first",
        "start": 1161.2,
        "duration": 5.28
    },
    {
        "text": "release of a reasoning model trained",
        "start": 1164.72,
        "duration": 4.72
    },
    {
        "text": "with RLVR openis01 had a scaling plot",
        "start": 1166.48,
        "duration": 4.48
    },
    {
        "text": "where if you increase the training",
        "start": 1169.44,
        "duration": 3.599
    },
    {
        "text": "compute logarithmically you get a linear",
        "start": 1170.96,
        "duration": 3.76
    },
    {
        "text": "increase in evaluations and this has",
        "start": 1173.039,
        "duration": 3.441
    },
    {
        "text": "been reproduced multiple times I think",
        "start": 1174.72,
        "duration": 2.88
    },
    {
        "text": "deepseeek had",
        "start": 1176.48,
        "duration": 3.12
    },
    {
        "text": "plot like this but there's no scaling",
        "start": 1177.6,
        "duration": 4.0
    },
    {
        "text": "law for RLHF where if you log increase",
        "start": 1179.6,
        "duration": 4.16
    },
    {
        "text": "the compute you get some performance in",
        "start": 1181.6,
        "duration": 4.4
    },
    {
        "text": "fact the seminal scaling paper for RLHF",
        "start": 1183.76,
        "duration": 4.08
    },
    {
        "text": "is scaling laws for reward model over",
        "start": 1186.0,
        "duration": 4.0
    },
    {
        "text": "optimization so it's like that's a big",
        "start": 1187.84,
        "duration": 5.12
    },
    {
        "text": "line to draw with RLVR and the methods",
        "start": 1190.0,
        "duration": 4.88
    },
    {
        "text": "we have now and in the future like they",
        "start": 1192.96,
        "duration": 4.8
    },
    {
        "text": "will follow the scaling paradigm which",
        "start": 1194.88,
        "duration": 5.76
    },
    {
        "text": "is like the best runs you can let to run",
        "start": 1197.76,
        "duration": 4.96
    },
    {
        "text": "for an extra six and you get a few",
        "start": 1200.64,
        "duration": 3.6
    },
    {
        "text": "performance but you can't do this with",
        "start": 1202.72,
        "duration": 3.6
    },
    {
        "text": "RHF and that is just going to be field",
        "start": 1204.24,
        "duration": 4.24
    },
    {
        "text": "defining and how people approach them",
        "start": 1206.32,
        "duration": 4.479
    },
    {
        "text": "where I'm a shill for people",
        "start": 1208.48,
        "duration": 4.48
    },
    {
        "text": "academically to do RHF and that's a good",
        "start": 1210.799,
        "duration": 4.0
    },
    {
        "text": "way to describe it is like to do the",
        "start": 1212.96,
        "duration": 4.32
    },
    {
        "text": "best RHF you might not need the extra 10",
        "start": 1214.799,
        "duration": 6.135
    },
    {
        "text": "or 100x of compute but to do the best",
        "start": 1217.28,
        "duration": 5.759
    },
    {
        "text": "snorts RLVR you do so I think there's",
        "start": 1220.934,
        "duration": 4.586
    },
    {
        "text": "a what I say is a seminal paper from",
        "start": 1223.039,
        "duration": 4.801
    },
    {
        "text": "what was a meta internship it's called",
        "start": 1225.52,
        "duration": 4.32
    },
    {
        "text": "it's like the art of scaling reinforce",
        "start": 1227.84,
        "duration": 4.0
    },
    {
        "text": "learning with language models they're",
        "start": 1229.84,
        "duration": 3.44
    },
    {
        "text": "what they describe as a framework as",
        "start": 1231.84,
        "duration": 3.44
    },
    {
        "text": "scale RL and their incremental",
        "start": 1233.28,
        "duration": 3.36
    },
    {
        "text": "experiment",
        "start": 1235.28,
        "duration": 4.08
    },
    {
        "text": "was like 10,000 B200 hours which is",
        "start": 1236.64,
        "duration": 4.88
    },
    {
        "text": "like thousands or tens of thousands of",
        "start": 1239.36,
        "duration": 4.16
    },
    {
        "text": "dollars per experiment And they do a",
        "start": 1241.52,
        "duration": 4.24
    },
    {
        "text": "lot of them which is just like this",
        "start": 1243.52,
        "duration": 4.56
    },
    {
        "text": "cost is not accessible to the average",
        "start": 1245.76,
        "duration": 4.88
    },
    {
        "text": "academic which is a hard equilibrium",
        "start": 1248.08,
        "duration": 5.04
    },
    {
        "text": "where it's trying to figure out how to",
        "start": 1250.64,
        "duration": 6.2
    },
    {
        "text": "learn from each community",
        "start": 1253.12,
        "duration": 3.72
    }
]