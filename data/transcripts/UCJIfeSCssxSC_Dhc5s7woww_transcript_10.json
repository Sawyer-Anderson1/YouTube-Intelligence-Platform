[
    {
        "text": " You mentioned RIP Llama. Is there a path to winning for Meta? i I think nobody knows They're moving a lot So, they're signing licensing deals with um Black Forest Labs, which is an image generation or midjourney or applying ma mainness. So, I think in some ways it's on the product and like consumer facing AI front It's too early to tell I think they have some people that are excellent and very motivated being close to Zuckerberg. So, I think that there's still a story to unfold there Llama is a bit different where Llama was the most focused expression of the organization and I don't see Llama being um supported to that extent I think it was a very successful brand for them So they still might do some part of participation in the open open ecosystem or continue the llama brand into a different surface People know what llama is i You think there's a llama i i Not an overweight one It's interesting Yeah, I think also just to recap a bit I think I mean Llama was the I would say pioneering open weight model and then Llama 123 lot of love but I think then I think what happened just hypothesizing or speculating I think the um leaders at Meta like the upper executives they I think they got really excited about Llama because they saw how popular it was in the community and then I think the problem was trying to let's say monetize the open not monetize the open source but like kind of use the open source forced to make a bigger splash in a s like to kind of force it almost it felt forced like developing these very big llama 4 models to have like the best like to be on the top of the benchmarks but I don't think the goal of llama models is to be on top of the benchmarks beating let's say chetropedia or other models I think the goal was to have a model that people can use trust uh modify understand it so that includes having smaller models they don't have to be the best models and what happened was just these models were of like the benchmarks suggest that they were better than they were by because I think they had like specific models trained on preferences that they performed well on the benchmark It's kind of like this overfishing thing to kind of force it to be the best but then at the same time well they didn't do the small models that people could used I think that no one could run these big models then And then there was kind of like a weird thing And I think it's just because people got too excited about headlines pushing the frontier I think I think i and too much like on the benchmarking side Yeah. Too much i I think it imploded under political are",
        "start": 2.96,
        "duration": 305.438
    },
    {
        "text": "then And then there was kind of like a weird thing And I think it's just because people got too excited about headlines pushing the frontier I think I think i and too much like on the benchmarking side Yeah. Too much i I think it imploded under political are misaligned incentives So like the researchers want to build the best models but there's a layer of organization and manager that is trying to demonstrate that they do these things And then there's lots of there's a lot of pieces and rumors where how like some horrible technical decision was made and how that comes in and it just seems like it kind of got too bad where it all just crashed out i We should we should also like give huge props to Mark Zuckerberg. I think it comes from Mark actually from Mark Zuckerberg from the top of the leadership saying open source is important I think that's like that if the fact that that exists means there could be a llama 5 where they learn the lessons from the benchmarking and say we're going to be GPTOSs and provide really awesome library of open source What people say is that there's a debate between Mark and Alexander Wong who is very bright but much more against open source And to the extent that he has a lot of influence over the AI or it seems much less likely because it seems like Mark brought him in for like a fresh um leadership aid in directing AI. And if the like open or closed is no longer the defining nature of the model I don't expect that to be a defining argument between Mark and Alex. So like they're both very bright But I just like I have a hard time understanding all of it because Mark wrote this piece in July of 2024 maybe which was like probably the best blog post at the time saying the case for open source AI and then July 2025 came around and it was like we're reevaluating our relationship with open source So it's just kind of like but I think also the the problem not the problem but I think well we may have been a bit also too harsh I think and that caused some of that because I think I mean we as open source developers or the open source community because I think even though the model was maybe not what everyone hoped for it got a lot of backlash and I think that was a bit unfortunate because I can see that as a company now they were hoping for positive headlines and uh instead of just getting no headlines or not these positive headlines in in turn they got negative headlines and then all it kind of reflected bad on the company and I think that is also something like where you it's maybe a spite reaction almost",
        "start": 156.239,
        "duration": 583.9990000000001
    },
    {
        "text": "for positive headlines and uh instead of just getting no headlines or not these positive headlines in in turn they got negative headlines and then all it kind of reflected bad on the company and I think that is also something like where you it's maybe a spite reaction almost something nice we try to g give you something cool like an open source model and now you are like you know kind of like being negative about us even like like for the company so in that sense it looks like well maybe then we'll change our mind I guess I don't know i yeah that's that's where the uh the dynamics of discourse on X can lead us as a community astray cut sometimes it feels random People pick the thing they like they don't like i And you can see the same thing with Gro uh 41 and Gro Code Fast one I don't think likewise people um love it publicly i Mhm. i But a lot of people use it So if you look to Reddit and X, they don't really give it praise from the programming community i but like they use it And the same thing with probably with Llama. I don't understand I don't understand the dynamics of either positive hype or negative hype I don't understand it I mean the story of one of the stories of 2025 is the US feeling the gap of llama which is like all the rise of these Chinese overweight models to the point where I was like that was the single issue I've spent a lot of energy on in the last five months is like trying to do policy work to get the US to invest in this Let's i tell me the story of Adam. i Adam project is it started as me calling it the American Deepseek project which doesn't really work for DC laughter audiences but it's the story of like what is the most impactful thing I could do with my career which is that the Chinese overweight models are cultivating a lot of power and there is a lot of demand for building on these open models especially in enterprises in the US that are very my about these Chinese models Going to Perplexity. The Atom Project American Truly Open Models is a US-based initiative to build and host highquality, genuinely overweight AI models and supporting infrastructure explicitly aimed at competing with and catching up to China's rapidly advancing open-source AI ecosystem i I think the one sentence summary would be that or two sentences One is a proposition that open models are going to be an engine for AI research because that is what people start with Therefore, it's important to own them And the second one is therefore the US should be building the best models so that the best researcher happens in the US and the US companies take the value",
        "start": 296.96,
        "duration": 873.4389999999999
    },
    {
        "text": "to be an engine for AI research because that is what people start with Therefore, it's important to own them And the second one is therefore the US should be building the best models so that the best researcher happens in the US and the US companies take the value is happening and without more investment in open models We have all the plots on the website where it's like and it's all these models that are excellent from these Chinese companies that are cultivating influence in the US and China and internationally And I think the US is spending way more on AI. And the ability to create open models that are half a generation or a generation beyond what the cutting edge of a closed labs is costs orders of like hundred million which is a lot of money but not a lot of the money to these companies So therefore we need a centralizing force of people who want to do this And I think we got signed engagement from people pretty much across the full stack whether it's policy i So there has been support from the administration I don't think anyone in the like technically in government has like signed it publicly but I know that people that have worked in AI policy both in Biden and Trump administration are very supportive of trying to promote open source models in the US. I think for example AI2 got a grant from the NSF for hund00 million over four years which is like the biggest CS grant the NSF has ever awarded and it's for AI2 to attempt to this and I think it's a starting point i but the best thing happens when there are multiple organizations building models because they can crosspollinate ideas and kind of build this ecosystem like I don't think of it just works if it's just llama releasing models to the world because then you can see llama can go away the same thing applies for AI too where it's I can't be the only one building models And I think that's like i that it becomes a lot of time spent on talking to people whether they're in policy I know Nvidia is very excited about this I think Jensen Wong has been specifically talking about the urgency for this and they've changed they've done a lot more in 2025 where the neutron models are more of a focus they've started releasing some data along with Nvidia's open models and like very few companies do this especially of Nvidia's size So like there is there is signs of progress and there we hear about reflection AI where they say their i billion fund raise is dedicated to building US open models and I feel like their announcement tweet is like it reads like a blog post sound right and I think that that cultural tide is starting to turn I think in in July was",
        "start": 444.0,
        "duration": 1154.3189999999993
    },
    {
        "text": "AI where they say their i billion fund raise is dedicated to building US open models and I feel like their announcement tweet is like it reads like a blog post sound right and I think that that cultural tide is starting to turn I think in in July was caliber Chinese overweight models in zero from the US and that's that's the moment where I was released this and I was like oh I guess I have to spend energy on this cut nobody else is going to do it i So it takes a lot of it takes a lot of people contributing together and I don't say that like the atom project isn't like the thing that's helping to move the ecosystem but it's people like me doing this sort of thing to get the word out",
        "start": 586.56,
        "duration": 1198.4789999999994
    }
]