[
    {
        "text": " For our first story, we have a brand new product from Chat GPT. This is called Pulse and it is a major change from having AI be mostly if not entirely reactive to being proactive. So, what ChatGpt Pulse is going to do for you is basically think overnight as you're not using it. Look at all of your conversation history. Look at all of the memory it has about you and come up with a proactive list of things that you might like to learn more about. All right, so I just opened up Chad GPT and here's what it looks like for me. So I have today's pulse, open AAI, Nvidia's massive 10 gawatt alliance, a clean GPU data center overlay, and AI agents trading without human oversight. So if I click into it, hi Matt, I'm here to surface what's helpful to you. Once a day, every day, you decide what shows up. And it's starting to give me different articles that I can read. So get insights from your emails and calendar. Let's go ahead and allow that. And yeah, as you can see, you can decide what stays and what doesn't. So, keep me updated on. If I click that, I could actually specifically type out topics, which is really nice. And then all of these topics are things that obviously I have been asking about. So, it has a little curate button in the bottom right. I click that and again, I can basically just tell it anything to keep me updated on stocks, weather, stories that I'm interested in. I can probably ask it to go into my email and start digging around in there and give me up-to-date information every morning. So, seems like a really cool feature. According to the blog post by OpenAI, Pulse is a new experience where Chatbt proactively does research to deliver personalized updates based on your chats, feedback, and connected apps like your calendar. You can curate what chatbt researches by letting it know what's useful and what isn't. So, here's an example of what that looks like. It kind of feels like what Perplexity does automatically. It surfaces research topics that it thinks you're going to be interested in or what is trending. And now chatbt does the same thing for you. It's only available on mobile and it's only available to pro users which Sam Alman already hinted was going to be the case with features being released over the next few weeks because they are very computeheavy. Now do you remember that research paper by letter AI called sleeptime compute? This kind of feels like that AI running in the background when you're not using it doing premputee for you figuring out things that you want to learn that you want to do and then when you wake up it presents it to you so you don't have to wait is a phenomenal strategy for getting a lot",
        "start": 0.16,
        "duration": 303.19900000000007
    },
    {
        "text": "in the background when you're not using it doing premputee for you figuring out things that you want to learn that you want to do and then when you wake up it presents it to you so you don't have to wait is a phenomenal strategy for getting a lot have open sourced a model that is better than Nano Banana. Plus we have variants of it like what was just released one 2.2 Animate. This open- source model allows you to create incredible textto image generations and then also animate them. So with W 2.2 Animate, bring your characters to life like never before. We're officially launching Juan 2.2 Animate, a unified model for highfidelity character animation and replacement. This is a very common, very popular use case. So if you haven't tried this out, definitely give it a try. Feed it a character image and a reference video and it will animate your character by precisely replicating the sourc's expressions and movements. Seamlessly swap the animated character into the original video scene. It automatically matches the lighting and color tone for perfect environmental integration. So if you want to try it out, just go to one. And they also have Juan 2.5, which is text to video. So these are fantastic models. We've been testing them internally. And more from text to video, we have a new model from Clling. And it's another fantastic model. Check this out. Introducing Cling AI 2.5 Turbo Video Model Next Level Creativity Turbocharged. Now at an even lower price from Cling AI. So you can see here, these are all videos from Cling. And again, we've been testing it out, having a lot of success. The clarity, the character consistency, the text consistency, all excellent. And because it's turbo, it is very fast. Look at this one. It is especially impressive. We have what looks to be going through some kind of black hole, a spaceship. We have anime, a handdrawn skier. This looks incredibly real. I cannot get over this. Every single detail on the soldier's outfit, the mud on the face, the helmet, everything just looks so real. So, go try it out. Cling AI. And quickly, let me just tell you about the sponsor of today's video, Windsurf. Windsurf is today's most powerful agentic IDE where developers are carrying out their best work from solo projects from tinkers all the way up to enterprise organizations with millions of lines of code. Windsurf is built to keep you moving fast but without sacrificing security especially after being acquired by Cognition the creators of Devon. The Windsurf team seems to be shipping faster than ever. Windsurf is faster. It's also gotten a makeover and it's more reliable. They also ship features like deep wiki and vibe and replace. Windsurf also comes with a one-click MCP store and a really sophisticated memory feature. And now a deep integration with Devon makes it even more powerful. If you've watched",
        "start": 151.36,
        "duration": 616.159
    },
    {
        "text": "faster. It's also gotten a makeover and it's more reliable. They also ship features like deep wiki and vibe and replace. Windsurf also comes with a one-click MCP store and a really sophisticated memory feature. And now a deep integration with Devon makes it even more powerful. If you've watched of Windsurf. So definitely check them out. I'll drop a link down below. Thanks again to Windsurf for sponsoring this video. Now back to the video. And another one from Alibaba. We have a new version of Quen. This is Quen imageEdit 25509 and it is again comparable to Nano Banana. These are fantastic models. So multi-image editing, single image consistency, control net builtin and it's open weights. You can find it on hugging face. So here are a few examples from the blog post. We have a woman, we have a man and we can put them together in what looks to be traditional Chinese garb. And then over here in wedding outfits, again, we have a chair, we have a woman, we can put the woman on the chair, we can put her in this little coffee shop, and it's all very easy, very consistent. The characters look the same between the image generations. Very impressive. Of course, we can even do product generations. So, we have the LV bag here. We have this woman. And, of course, now she's wearing the bag. And you can see the little LV logo here. And it's the same one as found in the original image. We have this beautiful car here, this woman. And now she's standing next to the car. We can even do character poses. So, here's the pose. Here's the woman. And now she's posed like that. And same here. Same thing. We have a new pose. And there it is. It can even do colorization. Here it is in black and white. And colorized. It looks really good. And it can also do photo restoration. So, look at this. absolutely destroyed photo and nearly put back perfectly. The only thing I see that might be a little wrong is this guy's eyes on the right side are looking towards the camera in the destroyed image and then in the new restored one he's looking down off to the right. But otherwise just fantastic. So give it a try. Download it to your machine. Let me know what you think. And another one from Quen. We have Quen 3 Max. We've supercharged coding and agentic skills. Quen 3 max instruct without thinking rivaling top models on sui bench tow bench super GPQA live codebench and Amy 2025 with max thinking equipped with tool use and deployed in heavy mode. It's nearly perfect on key benchmarks. Let's take a look. So here we have Quen 3 Max Instruct compared to Quen 3 Claude Opus 4 non-thinking and Deepseek v3.1 non-thinking. And yes, Quen 3 Max Instruct just demolishes. The only one",
        "start": 311.199,
        "duration": 925.197
    },
    {
        "text": "equipped with tool use and deployed in heavy mode. It's nearly perfect on key benchmarks. Let's take a look. So here we have Quen 3 Max Instruct compared to Quen 3 Claude Opus 4 non-thinking and Deepseek v3.1 non-thinking. And yes, Quen 3 Max Instruct just demolishes. The only one course, it loses out to Claude Opus for non-thinking. And Quen 3 Max thinking heavy with Python use scored a 100. Now, that is very impressive. But of course, Gro 4 and GPT5 Pro, both with Python, both got a 100 score. And on the GPQA, it's scoring an 85.4 4 as compared to 89.4 at the top slot with GPT5 Pro. These are phenomenal results. Chinese models have absolutely caught up at this point. And from Kimmy Moonshot, this is a feature release called Okay Computer, your AI product and engineering team allin-one. So from chat, multi-page websites, mobile first designs, editable slides from up to 1 million rows of data. You get interactive dashboards natively trained on tools. So this is just their agent mode essentially. and it has computer use. It has its own environment, more steps, tokens, and tools than chat mode with Turbo K2. And to use it, you go to Kimmy and there's an okay computer button right there. Next from Google, we have a robotics model, Gemini Robotics ER1.5, currently state-of-the-art on a set of embodied reasoning tasks and can be used directly through the Gemini API or Google AI Studio. This is a high-level reasoning model specifically for robots. You could try it today immediately with Google AI Studio. So what are the features of a model that is specifically made for robots? It has fast and powerful spatial reasoning, orchestrate advanced agentic behavior, flexible thinking budget, improved safety filters. Now, interestingly, one of the benchmarks for robots is called a pointing benchmark. And it is essentially the ability for a robot to point at something after being told what to point at. and Gemini Robotics ER1.5 scoring above 50%. It could also generate 2D points. So obviously it's taking in video and then it could label the things that it's seeing. So here's a dish rack, a faucet, dish soap, and a rice cooker. And the prompt is very simple. So point to the following items in the image. Dish soap, dish rack, faucet, rice cooker, and so on. Here we can actually see it with robot arms moving the objects around while still maintaining the labels. So, if you're building a robot or you just want to try it out, go check it out. Google AI Studio. Next, XAI is now being made available to the US government, announcing an expansion to XAI for government, making industryleading Frontier AI accessible to the United States federal government users. All federal agencies and departments will get access to our Frontier AI models, Grock 4, Gro 4 fast, for 42 cents per department for a period of 18 months",
        "start": 467.199,
        "duration": 1241.0369999999998
    },
    {
        "text": "US government, announcing an expansion to XAI for government, making industryleading Frontier AI accessible to the United States federal government users. All federal agencies and departments will get access to our Frontier AI models, Grock 4, Gro 4 fast, for 42 cents per department for a period of 18 months of Grock engineers to help the government harness our AI to its fullest potential. So 42 cents for 18 months sounds pretty darn good to me. And next, if you've ever used AI for creative writing or any writing, you probably know what it looks like when AI writes a paragraph or an essay or a tweet. It's called AI slop. And apparently there might be a way to actually detect AI slop in a new paper measuring AI slop in text from Northeastern University. They apparently have found a way to detect AI slop. So check this out. We have a few paragraphs of text here and indicator of human writing. The word dribbling indicator of human writing rescued in quotes. And another one, Adam's media team did not immediately respond to request for comment. Okay, now let's look at what slop looks like. So, density, verbosity, tone, filled the earth and area that formerly held the puddle, just too many words, a little bit wordy around the repaired hydrant, leaving it looking like the city's smallest ever crime and so on. And then we have an indicator of human writing and slop. So, a little bit of both. And so, yeah, apparently they figured out a way to detect it. And if you can detect it, you can improve it. And I'm really hoping AI slop gets improved soon because I want to use it for creative writing. But it's just so painfully obvious when AI has written something for you. So here's the paper. If you want me to do a full breakdown, let me know in the comments below. Next, we have a new model coming out of Meta. Now, this is the fair team. This is not the TBD team, the new Alexander Wang team. This is the existing fair team led by Yan Lun. So new from Metaphair code world model a 32 billion parameter research model designed to explore how world models can transform code generation and reasoning about code and it is an openw weightights model and it also is open-source. So what makes this model different is that it's not learning based on existing code. It is actually generating code and learning from code execution. It's basically learning how models learn to play chess. It just plays chess over and over again and finds what works. Now it's doing that with code. And this is more in the direction of understanding worlds, which is very different from just understanding the words that are given to it. And this is very much what Yan Lun is all about. He says large language models are not enough to reach AGI. And",
        "start": 627.519,
        "duration": 1530.317
    },
    {
        "text": "that with code. And this is more in the direction of understanding worlds, which is very different from just understanding the words that are given to it. And this is very much what Yan Lun is all about. He says large language models are not enough to reach AGI. And understanding is definitely a Yan Lun signature. So check it out. I'll drop the links down below. And next, it seems like the $500 billion number for building out new data centers, people were doubting the Stargate project and it seems like it's coming to fruition right now. So, OpenAI, Oracle, and SoftBank expand Stargate with five new AI data center sites. It puts it ahead of schedule to secure the 500 billion 10 gigawatty commitment by the end of 2025. They have their flagship site in Abalene, Texas, and more sites coming in Shackleford County, Texas, Da Anna County in New Mexico, and a site in the Midwest, which they expect to announce soon. Together, these sites are expected to create over $25,000 jobs. And that's not all. Nvidia is putting in $100 billion into Open AI. It really seems like Nvidia is playing kingmaker here. Open AAI and Nvidia today announced a letter of intent for a landmark strategic partnership to deploy at least 10 gigawatts of Nvidia systems. Unreal. That is an unreal amount of compute. And I don't really understand how that's happening. Nvidia is giving OpenAI money and then OpenAI is going to pay Nvidia for the chips and they both get credit for the revenue or it's very confusing. I'm thinking about making a breakdown video just explaining how all of these roundtrip payments work between Oracle and OpenAI, Nvidia, Coreeave, etc. So, all of these companies seem to just be paying each other over and over again. It's kind of weird. And next, Meta. Facebook specifically is getting into the AI dating assistant game. Facebook Dating adds features to address swipe fatigue. We're introducing a dating assistant and meet cute, two new Facebook dating features that help you skip the swipe and give you fresh ways to connect with the people you want to date. It gives you personalized help on your dating journey. It can help find better matches based on your interests and preferences, giving you refined search and custom match recommendations. Now, at least this isn't an AI girlfriend. And if it's helping people find romantic connections, great. And next, Sam Alman gave some hints as to what is coming over the next few weeks. Remember, just two weeks from now is dev day. Over the next few weeks, we are launching some new compute intensive offerings. Because of the associated cost, some features will initially only be available to pro subscribers. You know, I'll test it out. You know, I'll break it down and I will show you. Our intention remains to drive the cost of intelligence down as aggressively as we can to make our services widely",
        "start": 774.56,
        "duration": 1834.2349999999997
    },
    {
        "text": "the associated cost, some features will initially only be available to pro subscribers. You know, I'll test it out. You know, I'll break it down and I will show you. Our intention remains to drive the cost of intelligence down as aggressively as we can to make our services widely get there over time. But we also want to learn what's possible when we throw a lot of compute at today's model costs. Some people are thinking this means Sora 2 is coming because that is probably the most comput inensive model that they have. Maybe it's some kind of extended GPT5 Pro version where it's multiple agents going at the same time. We don't know yet, but as soon as I find out, you'll be the first to know. So, that's it for today. If you enjoyed this video, please consider giving a like and subscribe.",
        "start": 929.199,
        "duration": 1888.5559999999996
    }
]