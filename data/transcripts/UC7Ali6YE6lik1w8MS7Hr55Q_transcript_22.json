[
    {
        "text": " Let's talk about how AI is actually changing customer service, whether it will lead to job loss, and whether the models are good enough to make an impact today. We're joined today by Adrien McDermott, the chief technology officer of Zenesk in a conversation brought to you by Zenesk. Adrien, it's great to see you. Welcome to the show. Great to see you, Alex. Thanks for having me. Pleasure to be here. All right. Yeah, pleasure to have you. And I'm thrilled to have you. See, I'm already jumping to ask you question one because you have a great insight into what's happening in the sort of the one of the most applicable areas of artificial intelligence technology which is customer service. And there's been all this conversation and you know maybe I've contributed it to as to it as well about like how AI might come for customer service jobs before it comes for everything else. And you guys are using artificial intelligence to answer customer service queries at Zenesk. So still early on, but what can you tell us about the impact of AI on customer service jobs so far? Well, I think first it's sort of interesting to compare and contrast the two big areas where AI is impacting jobs, right? I think one is software engineering development and the other is customer service. different in some ways. obviously customer service is a little bit more repetitive, a lot of repetitive question answering and these kind of things, stuff that AI does pretty well. Development is a lot about understanding syntax and context and being able to generate. The core difference I see is that with software engineering jobs, people acknowledge that, you know, it's common knowledge that no one's saying, you know what, I don't have I have I have enough product. I don't need anymore. So if you get 10x 5x developer productivity, the immediate response isn't to go fire a bunch of developers. But in customer service, right, where you can 5x 10x productivity of a customer service team, I think customer service professionals and chief customer officers are more likely to be saying, you know what, I don't actually have enough customer service. I have a customer service debt to pay down with my users. But at the same time, no one is going to miss some of these jobs, right? some of these jobs where you're just kind of like answering the change password question or everything else, those can be upskilled and those can be treated differently. The other thing that you can do is you can know you can increase hours, increase language coverage, add new channels and just basically meet your customers where they want to be met. Huge opportunity I think for brands to differentiate by doing that. So we're seeing a tension the tension between sort of budget pressure and you know this idea of thinking about customer service as a cost of",
        "start": 0.08,
        "duration": 336.4799999999999
    },
    {
        "text": "channels and just basically meet your customers where they want to be met. Huge opportunity I think for brands to differentiate by doing that. So we're seeing a tension the tension between sort of budget pressure and you know this idea of thinking about customer service as a cost of tension then between that and the fact that your customers are really important to you and they help you grow your business and service is one way to differentiate. In my early years of reporting on marketing technology, , which I did way back in the day, , one of the things that people were talk talked about in that in that world was, , that companies were going to differentiate themselves on the basis of customer experience. You know, it gets to a certain point in a service economy where your products matter, but how customers feel about the way that they interact with you , is going to matter even more. That will be the difference between companies. And so to me, and I'm curious if you've seen this in the data, it always found I always found it funny that people say, \"Okay, well, you know, we'll fire customer service reps if AI can do part of their job.\" Because these are the people who are having the interactions with the end customer. And you're right, like if you can get the sort of change password questions out of the way, you now take this this division which ends up like which is has been dealing with problems and you make them sort of the owners of the relationship with the with the end customer. Does that does that sound right? Yeah. If you think about it, you know, you have a long relationship. We talk about lifetime value in marketing, right? If I'm not mistaken, in terms of how much is this dollar of email spend getting you, how much is this dollar of advertising getting you? After you that initial conversion, the only people who really talk to the customer are the customer service agents. You know, if we look at our own company data, 54% of our customers contacted us for support in 2024, but they represented 95% of revenue. Right? So, the most important customers are speaking to you. They're speaking to you in what we would call the moments that matter where they need some help. And I think, you know, AI is gives you this incredible potential to raise the level of every agent up to the level of the best and longest serving customer service agent you have with co-pilot technology and assistance, right? It [snorts] also means that you can kind of like have an immediate response and kind of deal with things. To a certain extent, customer service is this humanpowered factory, right? Right. The metrics are ones of throughput and effort. It's like tickets to day per day, time to first response, you know,",
        "start": 168.16,
        "duration": 615.9989999999998
    },
    {
        "text": "means that you can kind of like have an immediate response and kind of deal with things. To a certain extent, customer service is this humanpowered factory, right? Right. The metrics are ones of throughput and effort. It's like tickets to day per day, time to first response, you know, measuring productivity, average handle time. In an AI world, you know, especially where you're automating tickets, tickets per day is infinite. You know, I'll just there will be more inference. It's fine, right? Average handle time is talk to me for as long as you want. The more you the longer you engage, the better it is, right? Time to first response is usually about 300 milliseconds depending on how many inference trips chips are available for your provider. And so even the metrics are outdated in an AI era. And what you're really then trying to do is sort of say well what are my customers looking for and how can I help them? Right. And so take us through the continuum of someone who's adopting this technology like what does it look like from when they first get a taste of it to when they're fully deployed? I think as as with a lot of use cases that probably your listeners are seeing, [snorts] you begin optimizing human behavior and human potential, right? And in customer support, that's really looking at the human in the loop capabilities and seeing what you can do. The other thing is you look at LLMs, you know, and they they they have an incredible world knowledge. They can generate content and they can reason, which makes them super useful for search. Generative search is taking over. you know, Gemini 3 was recently released. We're seeing the effect at Google of that kind of technology. And so, the first thing our customers are doing is they're basically deploy, you know, building out their knowledge and getting some of that generated with AI. They're deploying generative search and they're seeing, you know, upwards of 30 40% of inquiries being handled by generative search. users who spend, you know, probably two human generations learning to type into a box and process 10 blue links have suddenly pivoted and they just want the answer in the results. And if I think that's table stakes for customer support at this point and [snorts] then we look at co-pilot experiences where you can you know think about customer service there's high turnover you know you don't necessarily get time to train people as new things happen in your company new breaks new fixes you know it's tough for teams to come up to speed and what we see with co-pilot is we can lower the training burden and increase consistency and so adoption of these things is rapid [snorts] you know AI agents there's a little more reticence right there's a lot of we're still building trust you know there's a lot of guardrails that",
        "start": 311.199,
        "duration": 906.2379999999999
    },
    {
        "text": "what we see with co-pilot is we can lower the training burden and increase consistency and so adoption of these things is rapid [snorts] you know AI agents there's a little more reticence right there's a lot of we're still building trust you know there's a lot of guardrails that ability to write really great procedures that are that a generative AI can understand it's a nent skill you know we spent a couple of years ourselves learning prompt development but getting a getting a model to follow or an AI agent to follow a prescriptive script of you know first you get the order number, then you find out the item, then you kind of process the return, you make sure it's in in 30 days, etc., etc. That's something where, you know, we're helping our customers with right now and we're building tools to kind of build out. Those who get there, they get great results because the models work. So, a light bulb went off for me when you talked about generative search. So for me with generative search like my thought is what's happening and you can correct me if I'm wrong is that people go to a website they have some like customer service style inquiry and they like just type it in the search bar and there might be a chatbot there or maybe in the bottom right hand window and they get a chance to have a conversation with that bot. I wonder you know because you you're the chief technology officer of Zenesk so you'll have an insight into this. Do you think that customer service is going to happen on let's say client websites in the future or do you think it might migrate into like the big broader bots like chat GPT? I think that if the bots represent our agents, it's clearly clearly there's going to be some kind of migration, right? Already for a given brand, you know, if you want to know about some companies, you begin with a search in Google and turns out Google's results are usually pretty good. I think the same is happening with chat GPT. But when we get into like real service flows where will I be saying to chat GPT I bought these shoes last week you know go go figure out that order return them and generate me a generate me a packing label it yeah I think that's probably going to happen as brands shortcircuit now is that the customer service flow so much as the action flow where we're actually moving towards systems of action that do that I think it's all becoming integrated and the nature is changing On at the back of it though, everyone is still probably going to need to have those moments where a place to go to actually get contact and talk to a brand. [snorts] We you know recently we kind of looked at we took a sample of",
        "start": 457.199,
        "duration": 1194.7990000000004
    },
    {
        "text": "nature is changing On at the back of it though, everyone is still probably going to need to have those moments where a place to go to actually get contact and talk to a brand. [snorts] We you know recently we kind of looked at we took a sample of conversations across customers and we we actually use chat GPT to classify the contact reasons or the intents and kind of group them into cohorts and you get something along the lines of 47% are basically there was some kind of failure in the business right there was something that happened for about half of them where the product didn't work the product didn't show up, the service is wrong, they just want to cancel whatever it is. Another another quarter actually are just people who know that the delivery date is October 10th, but they're going to call and ask you when the delivery date any is anyway. They're going to say, can I get it on the 9th or is it really the 10th? There's so much of that is sort of what we call the cost of doing business of customer support. And in many ways, those people just need a human connection. Now, are they going to want to, you know, is an automated connection going to be enough? maybe for about half of them, but I think many will still be looking for that human connection. Then the final quarter of all inquiries is actually sort of upsell, cross-ell advice. And again, it'll be a personal preference, but many of those people will actually be looking for a human connection. And so I think yes, we will, you know, if you think about, you know, you have a chat channel and a voice channel and you have, you know, a messaging channel and an email channel. You're going to have an LLM channel where the LLM will kind of be the initiator and have the conversation. But as you go, you know, one of the things that we say is automation drives escalation. You know, as I automate something, more and more people, the Alexes of the world are pressing zero and asking to talk to the operator, and that isn't going away. Yeah, [snorts] I am just the zero till I get a representative person. It's just it's kind of interesting to me that we just kind of want to talk like we need that reassurance, you know, as as people sometimes that we just need to call and be like that thing's still coming or let's just have a conversation about, you know, what I've what I've purchased or what I'm hoping for in a service. Yeah. See, I'm I'm a true CTO. I consider that to be representative roulette. It's a thing that I will generally try and avoid. That does make sense. So, all right, let's go back to the CTO hat of",
        "start": 604.24,
        "duration": 1454.7980000000007
    },
    {
        "text": "what I've purchased or what I'm hoping for in a service. Yeah. See, I'm I'm a true CTO. I consider that to be representative roulette. It's a thing that I will generally try and avoid. That does make sense. So, all right, let's go back to the CTO hat of where the technology is today for what you're trying to build. So, we've talked through a bunch of different use cases. Generative search, a co-pilot, which if I have it correctly, is a AI assistant that's going to be there with customer service reps to help give them information about similar cases and how to how to resolve things and information about the client. and and of course, there's going to be some automation of customer service. some of those you know easy things I imagine like the password reset that you spoke about how are you finding the models today are they enough for what you're looking to do and what would you sort of wish for in the models of the future I would say we've spent probably the last two years or you could think about I think all of SAS and a lot of industry development where people are building apps on top of LLMs right has been sort of the the lump and proletaria of the developer class building guard rails and checks and balances and deployability basically forcing non-deterministic libraries and we're not used to to programming against nondeterministic libraries to behave deterministically and for many of us you know we have products in market now like Zendesco's 20,000 people using some kind 20,000 customers using some kind of AI we've gotten to a point where we're innovating on top of it and moving pretty quickly. So, the next Frontier model release kind of comes along and it's sort of like iPhone 16 to 17. It's like, oh, you know, here's a vapor chamber. , great. But we've actually spent a couple of years dealing with hallucinations and dealing with unpredictability. And so, it's great that the models have less of that, right? that is that does make a difference but ev the evolutionary improvements at the moment the incremental improvements aren't moving the needle like our most frontier use cases right now where it's like only the latest model will do is something like we have a we have an agent that listens to every conversation that is automated and said you know because we we run a resolution platform and we charge for actual resolutions not just conversations and so we need to know that the customer's problem was resolved D and so we use I think we use the latest one of the latest claude models in bedrock to do that and it's listening in like that's a thing with judgment and with reasoning and with skill it's also lower latency so it's something you can use a frontier model for and every time that gets better it makes a difference",
        "start": 737.519,
        "duration": 1761.597000000001
    },
    {
        "text": "of the latest claude models in bedrock to do that and it's listening in like that's a thing with judgment and with reasoning and with skill it's also lower latency so it's something you can use a frontier model for and every time that gets better it makes a difference customer the AI agent you know which you know the task identification agent that starts talking to you and figure figures out what is it that Alex wants every time a model gets better and we can move to a new generation ation that really makes a difference. But for 90% of the work, you know, those rag searches, , model improvements are aren't making a huge difference. We're only just getting to the point in which we're really utilizing the capabilities that they have. So, you have a clawed agent that will effectively look at conversations that reps are having or AI reps are having with customers and then and that clawed agent will look at that activity and determine whether it's been resolved or not. That's exactly right. Yeah. And we we do that across every automated conversation. That's fascinating. And this sort of gets into the orchestration of the models, right? Like one one like you could have one bot doing one thing and another bot checking its work and then another bot taking taking a task. The saying in AI, right, is you know, how do you solve a problem in AI? It's with more AI. So we have we have models watching models watching models. And so can you talk a little bit about I mean we had Mustafa Sullivan on the show a little while ago and he was talking about how he believes that the real lifts are going to be from orchestration because the models will commoditize and those that understand how to orchestrate them will end up doing the best with the technology. So I'd actually love to hear your perspective on how effective the orchestration is of of models and whether you agree with Mustafa on that front. yeah, I I really do. And I'll I'll put it in context from a customer service point of view. And you know, we've seen this over and over again. If I'm deploying automation, you know, if we're deploying automation for a customer and they have a reasonable kind of knowledgebased FAQ, you can imagine that you can get to sort of 20 30% automation absent the customers who are going to jump out of the loop. The Alex is pressing zero. you can kind of get to 20 30 40% just answering the question just by doing a really great job of generative search and putting an answer in front of them. If you want to go beyond that, you actually have to go out into the real world. You need that agent talking to the back office system, right? If it's financial services, you need to go into the customer management",
        "start": 893.279,
        "duration": 2041.1180000000006
    },
    {
        "text": "generative search and putting an answer in front of them. If you want to go beyond that, you actually have to go out into the real world. You need that agent talking to the back office system, right? If it's financial services, you need to go into the customer management it's retail, you need to go to the e-commerce and shipping systems and beyond. I need to go figure out who exactly you are, Alex. What exactly you recently did with the company because you really love it or you prefer it or you get annoyed when I don't have that context. And then I need to kind of figure out what it is that you want and I need to move move forward. Right? So it's integration and orchestration, integration and orchestration, integration, orchestration. Right? In LLM terms, it's all about tool use, right? You have to be able to select the right tool, go get the right information, and follow a procedure. And I think absolutely agree with Mustafa right that you know real you know the next phase of benefits the next phase of automation taking people to 80 not just actually able to perform the task but performing the task in such a way that Alex says to himself I would just rather go through it with this bot. I get the same result every time. It's consistent and it's really enjoyable. It's really fast. Never gets tired. It's on 24 hours a day. speaks every human language available including American English. and I can totally get this done and I think that is that is the goal and that's how we're using frontier models at the moment. Okay. But can I ask you when are these models going to be able to take action or these I guess orchestrated models be able and maybe they already are because one thing that I find with speaking with automated customer service is they're generally goodformationally right going to that generative search style thing. but like let's say I need to move a flight or I am asking for a refund and I have a pretty good case. then I'm always passed off. and and I wonder whether we'll ever see a moment where customer service is AI is going to get good enough to be able to say, you know, I've like checked with my you know, my counterpart refund AI agent and you're actually you are you qualify for one. So, Alex, the the future's here. It's just an evenly distributed, right? There are plenty of companies that are out there doing that. I think already. Yeah, I think so. But I think the different you know what is the key challenge and honestly out in the real world the key challenge to hearken back to the past of perhaps two or three years ago the key challenge is how far do people get on their digital transformation journey.",
        "start": 1035.52,
        "duration": 2341.2780000000016
    },
    {
        "text": "so. But I think the different you know what is the key challenge and honestly out in the real world the key challenge to hearken back to the past of perhaps two or three years ago the key challenge is how far do people get on their digital transformation journey. visit the chief customer officer of a company and you're you know, you're me and you're like, \"Okay, yeah, well, you want to get to 75 80% automation on your on your bot, so you need to orchestrate across these three backend systems and do these things and you know, you have a homegrown stack and a couple of other things, right? your order management system, I see it's homegrown like do you have an API for it?\" because we currently don't put bots in general like you know there is computer use right claude and and chat GBT both have sort of computer use versions that can pretend to be a human and you know kind of type into the thing and what human agents do for you is they are swivel share integration they go from this screen to this screen and they copy the information and they kind of make it work for you I think if you don't have an API on that system we can't swivel chair yet with an AI agent effectively or you know reliably and you know we can vibe code and build the integration for them but the API has to be there and so mostly the blocker like why couldn't you change that flight it's because they don't have that ability in their application at the moment or in their in their back end to be able to do that and that's really the only thing blocking is like it's the same thing that was blocking great customer service a few years ago like why doesn't Amazon for example have a a phone number or an email address on the website for customer support because they've auto they've made every single thing that you could do available for self-service. You can cancel your order, you can change your order, you can find out where it is, you can find out where it is on the street that it's five stops away, etc., etc. Everything is automated to reduce the need for customer service. That is that is beyond the budget and ability of most companies who are just focused on their core business and they don't have that scale. [snorts] But that is, you know, you need something approaching that or you need to build something approaching that to be able to do it. Because what we do in customer service today, we have humans that do that for us. We write a procedure for the human standard operating procedure and they follow it and they go from one system to another and they give you the answer, which is why you get transferred.",
        "start": 1186.64,
        "duration": 2607.0370000000025
    },
    {
        "text": "Because what we do in customer service today, we have humans that do that for us. We write a procedure for the human standard operating procedure and they follow it and they go from one system to another and they give you the answer, which is why you get transferred. everybody that's either watching this or working in it. , which is that, you know, there are these studies that AI is not leading to an ROI. So therefore, the technology must be flawed. But in reality, what if I'm hearing this right is that, you know, you need some underlying structure within an organization to be able to hand that over to AI. Yeah. I mean, AI does an incredible job with oneshot questions and oneshot answers, right? But if it's complex and it requires orchestration, it does need access. you know, you do need to be able to have it take on the identity of the user and log into something and act as them as or act as a customer service agent. And that's for some people the next step, but not everyone. And the tools to get that working are getting better and better every day because guess what? They're powered by AI, right? So are does that mean that like better models will be able to do this? Like is that what is that what's really needed? is I mean of course some work on on you know the company end but will better models like sort of I don't know maybe they can solve the capture so they can log into the system and then handle these requests I mean where do you think that that leap is going to be taken I think that better models will certainly be able to do a lot with that I actually think what's really going to make a difference more likely than computer use models computer using models is just the improvements in coding models mod and that's a little bit basing the future on the immediate past. Coding models have gotten gotten so good recently and they can make developers so productive that I think that that is going to unlock for a lot of internal builders and a lot of company builders. is just going to unlock this potential to create so many connections along with sort of tools that have agentic AI built in that can interrogate you know the API space of systems and create experiences. So, I think we're going to see what could be semi-daunting projects for people to take on just to automate another 3% of customer service tickets suddenly become things where the ROI is a lot clearer and they were like, \"Yeah, I could do that. I could I could knock that up in cursor. I could get, you know, opening a codeex to do that with me and it wouldn't take me too long.\" Right. Okay. Okay, so just to put a bow",
        "start": 1323.12,
        "duration": 2881.997000000002
    },
    {
        "text": "a lot clearer and they were like, \"Yeah, I could do that. I could I could knock that up in cursor. I could get, you know, opening a codeex to do that with me and it wouldn't take me too long.\" Right. Okay. Okay, so just to put a bow models are actually pretty good and once you build some of the processes around them to minimize hallucinations, you can actually get pretty far. Yeah, I think that's if you think about the the stack of customer service work at the bottom, you have tier one and tier or tier zero and tier one agents. They figure out who you are, what it is you want. They'll give you a oneshot annual answer if they can read it from the FAQ or the manual. Maybe they'll do some simple stuff and then they create a case and it goes somewhere else. All of tier 0, tier one automatable next to phase up tier three, tier four, a co-pilot sitting next to them that says, \"Oh, I see that Alex is trying to do a return. I'm going to pull up all these different orders and you're just going to ask him which one it is and then I'm going to you're going to tell me what has been returned. I'm going to generate the shipping label and do all that work for you.\" So, it's like bum bum bum, right? the available today. Similarly, generative search available today. And so that's a lot of the work of customer service. It's just the as you said the orchestration and the integration there. if it's an easy landscape and we can cover the API estate with what we have, you could really [snorts] get to 80 or 100% depending on where you want to go. so as of today it's all there. I think voice isn't quite there and that's a voice is a different conversation because human communication over voice is it's a it's a difficult thing because of the way people interact. Okay, I do want to get to voice in a minute, but one one follow up on this. we've talked about this a lot from like the company perspective like they have a chatbot and some of that is automated. What happens when the customer starts sending their own automated chatbot? Like for me, I'll tell you my dream is to have my own chatbot or my own AI agent, whatever you want to call it. And I I just want it to be called like simple simple agent. [laughter] And what it does is it knows my number, my credit card information, my address, , and all the account numbers with all the companies I do business with. And then it gets me past that tier one and tier zero, whether it's voice on the phone with a company or filling it out in the in the in the bot, you know, and then I'll get,",
        "start": 1461.76,
        "duration": 3155.118000000002
    },
    {
        "text": "all the account numbers with all the companies I do business with. And then it gets me past that tier one and tier zero, whether it's voice on the phone with a company or filling it out in the in the in the bot, you know, and then I'll get, so desperately want to have because it's what I love to do. I think I I share your dream, although mine actually goes all the way and does all the work and I don't have the conversation, but complex agent, I you know, there's there's a couple of standards out there. MCP which was developed by Anthropic and agent to agent and few other things and they're becoming fairly standard and I think we've been thinking about ways for you know is there some button that we can give our customers to click so 100,000 of them could turn on if you are an agent you know this is where we advertise what you can do for this customer you know here this is a retailer you can do returns here this is a financial services company you can like not do a lot depending on what it is right and so We we I think right now are thinking about well at some point it's going to make sense to develop this standard and have things using standardized interfaces. Already those agents I think know enough to go interrogate a knowledge base and FAQ get a generative answer and be able to guide you as to what you would do next. Many of them can fill in that first web form which is I'd like to create an issue and like have a conversation. So, we're a long way, but not all the way there. Yeah. All right. Well, I can dream. Also, those personal agents don't work yet cuz they don't have memory, but that will come too, right? Yeah. So, so I This is good. I'm I want to get to memory also. Well, go in order on voice. there's a great podcast. It's called Shell Game I've had the host on. Name's Evan Ratliff. He cloned his voice and had it like, you know, speak to his friends and try to fool them. sent it to business meetings, had it speak to his his wife and kids, and sent it to like they put put 8,000 words of his like deepest darkest secrets in its context window and then sent it to therapy and they worked through some real issues and sent it to an AI therapist, which was hilarious because they started doing breath work together. Like the AI therapist tells the bot, \"Take a deep breath.\" And the bot's like, \"I'm taking a deep breath.\" But like to me, you know, I I saw him pushing the limits of voice technology and I thought wow this is further along than I thought and we we are going to see this in action.",
        "start": 1600.88,
        "duration": 3433.6760000000017
    },
    {
        "text": "\"Take a deep breath.\" And the bot's like, \"I'm taking a deep breath.\" But like to me, you know, I I saw him pushing the limits of voice technology and I thought wow this is further along than I thought and we we are going to see this in action. your perspective that there's still a long way to go. so how far how far is there to go on voice? Well, I think on the speech to text, text text to speech front, we're already there, right? Like you can, you know, I think a company recently is or this they're already renting, you know, you can rent actually famous voices to say anything that you want. There are platforms where you can recreate yourself should you be so inclined, right? I've cloned I've cloned my voice for sure. There's enough of it out there. I complete it. Yeah. and I think you know the danger of that of course is that someone could be trading crypto on your behalf and like giving instructions to your financial advisor but there are ways around that too. But I think the the challenge of interactive human conversation is just one of latency, right? you you talking to me, me asking you a question, you asking me a question, you interrupting me, you using slang, all of those uses are in the you know we need sort of predictable response times basically is the way I would say it. There's a famous der of chips out there in the industry and a race to get enough inference chips and inference computing power to power all of these things. And I think you know the best frontier models sometimes think for a while and take a while to answer. It's just that that doesn't work in speech. So all of the technology is there right every almost every single piece of it. Some of it is just a little slow because if I'm going you say a thing to me and I convert it to text and I put the text into an LLM. I get back the answer. It's a great answer. You know I totally understood you. I get it back and then I take the answer and I convert it back into speech and then I play it to you. That's awesome. But 4 seconds went by on you know in the worst case right and so what we're working on now is not just for the happy path of I speak you speak and we both listen to each other because it turns out in customer service that's not sort of the that's not always the predominant case. You might be agitated, stressed and interrupting me. I need to react to the emotion in your voice because I'm definitely not going to try and upsell you if you're annoyed. and I'm going to try and read signals about, you know, how you're feeling in that moment. All",
        "start": 1742.159,
        "duration": 3705.5960000000023
    },
    {
        "text": "case. You might be agitated, stressed and interrupting me. I need to react to the emotion in your voice because I'm definitely not going to try and upsell you if you're annoyed. and I'm going to try and read signals about, you know, how you're feeling in that moment. All reaction to it, but it requires a lot of reasoning. So, next time you're on the phone with someone, like you hit zero and you get through to them, marvel at the at the low latency cognitive ability of the human brain and how it can handle all of that in a moment when it does it well. and the fact that you know it takes a lot of compute to get there right now with the current technology to do it in an artificial way. How many years away do you think we are to seeing this actually be ready for production? I know it's an unfair question. Well, I think it's it's basically ready now. So we're only kind of a yearish away, but I think to get it mass market, mass scale and always get the latency and reliability that we want. Probably still probably, you know, that's coming online in the next 6 months to a year. Okay. So fast. Yeah. I mean, things move fast in AI. Definitely. I know. It feels like we're living in dog years. on on the memory front, all the frontier labs or Yeah. All the frontier AI research labs are talking about how memory is so important to them. I imagine a big part of that is okay like if you're in chat GPT then it remembers you and it doesn't have this goldfish brain and it's actually become a lot better at that. it's I think something that Sam Alman has talked about as one of his one of his favorite releases. But then on an enterprise side I think it's also quite valuable. so where do you so obviously you're working with the cutting edge technology and you're seeing what these AI labs are shipping. So could you give us like a state of where memory is today and how useful it is? I think we're experiencing memory through putting really good summaries into the context window right or into the into the prompt. And so, you know, the way that looks is Alex comes and asks me a question. I might retrieve a bunch of information about Alex's recent orders and recent interaction and re recent customer service ratings. I might put that in an LLM and generate a summary about you about it and then I'll use that in the prompt which is sort of a hey just so you know Alex has given four negative seat ratings in a row. he's a minus 25 on net promoter score and he's had this recent bad experience right that is something that maybe should be known in the conversation but probably and who",
        "start": 1879.44,
        "duration": 3990.236000000002
    },
    {
        "text": "is sort of a hey just so you know Alex has given four negative seat ratings in a row. he's a minus 25 on net promoter score and he's had this recent bad experience right that is something that maybe should be known in the conversation but probably and who think we'd agree that the ultimate customer service agent would have total recall on every single conversation and every single interaction and every single transaction that you've done and really understand the nuances all the nuances of as soon as you basically say hi into the chat window or respond to the voice bot and start speaking to it. And so I think for me that's that's the that's going to be a huge leap not just for customer service actually but it also enables Alex's personal agent to be effective and it enables all these other use cases in the world and apps that you know that are hard to imagine now that could be incredible right in the sort of personal companion group companion or just automaton space that are just really exciting and it's also kind of the ultimate CRM you know you know you can you can talk to someone who is as though they were them basically as far as you're concerned and find out everything that you need to know. That's wild. Do you think it's a solvable problem? Because when you think about the way that large language models are structured, there's no easy way to bolt memory on. Yeah, I think there've been a couple of recent sort of frontier lab interviews where people have said there are you know what is it five or 10 great innovations that are required to get to AGI memory feels like it's one of them and so we might not get there with the exact technology that we're using for large language models at the moment but it feels like somewhere that we want to get to with sort of frontier level AI. Definitely. All right, last question for you. , continual learning, right? Models that get better as they go is another area on the frontier. , how useful would it be if you if you had, let's say, you could set a large language model loose for customer service, but through every interaction, it learned to get better at what it was doing. Oh, I mean, that seems like it's like, you know, I think I think Satya was asked about it and he said that's game, set, match. , do you feel the same way about customer service if that comes? I think , it's a it's what we would like is sort of the agent getting smarter every day. But what we have today actually , which I think is almost just as good if you think about all of someone's customer support, right? All the human agents, the search, the articles, the workflow, the procedures,",
        "start": 2023.919,
        "duration": 4300.637000000002
    },
    {
        "text": "what we would like is sort of the agent getting smarter every day. But what we have today actually , which I think is almost just as good if you think about all of someone's customer support, right? All the human agents, the search, the articles, the workflow, the procedures, all as one unit, this is my service estate today, right? Things like the Zenesk resolution loop. Like we can and this is this is something that we do. We can look and say you need to write this knowledgebased article. You've gotten 10 conversations about this. It's probably time that you do something or the way that agents respond to this type of problem here, this type of return of this type of item over 30 days. you need to write a new macro, a new repeatable response that deals with it. And so if you think about it, if you think about service as a machine, AI is so good at giving insights, you know, if you kind of set it up and do it in the right way that you can already do that. What would you do? You know, would it be incredible for as an individual customer service agent or one, you know, if I had one AI agent that I think about as the one that talks directly to Alex and tries to automate, if that could learn from every single conversation, that would also be very very cool. If if you owned that bot though, you'd probably be saying to yourself, I wonder what it's learned and how I can see. When we're changing the machine and we're writing new articles and we're building new macros, it's sort of easy for the humans who own that machine to understand what's going on. Like the the head of support technology can be like, \"Yep, yep. I that is the correct workflow. We should do that. That's those are our that's the rules of my business.\" I think when it's there's a little bit of a blackbox fright where you don't know what's going on inside, which is generally a large language bottle problem, right? where that kind of continual learning. I suppose we could have the model express what's happening chain of thought style, but that's some that's the sort of downside to it. Do you just put your trust in the machine and you believe it's going to be better? That's right. How much how much do you trust this technology? I I feel like I'm cheating because I I feel like some of the time, you know, we run evals on the technology before we deploy it. you know, we test every model and I kind of like we get to see what it's good at and what it's bad at. In my personal life, I'm very like risk preferring. , you know, laziness drives you there, right? Or optimize, a desire to optimize, let's call it that.",
        "start": 2180.64,
        "duration": 4576.717000000001
    },
    {
        "text": "know, we test every model and I kind of like we get to see what it's good at and what it's bad at. In my personal life, I'm very like risk preferring. , you know, laziness drives you there, right? Or optimize, a desire to optimize, let's call it that. , talking to I I, you know, like talking to the new Gemini model on your phone or talking to GPT on your phone with the pro version. This is an extraordinary thing to do, right? It does feel like you're living in the future. , and the thing is so convincing, you just trust it immediately or I do. Yeah. Yeah. No, I try to be given my my profession as skeptical as possible or a trust button verify guy, but there are times where chat GPT tells me to do something and I'm like I don't really have time to check. I will end up going with this this solution that you suggested. , and then anyway, I end up, you know, almost burning the house down. [laughter] Not always. It's never failed me on home maintenance. I will say that. Yeah. No, there's I think it definitely has trained on enough good stuff that it's it's pretty good on that front. Adrian, you know, I said at the beginning, I'll say it again. , someone like yourself, you're on the front line. You're deploying this stuff in real world applications and really have some great insight into the state of the technology and where it's most useful. and it's it's great speaking with you and it's always great speaking with you and the team at Zenesk. So, thanks for coming on. Thanks so much, Alex. Pleasure. Appreciate it. People want to learn more about Zenesk, where can they go? zenesk.com is a great place to start where you can learn all about the technology. and someone [music] machine or human will be there to help you. Okay, sounds great. A fitting way to end this conversation. Thank you so much, Adrian, and thank you everybody for watching. We'll be back on the feed with another video later this week. Thank you for watching.",
        "start": 2320.64,
        "duration": 4776.795000000002
    }
]