[
    {
        "text": " So, Microsoft just released something that I think is way bigger than it sounds at first, and it's called Optim. And if you hear that name and you're thinking, \"Okay, cool. Another AI model.\" Nah, this one is different because it's not trying to be a general chatbot. It's trying to solve a very specific problem that honestly has been blocking real world optimization for decades. Because in business, manufacturing, logistics, supply chains, scheduling, all that stuff, the real brain behind decision-m is usually not AI. It's math. It's optimization solvers. Like the same kind of solvers used by huge corporations to decide how many trucks to send, how to route shipments, how to schedule production, how to allocate resources, how to minimize cost, and how to maximize profit under constraints. And those solvers are insanely good. People use things like Gurob in real production environments. The solver itself is not the bottleneck. The bottleneck is the step before that. It's the part where some human has to take a realworld problem described in normal language like we have two factories, 15 products, demand constraints, limited capacity, certain delivery deadlines, penalties for delays and translate that into an actual mathematical optimization model. Specifically, a mixed integer linear program, a MLP. That translation process is brutal. Like it's not just typing. It's usually an expert job. People literally build careers around being able to convert business intent into decision variables, constraints, bounds, and an objective function. And even if you're good at it, it can take days, sometimes longer. You're basically turning messy real life into clean math. So Microsoft looked at that whole process and said, \"Why is this still manual?\" And that's what Optim tries to fix. Optim is basically an AI system that takes a natural language optimization problem description and converts it into solver ready optimization code and math and I mean actual executable code. You describe the decision problem in plain English and Optim outputs a clean mathematical formulation and then it also outputs Python code using Gurobi Pi meaning the official Python interface for Gurobi. So the model doesn't just explain the math. It generates a script that literally defines decision variables, adds constraints, sets the objective, calls the solver, and prints out the optimal decisions and optimal objective value. That's why this is such a big deal because if you can trust the output, this becomes the missing bridge between normal humans who understand the business problem and optimization solvers that can compute the best plan. Now, let's talk about what Microsoft actually released. The model is called Optim SFT. It's a specialized 20 billion parameter model built in the GPOS transformer family and it uses a mixture of experts architecture. That's important because mixture of experts is basically the same idea used in modern scaling. You don't activate the full model every time. You activate only parts of it. So it has huge capacity but the inference cost stays manageable. In",
        "start": 2.639,
        "duration": 353.52099999999996
    },
    {
        "text": "family and it uses a mixture of experts architecture. That's important because mixture of experts is basically the same idea used in modern scaling. You don't activate the full model every time. You activate only parts of it. So it has huge capacity but the inference cost stays manageable. In size is 20B, Microsoft says only about 3.6B parameters are active per token. That means the compute cost is closer to a midsize model while keeping high capacity when needed. And the context length is massive. 128,000 tokens. That's a big detail because optimization problem specs can get ridiculously long. Like if someone gives a full business scenario with multiple stages, edge cases, and constraints, you want the model to actually hold all of it in memory. With 128K tokens, it can take long specs and multi-step reasoning inside the same request. Now, in terms of model origin, the base model is OpenAI/GPT20B and Microsoft fine-tuned it into Microsoft/Optim SFT. And here's the licensing part that makes this extra crazy. It's released under the MIT license, meaning it's truly open. You can use it, build on it, integrate it, commercialize it, whatever, without the usual restrictive licensing headaches. So yeah, Microsoft Research just dropped a serious optimization focused model under MIT and it's designed to become a practical tool, not just a research demo. They also say it's available as a hugging face model and it's also deployed in Azure AI Foundry under the name Microsoft Optimine-St. And it can be served using SG Lang as an OpenAI compatible endpoint. That's also important because it means you can run it in a way that looks and feels like the normal OpenAI API workflow except it's your own model endpoint. Now, the training setup is also pretty wild. They fine-tuned it using eight Nvidia B200 GPUs, and they report the fine-tuning time was about 8 hours. That tells you the finetune was quite focused. This wasn't some year-long pre-training thing. It's more like take a strong base model, give it the right, clean data set, and specialize it hard. For inference and evaluation, their reference setup uses eight Nvidia H100 GPUs. And for regular users, they recommend at least 32GB of GPU VRAM on something like an A100, H100, or B200. So yeah, not exactly run this on your laptop territory, especially with 128K context. But for companies or research labs, this is totally doable. Also, the model has a dependency mentioned, unsloth/GPT O20BF16. So that tells you the ecosystem they're targeting for efficient serving. Now where does the smarts come from? They trained optimized SFT on cleaned versions of optimization data sets primarily based on or instruct and optimath train. But what's interesting is how much effort they put into cleaning because they're basically admitting something that a lot of people quietly know. Many benchmark data sets in specialized domains are noisy as hell. you get missing parameters, ambiguous statements, incorrect ground truth solutions, inconsistent problem",
        "start": 179.44,
        "duration": 685.2009999999998
    },
    {
        "text": "instruct and optimath train. But what's interesting is how much effort they put into cleaning because they're basically admitting something that a lot of people quietly know. Many benchmark data sets in specialized domains are noisy as hell. you get missing parameters, ambiguous statements, incorrect ground truth solutions, inconsistent problem formulations. So if you test a model and it fails, sometimes it didn't actually fail. The data set was broken. Microsoft leaned into that hard, and this might be the most important part of the whole work. They did what they call class-based error analysis. They took or instruct and optmath and classified problems into 53 seed classes. So instead of treating optimization as one blob, they categorize it into specific types like set cover, flow shop scheduling, traveling salesman problem, and tons of other O categories. Then they ran the base model, which is GPT OSS 20B base on samples of each class. And they looked for instances where the model output disagreed with the ground truth. And instead of just training harder, they brought in actual optimization experts. Those experts looked at the failures and they identified recurring formulation mistakes. Like the model might keep missing a constraint or it might use the wrong bounds or it might misunderstand variable types or mess up linking constraints that connect decisions across time. And for each class, the experts wrote short error descriptions and hint pairs. Basically saying, \"Here's the typical mistake. Here's how to prevent it. Here's the correct modeling trick.\" And they mention one concrete example that shows how technical this gets. For TSP, you need something like proper Miller Tucker Zlinin constraints because if you mess those up, the solver gives you nonsense routes with subours. So, the experts wrote hints like that. Now, here's where Microsoft gets smart. They didn't just use these hints at inference time. They used them to clean the data set itself. They ran a semi-automated pipeline where they regenerate solutions with a larger model prompted with these class-specific hints. Then they use majority voting across samples to improve quality and drop items that remain inconsistent. They also detect things like missing parameters or ambiguous statements and regenerate the problem descriptions when needed. So the end result is a cleaned training corpus that aligns better with correct formulations. And then when training on that, you basically get a model that has a much cleaner understanding of what correct optimization modeling looks like for evaluation. They didn't just test on raw benchmarks either. They use manually cleaned and expert validated versions of benchmarks like industry o mammo complex and opmath. This is actually massive because the paper says that on original noisy benchmarks existing models often only reach 20 to 50% accuracy. But once you rec clean and correct things, even without changing the model, apparent accuracy can jump a lot. They mention you can lift it from about 40 to 60% into the 70 to 90% range on corrected",
        "start": 348.32,
        "duration": 995.4399999999997
    },
    {
        "text": "original noisy benchmarks existing models often only reach 20 to 50% accuracy. But once you rec clean and correct things, even without changing the model, apparent accuracy can jump a lot. They mention you can lift it from about 40 to 60% into the 70 to 90% range on corrected benchmark issues. So Microsoft is basically calling out the evaluation pipeline too. They're saying it's not just models, it's data quality and correctness. Now let's talk about how it works at inference time because this is also not just a single prompt. Optimine behaves as a multi-stage system. So when you feed it a problem, first it classifies the instance into one of those 53 optimization classes. Then it augments the prompt with the error summary and hint pairs for that class. So essentially every time you ask it something, it's giving itself a little expert cheat sheet based on what that class usually needs. Then it generates a reasoning trace, then outputs the mathematical model, then outputs the Guro BPI code. And if you have more compute, it can use test time scaling, including self-consistency with majority voting. Meaning, it generates multiple candidate scripts, executes them, and selects the solution that appears most often within numerical tolerances. That's a very solver-like approach. It's basically saying, don't trust one generation, sample several, and pick the most consistent. Then there's also a multi-turn correction mode. This is where it becomes almost like an agent. It runs the code, captures execution errors or solver logs, feeds that feedback back to the model, and lets the model revise the formulation and code over a few rounds. So if the code throws an error or constraints cause infeasibility incorrectly, the system can adjust. Of course, this increases latency, but it reduces errors. Now the results on those clean benchmarks. Microsoft reports that Optim improves formulation accuracy significantly and the number they give is very specific. 20.7% improvement in formulation accuracy across multiple optimization benchmarks compared to the base model. And then with test time scaling like self-consistency and multi-turn feedback loops, it gets further gains. They also claim that the system outperforms other open- source models of similar or larger size and reaches performance competitive with proprietary Frontier models like GPT04 mini and GPT5 under their evaluation settings. So yeah, that's not small talk. Now they're also very clear about limitations which I respect. They say the model can still produce incorrect formulations, invalid code, or declare feasibility or optimality incorrectly. It's specialized to ORE benchmarks, so general domain behavior isn't guaranteed. And they also admit they didn't do dedicated red teaming against unsafe content categories like hate or violence or self harm or jailbreak attacks because the paper focuses on technical robustness metrics. And they strongly recommend human in the loop oversight, especially for anything consequential. They even explicitly call out of scope uses like safety critical and regulated applications including healthcare, finance, legal decisions, credit scoring, anything where you can't",
        "start": 506.0,
        "duration": 1328.5620000000004
    },
    {
        "text": "harm or jailbreak attacks because the paper focuses on technical robustness metrics. And they strongly recommend human in the loop oversight, especially for anything consequential. They even explicitly call out of scope uses like safety critical and regulated applications including healthcare, finance, legal decisions, credit scoring, anything where you can't result. They also warn against fully automated deployment where solver outputs directly decide real world actions without oversight. And especially they warn against automatic execution of generated code in production systems without sandboxing, logging, and security controls, which is super important because this model literally outputs code that interacts with a solver. If you're going to execute that automatically, you better sandbox it. Now, for people who actually want to use it, Microsoft gives a clear recommendation. Serve it using SG Lang. They even provide a workflow where you use SG Lang's OpenAI compatible API together with the official OpenAI Python client. So you literally do something like installing SGLang OpenAI Gurabippy. You launch a server pointing to Microsoft/Optimmind SFT and then you query it as if it's a normal chat completion endpoint. They recommend default temperature around 0.9 top P1.0 max tokens like 4,96 and you define a system prompt telling it that it's an expert in optimization in MP and it should reason step by step then output math modeling then output Python code. And yes, it requires a valid Gurobi license and they specify Python greater than or equal to 3.12. So it's definitely positioned for serious users, researchers, engineers, and teams working on decision support systems. And Microsoft also lays out primary use cases in a pretty grounded way. translating natural language or problems to MILPS for research and prototyping, benchmarking NL to MIL pipelines, educational use to teach modeling, and doing research on solver in the loop prompting and multi-turn correction. So overall, this is one of those releases that doesn't look flashy like new image model or new reasoning benchmark record, but it's potentially way more important for actual industries because if Optimine keeps improving, what you're looking at is a world where optimization workflows stop being locked behind a few scarce experts and start becoming accessible to teams who just understand the problem and the business. And suddenly AI isn't only generating text and code, it's generating decisions in a solver ready way. All right, that's it for today. If you want more AI breakthroughs explained in plain English like this, subscribe, drop a like, and I'll catch you in the next one.",
        "start": 674.88,
        "duration": 1596.9600000000007
    }
]