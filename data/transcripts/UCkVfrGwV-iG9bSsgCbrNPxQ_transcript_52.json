[
    {
        "text": " So this week there's been a ton of AI news. So let's talk about it. So one of the first things we need to talk about is Gemini 3. Gemini 3 is Google's third installation in their series and it's shaping up to be the incredibly performant model apparently especially on coding and multimodal capabilities. Now this is a tweet that was about a month ago now from semi analysis but semi analysis is a specialized research and consulting firm known for its deep technical analysis of of the semiconductor and AI industry. Now, this tweet is kind of flying under the radar, and I did make a video about the entire Gemini 3 thing. And [music] literally the same day I made that video, Sundar Pachai was on stage talking about, of course, Gemini 3 and the fact that 2026 is going to be a year of incredible AI capabilities. And it does seem like Gemini 3 will quite likely be here by the end of 2026. So, [music] I'm not entirely sure which date that is, but considering how they're talking about it and the things that they're saying, which I'll get into in a second, Gemini 3 seems pretty much on the horizon. Enterprise. [music] I I look at the model trajectory ahead. , you know, as we are working with Gemini 3.0 in 26, we're going to make a, you know, we've already had dramatic progress over the past couple of years. The progress ahead is palpably going to be you're going to feel that the these models are going to be really intelligent agents. This is another tweet that we got. Apparently, there are going to be completely vibecoded games. This is from Logan Kilpatrick. This guy is the lead product for Google AI Studio and the Gemini API. And he said, \"This is going to easily usher in the next $100 million developers with ease. [music] So many people get excited by creating games only to be hit with C, C++, and realize that it's not fun. So this should show you where Google are essentially putting their eggs in terms of where they're trying to focus. So with Gemini 3, it's quite likely that they're probably going to take on anthropic in terms of the coding market share. Currently we know that they took on open AI in terms of you know video generation and image generation. I pretty much exclusively use Google products now and even in chat generation sometimes Google provides superior responses and so I think Google is going for that last sort of you know really really big pillar that anthropic has which is we are the best software engineer. you can code with us the best. [music] And I think that if Google manages to really focus their efforts down on this last pillar, then they really could take over the entire AI industry. I mean, most users just gravitate to whatever is the cheapest",
        "start": 0.08,
        "duration": 351.99999999999994
    },
    {
        "text": "the best software engineer. you can code with us the best. [music] And I think that if Google manages to really focus their efforts down on this last pillar, then they really could take over the entire AI industry. I mean, most users just gravitate to whatever is the cheapest Google's able to produce something where vibe coding allows you to build things almost instantly and it's cheaper than Anthropic, then I think a lot of people [music] are going to pivot away from those companies and just simply move over to Google. I mean, Google's already got a heavy distribution engine, which means that it's not going to be that hard for them to get their products into hands of users. So, for me, I'm extremely bullish on Google moving forward, and I really don't underestimate their ability to get things done. They've pioneered so many incredible breakthroughs before. So, it will be really interesting to see exactly how that vibe coding does come through because Elon Musk also did say that by, you know, the end of 2025, they're going to be having a vibe coded game. And honestly, I'm not really sure on that timeline. We haven't seen any teasers or anything, but I think this might be the next big area. Now, of course, again, with Gemini 3, there was a tweet that said, you know, you can't really vibe code with Gemini 2.5. The others are superior. And then of course someone from Google AI Studio said that everything sets up for the next thing. So for those of you Google users out there, don't worry. There is clearly going to be some updates to the platform. Now what we had next was Google's quantum computer. And this was incredible. Like I said, Google's going through, you know, breakthroughs and going from strength to strengths. And they essentially had a new quantum computer that could solve problems much faster than traditional supercomputers. problems that would take a classical computer 10 septillion years. Willow did in just 5 minutes. Now, Willow uses, you know, quantum bits, which are cubits instead of classical bits, taking advantage of the quantum phenomena like superp position and entanglement to process information exponentially faster than conventional computers for specific tasks. Unlike most previous quantum chips, Willow actually becomes more accurate as the number of cubits increases thanks to the real-time quantum error correction, which is a long-standing, you know, issue in the field. And the the reason why Willow actually matters is because it's the first chip. It's the first chip to dramatically reduce errors while scaling up the number of cubits, which is marking a significant milestone towards practical large scale quantum computers. And Willow's breakthrough suggests that quantum computers may actually soon be able to do things that even the best classical computers could never do. And those quantum computing advances could revolutionize areas like AI, drug discovery, cryptography, and climate modeling in the future. So essentially,",
        "start": 175.92,
        "duration": 658.1589999999999
    },
    {
        "text": "practical large scale quantum computers. And Willow's breakthrough suggests that quantum computers may actually soon be able to do things that even the best classical computers could never do. And those quantum computing advances could revolutionize areas like AI, drug discovery, cryptography, and climate modeling in the future. So essentially, powerful computer that uses the weird rules of quantum physics to solve some problems almost instantly. problems that would take even the biggest ordinary computers longer than the age of the universe to finish. And this is possible because it fixes its own mistakes as it gets bigger, which is something that no quantum chip could ever do before. Now, if you're still building presentations the old way in 2025, we have to talk about Gamma. I've been using Gamma Agent lately, and this thing is genuinely different. It's not just another AI tool that makes slides look pretty. It's actually intelligent. Here's what I mean. I can tell the Gamma agent to fact check my entire deck and it automatically adds citations and hyperlinks. I can drop in a competitor's URL and it pulls research and build slides without me touching Google. I literally summarize a 20 slide pitch deck into a two-page executive summary with zero manual editing. And the craziest part is that over 50 million people are already using Gamma. It's the most popular AI presentation app in the world. [music] Teams are creating 700,000 presentation sites and docs in Gamma every single day. So whether you need web research that's baked into your deck, want to rewrite your presentation for a different audience, or just need to sound more executive ready instantly, Gamma Agent handles it like a trusted teammate. Head to gamma.app, that's gamma ma.ap and see why this is changing how smart teams work. Link in the description. Now, here's where we get into a little bit of speculation, but it's backed by some facts. And this is the Gro AGI debacle, where, you know, Elon Musk has been tweeting that the probability of Grock 5 achieving AGI is now 10% and it's rising. [music] And this isn't just based on pure pure speculation, but rather breakthrough paper that was published in the field that most people didn't really pay attention to. So Elon Musk tweeted in response to this tweet where they were talking about Grock 5 and this user asked if Grock 5 would have continuous learning. Elon Musk said dynamic reinforcement learning is important because Grock 5 like smart humans will learn almost immediately. And this stood out to me because it was only a few days later that we got this post where someone at Meta released a paper called continual learning via sparse memory fine-tuning. And I'm not going to, you know, get into all the details of this, but the main solution here is that they managed to solve one of the biggest problems with LLMs, and that problem is",
        "start": 330.639,
        "duration": 960.4790000000002
    },
    {
        "text": "where someone at Meta released a paper called continual learning via sparse memory fine-tuning. And I'm not going to, you know, get into all the details of this, but the main solution here is that they managed to solve one of the biggest problems with LLMs, and that problem is that now means is that you essentially have a system that has memory quite like a human because the biggest problem with LLMs is that when you try to, you know, train it on something new, a lot of the old parameters [music] get overwritten and it causes the model to forget and that's one of the biggest blockers to AGI. So if we now have a research paper which solves this to a very high degree which is you know it was like an 89% you know now 71 with the previous method and this one is you know 11%. This means that we could really start to get models that actually learn as they improve and evolve. And this would be one of those major milestones towards AGI. Which is why I believe that this tweet from Elon Musk actually holds a lot more weight than people do think because it's not just based on Elon's crazy timelines, but rather a research paper breakthrough that some in the industry are instantly putting to work. So if we do get AGI sooner than expected, I mean this could be why. Now if you're wondering about AGI, Sam Alman actually spoke about AGI and the term and he says that the term is pretty confusing and this was I think around just 2 days ago. I think it's [music] the AGI term has become hugely overloaded and as Jakob said it'll be this process over a [music] number of years that we're in the middle of. but one of the reasons we wanted to present what we did today is I think it's much more useful to say our intention [music] our goal is by March of 2028 to have a true automated AI researcher and define what that means [music] than it is to sort of try to you know satisfy everyone with a definition of AGI. And if we're talking about AGI we have to mention of course Yan Lunan. Now Yanlukan is you know a very very accomplished scientist one of the most accomplished AI scientists that currently exists and he has always taken a different you know road when it comes to going towards general intelligence or AGI and I think his perspective is most you know certainly fascinating because he doesn't you know follow the hype he just thinks in a different way and I think that's really really important and essentially what he's you know saying here is that everyone is missing something like we're missing something extraordinarily big and one of the key things that he's you know consistently said and I think it's starting to become",
        "start": 484.8,
        "duration": 1242.3990000000003
    },
    {
        "text": "in a different way and I think that's really really important and essentially what he's you know saying here is that everyone is missing something like we're missing something extraordinarily big and one of the key things that he's you know consistently said and I think it's starting to become learning at a rate in which humans do not like humans learn from a lot less experience than a human a lot less experience than you would have to put on to the models I mean these models are trained on trillions and trillions of pieces of data but humans are generally intelligent and you know you don't learn that much to become generally intelligent in the way that a human is. I mean, we're, you know, shoving just millions and millions of pieces of data down the model's throat. And it still fails remarkably in some areas that humans are really good at. We're missing something big that, you know, that that we need AI system to to learn from natural high bandwidth sensory data like video. We're never going to get to human level intelligence by just training on text. despite what you might hear for some people who are in the cult in Silicon Valley who are going to tell you, you know, by next year we're going to have, you know, a data center, you know, a country of geniuses in a data center. Yeah, you will have, you know, useful artifacts that can help people in their daily lives and and maybe feel like they have the intelligence of of a PhD, but but it's because they will be regurgitating things they've been trained on and those systems won't have actual intelligence of the type that we expect. So [laughter] I mean house cats have an understanding of the physical world that is completely amazing and they only have two billion 800 million neurons okay in their brain and they certainly have a very good understanding of physical world they can do complex planning of complex action and we are nowhere near matching that. So that's that's where that's what I'm interested in like how do we bridge that gap? How do we get systems to learn models of the physical world and that will require new architectures that are not generative? So I'm telling people I don't work on generative models so they all think I'm crazy but but I really believe this and as you say I'm trying to be ahead of the game. Now a little bit of a detour but this one actually makes sense and this is one of the craziest articles I've read and it just directly ties into the point that we've been discussing here. And remember how I said that Yanlick essentially said that we are missing something. If you see this you know article, it's called the Sakana AI CTO says he's absolutely sick of transformers, which is the tech",
        "start": 627.6,
        "duration": 1506.6380000000006
    },
    {
        "text": "and it just directly ties into the point that we've been discussing here. And remember how I said that Yanlick essentially said that we are missing something. If you see this you know article, it's called the Sakana AI CTO says he's absolutely sick of transformers, which is the tech this so important? Well, the Sakana AI CTO is someone who's really important. You see, Leon Jones, who co-authored the seminal 2017 paper, attention is all you need, and even coined the name Transformer, is the person saying this. So, this is the person who was really on the ground floor of all of this technology. And we have to understand that like they've got a point, okay? And one of the points that was made ages ago was the fact that, and this was by Yan Lakhan, and this is in a video which is one of my most viewed videos, but Yan Lakan essentially says that look guys, I'm I'm no longer working on LLMs because all of the funding and all of the resources, all of the talent is just going on to LLM because that is where the attention is right now. So he says that that actually might be potentially blinding researchers to the next break breakthrough because if everyone's looking at this one giant tree and everyone's trying to study the tree, they're trying to cut pieces of the branch. They're trying to, you know, plant more trees from that tree. Well, they're in a forest. Okay, AI is this giant giant forest. So maybe we need to look somewhere else in the forest and see if there are other trees. And we can see here that, you know, it says that this warning carries particular weight given Jones's role in AI history. you know the transformer architecture he helped develop at Google has become the foundation of the generative AI boom and it's crazy okay and essentially he just says he draws the analogy from AI itself the exploration versus exploitation trade-off that governs how algorithm algorithms search for solutions when a system exploits too much and explores too little it finds mediocre local solutions while missing the superior alternatives and he says that we are almost certainly in that situation right now in the AI industry He basically says that once Transformers arrived, all that work suddenly seemed irrelevant. All those previous architectures seemed irrelevant. And how much time do you think those researchers would have spent trying to improve the recurrent neural network if they knew something like transformers were around the corner? And he says that I'm worried that this current situation that we're in right now where we're just concentrating on one architecture and just permuting and just permuting and just changing it and trying different things where the breakthrough might just be around the corner of course might be a bit dangerous. And I think it's most certainly one of the most interesting",
        "start": 762.72,
        "duration": 1774.799000000001
    },
    {
        "text": "right now where we're just concentrating on one architecture and just permuting and just permuting and just changing it and trying different things where the breakthrough might just be around the corner of course might be a bit dangerous. And I think it's most certainly one of the most interesting know, like you have the entire industry looking in one direction and he [music] says maybe we're looking at the wrong thing. And then here we have Francis Olay who is the creator of the ARC AGI benchmark talking about the fact that well you know this benchmark is pretty difficult and LLM's alone which is once again the architecture that we just discussed might not actually be leading us to where we need to go. I would say LLM alone definitely not. An LLM is basically a way to acquire and encode programs. I mean yeah it's basically a repository for a bunch of free reusable vector programs and the way you acquire them is via gradient descent on human data right [music] and that's not what AGI is. It could be a component of AGI. I think it could be the the sort of like memory component, the knowledge and skill representation component, but the the defining characteristic of general intelligence is how efficiently you acquire your skills and your knowledge. So basically how efficiently you extract information from the world from your experience and turn it [music] into these programs that you generalize as as well as possible. And that's not what LLMs do. I mean in the in the LLM world the algorithm that's playing this role is just cryon descent and cry descent is you know four maybe five orders of magnitude less efficient than human intelligence at skill acquisition. So this is not what you're looking for. So Adams could be part of the solution but they are definitely not on their own the solution. Now something else that went pretty viral in the AI space was this called Alpha Arena. It was pretty interesting and the experiment is still ongoing. So the goal with Alpha Arena is to make benchmarks more like the real world. And essentially what they did was test the intelligence of models on the ability to trade. So every model gets $10,000 of real capital. And they essentially have the ability to trade cryptocurrency on a decentralized exchange that is completely audited and can be verified by anyone because it exists on the blockchain. So the AI models are trading in public and we can see where the models you know in terms of their balance like where they are and it's kind of like a very interesting benchmark because it somewhat changes in real time as the market shifts. So this runs until November the 3rd 2025 which is I think only 2 to 3 days from now. So it will be most certainly interesting to see where the models form. And one of",
        "start": 899.279,
        "duration": 2068.7990000000013
    },
    {
        "text": "a very interesting benchmark because it somewhat changes in real time as the market shifts. So this runs until November the 3rd 2025 which is I think only 2 to 3 days from now. So it will be most certainly interesting to see where the models form. And one of seen is that, you know, Deepseek and Quen, the models from China, seem to be doing the best. Now, some would say that this is because, you know, Deepseek and well, not and but Deepseek was created by a quant team and that essentially just means that they're really good with maths and numbers. And maybe that is the case here. But of course, you would have to run this multiple different times over multiple different scenarios to really judge whether or not this trading strategy or this model is actually good at trading. Because what we could be, you know, having here is just a scenario of noise where, you know, the random possibilities of an LLM just produce results that are good in this example or just produce results that are bad. So, it's really hard to say whether or not DeepSeek is good at investing or Chat GBT is bad. I think a lot of time needs to pass before we can truly say whether these models are going to be effective at buying or selling. Now, there was also some pretty big news in terms of the AI backlash/ AI lawsuit area. Udio music, a leading AI song generation platform was recently forced to halt open music generation due to the copyright laws from major record labels, especially Universal Music Group. And this move mirrors the wider shutdowns and restrictions across the AI music sector which is facing some escalating legal situations and legal challenges over the use of copyrighted works with AI without proper authorization. So this is a platform that essentially you know trained on millions of people's different songs and now they essentially said look we are going to stop the ability for you to be able to download songs and we're going to change the platform so that it works with creators. you're going to be able to essentially, you know, create songs from artists, you know, reference artist styles. [music] And in that way, I guess the artists that, you know, have the most, I guess, uses or remixes, they're going to get compensated somehow. So, it's changing and the music industry decides to, you know, aggressively defends artist rights, seeking either licensing fees, opt-in models, or complete bans on the unlicensed AI music. So, it's pretty hard for independent AI music startups to operate without backing from major labels. And it's going to be interesting. It really is going to be interesting because this is a landmark case that really sets the precedent for how things are going to be moving forward. Now, it wasn't just music. We also got backlash with OpenAI. Open AAI",
        "start": 1048.64,
        "duration": 2370.2399999999993
    },
    {
        "text": "backing from major labels. And it's going to be interesting. It really is going to be interesting because this is a landmark case that really sets the precedent for how things are going to be moving forward. Now, it wasn't just music. We also got backlash with OpenAI. Open AAI they essentially I don't want to say screwed the pooch because [music] that's a bit too far, but they kind of just wanted to go viral as quickly as possible and I think they just didn't really care. And so what they essentially did with the Sora 2 release was they told some right holders that they had to opt out of their characters to appear in Sora 2 while telling some people that they didn't have to opt out. And this just created, you know, mass confusion and outrage across many different agencies in Hollywood. And a lot of them were pretty upset because using someone's likeness without your consent is essentially copyright infringement. And when you tell one company, \"We're going to, you know, opt you out.\" And the other one is like, \"Well, you have to opt out yourself.\" It's like, \"Hey, what's going on here? Why are they getting preferential treatment?\" And the whole thing was just a complete, I don't want to say complete bad show, but it wasn't the best in terms of legalities, in terms of rolling out. Now, Sora 2 now is, you know, a lot more restrictive because, you know, when it was released, you could literally generate an entire episode of like Rick and Morty or South Park. You could just generate that at a whim. And these clips were going completely viral. And I think it's fair to say that that is, you know, some serious serious copyright infringement in those cases. And so, you know, right now people are wondering, okay, where do they stand? How are they going to move moving forward? Are there going to be companies that actually partner with OpenAI so that they can, you know, use the technology? Are TV shows going to be completely AI generated with Sora as the engine driver? It's super interesting to see, but once again, this is something that is a developing situation. And my personal belief is that it's it's almost inevitable that these companies are going to eventually use, you know, these AI tools. So, I wouldn't be surprised if there are some shows that do use these generative tools, especially in scenarios where you wouldn't even realize that the tool is AI. And I think that's the case with a lot of these not lowbudget animation shows, but animation styles where you aren't going to realize if it's AI generated or not because it doesn't require huge imper, you know, perfect CGI scenes [music] with the perfect lighting. So, there are some, you know, many use cases where you can get away with it. Now, if we talk about",
        "start": 1200.88,
        "duration": 2620.56
    },
    {
        "text": "styles where you aren't going to realize if it's AI generated or not because it doesn't require huge imper, you know, perfect CGI scenes [music] with the perfect lighting. So, there are some, you know, many use cases where you can get away with it. Now, if we talk about about 1x Neo. This is the robot/AI companion that went completely viral. And I personally do believe that this is somewhat different than most people do believe. Most humanoid robot companies now are creating humanoid robots for the factory. So, they're creating robots for like, you know, , you know, BMW's factory. That's what Figure is doing. They're create, you know, like Tesla bots are creating robots to work in factories to essentially automate human labor. But the 1X Neo is more like sort of this social product which is where you can have a robot that's in your house and it, you know, essentially does the chores. It helps you carry packages. It's able to, you know, take out the trash. It's able to water your plants. Kind of like a maid essentially. Kind of like a maid or someone that just helps you do many different things. And they're, you know, they're really really trying to emphasize that this is an AI companion and not like just a tool. And I think that kind of relationship is a bit different because they've designed it with this soft body. You know, they've designed it in a way that is basically going to be usable by huge huge markets. I mean, you've got, you know, kids that are going to be able to use this thing. You've got the elderly. You've got people who are disabled that are going to be able to use this thing. I personally think that this is a great great product because there is a lot of use cases where this would really help out people. I mean, imagine you're someone who's blind and you're able to have, you know, an AI robot that's walking through your house telling you, \"Oh, this is there, that is there, and is able to use its vision capabilities.\" Or imagine you're disabled. It's able to grab something from the top shelf. I think this is going to help out a lot of people in ways that you really didn't think before. So, for me, it's it's refreshing to see a new type of humanoid. And it's interesting because a lot of people didn't see this coming. Firstly, you know, when 1x Neo was was started, you know, we knew that the company had created robots that were essentially security robots, but now they're changing, you know, their design and they're moving towards a robot that is actually built for the home. So, home humanoid robots, I think 1x Neo is really going to, you know, change the game here. And it was incredible because I saw many of my in real life friends,",
        "start": 1329.12,
        "duration": 2878.4
    },
    {
        "text": "changing, you know, their design and they're moving towards a robot that is actually built for the home. So, home humanoid robots, I think 1x Neo is really going to, you know, change the game here. And it was incredible because I saw many of my in real life friends, this. I saw multiple orders on social media from people that aren't really paying attention in the AI space and they've ordered this. So, I think they're going to be flooded with the amount of orders that they do have. So, it's super super I kind of I guess you could say surprising at the response that this thing has been given. Now, of course, the only problem is is that 1x Neo I'm actually going to show you guys this video I found on Twitter, but it kind of shows where some people are having a problem with the the system because what you're currently looking at is a teleyoperated robot. So, the problem is that a lot of people thought the demo was entirely fully autonomous. Some parts weren't fully autonomous. And because of that, people are speculating on how good this project/root will actually be. And you know, you know, influencers like MKBHD have said that, you know, he's a little bit skeptical because, you know, a lot of the actions that people require in their homes will actually require it to be teleyoperated, which essentially just means someone in an office somewhere is going to be virtually controlling the robot, which means that you don't actually have that much privacy in those scenarios. So, there's a little bit concern there. Now, they've they've ironed out all the privacy concerns and all that kind of stuff, but I mean, you know, people are more skeptical to tech demos because every year we do get like a crazy tech demo. Everyone goes insane and then 6 months later you've got like this bloated piece of software that doesn't really work and then you've got, you know, massive amounts of refunds coming in. So, it will be interesting to see if they're able to live up to the promise. I personally think they will be able to because robotics is moving relatively quickly and I believe that a lot of people do want this to work because if it does work you know a lot of people's lives get better anyways. And remember how I said robotics is moving insanely fast. Take a look at this. We've got something coming out of the Beijing Academy of Artificial Intelligence and this is crazy. They've got a robot that is able to pull a car. And I'm guessing they done this via reinforcement learning. I'm not sure entirely how they train the robot, but the robot was able to adjust and move and drag this car. Like I like I'm borderline speechless because I just didn't expect this. Like every time I",
        "start": 1460.64,
        "duration": 3133.841000000001
    },
    {
        "text": "pull a car. And I'm guessing they done this via reinforcement learning. I'm not sure entirely how they train the robot, but the robot was able to adjust and move and drag this car. Like I like I'm borderline speechless because I just didn't expect this. Like every time I keep becoming more and more speechless because if I walked past a robot that was, you know, pulling away a car, I think [music] I would not freak out, but I I think I would do a double take. I would be like, am I am I dreaming right now? Because this video I would have thought initially was AI generated. But it just goes to show how quickly robots are able to move when you have an affordable humanoid robot where researchers and universities are able to really really get into the details on you know experiments and really try and push these things to their limit. So I mean think about where we're going to be 10 years from now with the amount of focus, time and effort and money pouring into these kind of sectors. I mean the future does look bright. Now, something super interesting and very controversial is OpenAI's initial public offering. OpenAI is actively laying the groundwork for an initial public offering, which could value the company at up to $1 trillion, making it potentially one of the largest IPOs in history. And OpenAI is considering filing with securities regulators as soon as the second half of 2026, with some internal targets suggesting a listing in 2027. And although these plans and details remain preliminary and subject to change based [music] on the company's growth and market conditions, OpenAI has undergone a corporate restructuring, transitioning into a public benefit corporation while maintaining its OpenAI nonprofit foundation. So this is super interesting because this is very very controversial. A lot of people are like, \"How on earth did you guys start a charity and now you're a public benefit corporation? That doesn't make sense at I mean, I'm not going to get into all of the structures, but I mean, I guess OpenAI do kind of need the company to be public if they're going to get realistically the funds they need to be able to continue moving forward with their mission. I think that [music] private capital eventually is going to run out. These guys are talking about raising trillions of dollars. And I don't see how they're going to do that with simply private investment alone. So, I guess it kind of makes sense. I know a lot of people are going to say, you know, Sam Alman says he has no equity in it, but yada yada yada. I mean, I'm kind of excited to see how this situation pans out because [music] this is one of the reasons, you know, Elon Musk has been suing OpenAI because he's like, \"Guys, I gave you this money to start the company",
        "start": 1589.76,
        "duration": 3400.1600000000017
    },
    {
        "text": "no equity in it, but yada yada yada. I mean, I'm kind of excited to see how this situation pans out because [music] this is one of the reasons, you know, Elon Musk has been suing OpenAI because he's like, \"Guys, I gave you this money to start the company now you guys are completely betraying the mission.\" So, it'll be completely interesting to see where that goes. Now, I haven't spoken about this in quite some time, but Ireland's plans to make a $1,500 a month basic income for artists permanent. Now, this is big news because most people don't realize that the economy is changing. There are multiple layoffs. And I hate to say it, but I personally believe that a lot of these layoffs are AIdriven. And I think that every year that we move on in the economy, it becomes easier to have a company with less employees. As the AI capabilities increase, it increases a person's capability to get more done. And so with that, you have layoffs coming down the line as a, you know, maybe fourth or fifth order consequence. And Ireland is basically saying that look, they're going to provide $370 a week to 2,000 artists, aiming to offer financial stability, and support creative work. And the government report found that the payments reduce financial stress, improved mental health, and fostered professional growth among the participants. And this is part of their 2026 budget. And their trial is successful. and they're saying that this is going to be a permanent national program in 2026. So why is this big news? Well, we know that in future the economy is going to change completely and money might not mean as much. But during these transitionary periods, it's going to be interesting to see how governments adopt certain policies and programs and universal basic income I believe is, you know, one of those keys that are going to be needed in honest opinion. Like there is there's not going to be a lot of work and I I keep seeing news articles and articles of people not being able to find a job. I'm not saying it's everywhere. I'm not saying, you know, it's all because of AI, but I believe that there is going to be a tipping point and you kind of want to get in a situation that you're comfortable with sooner rather than later. So, props to the government doing it from now because it's relatively early. They're realizing that this, you know, is really affecting them. Like these AI tools are pretty pretty good at, you know, doing that. And what's crazy, okay, what's absolutely crazy is that you would think that, you know, AI tools might slow down, but no, Google actually released this design tool. And this is the design tool, which is really cool. Okay, I'm going to show you guys this video now. So, this is called Pomelli. And this is an AI powered",
        "start": 1725.12,
        "duration": 3668.8800000000006
    },
    {
        "text": "you would think that, you know, AI tools might slow down, but no, Google actually released this design tool. And this is the design tool, which is really cool. Okay, I'm going to show you guys this video now. So, this is called Pomelli. And this is an AI powered help small and medium-sized businesses easily create professional onbrand marketing campaigns, especially for social media. It works in three main ways. What you do is you put into your website and you basically just get your business DNA. You can essentially get colors, fonts and styles and then it generates custom campaigns, ideas and it lets you, you know, input your own text if you do want and it just creates branded visuals on style that you can actually edit. So unlike generative images where you just have one image and you can't edit the text and you can't edit that, you can actually edit the text in these. So this is crazy because like I said, how many graphic designers used to do this? How many small agencies where you know you take someone's website and you you know get all of their stuff. How many businesses are going to be you know put out of business because this tool released by Google. I think on one side it's pretty good because it helps small businesses actually improve the quality of what they're doing. But at the same time I think that there are those who would do this work and are now probably going to get fired because of this. And that is the unfortunate truth. Okay. Like I know it sounds bad but that is the unfortunate truth. As the capabilities of these models increase, unfortunately, you know, there is less demand for people who can do this kind of work. But I do think that of course at the top end for like major major companies, they'll still be hiring humans because I think there's a lot that goes into large brands and they really can't afford to mess up. Now, now, additionally, we can talk about Meta's layoff. So, Meta actually laid off 600 employees from a bloated AI unit as Wang cement's leadership. So Meta decided to lay off people because they are essentially trying to become more focused in their AI efforts. I think they spent way too much money on hiring people. They spent like I think it was I don't even know. I think I think I think it was billions and billions of dollars. I mean they were offering some people a billion dollars over 10 years. And it's pretty crazy because the layoffs are intended to consolidate leadership and give Wang tighter control over Meta's AI direction after the crazy frustration with the lukewarm reception to Llama 4. And the affected employees will receive 16 weeks of severance plus 2 weeks per year of service. And Meta has, you know, it now has under 3,000 employees in its super",
        "start": 1860.799,
        "duration": 3931.039999999998
    },
    {
        "text": "give Wang tighter control over Meta's AI direction after the crazy frustration with the lukewarm reception to Llama 4. And the affected employees will receive 16 weeks of severance plus 2 weeks per year of service. And Meta has, you know, it now has under 3,000 employees in its super to invest in AI infrastructure, including [music] the $27 billion partnership with Blue Hour Capital to fund the Hyperion data center in Louisiana, which is one of the biggest in the world. So, they're continuing to spend, continuing to spend, and continuing to spend, and they're, you know, expected to grow further in 2026. So, I really do hope that they manage to pull together and get some good models out because it doesn't look good for Meta. Their, you know, Vibes app doesn't look good. their models haven't looked good and they're spending billions of dollars and so far it seems okay seems like their only AI product which is good are those AI glasses which honestly are pretty good and I think Meta should probably go all in on hardware. Now we also got co-pilot. So Microsoft rolled out a major update to co-pilot in 2025 including 12 significant features. Don't worry, I'm I'm not going to, you know, talk about all of them, but the long story short is Mo is this new lovable character that is acting as your companion rather than just a chatty that you just like talk and message. This is kind of like not really a person, but kind of like this just like an AI system, kind of like Clippy, I guess you could say, in [music] a sense. And it's a new way to interact with AI because the way how we interact with AI is pretty basic in most ways. And it's able to just do a bunch of different, you know, things. Like there's even co-pilot features in Edge where you can turn your browser into a voice-driven AI assistant. I mean, honestly, I made a video about this. I'll probably link it because if I talk about co-pilot, it's going to be it's going to be like an hour long video. And I don't I don't want to make the video too too long, but take a look at what Mustafa Sullean says. This is the guy who is currently leading the lab. And he basically says that, you know, soon people will, you know, interview you and your co-pilot. So, it's it's going to be crazy. It's going to be crazy. I think that it's naturally going to evolve to be more of a coworker because you want it to be able to fill in your gaps, right? You know, you think you have certain strengths and weaknesses. Some of us are more analytical, some of us are more creative, some of us are more structured. You can think of each one of us as this unique kind of, you know, key",
        "start": 1994.799,
        "duration": 4182.319999999998
    },
    {
        "text": "to fill in your gaps, right? You know, you think you have certain strengths and weaknesses. Some of us are more analytical, some of us are more creative, some of us are more structured. You can think of each one of us as this unique kind of, you know, key strengths and weaknesses. And I think that each co-pilot is going to adapt to the grooves of your unique constellation of skills. And so if it fits to you, it kind of means like you and your co-pilot are going to be like a [music] pair. You're going to be like a powerhouse. I mean, who knows? One day you might even go and do job interviews together because it's going to be like you're hiring me and my co-pilot. We're a pair, you know? , it's could well be your co-founder. All right. I I'm I'm expecting anytime soon people to declare that it's like them and their AI starting this new",
        "start": 2121.92,
        "duration": 4262.719999999998
    }
]