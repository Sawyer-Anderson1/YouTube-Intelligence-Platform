[
    {
        "text": " 2026 has just started and robots are already crossing a line many people never thought possible. You can now order an ultrarealistic female robot for just $7,999. [music] We're not talking about stiff mechanical machines anymore. We're talking about AI robots so realistic, so humanlike that they make you do a double take. Their facial expressions, their body language, even the way they hold eye contact, it all feels shockingly natural. And that's exactly what we're going to talk about today. Eva, developed by IO technology. Eva.i is described as a bionic embodied AI companion. That phrase sounds complex, [music] but the idea is simple. Eva.i is designed to feel present, not just responsive, but physically and emotionally aware. This is not a toy and it is not a screenbased assistant. Eva.aii is a physical AI companion built to interact using sight, sound, and touch at the same time. The team behind EVA. Is not experimenting casually. The emotional AI system is led by a technical director with a PhD from the University of Washington. The robot's face and body were designed by a former Marvel Studios artist with 18 years of experience creating realistic characters. The motion system was refined by engineers from Chinua University. Research support also came from the Chinese Academy of Sciences in Shenzhen. This is a carefully engineered product, not a prototype rushed to market. Eva is also the foundation of a much larger vision. IOT Technology is building an ecosystem called Robinova World. This ecosystem includes multiple humanoid robots, each built on the same hardware platform, [music] but trained with different personalities. Most of these robots cost $10,500. [music] Eva stands apart as the entry model priced at around $7,000 with only 200 units planned for the initial Kickstarter release. To understand why Eva feels so different, it helps to look at how the body is built. Eva uses a three layer composite skin system. The first layer is a thermal system that keeps the surface temperature at 99\u00b0 F or 37\u00b0 C. That is the same temperature as a human body. When someone [music] touches Eva, the surface feels warm instead of cold or artificial. The second layer is an electronic skin made using flexible circuits. This layer detects pressure and temperature changes. A light touch, a firm press, or a sustained contact all register differently. The system sends that information directly to the AI brain. The third layer is a precision outer shell designed to look and move like real skin. Beneath all of this is an aluminum alloy frame with intelligent joint control. This allows Eva. I to shift posture naturally, [music] display subtle facial movements, and even simulate breathing. The chest rises and falls in a calm rhythmic pattern, reinforcing the sense of presence. Evid eye does not only react visually. The robot sees, hears, and feels at the same time. This is called multimodal interaction. Instead of [music] processing voice, vision, and touch separately, the AI combines them into",
        "start": 4.319,
        "duration": 415.281
    },
    {
        "text": "chest rises and falls in a calm rhythmic pattern, reinforcing the sense of presence. Evid eye does not only react visually. The robot sees, hears, and feels at the same time. This is called multimodal interaction. Instead of [music] processing voice, vision, and touch separately, the AI combines them into break down AI and humanoid robots based on facts, not speculation. Subscribe if you want to understand where this technology is really going. There is also a clever design choice that avoids a major problem in humanoid robotics, the uncanny valley. Instead of placing cameras inside the eyes, Eva hides its vision system inside accessories like glasses or decorative elements. This allows the eyes to remain clear, expressive, and lifelike. The robot can still track faces and expressions, but without the unsettling dead eye effect common in other humanoids. The AI system analyzes voice tone to detect emotional states such as calm, stress, [music] excitement, or hesitation. Facial cues help confirm mood. Touch input adds context. All of this happens locally on the device. Evodi can operate fully offline using onboard processing and encrypted storage. Cloud features are optional and controlled entirely by the user. The companion app plays a key role in this experience. The app connects the physical robot with a virtual interface, creating what IO technology calls a fourth relationship. This is not family, friendship, or romance. It is described as a relaxed emotional connection without pressure or fear of rejection. Do you think a fourth relationship is healthy or risky? Comment your thoughts. The app tracks emotional patterns over time. It learns which topics [music] feel engaging, which conversations bring comfort, and which interactions help stabilize mood. Psychologists were involved in designing these systems to support emotional independence rather than dependency. The company is clear that Eva.i is meant to supplement human interaction, not replace it. EVA.ai is only the beginning. The Robinova lineup includes several other humanoid companions, each priced at $10,500 and built around a specific [music] role. Akira is designed as an aerys and entrepreneur personality. Conversations focus on business ideas, planning, and decision-making. The AI adjusts tone based on confidence and hesitation detected in [music] speech and facial expression. Arya is a fashion focused storyteller. The AI discusses style, trends, and creative expression. The vision system can observe clothing choices and guide conversations around confidence [music] and presentation. Marco is trained as a restaurant owner. Topics include food, hospitality, and service culture. The robot responds naturally to gestures like handshakes supported by pressure sensitive skin. Minda is built around dance and movement. Enhanced [music] joint control allows smoother motion. The robot can mirror movements and adjust [music] breathing rhythm to match music tempo. RKU represents an art school student personality. Conversations center on visual art, creativity, and design thinking. The AI adapts encouragement or critique based on emotional signals. [music] Suk functions as a product manager companion. Discussions include technology, planning, and teamwork. The AI detects frustration or confusion and",
        "start": 212.08,
        "duration": 815.4410000000003
    },
    {
        "text": "match music tempo. RKU represents an art school student personality. Conversations center on visual art, creativity, and design thinking. The AI adapts encouragement or critique based on emotional signals. [music] Suk functions as a product manager companion. Discussions include technology, planning, and teamwork. The AI detects frustration or confusion and accordingly. All of these robots share the same core technology. Warm surface temperature, electronic skin, hidden vision systems, offline emotional AI. The difference lies in personality training and interaction focus. If you could choose just one personality, which one would you pick? Comment the name below. I'm curious. The emotional AI market is growing rapidly. Research forecasts annual growth above 20%. [music] Digital loneliness is becoming more common as social interaction shifts online. Iotechnology is positioning embodied AI companions as one possible response to this shift. Mass production is planned for early 2026 following the Kickstarter campaign. Eva's limited 200 units will ship first. Additional personality models will follow. The company is also exploring licensed character collaborations for future robots, expanding Robinovo world further. What makes this moment significant is not just the technology itself. It is the transition. AI companions are moving from screens into physical space. They are becoming warm, responsive, and emotionally aware. Eva represents the first affordable step into that future. The real question is not whether this technology works. The question is how people will respond to machines that feel present, remember interactions, and engage emotionally. Iotechnology is betting that society is ready to take that step. The robots are no longer coming someday. They are arriving now. Uni has released a new H2 humanoid robot demonstration, and it has left a lot of people uneasy. At first glance, the footage looks like a catastrophic mistake. During a live demo, the H2 appears to launch a powerful kick straight toward the head of its own CEO. For a split second, it feels like you're watching something spiral out of control. But once you understand what's really happening, the moment becomes far more unsettling. Some viewers are already calling it the closest thing we've seen to a realworld Terminator. Hey everyone, welcome back to the AI Nexus. This week, humanoid robotics crosses into a much more dangerous phase. Let's begin. The demonstration opens with something that feels more like a stunt from an action film than a robotic showcase. The H2 executes a flying front kick with speed and balance that doesn't look mechanical at all. Then the tone shifts. The robot repeats the same move, but this time the target is human. Standing directly in front of the robot is Unit's founder and CEO, Wong Shing. He doesn't flinch. As the H2 launches its 154-lb machine frame into the air, its foot stops just short of his face. The distance is razor thin. Wong's expression says everything. This is someone who understands exactly how much force that leg can produce. If the system had been even slightly off, the outcome could have been catastrophic.",
        "start": 415.12,
        "duration": 1191.0409999999995
    },
    {
        "text": "154-lb machine frame into the air, its foot stops just short of his face. The distance is razor thin. Wong's expression says everything. This is someone who understands exactly how much force that leg can produce. If the system had been even slightly off, the outcome could have been catastrophic. value. It was a calculated display of accuracy. For a humanoid robot to jump, extend a limb toward a human head, [music] and stop with that level of precision requires extreme control, rapid computation, and incredibly responsive actuators. But precision alone isn't the headline here. The demo quickly proves how much destructive [music] power sits behind that control. The H2 transitions into a spinning jump hook kick, rotating fully in midair. This time, the target is a watermelon. The result is instant and [music] violent. The fruit doesn't crack, it explodes. That single strike demonstrates how much rotational force the robot can generate while staying perfectly balanced. Things escalate further when the test shifts to raw impact strength. Engineers place a 66-lb sandbag about 30 kg in front of the robot. One kick sends it swinging effortlessly through the air. They replace it with a heavier 132lb bag, about 60 kg, roughly the weight of a small adult. The H2 strikes again, and the bag flies just as easily. Online reactions didn't take long. Comment sections are already describing this stage as the Terminator era, with viewers pointing out that a strike like this could be fatal to a human. The hardware explains why. The H2's knee joints alone output around 360 [music] new m of torque. All of that power is packed into a humanoid frame weighing just 154 lb [music] frame, about 70 kg. And Uniritri isn't alone in pushing humanoid strength beyond human limits. Engine AI recently released footage that put an end to accusations that their earlier demonstrations were staged. In the video, their T800 humanoid delivers a strike so powerful that it physically lifts the company's CEO off the ground. Before we continue, if you want grounded, no hype updates on humanoid robots and AI, make sure you're subscribed to the AI Nexus. We focus on what actually matters. In Engine AI's test, CEO Xiao Tong Yang wears full protective equipment and braces behind a padded shield. [music] He stands directly in front of the T800. The robot locks onto the target, adjusts its stance, and then fires a [music] kick with explosive force. The impact launches Xiao backward. across the mat. This wasn't a shove or a loss of balance. It was a deliberate engineered strike. The T800's leg actuators are rated at roughly 450 new m of torque, surpassing even the H2. What stands out even more than the hit is what happens afterward. The T800 doesn't stumble. It doesn't tip or struggle to recover. Its balance system compensates almost instantly. Gyroscopic sensors and real-time feedback loops shift its center of mass in milliseconds. While Unitri positions the H2 as an",
        "start": 604.88,
        "duration": 1560.3219999999992
    },
    {
        "text": "H2. What stands out even more than the hit is what happens afterward. The T800 doesn't stumble. It doesn't tip or struggle to recover. Its balance system compensates almost instantly. Gyroscopic sensors and real-time feedback loops shift its center of mass in milliseconds. While Unitri positions the H2 as an under its Destiny awakening vision engine AI is clearly optimizing for brute durability. The T800 is being prepared for a competitive robot boxer event where humanoids will physically spar against each other. This is no longer the age of robots falling over from minor contact. These machines can absorb force [music] and return it with even greater intensity. But power and precision don't guarantee safety. Sometimes the very systems that make these robots feel human are the same ones that cause serious problems. That brings us to a viral incident involving Unit's smaller humanoid, the G1. The G1 is designed as a lowercost platform for AI training and research. [music] It's best known for its martial arts style demonstrations, but one training session gained attention for an entirely different reason. The G1 uses real-time motion imitation. An engineer wears a motion capture setup and the robot mirrors every movement instantly. It's an effective method for teaching balance and coordination. During one session, the engineer demonstrates a simple front kick. He lifts his leg and kicks forward. The robot copies the motion perfectly. The issue was positioning. Both the engineer and the robot were facing the same direction with the G1 [music] standing directly behind him. When the kick was executed, the robot's leg followed through straight into the engineer's groin. He dropped to the floor immediately, but the situation became even [music] stranger. Still operating in mirror mode. The G1 observed the engineer doubling over in pain and collapsing. It instantly mimicked that reaction, bending forward [music] and falling in the same way, as if reacting to pain itself. The clip spread rapidly online. While many found it funny, it exposed a serious reality. The robot didn't malfunction. It performed exactly as trained. Its motion accuracy was so high that it delivered a flawless strike to an target. This is the real danger of high performance humanoids. When machines move at human speed with mechanical strength, even a small oversight in training logic can lead to injury. This is why Unit's H2 demonstrations matter so much. The focus isn't just teaching movement. It's teaching spatial awareness, distance, and human presence. When you step back and look at the H2, the T800, and the G1 together, a clear pattern emerges. Humanoid training has fundamentally changed. Older robots relied on rigid pre-programmed joint paths. Movement looked artificial and fragile. Today's systems rely on reinforcement learning and human-guided feedback loops. The H2's quasi serial mechanical design places heavier motors higher in the legs, reducing inertia in the lower limbs that allows faster, more natural motion. Combined with a flexion, abduction rotation hip structure, the platform becomes far easier for AI",
        "start": 791.68,
        "duration": 1937.2819999999995
    },
    {
        "text": "Today's systems rely on reinforcement learning and human-guided feedback loops. The H2's quasi serial mechanical design places heavier motors higher in the legs, reducing inertia in the lower limbs that allows faster, more natural motion. Combined with a flexion, abduction rotation hip structure, the platform becomes far easier for AI advances also reveal what's still missing. As the G1 incident shows, humanoid robots don't yet understand context or social boundaries. They execute instructions perfectly, even when perfection leads to dangerous outcomes. The intelligence layer is still catching up. The hardware is already strong enough for the real world. The software, however, is still learning how humans actually live in it. And this is only the beginning. Forget everything you knew. CES 2026 just proved the robot revolution is officially here. Robotics unveiled the humanoid so lifelike it actually solves the [music] uncanny valley. Engine AI's T800 proved that robots can now jump and sprint [music] like pro athletes. Tombot introduced Jenny, the robotic pup designed for pure emotional comfort. [music] From rollable laptops to AI powered sneaker cleaners and L'Oreal AI face masks, it was a wild show. Realics introduced Davidbot, a male humanoid designed to push realism far beyond previous demos. Davidbot uses advanced facial animation systems that sync speech with micro expressions. When the robot smiles, muscles around the eyes react naturally. When it pauses, the face settles instead of freezing. This solves one of robotics's [music] biggest problems, the uncanny valley. Built on the Ask Arya platform, the system adjusts tone and expression based on detected emotion. It is positioned for entertainment, hospitality, and customer-facing roles. The [music] result feels less like a machine responding and more like a presence reacting in real time. If realism was one extreme, raw physical ability was the other. Engine AI showcased two humanoids that focus entirely on motion and strength. The PM01 is a lightweight embodied agent designed for realworld environments like malls, stations, [music] and guided tours. Movement is smooth, controlled, and practical. Then comes the T800. This full scale humanoid delivers up to 450 Newton meter of torque [music] per joint and 14,000 watts of instantaneous power. That level of force allows sprinting, jumping, and combat style movement. Instead of slow mechanical steps, the T800 moves like a trained athlete. This shift marks a move away from staged concepts and toward robots built for factories, [music] emergency response, and physical labor. Not every robot at CES was built for power or speed. Some were designed for comfort. Tombot presented Jenny, a robotic companion created for seniors with dementia and individuals dealing with anxiety. Jenny uses nine servo motors to control subtle movements, ears, head tilt, eyebrows, and tail. The design was developed with Jim Henson's Creature Shop, [music] giving it lifelike motion instead of rigid animation. Capacitive touch sensors allow the robot to respond when petted or held. When interaction stops, Jenny reacts with gentle movement to re-engage. Priced around $1,500, it replaces neither therapy nor care,",
        "start": 982.72,
        "duration": 2341.201000000001
    },
    {
        "text": "tail. The design was developed with Jim Henson's Creature Shop, [music] giving it lifelike motion instead of rigid animation. Capacitive touch sensors allow the robot to respond when petted or held. When interaction stops, Jenny reacts with gentle movement to re-engage. Priced around $1,500, it replaces neither therapy nor care, unable to maintain a real pet. Displays took a major leap forward with Lenovo's ThinkPad Rollable XD. At first glance, it looks like a standard 13.3 in laptop. Then the screen expands upward into a full 16in vertical workspace. The rollable panel is powered by dual motors and steel cable support to keep the display flat and rigid. Unlike earlier concepts, there's no warping or distortion. Part of the screen wraps around the exterior when closed, enabling a world-facing display for notifications or schedules. This design removes the need for external monitors while keeping the device travel friendly. It's a practical evolution of foldables focused on productivity rather [music] than spectacle. CES always delivers unexpected products. One of the most talked about was the Brolon Clear X, an AI powered shoe cleaning system. Shoes are scanned internally to identify material types like leather, suede or mesh. Based on that data, the system selects a cleaning and drying cycle automatically. The core technology uses micro nano bubbles which penetrate fabric [music] without soaking it. This removes dirt while preserving structure and glue. With an estimated price between $500 and $800, it targets collectors rather than casual users. for sneaker preservation. It may solve a problem most didn't know could be automated. Behind many of these machines is one key player, Qualcomm. At CES, the company unveiled the Dragon Wing IQ10 chip built specifically for physical AI systems. The chip features an 18 core Orion CPU and delivers 700 tops of AI performance. That's more than 10 times the power of most AI laptops. It supports up to 20 simultaneous camera inputs, allowing robots to see, reason, and act in real time. Qualcomm pairs this with a visual language action model, meaning robots understand what objects are and how they should be handled. This architecture is designed to move robotics out of labs and into everyday environments. Personal flight returned in a serious way with the air EV. Unlike air taxi concepts, this electric vertical takeoff and landing is designed for private ownership. The aircraft uses a flybywire system where onboard computers manage stability while the pilot controls direction. It reaches speeds of 155 mph with a range of 110 mi. For the 2026 [music] version, Blade geometry was redesigned to reduce noise, one of the biggest barriers to personal aircraft adoption. Instead of futuristic visuals, Air1 focuses on usability and garage scale storage. It positions personal flight as a lifestyle tool, not a science experiment. If Air1 is a flying car, the RTOR X4 [music] is closer to a flying dirt bike. Built for solo pilots, it uses a multi-rotor design with an open field of view. The standout feature is",
        "start": 1187.2,
        "duration": 2731.3609999999994
    },
    {
        "text": "scale storage. It positions personal flight as a lifestyle tool, not a science experiment. If Air1 is a flying car, the RTOR X4 [music] is closer to a flying dirt bike. Built for solo pilots, it uses a multi-rotor design with an open field of view. The standout feature is and ultrasonic sensors, the [music] system detects trees, cables, and terrain in real time. Takeoff and landing are fully AI assisted, lowering the barrier for new pilots. Battery density improvements pushed [music] flight time to 30 minutes, a notable jump from earlier versions. The X4 represents a shift from proving flight [music] is possible to proving it can be safe and accessible. Minimalism took an extreme form with the HP Elite Board G1A. There is no separate PC. The keyboard is the computer. Inside its 0.7 in chassis sits an AMD Ryzen AI 300 series processor, cooling system, speakers, and microphones. It qualifies as a co-pilot plus PC with a [music] dedicated NPU for AI workloads. Weighing under 1.5 lbs, [music] it connects to any display via USBC. The internal design is modular, allowing RAM and storage upgrades. This concept brings [music] back the spirit of early home computers, updated for cloud workflows [music] and AIdriven productivity. Wearables also received a major AI upgrade. Lenovo previewed Caira, lightweight AI powered glasses weighing just 45 [music] gram. The system delivers near instant live translation and contextual summaries of missed notifications, all without heavy hardware. For younger users, [music] the Luca AI cube targets Gen Alpha. The cube uses multimodal AI to identify objects and explain them through stories and facts. Instead of screenbased interaction, it encourages realworld exploration. These devices show AI moving away from apps and toward ambient everyday assistance. Beauty technology took a scientific turn with L'Oreal's LED face mask prototype. The flexible silicone mask uses 630 nanometers red light and 830 nmters near infrared light wavelengths known to support collagen production and skin repair. An integrated microcircuit controls exposure time and intensity to prevent overuse. Unlike rigid masks, this design conforms to facial contours for even treatment. Set for a 2027 launch, it represents skincare moving into regulated datadriven wellness rather than cosmetic experimentation. Displays reached another milestone with the Samsung Z trifold. Fully unfolded, it becomes a [music] 10in tablet-sized screen. Despite the size, the device is just 12.9 mm thick when folded. A dual hinge system allows three apps to run side by side with no performance drop. Powered by the Snapdragon 8 Elite and paired with a 200MP camera, the device focuses on productivity rather than novelty. This design shows foldables maturing into serious computing tools instead [music] of experimental form factors. The show closed on a softer note with Echovac Lilo, an emotional companion robot designed like a small animatronic dog. Lil Milo uses facial recognition and voice detection to interact naturally. Its charging station is shaped like a dog bed. When [music] battery runs low, the robot crawls in",
        "start": 1384.88,
        "duration": 3148.800000000003
    },
    {
        "text": "factors. The show closed on a softer note with Echovac Lilo, an emotional companion robot designed like a small animatronic dog. Lil Milo uses facial recognition and voice detection to interact naturally. Its charging station is shaped like a dog bed. When [music] battery runs low, the robot crawls in This design avoids mechanical reminders of power and maintenance. Liil Milo highlights a growing trend at CES. Robots not just as tools, but as quiet, emotional fixtures in everyday spaces.",
        "start": 1596.159,
        "duration": 3178.562000000002
    }
]