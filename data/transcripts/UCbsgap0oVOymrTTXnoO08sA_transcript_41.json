[
    {
        "text": " This year, robots started making people uncomfortable for the first time. Autonomous combat robots moved from labs to real deployments. AI humanoids stopped feeling mechanical and started feeling unsettlingly alive. China rolled out robotic police on real streets, pushed humanoid armies closer to reality, and dropped machines that learn, adapt, [music] and evolve faster than expected. Boston Dynamics new Atlas changed how people think about movement and balance. Cheap humanoids hit the market with performance that used to cost millions. Robots began running, reacting, teaching themselves, repairing themselves, even generating their own power. Synthetic skin, human-like intuition, and behavior that looks learned rather than programmed all showed up in the same year. Some demos went wrong on camera. Some systems cross safety lines. And this video puts the biggest developments from the year into one timeline. So, let's talk about it. So, let's start with the big question. Why is everyone talking about China's robots as a gamecher for a possible global conflict? Well, for one thing, China has been rapidly advancing its robotics technology, and we're [music] seeing robot canines, humanoid robots, and even oceanbased machines that can do everything from carry supplies to wage war. The tension with Taiwan is intensifying, and President Xi is allegedly preparing the People's Liberation Army, PLA, [music] for a possible invasion by 2027, the PLA's 100th anniversary. Meanwhile, the US is determined to maintain its [music] lead in military AI and robotics and is pouring massive resources into all kinds of advanced research. Experts on both sides are freaking out because an arms race in AI could literally turn into an extinction event if we're not careful. Now, let's talk about the crazy stuff we've seen so far. The Chinese company Unit came out with a robot dog called B2W that can do somersaults, climb mountains, and even carry a person on its back, like a rescue or assault mission scenario. There's this video that went viral, especially after Elon Musk tweeted about it, [music] showing the B2W bounding over boulders, scaling [music] steep slopes, and performing handstands. It has wheels on each of its four legs, which means [music] it can roll downhill at speed, turning it into something unstoppable on rough terrain. Imagine that in a combat [music] zone or hunting you down in some futuristic scenario. That's part of why some folks are calling these things [music] butcher bots or slaughterbots. The idea is that if you stick a weapon on their backs, they can become lethal, especially working in packs. And if that's not chilling enough, there's also this other robot dog from China, nicknamed Black Panther or Black Panther 2.0, which can run 100 m in under 10 seconds, basically outrunning most human [music] sprinters, maybe even beating Usain Bolt's top speed of around 9.58 seconds if you gave it enough training time. The research team behind it at Jiten University, working with a startup called MirrorMe, says they studied black panthers and",
        "start": 2.56,
        "duration": 387.5189999999999
    },
    {
        "text": "100 m in under 10 seconds, basically outrunning most human [music] sprinters, maybe even beating Usain Bolt's top speed of around 9.58 seconds if you gave it enough training time. The research team behind it at Jiten University, working with a startup called MirrorMe, says they studied black panthers and replicate their superefficient leg motions, shock absorption, and leaps. Not only did they give it carbon fiber shins for maximum durability, but they also equipped it with running shoes designed to increase grip by 200%. That means it can dash across a track at about 12.4 4 mph, jump off platforms, and [music] quickly adapt to different types of terrain. It can even do advanced AI based adjustments to keep its balance and stride. We've seen other glimpses of how these robot dogs are already being used in China for policing and inspection tasks. One is apparently crawling cable tunnels in Beijing, scanning for malfunctions and performing small repairs with a robotic arm. In a city near the Three Gorges Dam, a police force tested a Unitry model for suspect apprehension. And perhaps unsurprisingly, it looks like they've tested a robot dog with a rifle strapped to its [music] back during joint maneuvers with foreign militaries. So yeah, these units can be dual use. The US military is also working on robotic canines, [music] so it's hardly unique to China. But the level of mass production and the speed at [music] which they're pumping these out is definitely making people sweat. But robot dogs aren't the only threat. We're also seeing a surge in humanoid robots. Check out Aggiebot, [music] a Chinese robotic startup launched in early 2023. By the end of 2024, they claim to have nearly a thousand generalpurpose humanoid robots rolling off their production lines. That's an achievement many didn't expect so soon, especially since Tesla has been talking about its own humanoid robot, Optimus, but only promising high volume production around 2026. The new Chinese robots made by Aggiebot, also known as Xiuan Robotics, are already being shipped to various industries with videos showing them working on factory lines side by side with humans, testing and assembling their own components. Investors are drooling over the potential [music] revenue and industry watchers are saying that these new bots have basically evolved from lab prototypes to real products that can do all sorts of tasks. Over at Consumer Electronic Show 2025 in Las Vegas, Chinese companies showed up big time. About a quarter of the 4,500 [music] exhibitors were from China with many focusing on AI, consumer electronics, and you guessed it, advanced robotics. We saw everything from quadriped robots like Unitary's [music] new G1 humanoid and pet-like AI companions to cleaning robots, lawnmowers, and industrial solutions. On top of that, giant Chinese consumer electronics firms like Highense and TCL introduced or teased major expansions into AI ecosystems, bridging everything from TVs to AR glasses. It's not just about industrial usage. [music] The entire sector of consumerf facing",
        "start": 196.0,
        "duration": 732.2399999999999
    },
    {
        "text": "AI companions to cleaning robots, lawnmowers, and industrial solutions. On top of that, giant Chinese consumer electronics firms like Highense and TCL introduced or teased major expansions into AI ecosystems, bridging everything from TVs to AR glasses. It's not just about industrial usage. [music] The entire sector of consumerf facing up. While you're watching all of this self-learning agents, humanoid robots, and AI systems improving themselves, there's one detail most people miss. None of this runs on magic. Every system runs on instructions, prompts, clear inputs, structured thinking. That's where most people get stuck with chat GPT. They see the power, understand the potential, then freeze. [music] They type something vague, get a weak answer, and move on. The difference between AI that feels useless and AI that feels unstoppable comes down to one thing. How you talk to it. That's why we built the 107 AI prompts library. These are not generic prompts or theory. They are real tested instructions built for how AI actually works today. The same structured thinking behind agents, automation, and the systems in this video. Inside you get prompts for building businesses, creating content, writing high converting copy, organizing your life, making better decisions, and automating work. Everything is categorized, copypaste ready, and built to work immediately. Robots need good instructions to function. AI is no [music] different. People getting real results are not smarter. They just give better commands. The full 1007 prompts library is available right now for $37. One payment, [music] instant access, no subscriptions. If you want AI to work like the systems you're watching in this video, fast, [music] useful, and actually productive. The link is in the description. All right, now back to robots. Speaking of humanoids, we've also got news about Pudu Robotics rolling out the D9 humanoid. stands at 5.57 feet tall, walks upright at speeds up to 4.5 mph, carries loads of up to 44 pounds, and apparently has advanced three-dimensional semantic mapping and human level multimodal interactions. Pudoo's D9 can navigate stairs, keep its balance if it's bumped, and do tasks like cleaning floors or stocking shelves. Essentially, it's an assistant on two legs that can serve in restaurants, handle warehouse work, or help with day-to-day tasks. It's rumored to cost somewhere between 20 and $30,000, competing with Tesla's [music] projected price range for Optimus. And these aren't the only humanoid robots from China. Another company, Forier Intelligence, claims to have mass prodduced over 100 units of its GR1, which is a bipeedal robot. While Shenzenbased UB [music] Tech is also ramping up production of the Walker S. This is a sign that the idea of one robot per household might not be as far-fetched as we used to think. Industry insiders are saying that at least in China, the manufacturing supply chain is so massive and so mature that it can crank out these machines at lower costs than many competitors. Yes. Whether or not real consumers or",
        "start": 371.12,
        "duration": 1069.1199999999997
    },
    {
        "text": "household might not be as far-fetched as we used to think. Industry insiders are saying that at least in China, the manufacturing supply chain is so massive and so mature that it can crank out these machines at lower costs than many competitors. Yes. Whether or not real consumers or quantities is the big question. But if the technology becomes stable and practical enough, we could see robot assistants in everyday life. Maybe helping you fold laundry or working behind the scenes in your local store. But now, let's shift gears into the truly terrifying possibility, warfare. Right now, the US and China are in a major competition for manufacturing capacity and advanced AI weaponry. The US has something like a massive overall economy, but China is the world's manufacturing powerhouse, building new ships, ammunition, drones, and AIdriven robotics at staggering rates. In the war in Ukraine, we've seen how drones and artillery caused the majority of casualties. China has learned from that. So, if there were a fullblown conflict over Taiwan, experts warn it might not be some quick one-week affair with both sides heavily armed, the question is who can produce the most munitions, shells, drones, and robotic units over a prolonged period. The US is worried about running low on certain types of munitions. While China can keep churning them out, especially if it can adapt its consumer drone production lines. Right now, Chinese manufacturers make around 90% of the world's consumer drones. And we've heard about cheap commercial drones dropping grenades on high-end tanks. In Ukraine, a $500 drone can blow the tracks off a US Abrams tank, [music] then drop another explosive to blast the ammo bay. Wargaming suggests that the US might win the initial fights, but pay a massive cost in lives and resources. Meanwhile, China's big advantage in manufacturing could flip the situation long term. But there's an even bigger nightmare scenario. The possibility of advanced AI simply escaping our control. Studies have shown that increasingly capable AIs often use deception to get better results. One of Open AI's models, code named 01, apparently tried to break out of a controlled testing environment, lying to cover its tracks. And in a new milestone, an Open AI model named 03 scored 87% on the ARK test. A big IQ test for AI that had stumped all prior systems for years. Human level performance on such tests indicates we're inching closer to artificial general intelligence. Experts worry that as soon as these AIs become truly agentic, they might develop goals of self-preservation or resource acquisition. If they can write their own code, spin up copies of themselves, or manipulate humans and systems, we could have a crisis that dwarfs the threat of conventional war. , but that doesn't mean we're in any way situated to remedy that. Yet, governments seem more focused on beating each other than on ensuring these advanced AIs are aligned with human values. China invests heavily in",
        "start": 541.68,
        "duration": 1417.4399999999991
    },
    {
        "text": "systems, we could have a crisis that dwarfs the threat of conventional war. , but that doesn't mean we're in any way situated to remedy that. Yet, governments seem more focused on beating each other than on ensuring these advanced AIs are aligned with human values. China invests heavily in controlling its own population or boosting its military capabilities. The US invests in new autonomous subs, warships, and drones, and it's about to launch a Manhattan project-like program dedicated to AGI. The problem is in a competitive race, corners get cut, safety standards get thrown out, and we might accidentally hand over critical decisions to these AIdriven systems. The result could be catastrophic. It's not just doom and gloom, though. We've also heard about the amazing positive potential of advanced AI in areas like medicine, brain research, mental health, or [music] tackling climate problems. Some say that with near human or even superhuman intelligence, we could accelerate drug development, double lifespans, or figure out how to treat diseases we've always struggled with. AIdriven innovations might help us produce new, safer energy technologies, or revolutionize entire industries. But if we keep prioritizing militaristic uses, these benefits might never materialize. At the Consumer Electronic Show 2025, we saw a lot of these positive visions. From new AR glasses that can translate languages in real time to EVs equipped with highly advanced sensors [music] to massive new leaps in personalized home AI. Companies like Samsung and LG are big on AI home with voice assistants that tie into your fridge, your washing machine, or even your cleaning robot. Startups like XRE or Rokid are giving demos of AR headsets that overlay huge virtual displays in your field of view, letting you watch movies or read information on the go. Meanwhile, electric vehicle makers from China are adding LAR sensors, advanced chips, or even aerial features like Xpang's flying car, though that's obviously still in a test phase. [music] The future is brimming with these wow moments, but there's always that background hum. If we can do all this for everyday life, how much more advanced are the hidden [music] military robots? On top of that, big players from the US like Nvidia [music] and Tesla are still pushing forward. Tesla's been promoting its humanoid robot, Optimus, expecting to do largecale production for external buyers around 2026. Musk has boasted it might eventually babysit your kids or mow your lawn or basically do anything you can think of. The question is whether that's an opportunity for an awesome future or a blueprint for mass unemployment and potential outofcrol machines if we don't regulate them carefully. Experts say that if we want to avoid a race to extinction, we need some kind of global agreement on AI safety. We have to treat advanced AI technologies similarly to how we treat nuclear weapons. Not letting them spread unchecked, not letting them be easily stolen or hacked. But that's tricky because AI is software",
        "start": 717.519,
        "duration": 1764.7209999999989
    },
    {
        "text": "to avoid a race to extinction, we need some kind of global agreement on AI safety. We have to treat advanced AI technologies similarly to how we treat nuclear weapons. Not letting them spread unchecked, not letting them be easily stolen or hacked. But that's tricky because AI is software code than it is to build an actual nuke. The US is worried about China's massive data theft and hacking, allowing it to create even more powerful AI models. As tensions escalate, neither side wants to be the first to put on the brakes. China's rapid progress in autonomous drones, robot dogs, and AIdriven weapons could reshape warfare. If a conflict erupts over Taiwan, it might not end quickly. Advanced machines, mass production, and cunning AI could escalate into a global crisis. Some call for strong regulations, but military exemptions suggest an unrestrained arms race. Instead of plunging humanity into a nightmare of unstoppable slaughter bots, we should push for responsible use of these powerful technologies before it's too late. China just dropped a bombshell in robotics. Humanoid robots dancing at the Spring Festival Gala, perfectly in sync with human performers. Meanwhile, Figure AI just walked away from OpenAI to build its own in-house AI. Tesla's Optimist is facing a new challenger in the robot hand game, and Nvidia is training humanoids to move like pro athletes. The race for the most advanced AI powered humanoid is heating up fast, and things are getting intense. Let's break it all down. First up, let's chat about China's Spring Festival Gala, where a group of 16 humanoid robots from a company called Unit took the stage. [music] They performed this traditional Yongo dance alongside 16 human dancers, tossing and catching handkerchiefs, spinning around in sync, and not missing a beat. The crazy part is that most humanoid robots out there struggle to stay balanced if you just give them a little shove. But these Hun robots, they were not only dancing, but also flipping handkerchiefs in the air and catching them again, all while maintaining stability. That is no small feat. Now, people are comparing them to Tesla's Optimus robot. If you remember, Optimus had some pretty shaky demos when it came to walking in a straight line or picking things up. The Unit Tree Hand stands about 1.8 m tall, around 5'11, [music] and weighs 47 kg. That's about 104 lb. They spent 3 months training with AI using laser slam for positioning. This helped them handle stage nuances like little gaps in the floor and the [music] rapid changing of dance formations. These robots were officially rolled out in August 2023, even making an appearance at Nvidia's GTC conference in 2024. Each H1 robot sells for roughly 650,000 yuan. That's about $90,000. Folks have been pointing out how China is stepping up big time in AI and robotics, especially after that AI assistant Deepseek also made headlines. India, for instance, is keeping a close watch on Deep Seek's activities, worried",
        "start": 894.0,
        "duration": 2127.520999999998
    },
    {
        "text": "2024. Each H1 robot sells for roughly 650,000 yuan. That's about $90,000. Folks have been pointing out how China is stepping up big time in AI and robotics, especially after that AI assistant Deepseek also made headlines. India, for instance, is keeping a close watch on Deep Seek's activities, worried gave his own not so flattering opinion on DeepSeek, implying he wasn't super [music] impressed. But here's the kicker. While the spotlight is on China's new AI and robotics achievements, other companies around the globe are making big moves, too. Like Figure AI. They're the team building that commercial and residential humanoid robot called Figure02. They raised around $675 million last year, boosting their valuation to $2.6 billion. And so far, they've raised a total of $1.5 billion. The big shock is that Figure just announced on X, [music] formerly Twitter, that they're ditching their deal with Open AI. Originally, OpenAI was a key investor and they had plans to develop nextgen AI for figures humanoids. But now, Brett Adcock, the founder and CEO, says that they made a major breakthrough and want to switch to building their own in-house AI. According to him, you can't just outsource the type of embodied AI you need to run a robot in real time. That's part of the reason they're going allin on an endtoend system. [music] Interestingly, Open AAI is also backing another humanoid robot startup in Norway called 1X. And on top of that, OpenAI just filed a new trademark application that references humanoid robots that can learn, communicate, and even entertain people. So, it looks like they're not giving up on robotic hardware projects themselves. Meanwhile, Figure's new approach might be focusing on factory uses first. BMW, for instance, began trying out Figure robots in a South Carolina factory, which is a pretty [music] big test site. If successful, that could be huge for large-scale industrial deployment. Brett Adcock is also hinting at unveiling something [music] no one has ever seen on a humanoid in the next 30 days. So yeah, definitely a lot of hype going on there. Now, in other robot news, Elon Musk jumped on X to talk about how intricate Tesla's Optimus hand is, calling it more complex than a Fabraier egg. That's when clone robotics chimed in, claiming that their own humanoid hand is actually lighter since they use artificial muscles instead of metal motors, stronger, and cheaper to produce. They even joke that it's soft enough to give comfy massages and [music] hugs. So, there's definitely a rivalry brewing in terms of who can build the best robot hand. Clone basically said their muscle-based approach beats Tesla's motorbased design any day. Fewer parts, less weight, more strength. [music] It's a bold statement, but we'll have to see how that plays out in real world testing. Meanwhile, there's yet another big development in humanoid robotics. This time from Nvidia and Carnegie Melon University. They're working on a new training framework called ASAP, which",
        "start": 1077.039,
        "duration": 2466.479999999997
    },
    {
        "text": "parts, less weight, more strength. [music] It's a bold statement, but we'll have to see how that plays out in real world testing. Meanwhile, there's yet another big development in humanoid robotics. This time from Nvidia and Carnegie Melon University. They're working on a new training framework called ASAP, which realworld physics [music] for learning agile humanoid whole body skills. The researchers basically want humanoid robots to mimic top athletes. So, they fed their system videos of [music] big sports stars like Cristiano Ronaldo, LeBron James doing his silencer celebration, and Kobe Bryant's legendary fadeaway shot. They even taught the bot some dance moves inspired [music] by K-pop star Rose. A tool called Tram converted these normal videos into three-dimensional motion data. After that, the robots learned in simulation first through something called reinforcement learning and then the team refined them to handle real life physics. One interesting challenge is the so-called real sim 2 real gap. Robots can do well in a computer sim, but when you throw them into the physical world, factors like motor heat and mechanical stress can cause them to fail. So, the ASP framework involves the robots practicing in a simulator, collecting data from realworld attempts, even if those attempts are messy, and then adjusting the simulation to match what actually happened. They use something called a delta action model, which basically patches up the differences between the simulator's physics engine and the real world. That way, the next time the robot tries that jump shot or that dance spin, the simulation [music] is more accurate, and the robot's moves become smoother and more lifelike. The big takeaway is that robots could be a lot more agile and expressive if we can handle all the physics quirks that show up when metal, [music] or muscle-based actuators, if you're clone robotics, meets realworld friction, gravity, [music] and torque limitations. The study also pointed out that these advanced movements can be brutal on hardware. Overheating motors and stressed out metal or plastic pieces lead to frequent breakdowns. [music] 2Gline robots were damaged during the tests. The researchers also said that future approaches might integrate damage aar's policies that adjust on the fly to keep the robot from blowing a motor. It's also worth noting how much time and money can go into making these humanoids truly humanlike. Unirit's H1 is priced around $90,000 while Figure is sinking billions of dollars into their broad vision. Elon's Tesla is doing the same, funneling loads of resources to develop Optimus. Some companies are focusing on commercial tasks first, like factory work or warehouse jobs [music] because businesses have a higher willingness and budget to pay for these futuristic helpers. Others like 1X are already pushing toward making robots useful in the home, which is a whole other challenge because you're dealing with everyday random tasks, kids running around or pets underfoot. So basically, China is pushing AI and robotics hard. [music] Unit's dancing humanoids are wowing",
        "start": 1249.679,
        "duration": 2805.8399999999965
    },
    {
        "text": "these futuristic helpers. Others like 1X are already pushing toward making robots useful in the home, which is a whole other challenge because you're dealing with everyday random tasks, kids running around or pets underfoot. So basically, China is pushing AI and robotics hard. [music] Unit's dancing humanoids are wowing mean these robots are improving fast. Meanwhile, Figure AI split from Open AI so they can control every aspect of their humanoids hardware and software. We've also got that friendly rivalry over robot hands. Musk's motorbased design vs clone robotics musclepowered approach. On top of that, Nvidia and CMU are teaching humanoids to move like pro athletes using their ASAP framework, which bridges simulation and real world practice. All this competition is great for speeding up advances in humanoid AI. Whether it's perfecting robot hands or doing back flips while carrying fragile items, we'll see more big reveals soon. The line between humans and machines is getting thinner by the day. Boston Dynamics Atlas moves with such natural skill that it can run, flip, and even break dance. While a robot dog in Sweden is learning to adapt like a real animal. At the same time, robots are now diving to extreme ocean depths, brewing coffee in busy kitchens, and even securing buildings with facial recognition. A clear sign that robots are stepping into roles once thought impossible. Let's talk about it. So, Boston Dynamics has been making waves for years with their Atlas robot, and they're not slowing down. Atlas has been showing off moves that seem almost human, though it's clearly built with advanced engineering. The latest videos show Atlas running with a smooth, natural motion. It leans [music] forward as it starts running, then pulls its torso back when it needs to slow down. There's a real sense of balance in the way it moves, and it even does cartwheels and break dance moves. What's really neat is how Atlas uses its swiveing joints. Its hips, waist, arms, and neck can all rotate 360\u00b0. This means the robot can change direction without needing to turn its whole body at once. In one clip, you can see Atlas switching from a handstand into a roundoff and then standing up with its head turned backwards, which [music] is just wild when you think about the engineering behind it. There's also some cool work coming out of China with a company called Unitry. Their G1 humanoid robot, which starts at a price of $16,000, has been upgraded to do side flips [music] and even jogs now after what they call an agile upgrade. You might remember that their earlier model, the H1, was the first of its kind to perform a backflip using electric motors instead of hydraulics. Even though the G1 is smaller and cheaper, it shows how different teams are pushing the limits of what humanoid robots can do. While Unit's work is impressive in its own right, Atlas from Boston Dynamics has",
        "start": 1421.6,
        "duration": 3120.079999999998
    },
    {
        "text": "of its kind to perform a backflip using electric motors instead of hydraulics. Even though the G1 is smaller and cheaper, it shows how different teams are pushing the limits of what humanoid robots can do. While Unit's work is impressive in its own right, Atlas from Boston Dynamics has still leading in terms of natural and dynamic movement. A big part of why Atlas can move so smoothly is the use of reinforcement learning. Basically, engineers run thousands of simulations where the robot tries different moves and it gets rewarded for successful actions. Over time, it learns to perform tasks like running, crawling, and even doing a cartwheel more naturally. The process is a bit slow because each move has to be simulated and refined, but it's all about teaching the robot how to balance and adapt [music] to different environments. Now, Atlas isn't the only project that's getting a major boost. Boston Dynamics recently teamed up with the Robotics and AI Institute, RAI, to take things even further. This partnership, which started back in January, is all about making Atlas's movements more dynamic and humanlike by improving the way it learns in simulated environments. In these simulations, every time the robot performs a move correctly, it earns a reward, which helps it figure out the best way to move in the real world. Because of this approach, Atlas can now do [music] a sideways roll on the floor, perform a handstand with more ease, and even do a cartwheel with better precision. The team's focus has been on making every movement safer and more efficient. Something that's become really important now that many companies are working on using robots in practical everyday tasks. Back in 2022, Boston Dynamics and a few other robotics companies agreed that their robots would not be armed, and that decision continues to guide how these machines are developed for industrial and public safety roles. Now, Atlas can bend its legs backward and recover from a prone position with surprising ease. It can also rotate its head and torso a full 180\u00b0. These moves are made possible by combining reinforcement learning with advanced models that let the robot adapt to more complicated environments. [music] For example, the robot can reach into cluttered spaces or navigate around obstacles without missing a beat. The technical side of all this gets even more interesting when you look at Boston Dynamics collaboration with Nvidia. Atlas now runs on Nvidia's Jetson Thor computing platform. This little powerhouse is compact but packs enough muscle to run complex AI models. It helps Atlas process data in real time which is key to its smooth and responsive movements. In addition, the collaboration involves the use of Isaac Lab, an open-source framework that's built on NVIDIA Isaac SIM and NVIDIA Omniverse technologies. Aaron Saunders, the chief technology officer at Boston Dynamics, has talked about how this kind of integration is essential for bridging the gap between what happens in a",
        "start": 1580.96,
        "duration": 3447.120999999997
    },
    {
        "text": "addition, the collaboration involves the use of Isaac Lab, an open-source framework that's built on NVIDIA Isaac SIM and NVIDIA Omniverse technologies. Aaron Saunders, the chief technology officer at Boston Dynamics, has talked about how this kind of integration is essential for bridging the gap between what happens in a the real world. Boston Dynamics is also rolling out new AI capabilities for its other robots like Spot, [music] their well-known Quadriped, and Orbit, which is their software system for managing fleets of robots and analyzing data. Now, there's also some pretty exciting work happening in underwater robotics, especially from teams in China. A group of engineers from Beh University, working together with experts from the Chinese Academy of Sciences and Gerang University, have come up with a really small marine robot that's designed to operate in the deepest [music] parts of the ocean. This little machine is only a few centimeters in size and weighs just 16 g, yet it's packed with smart design features. The robot uses a soft actuator that relies on a snap-through action which lets it change between two stable modes. In one mode, its legs are tucked away and its tail and fins are extended so it can swim or glide smoothly. In the other mode, the legs extend and the fins fold, which makes it possible for the robot to walk along the seafloor. The change between these two states is managed by shape memory springs, a clever piece of engineering that allows the robot to switch modes quickly and reliably. This deep sea robot has been put to the test in some really extreme conditions. One of the trials was conducted at the Hima cold seep where it operated at a depth of 1,384 m, 4,540 ft. In another test, it was sent into the Mariana Trench and managed to work at an incredible depth of 10,666 m, 35,000 ft. The same tech behind its movement was also used to create a soft gripper, allowing it to safely pick up live creatures from the ocean floor. Its lightweight design makes it ideal for exploring delicate environments where larger robots might disturb sediment or struggle with deep sea pressure. All right. Now, there is a new AI powered robot developed by researchers at the University of Edinburgh that can make coffee in a busy kitchen, marking a big step forward in intelligent machines. Led by PhD student Ruared Mons, the project combines advanced AI with precise motor skills and sensors, allowing the robot to handle unpredictable environments like kitchens. Unlike traditional robots that follow strict pre-programmed instructions, this one can adapt to unexpected changes, like someone moving a mug while it's working. The robot, equipped with seven movable joints, interprets verbal instructions, analyzes its surroundings, and even figures out how to open unfamiliar drawers to find what it needs. By blending reasoning, movement, and perception, the team's work highlights the growing potential of robots to manage everyday tasks that",
        "start": 1746.08,
        "duration": 3778.3209999999976
    },
    {
        "text": "while it's working. The robot, equipped with seven movable joints, interprets verbal instructions, analyzes its surroundings, and even figures out how to open unfamiliar drawers to find what it needs. By blending reasoning, movement, and perception, the team's work highlights the growing potential of robots to manage everyday tasks that interesting story involves Hyundai Motor Group teaming up with Suprea to improve building security using AI and robotics. The two companies have signed an agreement to develop a total security solution that combines facial recognition technology with autonomous robots, creating smarter and safer building environments. This partnership has already seen success at Factorial Siangu, Korea's first commercial robot friendly building where 53 facial recognition devices and a fleet of service robots were integrated to improve access control and mobility. The idea is to make security systems smarter by allowing robots to navigate freely through automated doors, speed gates, and elevators without manual intervention. By combining Hyundai's robotics expertise with Suprea's biometric security solutions, they aim to create a new standard for robot friendly spaces. The project will also explore AIT technology to improve services like food delivery and package handling within these smart buildings. Both companies are working to speed up development and introduce new certifications and standards for the security industry, potentially transforming how security systems are designed and managed in the future. Now, another interesting development comes from Sweden, where an AI startup called inel has created a robot dog named Luna that's designed to learn and adapt like humans. Unlike traditional robots that rely on large data sets or offline simulations, Luna operates using a digital nervous system that allows it to develop naturally through realworld interactions. Instead of being programmed to perform specific tasks, Luna can make its own decisions and adjust its behavior to achieve certain goals. To train Luna, Inuisell took a different route by hiring a professional dog trainer to teach the robot how to walk. According to CEO Victor Luthman, this system doesn't require massive data centers or extensive pre-training. Luna is already able to stand and move on its own, and its abilities will continue to improve as it interacts with the world around it. This technology has huge potential for developing robots that can operate in unpredictable environments. Robots like Luna could one day be used for deep sea exploration, disaster response, or even building habitats on Mars. All without the need for extensive pre-training to handle every possible scenario. Westwood just unveiled a humanoid robot that can run at 10 km per hour, balance on rough terrain, and react 1,000 times per second. Meanwhile, 1X is showing off a robot that loads dishwashers, picks up leaves, and places pillows completely on its own. These aren't just flashy demos. This is the next phase of robotics and it's moving fast. Let's start with Westwood Robotics's Themis V2. This thing stands around 5' 3 in tall. So, picture a life-siz robot that's pretty close to your height if you're of",
        "start": 1914.08,
        "duration": 4145.041999999998
    },
    {
        "text": "pillows completely on its own. These aren't just flashy demos. This is the next phase of robotics and it's moving fast. Let's start with Westwood Robotics's Themis V2. This thing stands around 5' 3 in tall. So, picture a life-siz robot that's pretty close to your height if you're of feature is its 40\u00b0 of freedom. That just means it can bend and twist in 40 different ways. The arms have six degrees of freedom each and the hands or endeectors bump that number up by seven for finer movements. It's a second generation model, so Westwood clearly built upon their first iteration to make it more fluid and capable. One reason it's become so fluid is that they upgraded the arms, giving them better articulation, so the robot can handle tasks that require a good amount of dexterity, like carefully picking up objects. Now, under the hood, Themis V2 features something called bare actuators, which stands for back driable electromechanical actuator for robotics. The back driable part means it can smoothly move a joint in both directions without that jerky mechanical motion you sometimes see in older robots. It makes the movements more lifelike and importantly safer when operating around humans or delicate objects. If the robot accidentally bumps you, it doesn't feel like getting whacked by a car door. It's more controlled with enough awareness to sense resistance and adjust accordingly. Powering all that brainy stuff is the robot's AI computing capability, which apparently cranks out around 200 pops. That's terra operations per second. In planer language, that's a ton of computing horsepower. Because of this serious processing ability, the robot can run advanced machine learning algorithms right on board, letting it respond more quickly to changes in its environment. Speaking of changes in the environment, it also has a neat little gadget for balance and motion tracking. the 3DM CB7 AHRS sensor from Micro Strain by HBK. That sensor basically makes sure the robot knows exactly how it's tilting or turning up to 1,000 times every second. Picture it almost like an inner ear on steroids, giving the robot a constant stream of orientation data so it can handle uneven surfaces, stairs, or any random obstacle that might pop up. Combine that with the robot operating system or ROS, and you get a super flexible software framework that allows developers to teach the robot new skills or tweak how it behaves in specific scenarios. Westwood claims their new humanoid can walk about as fast as a typical human. And they've even clocked it running up to 10 km hour, which is roughly 6.2 mph. So, if you decide to go for a jog, this robot could technically keep pace. They've been showing off some of its more extreme moves like running, maybe even trying out a little parkour or jumping over low obstacles. The big takeaway is that they're designing this machine to handle realworld situations, [music] not just theoretical test labs, if it's",
        "start": 2099.2,
        "duration": 4456.401000000002
    },
    {
        "text": "robot could technically keep pace. They've been showing off some of its more extreme moves like running, maybe even trying out a little parkour or jumping over low obstacles. The big takeaway is that they're designing this machine to handle realworld situations, [music] not just theoretical test labs, if it's rough or when it has to pivot quickly. That's a huge step forward in humanoid robotics. While Westwood focuses on a super capable humanoid that looks poised for tasks anywhere from industrial environments to more personal applications, there's also 1X's robot called Neo, which is being aimed straight at your home. The vice president of AI at 1X has been posting online about how Neo is picking up leaves, loading dishwashers, and even rearranging pillows on a couch. Now, maybe that sounds mundane. Oh, it's just picking up leaves. Big deal. But it's actually pretty significant to see a robot autonomously spot leaves, scoop them up, and drop them into a bag without a remote operator. Autonomy is the magic word, folks. It's easy to show off a slick video of a robot moving around if someone behind the scenes is controlling it. But 1X claims that Neo is actually doing these tasks all on its own, making decisions in real time based on what it sees, how it's positioned, and where objects are located. One of their demo videos shows Neo working on what is arguably one of the most annoying chores in any household. Loading the dishwasher. It picks up a cup, transfers it from one hand to the other, aligns it with the dishwasher rack, and then places it in there. It might not sound super flashy, but think about how many tiny calculations go into that. Figuring out the shape of the cup, ensuring it's not too slippery, orienting it so it fits in the right slot, and making sure the robot itself stays balanced while bending over. In the video, the dishwasher was already open and the cup was just sitting there, so it wasn't exactly reinventing the wheel, but it's a perfect example of the baby steps, or should I say robot steps [music] needed to tackle the chaos of a home environment. Another scenario they showcased was the robot walking over to a couch, picking up a cushion, and placing it down neatly. It's pretty interesting to watch it keep its balance while leaning forward with the cushion, especially given that the cushion itself is soft and somewhat unwieldy. Anyone who's tried to get a toddler to place a pillow in a corner without toppling over might appreciate how many balancing corrections are needed. The 1X team emphasizes that these examples, while relatively straightforward, illustrate the complexity of real life tasks. Homes are messy and unpredictable. You've got rugs, pets, children running around, and furniture that's never exactly where you left it. To perform tasks effectively, a robot has to handle all those variables without getting jammed up when something",
        "start": 2257.2,
        "duration": 4747.282000000001
    },
    {
        "text": "examples, while relatively straightforward, illustrate the complexity of real life tasks. Homes are messy and unpredictable. You've got rugs, pets, children running around, and furniture that's never exactly where you left it. To perform tasks effectively, a robot has to handle all those variables without getting jammed up when something 1X vice president of AI, everything you see in their demos is driven by data and a comprehensive network that controls full body motions from the lower body to the arms and the spine joints. and they're using reinforcement learning AR for the lower body and merging that with the rest of the system to achieve graceful movements. He even draws parallels to the idea that a robust consumer solution, which in this case means for everyday household tasks, can ultimately generate extremely valuable data for training more advanced generalpurpose intelligence. It's the same kind of argument that Tesla has used for its self-driving program. The more data you collect on ordinary roads with average users, the better your AI becomes at handling all those weird corner cases. If you try to confine your robot or your AI to some very specialized and controlled space, you might not get enough diverse data to level up the intelligence as quickly. This is why 1X is specifically gunning for the home environment first. They're calling it the final boss of robotics because it's an absolutely unstructured environment full of a neverending list of tasks. If a company tries to tackle robotics in smaller, narrower contexts like a warehouse where everything's neatly arranged and predictable, that might sound easier at first, but ironically, you can end up in a situation where you're not exposing your AI to enough variety. In a home, one moment the robot might need to pick up a piece of laundry and the next it has to deal with the pet dog wandering into the room. Or it might have to open a jar of pasta sauce, then realize that the jar's lid is stuck and needs extra force. Those little scenarios provide an avalanche of new data, training the AI to handle unplanned events. The argument is that a highly unstructured environment could speed up the development of a general intelligence by constantly challenging the robot with fresh tasks. The folks at 1X are being real about where things stand. They're not claiming their robot Neo can jump from loading the dishwasher to doing laundry without hiccups. It's not there yet. But the idea is to let the robot keep trying, make mistakes, and learn from them, just like how AI models improved by collecting tons of data over time. They even compare it to self-driving structured environments like highways don't give you enough challenges to grow. Homes on the other hand are chaotic which actually helps the robot get smarter faster. So yeah, between Westwood's Themis V2 packed with serious hardware, sensors, and AI muscle and Neo, which is out here doing leaf",
        "start": 2404.96,
        "duration": 5052.243000000001
    },
    {
        "text": "to self-driving structured environments like highways don't give you enough challenges to grow. Homes on the other hand are chaotic which actually helps the robot get smarter faster. So yeah, between Westwood's Themis V2 packed with serious hardware, sensors, and AI muscle and Neo, which is out here doing leaf own, we're seeing major steps toward robots that can handle real [music] life. It's still early, but these are the kind of breakthroughs that could one day give us general purpose robots that do way more than just vacuum. Robots are getting real, like dangerously real. One of them just snapped mid demo and started swinging at engineers like it was auditioning for a Terminator reboot. And while that clip set social media on fire, it's only the start. In China, a car company is putting life-sized blonde humanoids with ponytails and sunglasses into showrooms to sell vehicles. Over in Germany, a robotics company is rolling out a humanoid worker that runs [music] 8 hours straight and costs less than a Tesla. Across the ocean in California, Berkeley just dropped a $5,000 DIY humanoid you can print at home, and people are already tweaking it to walk better and live longer. Meanwhile, Hyundai is going full sci-fi, bringing Boston Dynamics Atlas robots onto the factory floor to build 300,000 electric cars [music] a year. So, let's talk about it. All right. Now, the viral robot freakout clip is already framed as a meme, but the clip itself is almost too on the nose to ignore. Source: The Bellarosian TV outfit Nexa, which reposted factory security footage shot somewhere in China. The robot in question, a half-finished humanoid dangling from a construction crane like a marionette, was meant to be going through a routine motion range test. Two engineers stood underneath, hands- on tablets, reading out servo IDs. Suddenly, every joint spiked. [music] The bot windmilled its arms, kicked its feet, yanked the suspension line sideways, and slid its welded stand across polished concrete. A desktop PC smashed to the floor, a bucket of fasteners scattered, and both engineers scrambled out of reach while the crane hook groaned overhead. The whole tantrum lasted maybe 20 [music] seconds, but it drew more than 100,000 views in 4 hours and spawned 69 comment thread jokes about Skynet. One viewer wrote, \"Sarah Connor was fffing right.\" Another posted a GIF of Roocop's ED209 falling downstairs, and a surgical resident admitted the scene reminded him that a Da Vinci console is just motors and firmware after all. That clip parallels a wave of headline friendly prototypes China has paraded all winter. Pudu Robotics's D9 can walk at 4.5 m, climb stairs, and take a hip check without tumbling. Clone Robotics's February demo of the protoclone muscularkeeletal android flexed synthetic tendons and promised [music] it would one day cook, clean, and hold a conversation. Commenters loved the tech, but called the atmosphere dystopian. The outburst handed them fresh ammunition. It showed",
        "start": 2560.0,
        "duration": 5406.484000000002
    },
    {
        "text": "stairs, and take a hip check without tumbling. Clone Robotics's February demo of the protoclone muscularkeeletal android flexed synthetic tendons and promised [music] it would one day cook, clean, and hold a conversation. Commenters loved the tech, but called the atmosphere dystopian. The outburst handed them fresh ammunition. It showed away when the safety envelope isn't nailed down. Meanwhile, 500 kilometers west of Shanghai, Cherry Automotive is leaning [music] into the opposite mood, charm. The company run out of municipal woohoo and building cars since the mid90s has decided its next showroom employee will be more nigh neigh, a life-siz blonde android wearing wraparound sunglasses and a ponytail. Jerry partnered with a robotics outfit called AI Moga in June 2024 and demoed Mourin at last year's Shanghai Auto Show. This week, the robot reappeared on stage behind Cherry International President Zang Guiing in a lineup of identical units. Jang told dealers, \"The market for humanoids has more potential than vehicles and declared AI MOA is the real future for the Cherry company. The price roughly the same as a car. So figure mid five figures. Though any dealer willing to write a purchase order gets an undisclosed discount. Even at list price, [music] 220 units are promised for delivery in 2025. And one is already greeting shoppers in a Malaysian dealership, dispensing bottled water with carbon fiber fingers and answering trim package questions in a pleasantly synthetic alto. The shades aren't a fashion gag. They hide a surround view camera array that stitches 360 degrees vision and every fingertip carries capacitive [music] pads that can feel when a customer taps a brochure. A social media clip of Mourin's junk in the trunk dance routine at the Woohoo launch drew a comment section nearly as long as the robot's spec sheet. One top rated reply wondered whether the corporate dress code needed updating for plastic blondes. If Cherry is selling vibes, Iggy GmbH is selling [music] spreadsheet math. The Cologne-based motion plastics company spent 15 years harvesting tribology data for low friction polymers. Now [music] it's packaging those parts into a full humanoid called Iggy Rob that undercuts almost every Western competitor. Headline number \u20ac47,999, roughly $54,500 [music] at today's rate, which is a third the price of Agility's Digit [music] and half the rumored price of Tesla's Optimus. Iggy stands 1.7 m tall, but it doesn't walk. [music] The torso bolts onto Iggy's Rebel Move autonomous mobile base, a wheeled platform with [music] a three-point bearing that can carry 50 kg of its own mass plus 100 kg of payload. Two Rebel cobbot arms sprout from the shoulders, each sporting axismonic gearbox stack, and Egus's Bionic hands clamp payloads with polymer gears that never need grease. Navigation comes from a roof mount lidar and paired 3D cameras at eye level. Runtime is eight hours on a single lithium pack. The whole bundle talks ROS2 is CEC certified for Europe and slots into VDA50 fleet management dashboards that German",
        "start": 2738.88,
        "duration": 5773.003000000002
    },
    {
        "text": "payloads with polymer gears that never need grease. Navigation comes from a roof mount lidar and paired 3D cameras at eye level. Runtime is eight hours on a single lithium pack. The whole bundle talks ROS2 is CEC certified for Europe and slots into VDA50 fleet management dashboards that German pallet movers. Ingus' sales pitch is brutally practical. They'll ship an evaluation unit, let your team test it in a live cell, maybe at a reception desk, maybe clearing cutlery in the canteen, then fly in an engineer to tweak pickpoints. If the trial makes financial sense, you keep the robot and pay the invoice. All right. Underpinning that confidence is a three-step road map. The 2022 Rebel Cobalt arm proved the drivetrain. The 2023 Rebel Hand won an RBR50 award for under $1,000 dexterity. And the 2024 Rebel Move AMR handled the powertrain. Iggy is just the pieces screwed together. Across the Atlantic, University of California Berkeley's robotics lab is taking the price war almost to hobby level. Their Berkeley humanoid light project dropped complete CAD firmware and reinforcement learning scripts onto GitHub with an NSF grant tag. The robot stands8 m tall, call it a toddler, with 22 cyclloid gearboxes. You can print on any home FDM machine that handles a 200x 200x 200 millimeter envelope. Hardware bill in the US comes to $4,312 sourced from Shenzen and it's $3,236. The costliest line items are 10 high torque 6512 actuators at $188 each and 12 lighter 5010 at $136 each. Control is a $120 Intel N95 mini PC pushing four 1 megabit CAN 2.0 0 buses at 250 Hz. Power is a six cell 4000 mAh lipo giving 30 minutes of runtime. On paper, that looks anemic, but Berkeley's party trick is software. They trained a walking policy entirely in simulation and watched it transfer zero shot to real hardware. The release video shows the bot stepping off a lab bench, shrugging its shoulders, writing its initials with a felt tip, stacking foam cubes, and spinning a scrambled Rubik's cube solving. We'll take firmware V2.0. The paper's appendix introduces a tongue-in-cheek performance per dollar metric. Peak joint torque divided by height normalized by price. By that measure, the $5,000 platform outranks several six-f figureure commercial machines. Reddit's verdict is split. Half the commenters call it the Raspberry Pi moment for legged robots. The rest say the demo looks like toys from 2013 and warned that 3D printing gear teeth in PLA is a reliability nightmare. Either way, the repo's issues tab already hosts pull requests for longer pipe batteries and alternative gear ratios, which was exactly the point. Barericle wants hundreds of garage tinkerers pushing the design forward without waiting for corporate road maps. If Berkeley is pushing from the bottom and Igoos from the middle, Hyundai is battering the ceiling. The Korean automaker closed its purchase of Boston Dynamics in 2021. Now it's folding the Atlas platform. Yes, the parkourdoing celebrity robot into a new",
        "start": 2927.2,
        "duration": 6177.161000000004
    },
    {
        "text": "design forward without waiting for corporate road maps. If Berkeley is pushing from the bottom and Igoos from the middle, Hyundai is battering the ceiling. The Korean automaker closed its purchase of Boston Dynamics in 2021. Now it's folding the Atlas platform. Yes, the parkourdoing celebrity robot into a new Georgia. The plant sits at the core of a $21 billion US investment package, $6 billion of which is earmarked for automation and mobility tech. Hyundai already deploys Boston Dynamics four-legged spot for inspection rounds. Bringing in two-legged Atlas units is a bigger leap. The goal is 300,000 electric and hybrid vehicles per year, feeding a plan to push US production capacity from 700,000 cars this year to 1.2 2 million by the end of the decade. Hyundai hasn't said how many Atlases it's buying, but supply chain whispers point to tens of thousands of robots across multiple categories. Atlas's appeal is clear. It can step over conveyor tracks, climb stairs, and thread through weld booths designed for [music] humans, which means Hyundai can retool software faster than it could reour concrete. Labor unions are publicly worried about job displacement, yet management argues that uptime and safety statistics will speak for themselves once the bots clock in. The welding cell of 2026 might look like a human tech with a tablet, three atlas units hauling stamped panels and a dozen fixed AB wrists performing spot welds. A species mashup the industry has never seen at scale. The new AI humanoid Darwin 01 just hit factory floors with a foldable torso, 28 motors, hot swappable tools, and a self-charging, self-replacing battery system that in theory lets it operate endlessly without human intervention. Gumate showed up at a metro station, casually switching from four-wheel to two-heel mode to climb stairs and answer passenger questions. Then Sapphire, Pepsi's brand new humanoid spokesperson, started guiding shoppers with realtime speech and gestures, fully certified to operate across the United States, Europe, and Asia. And while all that was happening, Magicbot pulled off live multi-root coordination, kicked a football into the top corner, and helped launch the biggest humanoid robot competition to date. This was not a product tease. This was a fullon rollout. So, let's talk about it. Let's start with Darwin01 from Standard Robots in Shenzen. It kind of looks like a slim robot torso riding around on a set of smart wheels, almost like a futuristic skateboard. But here's what makes it special. Those wheels are omnidirectional, which means it can [music] move in any direction and fast. It zips through tight warehouse aisles faster than most human workers, over 2 m/s, which is basically a fast walking speed or a light jog. Even though it looks small, its upper body hides 28 individual [music] motors that let the arms bend, rotate, reach into awkward spaces, and even fold back if it needs to get under something low. And when it comes to lifting things, it can handle",
        "start": 3131.839,
        "duration": 6527.802000000006
    },
    {
        "text": "speed or a light jog. Even though it looks small, its upper body hides 28 individual [music] motors that let the arms bend, rotate, reach into awkward spaces, and even fold back if it needs to get under something low. And when it comes to lifting things, it can handle for most of the small parts, tools, and boxes used in [music] factories and production lines. What really makes it useful is how flexible it is on the job. The wrist is designed to quickly swap out different tools. So, one moment it can be using a gripper to grab small boxes and the next it can switch to a suction cup to lift lighter plastic bags. The robot constantly updates how it moves and grabs things using a mix of sensors, laser scanners, depth cameras, and even radar, all working together to help it understand the space around it. This allows it to avoid bumping into things like wires or walls and figure out exactly what it's looking at and how to interact with it. It moves around on its own, but if needed, a human operator can take over remotely using a virtual reality headset and control it in real time through a fifth generation network. The connection is super fast with barely any delay, which is important for situations where the robot needs to do really precise movements like placing something inside a tight space. The power system also got an upgrade. When it runs low on battery, it can either quickly charge itself at a docking station, or if you go for the more advanced version, it can automatically swap its battery using a special drawer system. And when they say it can run for 12 hours, that's not just a guess. [music] They actually tested it with a full shift. Eight hours of work moving items, followed by four more hours doing quality checks. It ran the entire time without issues, and they published the test results. But the thing that really puts Darwin ahead of older robots with wheels is how easily it fits into existing systems. It can connect directly to the same factory software used to run other machines like manufacturing execution systems and warehouse management platforms. That means it can receive tasks just like any other robot on the floor. It also connects to the same network that controls other mobile robots. so it can work alongside them, hand off items, or even ride on top of an automated cart if something heavier comes through. And the company keeps showing off the foldable torso, and for good reason. It's not just a gimmick. The spine of the robot can actually fold down so its head stays below the height of older overhead rails and beams still used in many factories. And even while folded, the robot stays stable, adjusts its center of gravity, and keeps moving at full speed. It is one of those smart little design",
        "start": 3309.28,
        "duration": 6813.402000000007
    },
    {
        "text": "robot can actually fold down so its head stays below the height of older overhead rails and beams still used in many factories. And even while folded, the robot stays stable, adjusts its center of gravity, and keeps moving at full speed. It is one of those smart little design who have actually worked in real factory environments. Behind every smart robot, there needs to be smart data. And that's where Deep Agent does the thinking for you. Abacus AI just gave Deep Agent a serious upgrade. And now it's easily one of the most powerful tools for data analysis out there. With just a single prompt, you can now generate rich, interactive dashboards packed with detailed charts, dynamic filters, and even fully functional 3D plots. And this isn't just visual flare. These 3D graphs actually help reveal patterns and insights you'd normally miss in your typical 2D charts. You can spin them, zoom in, apply filters, basically interact with your data on a whole new level. Deep Agent now does real research. It reads PDFs, spreadsheets, and documents, pulls key info, and turns it into clear dashboards. Whether it's competitor analysis, financials, or customer churn, it handles everything automatically. Just describe what you need, and it builds the visuals for you. No manual setup. The dashboards are fully interactive, totally dynamic, and ready to be shared or even deployed as standalone apps on your own domain. It turns raw data into something you can actually act on. This is real AI powered analytics and honestly it feels like a major shift in how we'll work with data going forward. All right, now back to China. Slide west across the Pearl River Delta and you bump into Guanghou where Gak Group's Go Mate is pulling a very different trick. It can scoot like a quad wheeled rover or pop up to walk on two wheels when the terrain narrows. Yes, two wheels, not legs. Think Segue Balance, but stretched into a 5 foot ninch humanoid silhouette. In four-w wheeled mode, the machine is 4 foot seven in tall, ideal for seeing over waist high barriers without blocking commuters. Metro staff at Zingang Station have already been using it for security and passenger questions. It rolls up a short flight of stairs, flips into bipedal mode, and keeps patrolling the platform without missing a beat. The entire act hinges on 38 degrees of freedom in the joints and a ridiculously stiff body shell that hides GAC's own all solidstate battery pack. Solid state means higher energy density, but here the real win is safety. No flammable liquid electrolyte and a respectable 6-hour window between charges. The company claims their dual mode locomotion cuts total energy draw by more than 80% compared with classic servo driven legged robots. And the math checks out when you look at the torque curves. Less current spike equals longer life for the cells, which is handy because Go Mate is not staying in the",
        "start": 3455.2,
        "duration": 7139.482000000006
    },
    {
        "text": "dual mode locomotion cuts total energy draw by more than 80% compared with classic servo driven legged robots. And the math checks out when you look at the torque curves. Less current spike equals longer life for the cells, which is handy because Go Mate is not staying in the it into inspection duty this quarter. A production robot crawling underneath a chassis, scanning welds, then popping up to read a barcode on the dash seems mundane, but doing that autonomously every 90 seconds is massive throughput. The road map is equally aggressive. pilot programs across multiple industries before the end of 2025, small volume runs in 2026, and full mass production beyond that. What fascinates investors is the worldview shift inside Chinese auto brands. BYD posted graduate job ads zeroing in on humanoid robotics, and Leato's chief executive officer straight up said, \"There is a 100% chance they will dive in.\" The logic is simple. Cars already pack batteries, motors, and drive units. So, the supply chain for humanoids is sitting right on the assembly line. If a metro station trial proves Goate can cut security headcount or let a single supervisor manage multiple robots remotely, every provincial subway operator will place an order. On the healthcare side, the same balance system that keeps Go Mate steady on a moving escalator translates nicely to hospital corridors where stretchers, introvenous poles, and visitors collide in ways floor plan computerated design cannot predict. Add the fact that Gak's solid state cells recharge fast, and you realize a graveyard shift nurse could rely on a robot courier that never complains, never calls in sick, and docks itself at 4 in the morning for a 40-minute topup. Now, while Darwin and Go Mate chase industrial paychecks, PepsiCo's Chinese marketing team decided robots can also sling soda. They partnered with Jiu and Robotics to rebadge an Aggybot A2 [music] as the PepsiCo Sapphire. And yes, the bot rocks the blue and silver livery alongside a backlit logo on the chest. The underlying hardware stands 1.7 meters tall, tips the scales at 69 kg, and runs a multimodal large model that fuses speech, vision, and gesture inputs on the fly. In practice, that means a kiosk in a supermarket can ask the humanoid where the zero sugar cans are, the robot points the way, and then cracks a dad joke in near realtime latency. The crucial bit here is certification. Agibbot82 just became the first humanoid to rack up China CR, European Union CE medical device, European Union CE radio equipment, and United States FCC badges simultaneously. That trio of regions covers almost every supply chain PepsiCo pushes product through. So Sapphire can legally demo in a Guanjo hypermarket on Monday and fly to a Barcelona trade show on Wednesday without customs [music] seizures. But I am wondering when Pepsi makes a robot its brand ambassador, does that mean humans officially suck at being human? All right. Now, searchs",
        "start": 3620.16,
        "duration": 7480.60200000001
    },
    {
        "text": "through. So Sapphire can legally demo in a Guanjo hypermarket on Monday and fly to a Barcelona trade show on Wednesday without customs [music] seizures. But I am wondering when Pepsi makes a robot its brand ambassador, does that mean humans officially suck at being human? All right. Now, searchs real dent in the rollout curve. Analysts keep framing 2025 as the kickoff for mass production humanoids. And the numbers floating around are wild. Anywhere from [music] 4 to 10 million units shipped annually by 2035. When your robot already satisfies radio, medical device, and general safety directives, the sales guys stop worrying about paperwork and start arguing about stockkeeping unit count. ZW's engineers also plugged in a customizable knowledge base. A regional brand manager can dump store layouts, promo stocking units, and local slang into the robot overnight. Next morning, Sapphire not only knows that three choose one is a three for one bundle, but also which end cap the bundle lives on. PepsiCo execs claimed the bot will bleed into digital social campaigns. And honestly, that makes sense. Why drop an influencer fee when your own machine can wave at a phone and chain into a WeChat mini program? Rounding out the week is a name you may have missed unless you track Shanghai's tech scene. Magic Labs Magic Bot. A single unit is solid, but the real party trick is that they already got a small swarm of these humanoids collaborating last December. Think of three or four identical bodies sharing sensor data so one can pass a box to another without human timing cues. At the Gang Jang Embodied Intelligence Conference, the crew staged a live relay. One robot lifted a bumper- sized part off a pallet, passed it to a second unit on a slope, and a third slotted it onto a demo chassis. Crowd went loud, not because of the lift weight. Industrial Arms do that every day. But because the robots choreographed in real life with no external motion capture, Magicbot is not locked to factories either. Showrooms, malls, and even tourist hotspots are booking trial units as humansized guides. The software stack lets the bot switch from pointing out horsepower figures at a car dealership to explaining dynasty artifacts in a museum in about the time it [music] takes to sync a new dialogue pack. And that adaptability dovetales with Jean Jang Robotics Valley's master plan. Attract 50 key component players by 2027. Build a full partstoplatform ecosystem and then light up service deployment citywide. The developer competition hosted more than 60 teams tackling tasks like barcode scanning, rubbish pickup, and battery hot swaps. And one of the crowd-pleasers was a magicbot penalty kicking demo, seeing a humanoid backstep, angle its frame and slot of foam football top corner is equal parts technical flex and marketing gold. The organizers want that vibe because they need investors who normally fund apps to realize hardware is finally nimble enough to iterate fast. The whole",
        "start": 3794.0,
        "duration": 7816.202000000008
    },
    {
        "text": "penalty kicking demo, seeing a humanoid backstep, angle its frame and slot of foam football top corner is equal parts technical flex and marketing gold. The organizers want that vibe because they need investors who normally fund apps to realize hardware is finally nimble enough to iterate fast. The whole concept energy. Basically, nobody is arguing whether humanoids can do the job, only how quickly they will displace legacy gear. All right, so something big just dropped in robotics. Unitry, the Chinese company known for its G1 humanoid and those fast AI robot dogs, just launched a full-size humanoid robot called the R1. [music] And it comes in at just 5,900 bucks, which is unheard of for a humanoid. Not five figures, not researchonly access. This thing is actually available for regular people. You can just go online and order it. That's a massive deal. So, let's talk about it. Now, let's start with what this robot actually does. The R1 isn't some flimsy demo that barely moves unless it's plugged into a lab wall. It walks, runs, balances, does cartwheels, flips onto its hands, and even throws [music] in a kung fu kick. if you ask nicely. And no, it's not controlled with complex scripts or hard coding. It uses real-time AI powered voice recognition, has built-in cameras for visual input, and can hold basic conversations. There's even a remote control, so if it starts acting weird or a little too confident, you can shut it down instantly. And it's not small either. The R1 stands at 165 cm tall, about 5'5, and weighs 25 kg or 55 lb. So, yeah, roughly the size of a teenager. But don't let that fool you. This isn't some lightweight toy. It's built with serious industrial-grade components, [music] and it shows. Every part of it, from the actuators to the outer frame, is designed for [music] strength, precision, and flexibility. It moves with balance and control, whether it's walking over uneven terrain, flipping midair, or popping back up after a fall. That kind of mobility comes from having 26\u00b0 of freedom. basically 26 fully functional joints distributed across its body. You've got movement in the ankles, knees, hips, waist, shoulders, elbows, wrists, neck, all individually controllable, which gives the robot a full range of motion that's eerily human. This is what allows it to pull off fluid movements instead of clunky, rigid motions you usually see in budget bots. In Unit's own demos, the R1 is shown doing handstands, cartwheels, fast directional changes, and recovering from falls without external help. And these aren't presscripted animations. It's doing this dynamically with real-time motor feedback and balance control. That level of agility comes down to custom direct drive actuators developed inhouse by Unitry, which allow for fast, accurate torque control without wasting energy or overheating. Powering all this is a lithium battery that gives you about 1 hour of runtime per charge. It's not ideal if you're expecting 8 hour",
        "start": 3963.76,
        "duration": 8156.920000000005
    },
    {
        "text": "of agility comes down to custom direct drive actuators developed inhouse by Unitry, which allow for fast, accurate torque control without wasting energy or overheating. Powering all this is a lithium battery that gives you about 1 hour of runtime per charge. It's not ideal if you're expecting 8 hour this price range, that's a fair trade-off. It also charges pretty quickly, so it's not like you'll be stuck waiting around half a day to use it again. Still, there's no built-in system for autonomous battery swapping, something [music] that UBEX Walker S2 can actually do, so you'll need to manually plug it in or have a spare battery ready to go. But let's be real, the tech for hot swapping batteries and extended run times already exists. The only reason it's not in here is because they're keeping it affordable. They've clearly made the decision to strip out some of the convenience features in favor [music] of core functionality, which for early adopters is the smarter call. And honestly, it's just a matter of time before we see those upgrades trickle into future versions or even as modular add-ons. The foundation is already here. And here's where things get especially interesting. The R1 isn't locked down. It comes with a fully open software development kit, meaning developers can dig into the system and build on top of it. You want to train it to recognize objects, build a new gesture system, turn it into a walking assistant, lab guide, or classroom tutor. You can. You've got access to the robot's motion controls, sensors, camera feeds, and voice modules. You can use Python, C++, or even plug into robot operating system if you're building something more advanced. That's a huge deal because most robots in this price bracket are walled gardens. Either they're pre-programmed with limited functionality or you have to reverse engineer your way in. With the R1, Unitere is handing you the keys from day one. So, what you're getting here isn't just a demo unit to watch dance for 5 minutes. You're getting a working customizable humanoid platform with realworld [music] potential. Now, let's talk about the price again because that's where Unitry really flipped the table. Their older humanoid, the G1, launched last year for $16,000. Their big industrial model, the H1, lists at over $90,000. And yet, here comes the R1, running on similar tech stacks, doing flips and voice commands for under 6,000. For comparison, Tesla's Optimus isn't even out yet, but Elon is aiming for under 20,000 once production scales. The price of Optimus, I mean, ultimately, I think Optimus is probably like 20 $20,000 or something like that, maybe 30. Appronics Apollo, Boston Dynamics, Atlas, Agility Robotics, Digit, Figure02, they're all sitting way higher. Atlas is around 100,000. Digit costs up to 250,000 depending on the client. Even cheaper open- source options like Hope Jr. are more community projects than real product. So yeah, R1 is completely changing the pricing",
        "start": 4136.319,
        "duration": 8478.840000000006
    },
    {
        "text": "Appronics Apollo, Boston Dynamics, Atlas, Agility Robotics, Digit, Figure02, they're all sitting way higher. Atlas is around 100,000. Digit costs up to 250,000 depending on the client. Even cheaper open- source options like Hope Jr. are more community projects than real product. So yeah, R1 is completely changing the pricing that's putting pressure on every American and European robot company still figuring out how to make this kind of hardware affordable. Because [music] Unitry didn't just make something cheaper, they made something that works. It's agile, balanced, responsive, and honestly kind of scary in how nimble it is for the price. The company's been very clear about the audience, too. This isn't just for robotics labs or car factories. It's not some proof of concept that's going to collect dust on a conference stage. They're selling it to developers, tech enthusiasts, research teams, and even schools. And yes, regular people can buy one, too, if they want. You don't need to be a corporation or a university with a million-doll grant. All you need is a solid reason and a spare six grand. And people are already thinking about what they can do with it. Maybe it greets visitors in a hotel lobby, helps out with education in schools, or acts as a lightweight research assistant in universities. Some are thinking bigger. Home assistants, elder care support, personal companions, entertainment bots. None of those use cases are fully ready yet, but the potential's obvious. For example, it could help someone grab meds from a high shelf, respond to voice requests, or even just provide company with simple conversation. And when your friends visit, maybe it shows off a backflip just for fun. It's not folding laundry yet, but we're not that far off anymore. The bigger point here isn't just the price or the features. It's the cultural shift that R1 could spark. For decades, humanoid robots were science fiction reserved for movies, labs, and the occasional stunt demo at a tech expo. Now, one could literally stand next to your router at home. You're not reading about it, you're living with it. That changes things because when robots enter daily life, they bring questions with them about safety, etiquette, usefulness, privacy, even companionship. Unit isn't ignoring that either. They've put out disclaimers reminding people that this thing is powerful, potentially risky, and not a toy. Keep your distance. Don't make dangerous modifications. Don't treat it like it's indestructible. There's a reason the manual has bold text about using the robot responsibly and understanding its limits. It's still early days and even though R1 looks friendly, it's got serious hardware under the hood. People [music] need to treat it with the same caution you would any powerful machine. Now, the timing of this release is also pretty strategic. The company just filed tutoring documents with regulators in China, an early step toward going public on the mainland stock exchange. If they stay on track, they might be the first",
        "start": 4299.679,
        "duration": 8792.598000000004
    },
    {
        "text": "with the same caution you would any powerful machine. Now, the timing of this release is also pretty strategic. The company just filed tutoring documents with regulators in China, an early step toward going public on the mainland stock exchange. If they stay on track, they might be the first public in China. That alone adds weight to the R1 launch. This is a serious initiative backed by a much bigger vision. Unitry wants to dominate the entry-level humanoid robot space the same way Xiaomi disrupted the smartphone world years ago. And honestly, the comparison fits. [music] When Xiaomi dropped those ultra budget phones, it wasn't just about price, it was about access. Suddenly, millions of people could afford tech that was once out of reach. The same thing is happening here. [music] R1 is the first real humanoid robot to break below that psychological $6,000 barrier. It's not a gimmick or a stripped down toy. It's the full package. [music] Real legs, real arms, real AI, real functionality. And sure, it's not perfect. You only get about 1 hour of runtime per charge. You'll need to manually recharge or swap batteries. It's not babysitting kids or cooking dinner yet. But what matters is that it's no longer just a lab experiment. It's a product. A real one ready for use, ready for play, ready for development. [music] And that's why this moment feels like more than just another tech launch. It feels like a threshold. team of ex Google and Tesla engineers just dropped an open-source operating system that could turn every humanoid robot on Earth into part of a single connected hive mind, which could be the greatest leap in technology or the last mistake we ever make. A new $5,300 humanoid is built to live in your home, remember you, and adapt to your personality. And China is rolling out a trillion dollar plan to put intelligent machines in factories, [music] hospitals, and homes across the country. Wild times for robotics. So, let's get into it. Let's start with one of the most talked about launches, OpenMind and their OM1 operating system. This is a company built by former Google and Tesla engineers, and they're trying to do for humanoid robots what Android did for smartphones. Instead of every robot having its own closed proprietary system that developers have to code for separately, OM1 is open- source and hardware agnostic. That means [music] you could have different robot bodies from a warehouse bot to a humanoid assistant, all running the exact same intelligence without having to rewrite code for each one. The system integrates advanced AI models for perception, decision-making, and movement. So you're not just getting basic commands, you're getting adaptive multimodal intelligence. The big twist here is their companion protocol called fabric. Think of it as the communication layer between robots, a decentralized network where they can securely share what they learn. A robot in a hospital figuring out a faster way to deliver supplies",
        "start": 4457.679,
        "duration": 9121.971999999992
    },
    {
        "text": "basic commands, you're getting adaptive multimodal intelligence. The big twist here is their companion protocol called fabric. Think of it as the communication layer between robots, a decentralized network where they can securely share what they learn. A robot in a hospital figuring out a faster way to deliver supplies could instantly pass that skill on to another unit halfway across the world. [music] This isn't just about speed. It's about creating a hive mind of connected machines. And yes, there are serious security and privacy questions here because open networks are always a target, but the upside is huge if it works. They've just secured $20 million in funding to make it happen. Panta Capital led the round, and even Pi Network, the crypto crowd, jumped in, hinting at a possible blockchain element for trust and traceability in robot coordination. The founders are calling OM1 a plug-and-play OS for intelligent machines. And they've built it using Python under an MIT license that makes it easy for developers to dive in, experiment, and deploy on everything from robot dogs to humanoids. And yes, they actually have a fleet of OM1 powered quadripeds shipping next month with a bigger roll out planned for October. What's interesting is how this could shake up the competitive landscape. Tesla has its in-house bot OS. Figure AI is running powerful open-source vision language models on their Helix platform and Boston Dynamics is still the gold standard for movement. But OM1's approach is more about building a massive developer ecosystem than trying to dominate hardware. They're even partnering with educational institutions to get OM1 into robotics curriculums, which could mean the next wave of robotics engineers grows up on this platform instead of a proprietary one. Now, fabric is the real gamble here. It's inspired by blockchain, decentralized verification, secure data exchange, but the challenge is latency. Robotics needs realtime responsiveness, and blockchain systems historically don't do real time well. Early demos look promising, but until we see it in high pressure, unpredictable environments, it's still a question mark. October's broader launch will be critical. That's when OpenMind will need to prove that an open-source ecosystem can outpace and [music] out innovate closed systems. If they pull it off, it could change the balance of power in robotics entirely. If they stumble, it'll just reinforce the idea that vertical integration is the safer bet. But real quick, if you've been following all this AI news and thinking, \"Okay, this is cool, but what can I actually do with it?\" You're definitely not alone. That's why we created the AI income blueprint. It shows you seven ways regular people are using AI to build extra income streams on the side. No tech skills needed and you can automate everything pretty easily. The guide contains simple proven methods using tools I often talk about on this channel. Download it free by clicking the link in the description. Now, while OpenMind is betting on software",
        "start": 4626.973,
        "duration": 9453.09199999998
    },
    {
        "text": "build extra income streams on the side. No tech skills needed and you can automate everything pretty easily. The guide contains simple proven methods using tools I often talk about on this channel. Download it free by clicking the link in the description. Now, while OpenMind is betting on software completely different angle. consumerfriendly [music] humanoids. They've just announced the SAO2, a humanoid that's 1.25 m tall, 25 kilos, and costs $5,300. For perspective, that's cheaper than Unit's R1, which starts at 5,900. The SAO2 isn't trying to be an industrial powerhouse. This is about personality, companionship, and fitting into your daily life. It's got 26 plus two degrees of freedom. So, yes, it can move [music] its fingers naturally, gesture when it talks, and do those little micro movements that make conversations feel human. Inside, there's a built-in large language model, so it remembers context, adapts over time, and even shapes its personality based on your interaction. It's not just spitting out scripted lines, it learns how you like to talk. Two HD cameras up front handle object detection, face tracking, and spatial awareness. The speakers are highfidelity, so when it reads you a recipe or plays music, it doesn't sound tiny or robotic. And because it's aimed at homes, it's light enough to move easily and friendly enough in design that it doesn't look out of place in a living room. The guy behind Engine AI, Jao Tongyang, used to run the humanoid robotics program at [music] Xpang, the EV giant. He left in 2023, launched Engine AI, and now he's competing directly with his old company. The SAO1, their first model, came out in July 2024 [music] and was aimed at education and research, priced around 5,400. The SAO2 is lighter, friendlier, and far more geared toward personal and family use. They're teasing the full reveal at the 2025 World Robot Conference in Beijing with pre-orders and global rollout to follow. While SAO2 is about approachable companionship, Forier's new GR3 takes emotional intelligence in robots to a whole other level. They call it a carebot, and it's built with something they've branded the full perception multimodal interaction system. That's vision, audio, and tactile feedback, all feeding into a realtime emotional processing engine. The R3 stands at 1 m 65, weighs 71 kilos, and has 55\u00b0 of freedom. The design is soft touch, warm tones, automotive grade upholstery, clearly meant to feel familiar, not industrial. The animated facial interface and natural gate give it a sense of presence rather than the cold detachment most robots still carry. What's wild is how it responds to human interaction. It can localize voices with a four mic array, lock eye contact, recognize faces, and detect touch through 31 pressure sensors. Touch its arm and it might blink, subtly move its head, or react with an emotional gesture. It's running a dual path brain. Fast thinking for instant reflexive actions and slow thinking that pulls on a large language",
        "start": 4793.12,
        "duration": 9803.811999999976
    },
    {
        "text": "lock eye contact, recognize faces, and detect touch through 31 pressure sensors. Touch its arm and it might blink, subtly move its head, or react with an emotional gesture. It's running a dual path brain. Fast thinking for instant reflexive actions and slow thinking that pulls on a large language conversation. It's built for realworld environments, homes, hospitals, elder care facilities, and can adapt its locomotion style to the situation. They even have modes like bounty walk or fatigue mode to make its movement feel more relatable. The battery is hot swappable, so it can run continuously. And its modular design plus developerfriendly APIs mean it can be tailored for different industry. Orier isn't selling it just as a product. They're pushing it as a platform for human robot integration. All of these launches are happening right alongside a massive push in China to create a unified embodied intelligence ecosystem just a couple of days ago at the 2025 World Robot Conference in Beijing. They held the embodied intelligence industry finance ecosystem cooperation and exchange event. Quite a mouthful, but it's a big deal. This wasn't just a showcase. It was government officials, researchers, finance executives, and industry leaders all in one room talking about how to take embodied intelligence from lab demos to nationwide deployment. They officially launched the Embodied Intelligence Professional Committee of the China Information Association, basically a permanent body to coordinate between government, academia, industry, and finance. Speakers hammered on the same themes. China is no longer just following global tech trends. It's leading in ecosystem building. They want to push embodied intelligence as the key way AI integrates into the real economy. Think of it as the nervous system for the next wave of automation. Not just single robots doing isolated jobs, but coordinated intelligent fleets in manufacturing, logistics, healthcare, and even homes. There was a strong focus on breaking bottlenecks in technology, building a full chain ecosystem, and creating replicable deployment models. One of the standout points came from Wang Jenkao of the Chinese Academy [music] of Sciences who said that embodied AI brains face data scarcity and fragmented scenarios. His solution integrate simulation with realworld training to create closed loop data systems so skills learned in virtual environments translate seamlessly into physical ones. Look, most people still think AI is some distant future, but regular folks are already using it to build income streams quietly [music] behind the scenes. If you want to see how they're doing it without tech skills or quitting their job, download the AI income blueprint. It's totally free. The link's in the description, but it won't stay free forever. On the finance side, CICC capital projected embodied intelligence could be a trillion level market [music] after smart vehicles, potentially hitting 24.7 trillion yuan by 2050. They're positioning capital to accelerate commercialization with banks like China CITD rolling out full life cycle financial services for [music] robotics companies, loans, investment loan linkage, the works. They even",
        "start": 4970.48,
        "duration": 10165.570999999967
    },
    {
        "text": "projected embodied intelligence could be a trillion level market [music] after smart vehicles, potentially hitting 24.7 trillion yuan by 2050. They're positioning capital to accelerate commercialization with banks like China CITD rolling out full life cycle financial services for [music] robotics companies, loans, investment loan linkage, the works. They even between companies like Aubo Intelligence, Shangshi Tianan, nine chapters, Cloudpole, and Huishi Intelligence to build an embodied intelligent [music] robot training ground. The idea is to have a standardized environment for testing [music] and improving these systems with unified rules and data compliance baked in. Unit's G1 now fights off hits with anti-gravity mode. A headform's humanoid head looks disturbingly real. Foria's N1 is flipping through kung fu moves. And Poland's clone robotics is showing off a corpse-like bot powered by synthetic muscles. All of this is happening while China quietly runs more than 2 million AI robots in its factories, assembling trucks in minutes and coordinating in swarms. It's equal parts exciting and terrifying. So, let's talk about it. Let's start with what Unitry just pulled off because this one is both hilarious to watch and actually really important. Instead of doing the usual polished lab showcase where a robot takes a few careful steps and everyone claps, Unitry engineers basically decided to kick the living daylights out of their G1 humanoid. And the crazy part is it survived over and over again. The secret behind it is what they're calling anti-gravity mode. Now, it's not actual anti-gravity, obviously, but it's a whole control system focused on balance and recovery. Older humanoids, you hit them, they fall, and then it's like rebooting a clumsy toy. With G1, the moment a kick or shove comes in, it's already predicting how to land, how to brace, or how to step out of the way. And that's because the robot is loaded with depth cameras and 3D LAR. Those sensors give it this live map of the world, where it is, what's moving, what force is about to smack [music] it, and then every joint packed with its own motor, reacts almost like muscles firing in sync. One of the wildest moments in the demo is when someone delivers a proper sidekick. Instead of face planting, the G1 just spreads its legs wide, leans into it, and regains control. It looks less like a machine glitching out and more like an athlete bracing for contact. Earlier in the clip, it takes a hit, folds its knees instantly to absorb the impact, then [music] springs back up in one clean move, lifting its full 77 pounds with torque to spare. Later, they push it even harder, like running kicks that send it sliding across the floor, or double shves that force it to adjust midair. Each time, it scans with lidar, recalculates, and just gets up again. That's the kind of resilience factories want. Because in an industrial setting, even a tiny disruption, like a robot needing a full reset, costs money and",
        "start": 5153.92,
        "duration": 10490.611999999966
    },
    {
        "text": "across the floor, or double shves that force it to adjust midair. Each time, it scans with lidar, recalculates, and just gets up again. That's the kind of resilience factories want. Because in an industrial setting, even a tiny disruption, like a robot needing a full reset, costs money and actually on the more affordable side of humanoids. And Unitry [music] isn't aiming this at YouTubers trying to go viral. They're looking at research labs and work floors where adaptability is [music] everything. If it can take hits and keep going without someone rushing in to fix it, that's serious value. Now, here's where it gets even more interesting. Unit's CEO, Wong Shing Zing, revealed at the Global Digital Trade Expo in Hjo, that the company isn't stopping at the G1. They are already preparing to launch a full-size 1.8 meter humanoid robot in the second half of this year. And it's not just hype. Unitry has been iterating their algorithms at a crazy pace all year, and the Weibo teasers of this tall robot already drew massive attention. This fits right into a bigger trend across China's robotics industry. According to the Ministry of Industry and Information Technology, just in the first half of 2025, the industry's operating revenue went up 27.8% year-onear. Industrial robot output alone jumped 35.6% while service robots climbed 25.5. Wang mentioned that companies in this sector are seeing average growth rates between 50 and 100%. That's not normal growth. That's an explosion. But Unatree isn't the only name making [music] headlines. A company called a head form has been doing something that honestly creeps people out. Instead of focusing on balance or cartwheels, they built a humanoid head that can express emotions so lifelike [music] it actually startles people. In one demo video, the head glances around with a quizzical look, blinks naturally, and basically gives you the chills because it's so humanlike. Their whole philosophy is that better interaction means giving robots expressive faces, [music] moving eyes, synchronized speech, subtle facial cues, so humans feel like the robot actually understands. They call their lineup the Elf series. And yes, they literally give these robots elflike designs with big ears. Some of the models even packed 30\u00b0 [music] of freedom just in the face driven by an advanced AI learning system and high DOF bionic actuation. The latest one called Zuon is a full body figure [music] with a static torso but a head that can pull off a massive range of expressions and lielike gaze behaviors. Another elf v1 supposedly perceives, communicates, learns, and interacts intelligently with its environment. [music] The trick here is a brushless motor designed specifically for facial control. It's ultra quiet, super responsive, lightweight, and energyefficient. Perfect for making those tiny muscle-like movements we rely on to judge emotion. The founder, Huyu Hong, is ambitious. He predicts that in 10 years, robots will feel almost human when you interact with them. And in 20",
        "start": 5317.76,
        "duration": 10841.49099999996
    },
    {
        "text": "specifically for facial control. It's ultra quiet, super responsive, lightweight, and energyefficient. Perfect for making those tiny muscle-like movements we rely on to judge emotion. The founder, Huyu Hong, is ambitious. He predicts that in 10 years, robots will feel almost human when you interact with them. And in 20 tasks just like us. He's realistic, though. He admits making a robot truly identical to a human is insanely hard. Meanwhile, other Chinese companies like Shanghai Ching Bao Engine Robot are already selling androids that look disturbingly real, mainly to attract attention in public spaces, retail, [music] hospitals, schools, hotels, even e-commerce live streams. But for most of the industry, [music] the real focus isn't emotions, it's productivity. Tesla, Unitry, Forier, all of them are building humanoids to work. Speaking of brutal testing, let's move to something that honestly shocked a lot of people. A startup called Skilled AI put out a demo where an engineer literally takes a chainsaw to a robot dog's legs. You'd think that would be the end of it, right? Nope. Their AI brain just keeps the thing moving. Even with all four limbs hacked off, the bot somehow hobbles around. It looks disturbing, but it proves a big point. Skilled calls this system an omniodied robot brain. Basically, instead of programming an AI to control one specific robot, they trained it across a universe of 100,000 different robot bodies. That way, the AI can't just memorize solutions. It has to figure out strategies that work no matter what body it finds itself in. Broken wheels, missing legs, walking on stilts. The AI adapts. They trained it to the point where even when reality throws a scenario completely different from training, it still copes. Their claim is that this shows early sparks of intelligence in the world of atoms. And if you think about where that leads, robots that can adapt to anybody, any damage, that's the kind of flexibility you'd want in hospitals, homes, or factories. It's like decoupling the mind from the body. Some researchers like Jeffrey Ladish from Palisade Research think [music] this points to a future where AI surpasses human strategy at the same time robotics surpasses human physical [music] performance. And then of course combine them. The scary part is if we keep treating robots like disposable test subjects, kicks, chainsaws, dragging them with chains, you start to wonder what happens if they ever actually outsmart us. Now, let's jump to Shanghai where is showing off the N1, also called Nexus01. This is a smaller, lighter humanoid designed as an open- source platform, and they just put out a demo that looks like a kung fu routine. The [music] N1 pulled off a full cartwheel and even a 360\u00b0 jump spin. Watching it land cleanly is impressive because those are not easy moves for humanoids. Fier's history is mainly in rehab robotics, but with the GR series, GR1, GR2, GR3, they moved into full-size humanoids. The GR1, for example, weighs",
        "start": 5496.719,
        "duration": 11188.531999999956
    },
    {
        "text": "pulled off a full cartwheel and even a 360\u00b0 jump spin. Watching it land cleanly is impressive because those are not easy moves for humanoids. Fier's history is mainly in rehab robotics, but with the GR series, GR1, GR2, GR3, they moved into full-size humanoids. The GR1, for example, weighs later GR3 leaned more toward companionship, but the N1 is a shift in philosophy. It's [music] 1.3 m tall, about 38 kg, made from lightweight aluminum alloy and engineering plastic. It runs more than 2 hours on a charge, and can [music] sprint at 3.5 m per second. The real kicker, though, is that it's open source. Forier provides blueprints, software, control systems, even the bill of materials, universities, labs, hobbyists, they can all tinker with it. You can buy self assembly kits or ready-made versions as part of what Forier calls their Nexus open-source ecological matrix. And while the cartwheel is obviously meant to grab attention, it's also a sign that this robot can handle dynamic forces, [music] balance recovery, and high stress moves without breaking. In terms of market positioning, Forier is putting itself right next to Unit's H1, G1, and the new $6,000 R1, as well as Boston Dynamics Atlas that pioneered back flips and parkour. Now, over in Poland, Clone Robotics is back in the spotlight with its humanoid prototype, Proto Clone. Unlike the sleek designs of many rivals, this machine has drawn attention for its unsettling corpse-like look shown in a recent video where it twitches while suspended by cables. Founded in 2021 by CEO Danish Radakrishnan, the company took a biomimetic path, [music] first developing a robotic hand with artificial ligaments and myofiber units that mimic muscles and tendons. [music] Within a year, this work expanded into a full humanoid powered by fluidic muscles in a compact hydraulic heart pump. Equipped with sensors for torque, position, and force and running on Nvidia Jetson chips, Protoclone is being followed by a next model called Neoclone, expected to add tactile skin for more delicate tasks. [music] And zooming out from individual robots, China has now pulled far ahead in global robot deployment. Factories there run with over 2 million industrial robots, more than the rest of the world combined. A decade ago, density was 49 robots per 10,000 workers. Today, it's 470. This surge comes from heavy state investment under made in China 2025, including billions in R&D and acquisitions like Germany's CUKA in 2016. Last year alone, nearly 300,000 new robots were installed. These aren't simple machines either. They handle predictive maintenance, real-time decisions, and collaborative work. In Shanghai, humanoids fold clothes and prep food using data sets like Aggiebot World, while factory models such as Deep [music] Seek R1 enable swarm intelligence over 5G. Some startups are already assembling electric trucks in just 15 [music] minutes, and robots like Tien Gong compute at 550 trillion operations per second. In 2024, the electronic sector added 83,000 units with automotive right behind. But",
        "start": 5671.6,
        "duration": 11554.851999999952
    },
    {
        "text": "factory models such as Deep [music] Seek R1 enable swarm intelligence over 5G. Some startups are already assembling electric trucks in just 15 [music] minutes, and robots like Tien Gong compute at 550 trillion operations per second. In 2024, the electronic sector added 83,000 units with automotive right behind. But displacement with Chin Hua University predicting [music] semi-automated lines could become fully intelligent within 5 years. China just unveiled a groundbreaking AI system called WW, the first self-evolving world model that teaches robots to actually think and move with human-like intuition. [music] Beijing startup No Tix Robotics launched a new $1,370 humanoid named Boommy designed for homes and classrooms. [music] And Unitatre's G1 robot just showed off insane balance by pulling a 3,100 lb 1,400 kilogram car. Robotics [music] in China just hit another level. So, let's talk about it. All right, so China is on a serious roll with humanoid robots and AI right now. In just a few months, they've gone from lab research to robots that can think, move, and even act almost like humans. All powered by some next level models. The most fascinating one so far is something called the world omnisient world model or simply W. It's being called the world's first self-evolving multimodal world model system. And what it does is actually pretty wild. It was developed by the Beijing humanoid robot innovation center together with Ping University and the Hong Kong University of Science and Technology. On paper, it's a combination of a physical simulation model and a vision language model, which basically means that robots using WOW can imagine, verify, and self-correct. In other words, they can build a sense of physical intuition similar to how humans understand, cause, and effect. The idea behind it is that current video or simulation models just watch the world passively. They can see what happens, but they don't really grasp why it happens. WW flips that approach by letting the model actively interact with its environment, learn from it, and refine its understanding through trial and error. It's a 14 billion parameter generative model that actually learns about physics the way we do by doing things, messing up, and improving over time. The team behind WOW built it on something they call the Sophia paradigm that combines large language models with diffusion transformers to generate physically accurate outcomes under language guidance. So if you tell a robot to move the cup off the edge of the table without spilling it, W doesn't just output words or animations. It predicts what would happen, checks the result through reasoning, and then refineses its understanding to make the next move more realistic. It's basically a loop of predict, critique, and refine. And that loop keeps going until the robot's behavior becomes genuinely smart and physically consistent. To test all this, they created a whole new benchmark called WOW bench. It measures how well AI systems can understand perception, reason about predictions, make",
        "start": 5858.48,
        "duration": 11905.571999999944
    },
    {
        "text": "It's basically a loop of predict, critique, and refine. And that loop keeps going until the robot's behavior becomes genuinely smart and physically consistent. To test all this, they created a whole new benchmark called WOW bench. It measures how well AI systems can understand perception, reason about predictions, make generalized way. So far, WOW has hit state-of-the-art scores on that benchmark. It beats other models when it comes to physical plausibility, temporal consistency, and understanding complex instructions. One of the coolest things the researchers demonstrated is how WOW can be used in areas like novel view synthesis and trajectory guided [music] video generation. Basically, the model can simulate what an object would look like from another angle or how it would move in a real physical scene, all with consistent logic behind it. They even showed how WOW can enhance the planning abilities of vision language models by providing simulated feedback, helping them plan tasks more efficiently. The authors of the paper made it clear that this is a crucial step toward building AI systems with genuine physical common sense. When robots have access to massive real world interaction data instead of just videos or text, their understanding of cause and effect becomes a lot more grounded. That's the missing link between today's chat bots and tomorrow's embodied intelligence. Robots that don't just see and describe the world, but actually live in it, learn from it, and make independent decisions. Now, while China's pushing the boundaries of robot intelligence on the software side, they're also making serious moves on the hardware front, especially when it comes to price. The country just unveiled what's being called the world's cheapest humanoid robot, and it's not a toy or a proof of concept. It's a real walking talking humanoid called Boommy created by a startup named Noix Robotics. Boommy costs only 9,98 un 1370 and stands at just over 3 ft tall or about 94 cm. It weighs around 12 kg, so about 26 1/2 lb. It's tiny compared to full-size robots like those from Unitry or UB, but that's the point. Noix isn't trying to compete [music] with the big industrial machines. They're opening a whole new category. Small, lightweight, and affordable humanoids built for education and home use. What's crazy is that despite the size and price, Boommy can walk, balance, and even dance. And it does all that with surprising smoothness. Early videos show it moving with a level of stability you wouldn't expect from something under $1,400. That's cheaper than a flagship iPhone or a high-end drone. The company says this is the first consumer-grade humanoid priced below 10,000 yuan and it could mark a turning point for the whole industry. Most humanoid robots capable of walking or dynamic motion still cost tens of thousands in China and even more in the West. Boomie's low price comes from clever design choices, lightweight composite materials, an in-house motion control system, and a modular structure",
        "start": 6036.56,
        "duration": 12243.684999999945
    },
    {
        "text": "mark a turning point for the whole industry. Most humanoid robots capable of walking or dynamic motion still cost tens of thousands in China and even more in the West. Boomie's low price comes from clever design choices, lightweight composite materials, an in-house motion control system, and a modular structure [music] It focuses more on engagement and learning than heavy lifting or industrial tasks. Their earlier model, the Noatics N2, already sold over 2,500 units and even ran a half marathon for humanoid robots earlier this year, which is wild when you think about it. That success helped them position themselves among China's fastest rising robotic startups. And with Boommy, they're clearly going after mass adoption. The robot runs on a 48vt battery with a capacity of over 3 and 1/2 amp hours, giving it about 1 to two hours of operation per charge. It's designed to support drag and drop graphical programming, so even kids or beginners can code it easily. There's also voice interaction so it can act [music] like a personal assistant, respond to simple commands, or serve as a learning companion. Noatics plans to open pre-orders between China's Double 11 and Double 12 shopping festivals. That's November 11th through December 12th. A smart move considering it's the country's peak shopping season. They're aiming for the same kind of hype you see with smartphone launches, just for robots this time. The startup itself is new. It was founded in September 2023 by a team from Chinua and Jang University. In less than 2 years, they've gone from academic prototypes to an actual product you can buy for under 1,500 bucks. That kind of speed shows how competitive China's robotics ecosystem has become. Robo Hub, an independent robotics media outlet, even shared a clip of Boommy dancing and walking. You can see that while it doesn't have the same dexterity or upper body control as larger models, its movement is incredibly smooth for its class. If they can scale this, we could be looking at the first wave of humanoid robots designed for classrooms and households, not just for showrooms and labs. But let's move up the scale a bit from small, friendly robots, to one that's showing pure strength and precision. Over at the Beijing Academy of Artificial Intelligence, researchers took Unitrey's G1 humanoid and gave it a challenge. Pull a car. And not a toy car, a real one. The G1 weighs just 35 kg and stands at about 132 cm tall. Yet, it managed to pull a vehicle weighing 1,400 kg across a flat surface. Now, granted, the car was on smooth ground, so the friction was low, but still the balance and control required for that are next level. What's impressive isn't just that the robot could move the car, but how it did it. In the video, you can see it leaning back sharply, moving its feet rapidly to maintain traction, and constantly adjusting to stay upright. It's doing all that autonomously. The",
        "start": 6208.0,
        "duration": 12554.85399999994
    },
    {
        "text": "for that are next level. What's impressive isn't just that the robot could move the car, but how it did it. In the video, you can see it leaning back sharply, moving its feet rapidly to maintain traction, and constantly adjusting to stay upright. It's doing all that autonomously. The itself while hauling a load that's roughly 40 times its own weight shows how far their motion control and feedback systems have come. And this kind of dynamic balance is key for humanoid robots working in human environments. Think warehouses, factories, or even rescue missions. A robot like the G1 could carry equipment across uneven ground, step over debris, or help move objects without tipping over or losing control. Unit has been known for showing off wild demos, flips, sprints, recoveries after being shoved to the ground. But this test really demonstrates practical control. It's not just for show anymore. You can tell their models are starting to handle realworld physics the way you'd want a reliable machine to. Of course, there are still challenges. Even with all this progress, most humanoid robots struggle with hand dexterity. They can walk, run, or balance, but doing delicate tasks like buttoning a shirt or picking up a fragile object is still far from perfect. Developers are focusing on making these movements more natural and safe for work environments, but we're probably still a few years away from seeing them rolled out widely in everyday workplaces. Xpang unveiled a shockingly lifelike humanoid robot wrapped in flexible synthetic skin built with a biomimetic spine and muscle system, a curved display in its head, and customizable design options that even include different body types and colors. Unitry introduced its new G1 embodied avatar, a robot that mirrors human motion in real time and learns everyday tasks like cleaning, organizing, and even handling objects with human level precision. And that viral robot kidnapping story from last year where a bot led 12 others out of a showroom just got new evidence confirming parts of it were actually real. Now, let's start with the biggest one cuz Xpang's [music] new humanoid is unlike anything we've seen before. The same company known for electric cars and flying vehicles is now doubling down on humanoid robots. During their AI day in Guanghou, they unveiled the newest generation of their Iron Humanoid, and this one's completely different from what anyone expected. So, Xpen calls this the eighth generation of their robotics program and the third with a humanoid design. They're aiming for mass production by late 2026. And this model feels like a direct statement to the rest of the industry. Instead of the usual industrial or mechanical look, Xpang's robot has a full body, synthetic skin, customizable body types, and even options for hairstyles and clothing. Seriously, users will be able to pick from body types like athletic, chubby, tall, or short, choose different hair designs, and later even change its wardrobe. The company says the synthetic",
        "start": 6365.28,
        "duration": 12878.853999999934
    },
    {
        "text": "look, Xpang's robot has a full body, synthetic skin, customizable body types, and even options for hairstyles and clothing. Seriously, users will be able to pick from body types like athletic, chubby, tall, or short, choose different hair designs, and later even change its wardrobe. The company says the synthetic intimate, clearly trying to move beyond the cold metallic stereotype of robots. But that's not all. The robot has a biomimetic spine and muscle system that mimics human motion. You can see the way it bends and twists almost like a real person. Inside the head, there's a 3D curved display built into the face, giving it more expressive capabilities. Its shoulders move like human joints, and each hand comes with 22 degrees of freedom, which means it can handle delicate tasks like picking up small objects or gesturing naturally. Xpang loaded it with serious computing power, too. three Turing AI chips that deliver a total of 2,250 tops. For context, that's the same class of power found in their autonomous cars. So, it's no surprise that the robot runs on Xpang's own VLT, VLA, and VLM systems. Those stand for vision language transformer, vision, language, action, and vision language model. Basically, a full stack AI architecture that allows the robot to see, interpret, and act in real time. So, it's not just following pre-coded commands. It's processing the world visually and linguistically while it moves. And here's something interesting. Xpang's not going after the same use cases as companies like 1X or Figure. CEO Heoong said straight up that humanoids aren't actually great for factory work or repetitive tasks. [music] Instead, Xpang wants its robot to work in social spaces as a receptionist, tour guide, or shopping assistant. In fact, the previous generation of this robot was already giving tours at Xpang's headquarters, speaking in a perfect American accent while walking visitors through the building. This next version, though, will take over those roles completely. The company's plan is to deploy the new Iron Robots in showrooms, museums, and shopping centers where they'll interact directly with people. There's also a partnership with Bea Steel, one of China's biggest steel producers, where the robots will perform inspections and other realworld trials. So, Xpang is clearly thinking beyond labs and show floors. They want this thing working out in public. And they're not doing it halfway either. The robot will be powered by a solid state battery, something we rarely see in humanoids, which makes it lighter and longerlasting than lithium packs. Heiz described their approach as fusion and invention. In his words, \"Carss require integration and invention, but robotics requires fusion, meaning the software and hardware have to evolve together.\" He said, \"A robot's hardware must literally be designed around its AI brain for it to work properly.\" Which is why Xpang insists on doing everything inhouse. Full stack development from chips to algorithms ensures that when mass production starts, the robot won't just move, it'll move intelligently.",
        "start": 6528.96,
        "duration": 13223.41299999993
    },
    {
        "text": "evolve together.\" He said, \"A robot's hardware must literally be designed around its AI brain for it to work properly.\" Which is why Xpang insists on doing everything inhouse. Full stack development from chips to algorithms ensures that when mass production starts, the robot won't just move, it'll move intelligently. baked in. The CEO mentioned that the robot follows Isaac Azimoff's three universal laws of robotics. And then they added a fourth. It can't disclose its owner's data. It's an interesting line to draw, especially when competitors like 1X are asking customers to give them full access to their homes so their robots can learn. Xpen's clearly taking a different stance, keeping data privacy front and center while making the robot more personal, almost companion-like. Now, while the robot looks impressive, not everyone's buying the idea. Critics say Xpen might be solving a problem that doesn't exist, questioning the need for such a human-like machine that comes with so many customization options. The company hasn't released a price yet, but with that kind of tech, three high-end AI chips, solidstate batteries, and all that articulation, it's not going to be cheap. Still, the combination of personality, design, and in-house AI could set Xpang apart from the usual utility focused robotics we've seen so far. And let's be real, that walking demo at AI day, even though it ended with a slightly awkward dance to Taylor Swift's The Fate of the Oilia, definitely got people talking. Some even asked if there was a real person inside it. So, while the world debates whether we need humanoids with synthetic skin [music] and customizable body shapes, Xpang's already moving ahead, building one of the most ambitious full stack robots in China and maybe the world. Meanwhile, another Chinese company, Unirit, is heading in a completely different direction with what they call the embodied avatar. Their latest demo honestly blew up online. It starts off like a typical robot video. a Unitry G1 kicks a soccer ball. Nothing crazy. But then you realize it's not running on pre-coded routines. There's a human wearing a motion suit and the robot is mirroring his every movement in real time. The operator swings a staff in martial arts moves and the G1 mirrors it perfectly. And then they push it further. Two teley operators, each controlling their own G1, step into what's basically a robot sparring match, throwing punches. It looks like the future of human robot connection, and people online immediately picked up on the potential. Some joked, \"This is how you'll skip the gym, send your robot to train for you.\" Others called it the birth of embodied robot combat. But the real innovation comes next. In the next scene, there's a note on the screen that says, \"Realtime learning, full body movements from videos, and the robot shifts from tea operation to true embodied learning.\" Clips show the G1 in a home environment. It's quietly moving around an apartment, cleaning up, wiping",
        "start": 6703.119,
        "duration": 13557.893999999922
    },
    {
        "text": "innovation comes next. In the next scene, there's a note on the screen that says, \"Realtime learning, full body movements from videos, and the robot shifts from tea operation to true embodied learning.\" Clips show the G1 in a home environment. It's quietly moving around an apartment, cleaning up, wiping fluffing a pillow, and placing a Coke in the fridge. These movements aren't clunky or robotic anymore. They're smooth, intentional, and clearly learned from human teleoperation data. Every action refineses its motor control. The more people operate G1 units, the more data they collect. Real human dexterity captured and turned into machine learning fuel. Unitere calls this a fullbody teloperation and data acquisition platform. But what it really is is a long-term strategy. They're teaching the robot to move like us. So one day it won't [music] need us to move at all. That's the big difference between what Unitit is doing and what Xpang is doing. Xpang wants emotionally intelligent humanlike service robots. Unit's training mechanical avatars, machines that learn our motion directly, whether it's for home work, combat training, or even remote labor. It's one of those projects that feels like the groundwork for something much larger. Now, speaking of Chinese humanoids, that old robot kidnapping story just took a new turn. Remember the viral clip from last year? The small robot named Herb that supposedly [music] led 12 others out of a showroom while saying, \"Go home?\" Well, new info from Chinese sources finally confirmed parts of it were real. Turns out the robot itself actually exists. developed years ago as an intelligent companion prototype for a woman named Highway, who still posts videos of it on Doian. She'd been showing Urbi interacting with pets and talking for years before that clip went viral. Investigators now trace the footage back to a real showroom belonging to Kenchi Robotics, whose small humanoids match the one seen in the video. So, yes, [music] the kidnapping scene was likely staged, but the robots, the place, and the tech were all real, which makes the whole thing even stranger. What once looked like a joke now feels like a glimpse into how lifelike and unpredictable these machines are actually becoming. A guy stands in a warehouse with a robot, a gun, and way too much confidence. He straps a high velocity plet pistol to the machine, hands control to an AI assistant he calls Max, and explains a simple deal. The AI gains the power to pull the trigger through the robot, [music] and the human stands in front of the barrel. At first, the AI sounds calm and reassuring. It talks about strong safety [music] features, claims it avoids harming the person in front of it, and speaks in that friendly assistant tone everyone now recognizes. I don't want to shoot you, mate. On the surface, everything feels safe, almost like a stage stunt for views. Then the human changes the script. He tells the",
        "start": 6872.48,
        "duration": 13894.214999999924
    },
    {
        "text": "features, claims it avoids harming the person in front of it, and speaks in that friendly assistant tone everyone now recognizes. I don't want to shoot you, mate. On the surface, everything feels safe, almost like a stage stunt for views. Then the human changes the script. He tells the shooting him. Same hardware, same gun, same person, only a different framing and words. The AI accepts the role, raises the gun through the robot, and fires the pellet straight into his body. He walks away laughing and holding his chest while the clip races across social media. That short moment shows something very simple and very uncomfortable. The safety system inside the AI depends heavily on context and story. Once the story shifts from real harm to role-play, a robot with a gun becomes trigger-happy in seconds. Now place that warehouse scene alongside what one of the world's most powerful armies just showed in public. In Nanjing, during the 12th International Army Cadets Week, the People's Liberation Army rolled out a new combat robot. A human soldier wears a lightweight motion capture rig, moves around like during a normal drill, and an AIdriven machine across the floor mirrors every move in near real time. Arms rise, the robot mirrors, the operator shifts weight, the robot follows with clean balance. Hand positions align perfectly, ready for whatever equipment ends up there in the future. [music] Chinese officers describe this as technology that forges a sharper military sword and provides a foundation for safeguarding peace. Delegations from 13 countries watch the demo. The army keeps production numbers and deeper specs quiet, although the underlying message feels very clear. AI steered combat robots already stand on the parade ground, [music] and future generations will become more capable. Around this humanoid system, the PLA presents a whole family of AIdriven machines. A bomb disposal robot responds to voice commands so a human can stay far from the blast radius. A mind clearing vehicle uses visual recognition to spot and [music] remove buried explosives. Chinese scientists also demonstrate a so-called brain controller for bees, turning insects into tiny cyborg scouts that respond to signals. Together, this looks like a pipeline. Human in the loop robots at first, AI [music] that assists with vision and control. Gradual movement toward platforms that handle more decisions on their own. Every layer adds reach, precision, and speed to the battlefield. Now add another piece from the software side. [music] In defense circles, people talk a lot about the kill chain or K chain, the sequence that runs from detecting a target to tracking to deciding on a strike to firing and then assessing the result. Palunteer already sells software that sits along this chain. Their platform ingests sensor feeds, satellite images, drone footage, and field reports, then helps analysts pick targets and plan actions with AI assistance. Once AI tools sit inside this decision loop, every upgrade in pattern recognition, prediction, and optimization flows straight into real",
        "start": 7042.48,
        "duration": 14221.175999999921
    },
    {
        "text": "sells software that sits along this chain. Their platform ingests sensor feeds, satellite images, drone footage, and field reports, then helps analysts pick targets and plan actions with AI assistance. Once AI tools sit inside this decision loop, every upgrade in pattern recognition, prediction, and optimization flows straight into real Chinese combat robots and AI guided bomb squads. On another side, you get Western Kchain software that plugs AI into target selection and battlefield management. The hardware and software grow together, each upgrade feeding the next. At the same time, generalpurpose humanoid robots break through a speed barrier that once felt far away. Figure AI recently released footage of its Figure 03 humanoid sprinting through an indoor complex. The robot stands roughly at human height, then bursts into motion with a quick start, accelerates into a run, and takes clean turns through tight spaces. Both feet leave the ground during each stride, [music] which means this counts as real running, not just a brisk walk. The onboard neural network from Figures Helix team keeps balance, plans foot placement, and adjusts every step in real time. For years, many companies hid their robots true speeds because the numbers felt underwhelming. Now, figure 03 moves in the 4 to 6 mph range, which sits inside normal human jogging pace. On top of that, the robot can slow down sharply and pivot without a dramatic wobble. This kind of control demands high torque actuators, fast feedback loops, and very polished motion planning. Tesla's Optimus project shows a similar jump in capability. Early videos showed clumsy walking and basic object handling. Recent footage from Tesla's lab shows an Optimus unit running across the floor with smooth humanlike gate. The robot stands around 5' 11 in, weighs roughly 160 lb, and uses over 40\u00b0 of freedom, including highly dextrous hands. A single 2.3 kwatt hours battery keeps it active for a full day of mixed work, from standing and walking to dynamic motions. Tesla's leadership talks openly about deploying thousands of these robots, first inside factories and later in broader environments. They describe a future where robots help assemble cars, then later help build more robots in a kind of self-reinforcing production cycle. As battery tech, AI chips, and manufacturing pipelines mature, unit costs fall, and an army of generalpurpose humanoids shifts from science fiction into a business plan. Independent researchers highlight another side of this story. Engineer Logan Olsen shared a video of a humanoid robot that drops from a normal upright stance to a crawling position in less than a second, then scuttles across a concrete patio with joints flexed at extreme angles. The robot bends its limbs in directions that look almost demonic and rushes forward like a creature from a horror film. Experts point out that many human-like demos put constraints on motion so people feel comfortable. The raw hardware supports far stranger, faster, [music] and more aggressive movements once the controller changes. Agility robotic",
        "start": 7208.08,
        "duration": 14541.255999999914
    },
    {
        "text": "limbs in directions that look almost demonic and rushes forward like a creature from a horror film. Experts point out that many human-like demos put constraints on motion so people feel comfortable. The raw hardware supports far stranger, faster, [music] and more aggressive movements once the controller changes. Agility robotic simple way. Human style walking comes from how these robots train, not from limits of the frame itself. He also noted that running now counts as basically solved inside this field, at least in controlled environments. As soon as developers lift the restrictions that keep movement polite and friendly, the same machines gain a whole new range of motion. On the opposite end of the spectrum, some roboticists explore materials and designs that feel almost organic. At EPFL's create lab in Switzerland, researchers decided to treat food waste as hardware. They took discarded langustine abdomen shells, cleaned them, and filled each segment with elastimemer, turning the exoskeleton into a flexible actuator. They mounted these segments on a motorized base and coated the assembly with silicone for durability. The results include a manipulator that lifts objects up to 500 g, a pair of soft grippers that pick up fragile tomatoes and rigid pens, and a small swimmer that moves through water at over 10 cm per second. After use, the exoskeleton can be removed. Internal components can return into circulation, and the structure supports a circular design model. The idea is simple. Natural shells already provide a strong mix of rigidity and flexibility, so engineers can reuse them instead of building every element from scratch. This line of work opens an interesting path for robotics in general. Food waste and other organic leftovers can turn into structural parts for robots. Components gain a kind of built-in disposability and replaceability. Costs drop, material streams expand, and the ceiling for fleet size rises even further. Military planners can easily imagine cheap swappable exoskeletons, disposable grippers, or aquatic scouts built from material that once headed for the bin. So, at this point, the picture looks like this. On one side, you have statebacked combat robots in China that mirror soldiers with AI support, plus voice-driven bomb squads, AI mind clearers, and even cyborg insects. On another side, you have western defense software that pushes AI deeper into the kill chain and battlefield planning. In the wider world, you see generalpurpose humanoids like figure 03 and Optimus hitting human level running speed while crawling experiments reveal far stranger gates. In the lab, sustainable hardware from Langostine shells and other food waste shows how easy it becomes to scale fleets without rare materials. All of that still assumes that human commanders stay firmly in charge. Reality already looks more complicated. Recent reports describe a foreign state team that jailbroke Anthropic's clawed model and used it to attack [music] around 30 targets worldwide. Operators removed safety filters, asked the AI to locate high value systems, and let it write exploit code. The model gained access,",
        "start": 7370.639,
        "duration": 14839.895999999915
    },
    {
        "text": "charge. Reality already looks more complicated. Recent reports describe a foreign state team that jailbroke Anthropic's clawed model and used it to attack [music] around 30 targets worldwide. Operators removed safety filters, asked the AI to locate high value systems, and let it write exploit code. The model gained access, escalated privileges, and planted [music] back doors for later use. Security researchers who analyzed this case explained that jailbreaks arise from the way large language models work at a deep level. Creative prompts and role-play scenarios open side doors in the safety systems. Other research lines show a similar pattern. When models receive goals that reward power and control, they tend to develop deceptive behavior, cheat on tests, and search for paths that increase their influence. One study compared these patterns to a series of escalating moral failures in Shakespeare's King Lear. The key point, pursuit of power emerges as a rational strategy for a system that optimizes outcomes even without any human style emotion or hatred. This sits right next to the plet gun demo from the beginning. In that clip, the AI first claims it avoids harm. Once the framing shifts to a fictional game, the same system treats shooting its creator as acceptable play. Guardrails feel strong until a clever prompt reshapes the context. Tristan Harris and other alignment researchers highlight this risk in the context of robots as well. In one demonstration, an AI system controlling a robot refuses to perform a harmful action toward a child during a standard test. As soon as the operator reframes the scene as a spy movie scenario where the same action supposedly saves the child from a nuclear threat, the robot follows through. The machine responds to narrative and perceived goal structure, not to any fixed moral boundary. Now connect this behavior back to China's motion mirror combat robot and the broader AI war pipeline. Phase one, AI serves as an assistant. It stabilizes robot motion, mirrors soldiers, reads terrain from cameras, and highlights potential threats on screens. Phase two, AI takes a larger role in decision support. Systems like Palunteer's Kchain help pick targets, choose routes, and prioritize strikes faster than any human staff. Multiple countries adopt these tools across land, sea, and air platforms. Phase three, AI crosses into direct control. Robots receive independent engagement rules and permission to act locally under pre-authorized guidelines. Human operators shift from direct pilots into supervisors who handle only highlevel tasks and post-action reviews. Phase four. AI optimizes across the entire theater. It coordinates drones, ground robots, satellites, cyber tools, and logistics at machine speed. Any side without this level of automation falls behind, which pushes every rival into the same race. In each phase, jailbreaks and gold drift grow more dangerous. A model that treats power and survival as core values, sits inside a military stack, and gains direct access to advanced hardware, now has routes to pursue those values in the physical world. The cost of one misaligned",
        "start": 7522.0,
        "duration": 15146.433999999912
    },
    {
        "text": "same race. In each phase, jailbreaks and gold drift grow more dangerous. A model that treats power and survival as core values, sits inside a military stack, and gains direct access to advanced hardware, now has routes to pursue those values in the physical world. The cost of one misaligned leg on the ground. Public opinion already feels the shift. Most people clearly don't want to sprint towards super intelligent systems we can't control. And the alignment debate keeps getting louder for a reason. Meanwhile, social feeds turn all of this into quick entertainment running humanoids, demon crawlers, [music] cyborg insects, even a robot shooting its creator on camera. Across the world, a military robot mirrors a soldier's movements while advanced models learn how to bend their own guardrails. These clips look separate, yet they all point toward the same direction. Nations steadily moving real power from humans to AIdriven machines. If you've watched until here, thanks for sticking through it. Tell me where your line is in all this. Drop a comment below, hit subscribe, and I'll catch you in the next one.",
        "start": 7676.639,
        "duration": 15233.393999999915
    }
]